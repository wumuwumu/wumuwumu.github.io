[{"title":"SpringCloudGateway基本操作-WebFlux","date":"+020201-01-25T09:00:00.000Z","path":"posts/ac39e4c0.html","text":"Create a WebFlux HandlerIn the Spring Reactive approach, we use a handler to handle the request and create a response, as shown in the following example: //src/main/java/hello/GreetingHandler.java package hello; import org.springframework.http.MediaType; import org.springframework.stereotype.Component; import org.springframework.web.reactive.function.BodyInserters; import org.springframework.web.reactive.function.server.ServerRequest; import org.springframework.web.reactive.function.server.ServerResponse; import reactor.core.publisher.Mono; @Component public class GreetingHandler &#123; public Mono&lt;ServerResponse> hello(ServerRequest request) &#123; return ServerResponse.ok().contentType(MediaType.TEXT_PLAIN) .body(BodyInserters.fromValue(\"Hello, Spring!\")); &#125; &#125; This simple reactive class always returns “Hello, Spring!” It could return many other things, including a stream of items from a database, a stream of items that were generated by calculations, and so on. Note the reactive code: a Mono object that holds a ServerResponse body. Create a RouterIn this application, we use a router to handle the only route we expose (“/hello”), as shown in the following example: //src/main/java/hello/GreetingRouter.java package hello; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.http.MediaType; import org.springframework.web.reactive.function.server.RequestPredicates; import org.springframework.web.reactive.function.server.RouterFunction; import org.springframework.web.reactive.function.server.RouterFunctions; import org.springframework.web.reactive.function.server.ServerResponse; @Configuration public class GreetingRouter &#123; @Bean public RouterFunction&lt;ServerResponse> route(GreetingHandler greetingHandler) &#123; return RouterFunctions .route(RequestPredicates.GET(\"/hello\").and(RequestPredicates.accept(MediaType.TEXT_PLAIN)), greetingHandler::hello); &#125; &#125; The router listens for traffic on the /hello path and returns the value provided by our reactive handler class.","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"},{"name":"SpringCloudGateway","slug":"SpringCloudGateway","permalink":"http://wumuwumu.github.io/tags/SpringCloudGateway/"}]},{"title":"ZooKeeper1-安装","date":"2021-03-05T06:00:00.000Z","path":"posts/eb173626.html","text":"单机下载https:&#x2F;&#x2F;zookeeper.apache.org&#x2F;releases.html 修改配置文件初次使用 ZooKeeper 时, 需要将 $ZOOKEEPER_HOME/conf 目录下的 zoo_sample.cfg 重命名为 zoo.cfg, zoo.cfg 默认配置如下: # The number of milliseconds of each ticktickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/tmp/zookeeper # the port at which the clients will connect clientPort=2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 # # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance # # The number of snapshots to retain in dataDir #autopurge.snapRetainCount=3 # Purge task interval in hours # Set to \"0\" to disable auto purge feature #autopurge.purgeInterval=1 配置项说明如下: tickTime: ZooKeeper 中使用的基本时间单元, 以毫秒为单位, 默认值是 2000。它用来调节心跳和超时。例如, 默认的会话超时时间是两倍的 tickTime。 initLimit: 默认值是 10, 即 tickTime 属性值的 10 倍。它用于配置允许 followers 连接并同步到 leader 的最大时间。如果 ZooKeeper 管理的数据量很大的话可以增加这个值。 syncLimit: 默认值是 5, 即 tickTime 属性值的 5 倍。它用于配置leader 和 followers 间进行心跳检测的最大延迟时间。如果在设置的时间内 followers 无法与 leader 进行通信, 那么 followers 将会被丢弃。 dataDir: ZooKeeper 用来存储内存数据库快照的目录, 并且除非指定其它目录, 否则数据库更新的事务日志也将会存储在该目录下。建议配置 dataLogDir 参数来指定 ZooKeeper 事务日志的存储目录。 clientPort: 服务器监听客户端连接的端口, 也即客户端尝试连接的端口, 默认值是 2181。 maxClientCnxns: 在 socket 级别限制单个客户端与单台服务器之前的并发连接数量, 可以通过 IP 地址来区分不同的客户端。它用来防止某种类型的 DoS 攻击, 包括文件描述符耗尽。默认值是 60。将其设置为 0 将完全移除并发连接数的限制。 autopurge.snapRetainCount: 配置 ZooKeeper 在自动清理的时候需要保留的数据文件快照的数量和对应的事务日志文件, 默认值是 3。 autopurge.purgeInterval: 和参数 autopurge.snapRetainCount 配套使用, 用于配置 ZooKeeper 自动清理文件的频率, 默认值是 1, 即默认开启自动清理功能, 设置为 0 则表示禁用自动清理功能。 更多 ZooKeeper 配置后面会写文章详细描述。 单机模式 zoo.cfg配置 ticketTime=2000 clientPort=2181 dataDir=/opt/zookeeper/data dataLogDir=/opt/zookeeper/logs 启动 ZooKeeper 服务 可以使用如下命令来启动 ZooKeeper 服务 zkServer.sh start 服务启动信息如下: 验证 ZooKeeper 服务 服务启动完成后, 可以使用 telnet 和 stat 命令验证服务器启动是否正常: 在单机模式中, Mode 的值是 “standalone”。 停止 ZooKeeper 服务 想要停止 ZooKeeper 服务, 可以使用如下命令: zkServer.sh stop 服务停止信息如下: 集群模式 zoo.cfg配置 在 master 机器上, 在单机模式的配置文件下增加了最后 5 行配置: ticketTime=2000 clientPort=2181 dataDir=/opt/zookeeper/data dataLogDir=/opt/zookeeper/logs initLimit=10 syncLimit=5 server.1=master:2888:3888 server.2=slave01:2888:3888 server.3=slave02:2888:3888 相关配置说明: 集群模式中, 集群中的每台机器都需要感知其它机器, 在 zoo.cfg 配置文件中, 可以按照如下格式进行配置, 每一行代表一台服务器配置: server.id&#x3D;host:port:port id 被称为 Server ID, 用来标识服务器在集群中的序号。同时每台 ZooKeeper 服务器上, 都需要在数据目录(即 dataDir 指定的目录) 下创建一个 myid 文件, 该文件只有一行内容, 即对应于每台服务器的Server ID。 ZooKeeper 集群中, 每台服务器上的 zoo.cfg 配置文件内容一致。 server.1 的 myid 文件内容就是 “1”。每个服务器的 myid 内容都不同, 且需要保证和自己的 zoo.cfg 配置文件中 “server.id=host:port:port” 的 id 值一致。 id 的范围是 1 ~ 255。 创建myid文件 在 dataDir 指定的目录下 (即 /opt/zookeeper/data 目录) 创建名为 myid 的文件, 文件内容和 zoo.cfg 中当前机器的 id 一致。根据上述配置, master 的 myid 文件内容为 1。 slave配置 按照相同步骤, 为 slave01 和 slave02 配置 zoo.cfg 和 myid 文件。zoo.cfg文件内容相同, slave01 的 myid 文件内容为 2, slave02 的 myid 文件内容为 3。 集群启动 在集群中的每台机器上执行以下启动命令: zkServer.sh start 启动信息如下: master 和 slave01 两台服务器的 Mode 值均为 follower, 表明它们在集群中的角色为 Follower。 slave02 服务器的 Mode 值为 leader, 表明它在集群中的角色为 Leader。 参考 https://www.jianshu.com/p/de90172ea680","tags":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"http://wumuwumu.github.io/tags/ZooKeeper/"}]},{"title":"VuePress搭建文档网站","date":"2021-02-27T06:00:00.000Z","path":"posts/0.html","text":"工程构建mkdir stong-user-manual &amp;&amp; cd stong-user-manual yarn init yarn add -D vuepress ## 按照常用插件 yarn add -D vuepress-bar boboidream/vuepress-plugin-rpurl vuepress-plugin-permalink-pinyin mkdir content 配置package.json&#123; \"scripts\": &#123; \"dev\": \"vuepress dev content\", \"build\": \"vuepress build content\" &#125; &#125; 创建工程结构 插件配置const getConfig = require(\"vuepress-bar\"); const &#123; nav, sidebar &#125; = getConfig(); module.exports =&#123; plugins: [\"permalink-pinyin\", \"rpurl\"], title: \"title\", description: \"description\", themeConfig: &#123; logo: \"/assets/img/logo.png\", nav: [&#123; text: \"官网\", link: \"http://www.sciento.cn/\" &#125;, ...nav], sidebar, &#125;, &#125;;","tags":[{"name":"公司","slug":"公司","permalink":"http://wumuwumu.github.io/tags/%E5%85%AC%E5%8F%B8/"}]},{"title":"SpringCloudSentinel学习2-Nacos储存规则","date":"2021-02-19T06:00:00.000Z","path":"posts/88fae02d.html","text":"要通过 Sentinel 控制台配置集群流控规则，需要对控制台进行改造。主要改造规则可以参考： https://github.com/alibaba/Sentinel/wiki/Sentinel-控制台（集群流控管理）#规则配置 其控制台推送规则： 将规则推送到Nacos或其他远程配置中心 Sentinel客户端链接Nacos，获取规则配置；并监听Nacos配置变化，如发生变化，就更新本地缓存。 控制台监听Nacos配置变化，如发生变化就更新本地缓存。从而让控制台本地缓存总是和Nacos一致。 改造Sentinel下载Sentinel 源代码，然后对sentinel-dashboard模块进行改造 https://github.com/alibaba/Sentinel/archive/1.7.2.zip 对pom.xml进行修改 &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-datasource-nacos&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> 将**test**注释掉 &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-datasource-nacos&lt;/artifactId> &lt;/dependency> 修改java代码 找到如下目录（位于test目录） sentinel-dashboard/src/test/java/com/alibaba/csp/sentinel/dashboard/rule/nacos 将整个目录拷贝到 sentinel-dashboard/src/main/java/com/alibaba/csp/sentinel/dashboard/rule/nacos 修改com.alibaba.csp.sentinel.dashboard.controller.v2.FlowControllerV2.java 修改成 修改HTML页面 修改配置文件 NacosConfig.java @Bean public ConfigService nacosConfigService() throws Exception &#123; Properties properties= new Properties(); if(DashboardConfig.getConfigNacosServerUrl() != null)&#123; properties.put(PropertyKeyConst.SERVER_ADDR, DashboardConfig.getConfigNacosServerUrl()); &#125;else &#123; properties.put(PropertyKeyConst.SERVER_ADDR,\"localhost:8848\"); &#125; if(DashboardConfig.getConfigNacosServerNamespace() != null)&#123; properties.put(PropertyKeyConst.NAMESPACE,DashboardConfig.getConfigNacosServerNamespace()); &#125; if(DashboardConfig.getConfigNacosUsername() != null)&#123; properties.put(PropertyKeyConst.USERNAME,DashboardConfig.getConfigNacosUsername()); &#125; if(DashboardConfig.getConfigNacosPassword() != null)&#123; properties.put(PropertyKeyConst.PASSWORD,DashboardConfig.getConfigNacosPassword()); &#125; return ConfigFactory.createConfigService(properties); &#125; DashBoardConfig.java public class DashboardConfig &#123; public static final int DEFAULT_MACHINE_HEALTHY_TIMEOUT_MS = 60_000; /** * Login username */ public static final String CONFIG_AUTH_USERNAME = \"sentinel.dashboard.auth.username\"; /** * Login password */ public static final String CONFIG_AUTH_PASSWORD = \"sentinel.dashboard.auth.password\"; /** * Hide application name in sidebar when it has no healthy machines after specific period in millisecond. */ public static final String CONFIG_HIDE_APP_NO_MACHINE_MILLIS = \"sentinel.dashboard.app.hideAppNoMachineMillis\"; /** * Remove application when it has no healthy machines after specific period in millisecond. */ public static final String CONFIG_REMOVE_APP_NO_MACHINE_MILLIS = \"sentinel.dashboard.removeAppNoMachineMillis\"; /** * Timeout */ public static final String CONFIG_UNHEALTHY_MACHINE_MILLIS = \"sentinel.dashboard.unhealthyMachineMillis\"; /** * Auto remove unhealthy machine after specific period in millisecond. */ public static final String CONFIG_AUTO_REMOVE_MACHINE_MILLIS = \"sentinel.dashboard.autoRemoveMachineMillis\"; public static final String CONFIG_NACOS_SERVER_URL = \"sentinel.dashboard.nacos.server\"; public static final String CONFIG_NACOS_SERVER_NAMESPACE = \"sentinel.dashboard.nacos.namespace\"; public static final String CONFIG_NACOS_USERNAME = \"sentinel.dashboard.nacos.username\"; public static final String CONFIG_NACOS_PASSWORD = \"sentinel.dashboard.nacos.password\"; private static final ConcurrentMap&lt;String, Object> cacheMap = new ConcurrentHashMap&lt;>(); @NonNull private static String getConfig(String name) &#123; // env String val = System.getenv(name); if (StringUtils.isNotEmpty(val)) &#123; return val; &#125; // properties val = System.getProperty(name); if (StringUtils.isNotEmpty(val)) &#123; return val; &#125; return \"\"; &#125; protected static String getConfigStr(String name) &#123; if (cacheMap.containsKey(name)) &#123; return (String) cacheMap.get(name); &#125; String val = getConfig(name); if (StringUtils.isBlank(val)) &#123; return null; &#125; cacheMap.put(name, val); return val; &#125; protected static int getConfigInt(String name, int defaultVal, int minVal) &#123; if (cacheMap.containsKey(name)) &#123; return (int)cacheMap.get(name); &#125; int val = NumberUtils.toInt(getConfig(name)); if (val == 0) &#123; val = defaultVal; &#125; else if (val &lt; minVal) &#123; val = minVal; &#125; cacheMap.put(name, val); return val; &#125; public static String getAuthUsername() &#123; return getConfigStr(CONFIG_AUTH_USERNAME); &#125; public static String getAuthPassword() &#123; return getConfigStr(CONFIG_AUTH_PASSWORD); &#125; public static int getHideAppNoMachineMillis() &#123; return getConfigInt(CONFIG_HIDE_APP_NO_MACHINE_MILLIS, 0, 60000); &#125; public static int getRemoveAppNoMachineMillis() &#123; return getConfigInt(CONFIG_REMOVE_APP_NO_MACHINE_MILLIS, 0, 120000); &#125; public static int getAutoRemoveMachineMillis() &#123; return getConfigInt(CONFIG_AUTO_REMOVE_MACHINE_MILLIS, 0, 300000); &#125; public static int getUnhealthyMachineMillis() &#123; return getConfigInt(CONFIG_UNHEALTHY_MACHINE_MILLIS, DEFAULT_MACHINE_HEALTHY_TIMEOUT_MS, 30000); &#125; public static void clearCache() &#123; cacheMap.clear(); &#125; public static String getConfigNacosServerUrl() &#123; return getConfigStr(CONFIG_NACOS_SERVER_URL); &#125; public static String getConfigNacosServerNamespace() &#123; return getConfigStr(CONFIG_NACOS_SERVER_NAMESPACE); &#125; public static String getConfigNacosUsername() &#123; return getConfigStr(CONFIG_NACOS_USERNAME); &#125; public static String getConfigNacosPassword() &#123; return getConfigStr(CONFIG_NACOS_PASSWORD); &#125; &#125; sidebar.html页面 sentinel-dashboard/src/main/webapp/resources/app/scripts/directives/sidebar.html并找到如下代码段后，并把注释放开 经过以上步骤就已经把流控规则改造成推模式持久化了。 修改请求接口 src/main/webapp/resources/app/scripts/controllers/identity.js 0x02：编译生成jar包 执行命令 mvn clean package -DskipTests 编译成功后，在项目的 target 目录可以找到sentinel-dashboard.jar ，执行以下命令可以启动控制台： java -jar sentinel-dashboard.jar 0x03：改造微服务 新建项目olive-nacos-sentinel-datasource 对应的pom.xml文件引入 &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.sentinel&lt;/groupId> &lt;artifactId>olive-nacos-sentinel-datasource&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;packaging>jar&lt;/packaging> &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.1.3.RELEASE&lt;/version> &lt;relativePath/> &lt;!-- lookup parent from repository --> &lt;/parent> &lt;name>olive-nacos-sentinel-datasource&lt;/name> &lt;url>http://maven.apache.org&lt;/url> &lt;properties> &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding> &lt;java.version>1.8&lt;/java.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-sentinel&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-datasource-nacos&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>Greenwich.SR3&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-alibaba-dependencies&lt;/artifactId> &lt;version>2.1.0.RELEASE &lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;/project> 新建SpringBoot启动类 package com.olive; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * Hello world! * */ @SpringBootApplication public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; &#125; 创建控制器 package com.olive.controller; import java.util.HashMap; import java.util.Map; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class UserController &#123; @GetMapping(\"/getUser\") public Map&lt;String, Object> getUser() &#123; Map&lt;String, Object> result = new HashMap&lt;>(); result.put(\"code\", \"000000\"); result.put(\"message\", \"ok\"); return result; &#125; &#125; 修改配置文件application.yml spring: application: name: olive-nacos-sentinel-datasource cloud: sentinel: transport: dashboard: localhost:8080 datasource: # 名称随意 flow: nacos: server-addr: localhost:8848 dataId: $&#123;spring.application.name&#125;-flow-rules groupId: SENTINEL_GROUP # 规则类型，取值见： # org.springframework.cloud.alibaba.sentinel.datasource.RuleType rule-type: flow server: port: 8866 0x04：验证 主要验证场景 场景1：用Sentinel控制台【菜单栏的 流控规则 V1 】推送流控规则，规则会存储到Nacos； 场景2：直接在Nacos上修改流控规则，然后刷新Sentinel控制台，控制台上的显示也会被修改； 场景3：重启Sentinel控制台，并重启微服务；刷新控制台，可以发现规则依然存在。 启动服务 Sentinel控制台 Nacos olive-nacos-sentinel-datasource Nacos中创建限流规则的配置 http://127.0.0.1:8848/nacos/#/login [ &#123; \"resource\": \"/getUser\", \"limitApp\": \"default\", \"grade\": 1, \"count\": 5, \"strategy\": 0, \"controlBehavior\": 0, \"clusterMode\": false &#125; ] 如下图 访问接口（olive-nacos-sentinel-datasource服务提供的接口） ​ http://localhost:8866/getUser 访问Sentinel控制台 ​ http://127.0.0.1:8080/#/login 以上这条记录就是在Nacos中配置的限流规则。可以测试在Sentinel控制台修改规则是否同步到Nacos，或者在Nacos上修改规则是否同步到Sentinel控制台。 参考 https://cloud.tencent.com/developer/article/1665816 https://blog.csdn.net/EnjoyEDU/article/details/109587953 配置sentinel持久化nacos https://bytetrick.com/archives/sentinel-dashboard%E6%8C%81%E4%B9%85%E5%8C%96nacos https://blog.csdn.net/u014386444/article/details/112064291 https://www.cnblogs.com/jian0110/p/14139044.html","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"}]},{"title":"SpringCloudSentinel学习1-安装","date":"2021-02-19T04:00:00.000Z","path":"posts/4bd69169.html","text":"手动安装获取 Sentinel 控制台您可以从 release 页面 下载最新版本的控制台 jar 包。 您也可以从最新版本的源码自行构建 Sentinel 控制台： 下载 控制台 工程 使用以下命令将代码打包成一个 fat jar: mvn clean package 启动 注意：启动 Sentinel 控制台需要 JDK 版本为 1.8 及以上版本。 使用如下命令启动控制台： java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar 其中 -Dserver.port=8080 用于指定 Sentinel 控制台端口为 8080。 从 Sentinel 1.6.0 起，Sentinel 控制台引入基本的登录功能，默认用户名和密码都是 sentinel。可以参考 鉴权模块文档 配置用户名和密码。 注：若您的应用为 Spring Boot 或 Spring Cloud 应用，您可以通过 Spring 配置文件来指定配置，详情请参考 Spring Cloud Alibaba Sentinel 文档。 Docker安装 Clone project git clone https:&#x2F;&#x2F;github.com&#x2F;zhoutaoo&#x2F;sentinel-dashboard-docker.git Build Image cd build docker build -t cike&#x2F;sentinel-dashboard-docker . Run With docker docker run -p 8021:8021 -it cike&#x2F;sentinel-dashboard-docker Run With docker-compose docker-compose up Open the Sentinel Dashboard console in your browser link：http://127.0.0.1:8021/","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"}]},{"title":"SpringCloudFeign学习2-自定义负载均衡规则","date":"2021-02-19T03:00:00.000Z","path":"posts/287249d4.html","text":"实战public class GrayMetadataRule extends AbstractLoadBalancerRule &#123; Logger logger = LoggerFactory.getLogger(getClass()); @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; @Autowired private NacosServiceManager nacosServiceManager; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) &#123; &#125; @Override public Server choose(Object key) &#123; String clusterName = this.nacosDiscoveryProperties.getClusterName(); String group = this.nacosDiscoveryProperties.getGroup(); DynamicServerListLoadBalancer loadBalancer = (DynamicServerListLoadBalancer)this.getLoadBalancer(); String name = loadBalancer.getName(); NamingService namingService = this.nacosServiceManager.getNamingService(this.nacosDiscoveryProperties.getNacosProperties()); List&lt;Instance> instances = null; try &#123; instances = namingService.selectInstances(name, group, true); &#125; catch (NacosException e) &#123; e.printStackTrace(); &#125; if(instances == null || instances.size() == 0)&#123; logger.warn(\"没有相关服务 &#123;&#125;\",name); return null; &#125; System.out.println(\"找到相关服务\"); return new NacosServer(instances.get(0)); &#125; &#125; 参考 https://www.cnblogs.com/ITPower/p/13353248.html https://blog.csdn.net/forezp/article/details/74820899 https://blog.didispace.com/springcloud-sourcecode-ribbon/ https://www.cnblogs.com/rickiyang/p/11802465.html","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"}]},{"title":"Feign添加认证请求头","date":"2021-02-02T08:00:00.000Z","path":"posts/6a05c2e6.html","text":"import feign.RequestInterceptor; import feign.RequestTemplate; import lombok.extern.slf4j.Slf4j; import org.springframework.security.core.Authentication; import org.springframework.security.core.context.SecurityContext; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationDetails; import org.springframework.context.annotation.Configuration; @Configuration public class FeignOauth2RequestInterceptor implements RequestInterceptor &#123; private final String AUTHORIZATION_HEADER = \"Authorization\"; private final String BEARER_TOKEN_TYPE = \"Bearer\"; @Override public void apply(RequestTemplate requestTemplate) &#123; SecurityContext securityContext = SecurityContextHolder.getContext(); Authentication authentication = securityContext.getAuthentication(); if (authentication != null &amp;&amp; authentication.getDetails() instanceof OAuth2AuthenticationDetails) &#123; OAuth2AuthenticationDetails details = (OAuth2AuthenticationDetails) authentication.getDetails(); requestTemplate.header(AUTHORIZATION_HEADER, String.format(\"%s %s\", BEARER_TOKEN_TYPE, details.getTokenValue())); &#125; &#125; &#125;","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"}]},{"title":"SpringSecurity3-Oauth2自定义返回","date":"2021-02-02T06:00:00.000Z","path":"posts/2af70476.html","text":"token返回扩展参数 public class CusTokenConverter implements TokenEnhancer &#123; @Override public OAuth2AccessToken enhance(OAuth2AccessToken accessToken, OAuth2Authentication authentication) &#123; Map&lt;String, Object> additionalInformation = new LinkedHashMap&lt;>(); Map&lt;String, Object> info = new LinkedHashMap&lt;>(); info.put(\"author\", \"wumu\"); info.put(\"user\", SecurityContextHolder.getContext().getAuthentication().getPrincipal()); additionalInformation.put(\"info\", info); ((DefaultOAuth2AccessToken) accessToken).setAdditionalInformation(additionalInformation); return accessToken; &#125; &#125; 重新格式化返回结果 @RestController @RequestMapping(\"/oauth\") public class OauthController &#123; @Autowired private TokenEndpoint tokenEndpoint; @GetMapping(\"/token\") public Map&lt;String,Object> getAccessToken(Principal principal, @RequestParam Map&lt;String, String> parameters) throws HttpRequestMethodNotSupportedException &#123; return custom(tokenEndpoint.getAccessToken(principal, parameters).getBody()); &#125; @PostMapping(\"/token\") public Map&lt;String,Object> postAccessToken(Principal principal, @RequestParam Map&lt;String, String> parameters) throws HttpRequestMethodNotSupportedException, HttpRequestMethodNotSupportedException &#123; return custom(tokenEndpoint.postAccessToken(principal, parameters).getBody()); &#125; //自定义返回格式 private Map&lt;String,Object> custom(OAuth2AccessToken accessToken) &#123; DefaultOAuth2AccessToken token = (DefaultOAuth2AccessToken) accessToken; Map&lt;String, Object> data = new LinkedHashMap(token.getAdditionalInformation()); data.put(\"accessToken\", token.getValue()); if (token.getRefreshToken() != null) &#123; data.put(\"refreshToken\", token.getRefreshToken().getValue()); &#125; return data; &#125; &#125; 认证错误 @ControllerAdvice public class ExceptionConfig &#123; @ResponseBody @ExceptionHandler(value = OAuth2Exception.class) public Map&lt;String,Object> handleOauth2(OAuth2Exception e) &#123; Map map = new HashMap&lt;String,Object>(); map.put(\"code\",0); map.put(\"message\",e.getMessage()); return map; &#125; &#125; 参考 https://blog.csdn.net/u012702547/article/details/105804972 https://juejin.cn/post/6857296054392471559 https://blog.csdn.net/u013905744/article/details/100637224","tags":[]},{"title":"SpringSecurity-利用jwt生成token","date":"2021-01-31T12:00:00.000Z","path":"posts/46051755.html","text":"开篇实现Token的方式有很多，本篇介绍的是利用Json Web Token(JWT)生成的Token.JWT生成的Token有什么好处呢？ 安全性比较高，加上密匙加密而且支持多种算法。 携带的信息是自定义的，而且可以做到验证token是否过期。 验证信息可以由前端保存，后端不需要为保存token消耗内存。 本篇分3部分进行讲解。 什么是JWT JWT的代码实现 用HS256 对称算法加密 用RS256 非对称算法加密 总结 如果原理很难懂，没关系。可以直接看JWT的代码实现。代码已经上传github。已经对代码进行封装成工具类。可以直接使用。 什么是JWTJSON Web Token 简称JWT。 一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名。 JWT生成的token是这样的 eyJpc3MiOiJKb2huI.eyJpc3MiOiJ.Kb2huIFd1IEp 生成的token，是3段，用.连接。下面有解释。 头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以被表示成一个JSON对象。 例如： &#123; \"typ\": \"JWT\", \"alg\": \"HS256\" &#125; 载荷其实就是自定义的数据，一般存储用户Id，过期时间等信息。也就是JWT的核心所在，因为这些数据就是使后端知道此token是哪个用户已经登录的凭证。而且这些数据是存在token里面的，由前端携带，所以后端几乎不需要保存任何数据。 例如： &#123; \"uid\": \"xxxxidid\", //用户id \"exp\": \"12121212\" //过期时间 &#125; 签名签名其实就是： 1.头部和载荷各自base64加密后用.连接起来，然后就形成了xxx.xx的前两段token。 2.最后一段token的形成是，前两段加入一个密匙用HS256算法或者其他算法加密形成。 所以token3段的形成就是在签名处形成的。 JWT的原理参考文章 代码实现1.看代码前一定要知道JWT是由头部、载荷与签名组成。 2.代码已上传github,希望点个赞 代码将JWT封装成两个工具类，可以直接调用。 需要下载的jar包&lt;dependency> &lt;groupId>com.nimbusds&lt;/groupId> &lt;artifactId>nimbus-jose-jwt&lt;/artifactId> &lt;version>6.0&lt;/version> &lt;/dependency> HS256 对称加密生成token/** * 创建秘钥 */ private static final byte[] SECRET = \"6MNSobBRCHGIO0fS6MNSobBRCHGIO0fS\".getBytes(); /** * 过期时间5秒 */ private static final long EXPIRE_TIME = 1000 * 5; /** * 生成Token * @param account * @return */ public static String buildJWT(String account) &#123; try &#123; /** * 1.创建一个32-byte的密匙 */ MACSigner macSigner = new MACSigner(SECRET); /** * 2. 建立payload 载体 */ JWTClaimsSet claimsSet = new JWTClaimsSet.Builder() .subject(\"doi\") .issuer(\"http://www.doiduoyi.com\") .expirationTime(new Date(System.currentTimeMillis() + EXPIRE_TIME)) .claim(\"ACCOUNT\",account) .build(); /** * 3. 建立签名 */ SignedJWT signedJWT = new SignedJWT(new JWSHeader(JWSAlgorithm.HS256), claimsSet); signedJWT.sign(macSigner); /** * 4. 生成token */ String token = signedJWT.serialize(); return token; &#125; catch (KeyLengthException e) &#123; e.printStackTrace(); &#125; catch (JOSEException e) &#123; e.printStackTrace(); &#125; return null; &#125; 验证token/** * 校验token * @param token * @return */ public static String vaildToken(String token ) &#123; try &#123; SignedJWT jwt = SignedJWT.parse(token); JWSVerifier verifier = new MACVerifier(SECRET); //校验是否有效 if (!jwt.verify(verifier)) &#123; throw ResultException.of(-1, \"Token 无效\"); &#125; //校验超时 Date expirationTime = jwt.getJWTClaimsSet().getExpirationTime(); if (new Date().after(expirationTime)) &#123; throw ResultException.of(-2, \"Token 已过期\"); &#125; //获取载体中的数据 Object account = jwt.getJWTClaimsSet().getClaim(\"ACCOUNT\"); //是否有openUid if (Objects.isNull(account))&#123; throw ResultException.of(-3, \"账号为空\"); &#125; return account.toString(); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; catch (JOSEException e) &#123; e.printStackTrace(); &#125; return null; &#125; 调用的业务逻辑 public class TestHS256 &#123; public static void main(String[] args) throws InterruptedException &#123; TestHS256 t = new TestHS256(); t.testHS256(); &#125; //测试HS256加密生成Token public void testHS256() throws InterruptedException &#123; String token = JWTHS256.buildJWT(\"account123\"); //解密token String account = JWTHS256.vaildToken(token); System.out.println(\"校验token成功，token的账号：\"+account); //测试过期 Thread.sleep(10 * 1000); account = JWTHS256.vaildToken(token); System.out.println(account); &#125; &#125; 结果校验token成功，token的账号：account123 测试token过期------ Exception in thread \"main\" token.ResultException: Token 已过期 at token.ResultException.of(ResultException.java:59) at token.jwt.JWTHS256.vaildToken(JWTHS256.java:89) at token.jwt.TestHS256.testHS256(TestHS256.java:24) at token.jwt.TestHS256.main(TestHS256.java:11) RS256 非对称加密生成加密密钥/** * 创建加密key */ public static RSAKey getKey() throws JOSEException &#123; RSAKeyGenerator rsaKeyGenerator = new RSAKeyGenerator(2048); RSAKey rsaJWK = rsaKeyGenerator.generate(); return rsaJWK; &#125; 生成token/** * 过期时间5秒 */ private static final long EXPIRE_TIME = 1000 * 5; private static RSAKey rsaKey; private static RSAKey publicRsaKey; static &#123; /** * 生成公钥，公钥是提供出去，让使用者校验token的签名 */ try &#123; rsaKey = new RSAKeyGenerator(2048).generate(); publicRsaKey = rsaKey.toPublicJWK(); &#125; catch (JOSEException e) &#123; e.printStackTrace(); &#125; &#125; public static String buildToken(String account) &#123; try &#123; /** * 1. 生成秘钥,秘钥是token的签名方持有，不可对外泄漏 */ RSASSASigner rsassaSigner = new RSASSASigner(rsaKey); /** * 2. 建立payload 载体 */ JWTClaimsSet claimsSet = new JWTClaimsSet.Builder() .subject(\"doi\") .issuer(\"http://www.doiduoyi.com\") .expirationTime(new Date(System.currentTimeMillis() + EXPIRE_TIME)) .claim(\"ACCOUNT\",account) .build(); /** * 3. 建立签名 */ SignedJWT signedJWT = new SignedJWT(new JWSHeader(JWSAlgorithm.RS256), claimsSet); signedJWT.sign(rsassaSigner); /** * 4. 生成token */ String token = signedJWT.serialize(); return token; &#125; catch (JOSEException e) &#123; e.printStackTrace(); &#125; return null; &#125; 验证tokenpublic static String volidToken(String token) &#123; try &#123; SignedJWT jwt = SignedJWT.parse(token); //添加私密钥匙 进行解密 RSASSAVerifier rsassaVerifier = new RSASSAVerifier(publicRsaKey); //校验是否有效 if (!jwt.verify(rsassaVerifier)) &#123; throw ResultException.of(-1, \"Token 无效\"); &#125; //校验超时 if (new Date().after(jwt.getJWTClaimsSet().getExpirationTime())) &#123; throw ResultException.of(-2, \"Token 已过期\"); &#125; //获取载体中的数据 Object account = jwt.getJWTClaimsSet().getClaim(\"ACCOUNT\"); //是否有openUid if (Objects.isNull(account))&#123; throw ResultException.of(-3, \"账号为空\"); &#125; return account.toString(); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; catch (JOSEException e) &#123; e.printStackTrace(); &#125; return \"\"; &#125; 业务逻辑调用public class TestRS256 &#123; public static void main(String[] args) throws InterruptedException &#123; TestRS256 t = new TestRS256(); t.testRS256(); &#125; //测试RS256加密生成Token public void testRS256() throws InterruptedException &#123; String token = JWTRSA256.buildToken(\"account123\"); //解密token String account = JWTRSA256.volidToken(token); System.out.println(\"校验token成功，token的账号：\"+account); //测试过期 Thread.sleep(10 * 1000); account = JWTRSA256.volidToken(token); System.out.println(account); &#125; &#125; 结果校验token成功，token的账号：account123 测试token过期------ Exception in thread \"main\" token.ResultException: Token 已过期 at token.ResultException.of(ResultException.java:59) at token.jwt.JWTRSA256.volidToken(JWTRSA256.java:96) at token.jwt.TestRS256.testRS256(TestRS256.java:24) at token.jwt.TestRS256.main(TestRS256.java:11) 总结JWT 的实践其实还是挺简单。安全性也是得到了保证，后端只需要保存着密匙，其他数据可以保存在token，由前端携带，这样可以减低后端的内存消耗。 虽然token是加密的，但是携带的验证数据还是不要是敏感数据.","tags":[]},{"title":"redis持久化","date":"2021-01-29T04:00:00.000Z","path":"posts/dcfaa904.html","text":"Redis有两种持久化的方式：快照（RDB文件）和追加式文件（AOF文件）： RDB持久化方式会在一个特定的间隔保存那个时间点的一个数据快照。 AOF持久化方式则会记录每一个服务器收到的写操作。在服务启动时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟Redis协议一致，以追加的方式进行保存。 Redis的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。 两种方式的持久化是可以同时存在的，但是当Redis重启时，AOF文件会被优先用于重建数据。 RDB工作原理 Redis调用fork()，产生一个子进程。 子进程把数据写到一个临时的RDB文件。 当子进程写完新的RDB文件后，把旧的RDB文件替换掉。 优点 RDB文件是一个很简洁的单文件，它保存了某个时间点的Redis数据，很适合用于做备份。你可以设定一个时间点对RDB文件进行归档，这样就能在需要的时候很轻易的把数据恢复到不同的版本。 基于上面所描述的特性，RDB很适合用于灾备。单文件很方便就能传输到远程的服务器上。 RDB的性能很好，需要进行持久化时，主进程会fork一个子进程出来，然后把持久化的工作交给子进程，自己不会有相关的I/O操作。 比起AOF，在数据量比较大的情况下，RDB的启动速度更快。 缺点 RDB容易造成数据的丢失。假设每5分钟保存一次快照，如果Redis因为某些原因不能正常工作，那么从上次产生快照到Redis出现问题这段时间的数据就会丢失了。 RDB使用fork()产生子进程进行数据的持久化，如果数据比较大的话可能就会花费点时间，造成Redis停止服务几毫秒。如果数据量很大且CPU性能不是很好的时候，停止服务的时间甚至会到1秒。 文件路径和名称默认Redis会把快照文件存储为当前目录下一个名为dump.rdb的文件。要修改文件的存储路径和名称，可以通过修改配置文件redis.conf实现： # RDB文件名，默认为dump.rdb。 dbfilename dump.rdb # 文件存放的目录，AOF文件同样存放在此目录下。默认为当前工作目录。 dir .&#x2F; 保存点（RDB的启用和禁用）你可以配置保存点，使Redis如果在每N秒后数据发生了M次改变就保存快照文件。例如下面这个保存点配置表示每60秒，如果数据发生了1000次以上的变动，Redis就会自动保存快照文件： save 60 1000 保存点可以设置多个，Redis的配置文件就默认设置了3个保存点： # 格式为：save &lt;seconds&gt; &lt;changes&gt; # 可以设置多个。 save 900 1 #900秒后至少1个key有变动 save 300 10 #300秒后至少10个key有变动 save 60 10000 #60秒后至少10000个key有变动 如果想禁用快照保存的功能，可以通过注释掉所有”save”配置达到，或者在最后一条”save”配置后添加如下的配置： save &quot;&quot; 错误处理默认情况下，如果Redis在后台生成快照的时候失败，那么就会停止接收数据，目的是让用户能知道数据没有持久化成功。但是如果你有其他的方式可以监控到Redis及其持久化的状态，那么可以把这个功能禁止掉。 stop-writes-on-bgsave-error yes 数据压缩默认Redis会采用LZF对数据进行压缩。如果你想节省点CPU的性能，你可以把压缩功能禁用掉，但是数据集就会比没压缩的时候要打。 rdbcompression yes 数据校验从版本5的RDB的开始，一个CRC64的校验码会放在文件的末尾。这样更能保证文件的完整性，但是在保存或者加载文件时会损失一定的性能（大概10%）。如果想追求更高的性能，可以把它禁用掉，这样文件在写入校验码时会用0替代，加载的时候看到0就会直接跳过校验。 rdbchecksum yes 手动生成快照Redis提供了两个命令用于手动生成快照。 SAVESAVE命令会使用同步的方式生成RDB快照文件，这意味着在这个过程中会阻塞所有其他客户端的请求。因此不建议在生产环境使用这个命令，除非因为某种原因需要去阻止Redis使用子进程进行后台生成快照（例如调用fork(2)出错）。 BGSAVEBGSAVE命令使用后台的方式保存RDB文件，调用此命令后，会立刻返回OK返回码。Redis会产生一个子进程进行处理并立刻恢复对客户端的服务。在客户端我们可以使用LASTSAVE命令查看操作是否成功。 127.0.0.1:6379&gt; BGSAVE Background saving started 127.0.0.1:6379&gt; LASTSAVE (integer) 1433936394 配置文件里禁用了快照生成功能不影响SAVE和BGSAVE命令的效果。 AOF快照并不是很可靠。如果你的电脑突然宕机了，或者电源断了，又或者不小心杀掉了进程，那么最新的数据就会丢失。而AOF文件则提供了一种更为可靠的持久化方式。每当Redis接受到会修改数据集的命令时，就会把命令追加到AOF文件里，当你重启Redis时，AOF里的命令会被重新执行一次，重建数据。 优点 比RDB可靠。你可以制定不同的fsync策略：不进行fsync、每秒fsync一次和每次查询进行fsync。默认是每秒fsync一次。这意味着你最多丢失一秒钟的数据。 AOF日志文件是一个纯追加的文件。就算是遇到突然停电的情况，也不会出现日志的定位或者损坏问题。甚至如果因为某些原因（例如磁盘满了）命令只写了一半到日志文件里，我们也可以用redis-check-aof这个工具很简单的进行修复。 当AOF文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时Redis会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis会把新旧文件进行切换，然后开始把数据写到新文件上。 AOF把操作命令以简单易懂的格式一条接一条的保存在文件里，很容易导出来用于恢复数据。例如我们不小心用FLUSHALL命令把所有数据刷掉了，只要文件没有被重写，我们可以把服务停掉，把最后那条命令删掉，然后重启服务，这样就能把被刷掉的数据恢复回来。 缺点 在相同的数据集下，AOF文件的大小一般会比RDB文件大。 在某些fsync策略下，AOF的速度会比RDB慢。通常fsync设置为每秒一次就能获得比较高的性能，而在禁止fsync的情况下速度可以达到RDB的水平。 在过去曾经发现一些很罕见的BUG导致使用AOF重建的数据跟原数据不一致的问题。 启用AOF把配置项appendonly设为yes： appendonly yes 文件路径和名称# 文件存放目录，与RDB共用。默认为当前工作目录。 dir .&#x2F; # 默认文件名为appendonly.aof appendfilename &quot;appendonly.aof&quot; 可靠性你可以配置Redis调用fsync的频率，有三个选项： 每当有新命令追加到AOF的时候调用fsync。速度最慢，但是最安全。 每秒fsync一次。速度快（2.4版本跟快照方式速度差不多），安全性不错（最多丢失1秒的数据）。 从不fsync，交由系统去处理。这个方式速度最快，但是安全性一般。 推荐使用每秒fsync一次的方式（默认的方式），因为它速度快，安全性也不错。相关配置如下： # appendfsync always appendfsync everysec # appendfsync no 日志重写随着写操作的不断增加，AOF文件会越来越大。例如你递增一个计数器100次，那么最终结果就是数据集里的计数器的值为最终的递增结果，但是AOF文件里却会把这100次操作完整的记录下来。而事实上要恢复这个记录，只需要1个命令就行了，也就是说AOF文件里那100条命令其实可以精简为1条。所以Redis支持这样一个功能：在不中断服务的情况下在后台重建AOF文件。 工作原理如下： Redis调用fork()，产生一个子进程。 子进程把新的AOF写到一个临时文件里。 主进程持续把新的变动写到内存里的buffer，同时也会把这些新的变动写到旧的AOF里，这样即使重写失败也能保证数据的安全。 当子进程完成文件的重写后，主进程会获得一个信号，然后把内存里的buffer追加到子进程生成的那个新AOF里。 Redis 我们可以通过配置设置日志重写的条件： # Redis会记住自从上一次重写后AOF文件的大小（如果自Redis启动后还没重写过，则记住启动时使用的AOF文件的大小）。 # 如果当前的文件大小比起记住的那个大小超过指定的百分比，则会触发重写。 # 同时需要设置一个文件大小最小值，只有大于这个值文件才会重写，以防文件很小，但是已经达到百分比的情况。 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb 要禁用自动的日志重写功能，我们可以把百分比设置为0： auto-aof-rewrite-percentage 0 Redis 2.4以上才可以自动进行日志重写，之前的版本需要手动运行BGREWRITEAOF这个命令。 数据损坏修复如果因为某些原因（例如服务器崩溃）AOF文件损坏了，导致Redis加载不了，可以通过以下方式进行修复： 备份AOF文件。 使用redis-check-aof命令修复原始的AOF文件： $ redis-check-aof --fix 可以使用diff -u命令看下两个文件的差异。 使用修复过的文件重启Redis服务。 从RDB切换到AOF这里只说Redis &gt;= 2.2版本的方式： 备份一个最新的dump.rdb的文件，并把备份文件放在一个安全的地方。 运行以下两条命令： $ redis-cli config set appendonly yes $ redis-cli config set save &quot;&quot; 确保数据跟切换前一致。 确保数据正确的写到AOF文件里。 第二条命令是用来禁用RDB的持久化方式，但是这不是必须的，因为你可以同时启用两种持久化方式。 记得对配置文件redis.conf进行编辑启用AOF，因为命令行方式修改配置在重启Redis后就会失效。 具体方案持久化配置 RBD和AOF建议同时打开（Redis4.0之后支持） RDB做冷备，AOF做数据恢复（数据更可靠） RDB采取默认配置即可，AOF推荐采取everysec每秒策略 AOF和RDB还不懂的，请转移到如下几篇： 看完这篇还不懂Redis的RDB持久化，你们来打我！ 天天在用Redis，那你对Redis的AOF持久化到底了解多少呢？ 数据备份方案需求我们需要定时备份rdb文件来做冷备，为什么？不是有aof和rbd了吗为什么还要单独写定时任务去备份？因为Redis的aof和rdb是仅仅有一个最新的，比如谁手贱再Redis宕机的时候执行rm -rf aof/rdb了，那不就GG了吗？或者rdb/aof文件损坏了等不可预期的情况。所以我们需要单独备份rdb文件以防万一。 为什么不定时备份aof而是rdb？定时备份aof没意义呀，定时本身就是冷备份，不是实时的，rdb文件又小恢复又快，她哪里不香？ 方案 写crontab定时调度脚本去做数据备份。 每小时都copy一份redis的rdb文件到一个其他目录中，这个目录里的rdb文件仅仅保留48小时内的。也就是每小时都做备份，保留2天内的rdb，只保留48个rdb。 每天0点0分copy一份redis的rdb文件到一个其他目录中，这个保留一个月的。也就是按天备份。 每天半夜找个时间将当前服务上的所有rdb备份都上传到云服务上。 实现按小时 每小时copy一次备份，删除48小时前的数据。 crontab -e # 每小时都执行/usr/local/redis/copy/redis_rdb_copy_hourly.sh脚本 0 * * * * sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh # redis_rdb_copy_hourly.sh脚本的内容如下： #!/bin/sh # +%Y%m%d%k == 年月日时 cur_date=`date +%Y%m%d%k` rm -rf /usr/local/redis/rdb/$cur_date mkdir /usr/local/redis/rdb/$cur_date # 拷贝rdb到目录 cp /var/redis/6379/dump.rdb /usr/local/redis/rdb/$cur_date # date -d -48hour +%Y%m%d%k == 48小时前的日期，比如今天2020060214，这个结果就是2020053114 del_date=`date -d -48hour +%Y%m%d%k` # 删除48小时之前的目录 rm -rf /usr/local/redis/rdb/$del_date 按天 每天copy一次备份，删除一个月前的数据。 crontab -e # 每天0点0分开始执行/usr/local/redis/copy/redis_rdb_copy_daily.sh脚本 0 0 * * * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh # redis_rdb_copy_daily.sh脚本的内容如下： #!/bin/sh # 年月日 cur_date=`date +%Y%m%d` rm -rf /usr/local/redis/rdb/$cur_date mkdir /usr/local/redis/rdb/$cur_date # 拷贝rdb到目录 cp /var/redis/6379/dump.rdb /usr/local/redis/rdb/$cur_date # 获取一个月前的时间，比如今天是20200602，那么del_date就是20200502 del_date=`date -d -1month +%Y%m%d` # 删除一个月前的数据 rm -rf /usr/local/redis/rdb/$del_date 传到云没法演示，最终目的就是磁盘备份完上传到云，云保留多少天等策略自己看需求。 数据恢复方案redis挂了如果仅仅是redis进程挂了，那么直接重启redis进程即可，Redis会按照持久化配置直接基于持久化文件进行恢复数据。 如果有AOF则按照AOF，AOF和RDB一起开的话也走AOF。 持久化文件丢了如果持久化文件（rdb/aof）损坏了，或者直接丢失了。那么就要采取我们上面所做的rdb备份来进行恢复了。 不要脑子一热想着很简单，就以为直接把rdb拖过来重启redis进程就完事了，这种想法有很多问题。慢慢道来。 问题问题一：直接把备份的rdb扔到redis持久化目录下然后重启redis不行的原因在于：redis是按照先aof后rdb进行恢复的，所以都是开启aof的，redis启动后会重新生成新的aof文件，里面是空的。所以不会进行任何数据恢复，也就是说虽然你把rdb丢给redis了，但是redis会按照aof来恢复，而aof是redis启动的时候新生成的空文件，所以不会有任何数据进行恢复。 问题二：那么我们把rdb文件丢给redis后，先将redis的aof关闭再启动redis进程不就能按照rdb来进行恢复了吗？是这样的，没毛病！但是新的问题来了，我们aof肯定要开的，aof对数据保障更可靠。那什么我们按照rdb文件恢复完后再修改redis配置文件开启aof然后重启redis进程不就得了嘛？大哥…你打开aof然后重启redis，这时候redis又会生成一个空的aof文件，这时候恢复的时候又是啥数据都没了。 因为数据是存到内存里，你重启后肯定没了，需要持久化文件来恢复。这时候aof是空的，我恢复个鸡毛啊。 具体方案 可能有人想到方案了，但是耐心看完，看看我的文采如何。 我不管你是持久化文件丢了还是坏了，我都先rm -rf * 给他删了。 停止redis进程 删除坏掉的rdb和aof持久化文件。 修改配置文件关闭redis的aof持久化。 找到最新备份的rdb文件扔到redis的持久化目录里。（这里最新的肯定是按照小时备份的最后一个） 启动Redis进程 执行set appendonly yes动态打开aof持久化。 也就是说打开aof的操作不是修改配置文件然后重启，而是先热修改让他生成aof，这次生成肯定是会带着内存中完整的数据的。然后再修改配置文件重启。 等aof文件生成后再修改redis配置文件打开aof。 重启redis进程。 完美收官。","tags":[]},{"title":"redis基本操作","date":"2021-01-29T03:00:00.000Z","path":"posts/2a3c893b.html","text":"Redis 基本(basic)命令 Redis 键(key)命令 Redis 数据类型概述 Redis 字符串(String) Redis 哈希（Hash） Redis 列表(List) Redis 集合(Set) Redis 有序集合(sorted set) Redis 基本(basic)命令1、Redis 命令用于在 redis 服务上执行操作，要在 redis 服务上执行命令需要一个 redis 客户端。安装目录下的 redis-cli 就是自带的测试客户端。 命令行启动自带的 redis-cli 客户端连接到本地的 redis 服务：redis-cli连接远程 redis 服务器：redis-cli -h host -p port -a password PING 用于检测 redis 服务是否启动,连接是否正常，连接成功时返回 PONG select index Redis Select 命令用于切换到指定的数据库，数据库索引号 index 用数字值指定，以 0 作为起始索引值。 exit 退出 redis-cli auth password 当 redis 服务器开启密码验证，客户端连接时没有指定密码时，连接后必须使用 “auth 密码” 先进行授权，否则其它命令会使用不了。 set key value 往 redis 数据库设置数据 get key 从 redis 数据库读取数据。key 不存在时，返回 nil keys * 查询 redis 数据库中的所有 key 值 del key 删除指定的 key 的内容 Redis 键(key)命令1、Redis 键命令用于管理 redis 的键。 2、Redis 键命令的基本语法：command KEY_NAME 序号 命令 描述 1 del key 删除指定的 key。key 不存在时不影响。可以同时删除多个，如 del key1 key2 …。list、set、zset、hash 中的元素全部删除后，key 也会自动被删除。 2 dump key 序列化给定 key ，并返回被序列化的值。 3 exists key 检查给定 key 是否存在。返回 1 表示存在，返回 0 表示不存在。 4 expire key seconds 为给定 key 设置过期时间。单位 秒。如果 key 后续被重新设置值，比如 set key value，则 key 过期时间失效。 5 expireat key timestamp EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。如果 key 后续被重新设置值，比如 set key value，则 key 过期时间失效。 6 pexpire key milliseconds 设置 key 的过期时间亿以毫秒计。如果 key 后续被重新设置值，比如 set key value，则 key 过期时间失效。 7 pexpireat key milliseconds-timestamp 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计。如果 key 后续被重新设置值，比如 set key value，则 key 过期时间失效。 8 keys pattern 查找所有符合给定模式( pattern)的 key 。* 表示1个或多个，？ 表示一个任意字符。keys * ：查找所有key，keys user*：查找以 user 开头的 key，keys ag?：查找 ag 开头，且后面只有一个字符的 key。 9 move key db 将当前数据库的 key 移动到给定的数据库 db 当中。 10 persist key 移除 key 的过期时间，key 将持久保持。 11 pttl key 以毫秒为单位返回 key 的剩余的过期时间。如果没有对 key 设置超时，则返回 -1；-1 表示超时不存在。正常情况返回大于0的正数。 12 ttl key 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。 13 randomkey 从当前数据库中随机返回一个 key 。 14 rename key newkey 修改 key 的名称。key 不存在时会报错：(error) ERR no such key。如果 newkey 已经存在时，则会删除旧值。 15 renamenx key newkey 仅当 newkey 不存在时，将 key 改名为 newkey 。key 不存在时报错。 16 type key 返回 key 所储存的值的类型。有 string、list、set、zset、hash。如果 key 不存在，则返回 none 在线命令演示源码：[Redis 基本命令、键（key）命令、数据类型概述.sql](https://gitee.com/wangmx1993/my-document/blob/master/redis/Redis 基本命令、键（key）命令、数据类型概述.sql) Redis 数据类型概述1、Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。 2、这里暂时先做个概述，后续会详细说明。 3、在线命令演示源码：[Redis 基本命令、键（key）命令、数据类型概述.sql](https://gitee.com/wangmx1993/my-document/blob/master/redis/Redis 基本命令、键（key）命令、数据类型概述.sql) Redis 字符串(String)1、string 是 redis最基本的类型，一个key对应一个value。一个键最大能存储512MB。 2、string 类型是二进制安全的，可以包含任何数据，比如 jpg 图片或者序列化的对象 。 3、Redis 字符串(String)官网文档：https://www.redis.net.cn/order/3544.html 序号 命令 描述 1 set key value 设置指定 key 的值。key 存在时，覆盖其值。总是返回ok。设置的数字会自动转为字符串存储 2 get key 获取指定 key 的值。如果 key 不存在，则返回 (nil) 相当于 null。如果 key 的类型不是 string ，则报错。 3 getrange key start end range：范围、界限。返回 key 中字符串值的子字符。索引 [start ,end] 从 0开始。可以为负数，如 -1表示倒数第一位，-2 表示倒数第二位。 4 getset key value 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。key 不存在时返回为(nil)，同时创建新值。 5 getbit key offset 对 key 所储存的字符串值，获取指定偏移量上的位(bit)。 6 [mget key1 key2..] 获取所有(一个或多个)给定 key 的值。不存在的 key 返回 (nil) 7 setbit key offset value 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。 8 setex key seconds value 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。 9 setnx key value 只有在 key 不存在时设置 key 的值。 10 setrange key offset value 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。 11 strlen key 返回 key 所储存的字符串值的长度。不存在的 key 返回 0 12 [mset key value key value …] 同时设置一个或多个 key-value 对。key 存在时，覆盖其值。 13 [msetnx key value key value …] 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在才设置。 14 psetex key milliseconds value 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。 15 incr key 将 key 中储存的数字值增一。increment：ˈɪŋkrəmənt 增量、增加。如果不是数值，则报错。如果 key 不存在，则新建，incr 后，值为1。 16 incrby key increment 将 key 所储存的值加上给定的增量值（increment） 。如果不是数值，则报错。如果 key 不存在，则新建。 17 incrbyfloat key increment 将 key 所储存的值加上给定的浮点增量值（increment） 。如果不是数值，则报错。如果 key 不存在，则新建。increment 不能是变量。 18 decr key 将 key 中储存的数字值减一。如果不是数值，则报错。如果 key 不存在，则新建，decr 后，值为 -1。如果 key 不存在，则新建。 19 decrby key decrement key 所储存的值减去给定的减量值（decrement） 。如果 key 不存在，则新建。increment 20 append key value 如果 key 已经存在并且是一个字符串， APPEND 命令将 value 追加到 key 原来的值的末尾。如果 key 不存在，则新建。value 不能是变量。 4、在线命令演示：[Redis 字符串(String)命令演示.sql](https://gitee.com/wangmx1993/my-document/blob/master/redis/Redis 字符串(String)命令演示.sql) Redis 哈希（Hash）1、Redis hash 是一个键值对集合，值可以看成一个 Map。 2、Redis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。 3、每个 hash 可以存储 40多亿键值对。 hmset key filed value [filed2 value2 filed3 value3 …]：同时为 key 指定多个 filed 与 valuehgetall key：获取 key 中的所有 filed-value 4、Redis 哈希(Hash)官网文档：https://www.redis.net.cn/order/3564.html 序号 命令 描述 1 [hdel key field2 field2] 删除一个或多个哈希表字段。返回值成功删除的个数。key 或 field 不存在时会自动忽略。 2 hexists key field 查看哈希表 key 中，指定的字段是否存在。返回1表示有，返回0表示没有。key 不存在时也返回0. 3 hget key field 获取存储在哈希表中指定字段的值。key 或 field 不存在时，返回 (nil)。 4 hgetall key 获取在哈希表中指定 key 的所有字段和值 5 hincrby key field increment 为哈希表 key 中的指定字段的整数值加上增量 increment 。field 必须是数值，否则报错。key 不存在时会自动新建。field 不存在时也会自动新建。 6 hincrbyfloat key field increment 为哈希表 key 中的指定字段的浮点数值加上增量 increment 。field 必须是数值，否则报错。key 不存在时会自动新建。field 不存在时也会自动新建。 7 hkeys key 获取所有哈希表中的字段 8 hlen key 获取哈希表中字段的数量。key 不存在时返回0. 9 [hmget key field1 field2] 获取所有给定字段的值。key 或 field 不存在时，返回 (nil)。 10 [hmset key field1 value1 field2 value2 ] 同时将多个 field-value (域-值)对设置到哈希表 key 中。field 存在时，覆盖 value。 11 hset key field value 将哈希表 key 中的字段 field 的值设为 value 。field 存在时，覆盖 value。 12 hsetnx key field value 只有在字段 field 不存在时，设置哈希表字段的值。 13 hvals key 获取哈希表中所有值 14 HSCAN key cursor [MATCH pattern] [COUNT count] 迭代哈希表中的键值对。 5、命令在线演示：[Redis 哈希（Hash）命令演示.sql](https://gitee.com/wangmx1993/my-document/blob/master/redis/Redis 哈希（Hash）命令演示.sql) Redis 列表(List)1、Redis 列表是简单的字符串列表，按照插入顺序排序，可以添加一个元素导列表的头部（左边）或者尾部（右边）。 2、每个列表最多可存储 4294967295 个元素（约40多亿) lpush key value1 value2 value3 …：在指定的 key 关联的 lsit 的头部插入所有的 value，如果 key 不存在，则会先创建一个与该 key 关联的空链表，之后向链表的头部插入数据，插入成功，返回插入的个数。lrange key start end：获取链表中 [start,end] 之间的元素值，从0开始计数。可以为负数，如 -1 表示链表尾部的元素，-2 表示倒数第二个。 3、Redis 列表(List)官网文档：https://www.redis.net.cn/order/3577.html 序号 命令 描述 1 [blpop key1 key2 ] timeout 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 2 [brpop key1 key2 ] timeout 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 3 brpoplpush source destination timeout 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 4 lindex key index 通过索引获取列表中的元素 5 linsert key BEFORE|AFTER pivot value 在 pivot 元素前/后插入 value 元素。成功时返回列表中元素的个数。key 不存在时返回0。pivot 不存在时返回-1。 6 llen key 获取列表长度。key 不存在时返回0； 7 lpop key 返回并弹出指定 key 关联的列表中的第一个元素（头部元素）。如果 key 不存在，则返回(nil)。弹出之后，列表中的此元素也就不存在了。 8 [lpush key value1 value2] 将一个或多个值插入到列表头部。如果 key 不存在，则先创建一个与该 key 关联的空列表，然后向列表的头部插入数据，返回插入成功的个数。因为有索引，所以可以插入重复的元素。返回 list 中的元素个数。 9 lpushx key value 将一个或多个值插入到已存在的列表头部 10 lrange key start stop 获取链表中 [start,end] 之间的元素值。索引从0开始，可以为负数，如 -1 表示倒数第一个元素，-2 表示倒数第二个元素…。end 可以超出列表的整个大小，此时多余的会自动忽略。 11 lrem key count value 删除 count 个值为 value 的元素。count &gt; 0，则从头向尾遍历并删除 count 个值为 value 的元素，count &lt; 0 ，则从尾向前遍历进行删除。count =0，则删除链表中所有的 value 元素。返回删除成功的个数。value 不存在时返回0。key 不存在时返回0。 12 lset key index value 设置列表中索引为 index 的元素值，0 表示首元素，-1表示尾元素。如果 index 不存在，则抛出异常。如果 key 不存在，也抛出异常。 13 ltrim key start stop 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。 14 rpop key 移除并获取列表最后一个元素 15 rpoplpush source destination 将 resource 链表的尾部元素弹出并添加到 destination 链表的头部。成功时返回操作的元素。如果resource不存在，则返回（nil）。如果 destination 不存在，则自动会新建。 16 [rpush key value1 value2] 在列表尾部添加一个或多个值 17 rpushx key value 为已存在的列表的尾部添加值 rpoplpush 使用场景： Redis 链表经常会被用于消息队列的服务，已完成多程序之间的消息交互。 假设一个应用程序正在执行 lpush 操作向链表头部插入新的元素，通常将这样的程序称之为”生产者(Producer)”， 而另一个应用程序正在执行 rpop 操作从链表的尾部取出元素，通常称之为”消费者（Consumer）”。 如果此时消费者程序取出消息后突然崩溃了，由于该消息已经被取出且没有被正常处理，那么就认为此消息已经丢失，由此可能导致业务数据丢失。 然而通过 rpoplpush 命令，消费者程序在主消息队列中取出消息之后再将其插入到备份队列中，直到消费者程序完成正常的处理后，再将该消息从备份列表中删除。 同时还可以提供一个守护进程，当发现备份队列中的消息过期时，可以重新将其再放回到主消息队列中，以便其它消费者程序继续处理。 Redis 集合(Set)1、Redis 的 Set 是 string 类型的无序集合。和 java 一样，集合中不会有重复的元素。 2、集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 3、每个集合中最大的成员数为 4294967295（40多亿个成员)。 sadd key value1 value2 …：向集合 key 中添加元素，key 不存在时会自动新建，value 存在时，后一次的会被忽略。smembers key：获取集合 key 中的所有元素。 4、Redis 集合(Set)官网文档：https://www.redis.net.cn/order/3594.html 序号 命令 描述 1 [sadd key member1 member2] 向集合添加一个或多个成员。如果 value 已经存在，则不会再添加。返回插入成功的个数。 2 scard key 获取集合的成员数。key 不存在时，返回0。 3 [sdiff key1 key2] 返回给定所有集合的差集。求 key1 与 key2 key3 …的差集，即 key1 中有，但 key2 key3 …都没有的元素。 4 [sdiffstore destination key1 key2] 将 key1 集合与其它集合的差集放入到 destination 集合中。如果 destination 已经存在且有值，则会被全部清除，不存在时会新建。 5 [sinter key1 key2] 返回给定所有集合的交集。求 key1 与 key2 key3 …集合的交集。 6 [sinterstore destination key1 key2] 将 key1 与其它集合的交集存放到 destination 集合中。如果 destination 集合已经有值，则会先被清理。 7 sismember key member 判断 member 元素是否是集合 key 的成员。返回1表示存在，返回0表示不存在。key 不存在时也返回0。 8 smembers key 返回集合中的所有成员 9 smove source destination member 将 member 元素从 source 集合移动到 destination 集合 10 spop key 移除并返回集合中的一个随机元素 11 [srandmember key count] 返回集合中一个或多个随机数。key 不存在时返回（nil） 12 [srem key member1 member2] 移除集合中一个或多个成员。返回成功删除的个数。 当然也可以使用 del key 直接删除整个集合。 13 [sunion key1 key2] … 返回所有给定集合的并集。求 key1 与集合 key2 key3 …的并集。 14 [sunionstore destination key1 key2] … 所有给定集合的并集存储在 destination 集合中。将并集结果存放到 destination 集合中。如果 destination 已经有值，则会被清除。 15 [sscan key cursor MATCH pattern] [COUNT count] 迭代集合中的元素 Redis 有序集合(sorted set)1、Redis zset 和 set 一样也是 string 类型元素的集合，且不允许重复的成员。 2、不同的是每个元素都会关联一个 double 类型的分数，redis 正是通过分数来为集合中的成员进行从小到大的排序。 3、zset 的成员是唯一的，但分数(score)却可以重复。 zadd key score1 member1 score2 member2 …：添加元素到集合，元素在集合中存在则更新对应 score：zrangebyscore key min max ：返回分数在 [mix,max]之间的成员，并按照分数由低到高排序。 4、Redis 有序集合(sorted set)官网文档：https://www.redis.net.cn/order/3609.html","tags":[]},{"title":"SpringSecurity自定义异常","date":"2021-01-28T07:00:00.000Z","path":"posts/d6f2c8a8.html","text":"Spring Security 中的异常主要分为两大类：一类是认证异常，另一类是授权相关的异常。 AuthenticationExceptionAuthenticationException 是在用户认证的时候出现错误时抛出的异常。主要的子类如图： 根据该图的信息，系统用户不存在，被锁定，凭证失效，密码错误等认证过程中出现的异常都由 AuthenticationException 处理。 AccessDeniedExceptionAccessDeniedException 主要是在用户在访问受保护资源时被拒绝而抛出的异常。同 AuthenticationException 一样它也提供了一些具体的子类。如下图： AccessDeniedException 的子类比较少，主要是 CSRF 相关的异常和授权服务异常。 Http 状态对认证授权的规定Http 协议对认证授权的响应结果也有规定。 401 未授权状态HTTP 401 错误 - 未授权(Unauthorized) 一般来说该错误消息表明您首先需要登录（输入有效的用户名和密码）。 如果你刚刚输入这些信息，立刻就看到一个 401 错误，就意味着，无论出于何种原因您的用户名和密码其中之一或两者都无效（输入有误，用户名暂时停用，账户被锁定，凭证失效等） 。总之就是认证失败了。其实正好对应我们上面的 AuthenticationException 。 403 被拒绝状态HTTP 403 错误 - 被禁止(Forbidden) 出现该错误表明您在访问受限资源时没有得到许可。服务器理解了本次请求但是拒绝执行该任务，该请求不该重发给服务器。并且服务器想让客户端知道为什么没有权限访问特定的资源，服务器应该在返回的信息中描述拒绝的理由。一般实践中我们会比较模糊的表明原因。 该错误对应了我们上面的 AccessDeniedException 。 Spring Security 中的异常处理我们在 Spring Security 实战干货系列文章中的 自定义配置类入口 WebSecurityConfigurerAdapter 一文中提到 HttpSecurity 提供的 exceptionHandling() 方法用来提供异常处理。该方法构造出 ExceptionHandlingConfigurer 异常处理配置类。该配置类提供了两个实用接口： AuthenticationEntryPoint 该类用来统一处理 AuthenticationException 异常 AccessDeniedHandler 该类用来统一处理 AccessDeniedException 异常 我们只要实现并配置这两个异常处理类即可实现对 Spring Security 认证授权相关的异常进行统一的自定义处理。 4.1 实现 AuthenticationEntryPoint以 json 信息响应。 import com.fasterxml.jackson.databind.ObjectMapper; import org.springframework.http.MediaType; import org.springframework.security.core.AuthenticationException; import org.springframework.security.web.AuthenticationEntryPoint; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; import java.io.PrintWriter; import java.util.HashMap; /** * @author dax * @since 2019/11/6 22:11 */ public class SimpleAuthenticationEntryPoint implements AuthenticationEntryPoint &#123; @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException, ServletException &#123; //todo your business HashMap&lt;String, String> map = new HashMap&lt;>(2); map.put(\"uri\", request.getRequestURI()); map.put(\"msg\", \"认证失败\"); response.setStatus(HttpServletResponse.SC_UNAUTHORIZED); response.setCharacterEncoding(\"utf-8\"); response.setContentType(MediaType.APPLICATION_JSON_VALUE); ObjectMapper objectMapper = new ObjectMapper(); String resBody = objectMapper.writeValueAsString(map); PrintWriter printWriter = response.getWriter(); printWriter.print(resBody); printWriter.flush(); printWriter.close(); &#125; &#125; 4.2 实现 AccessDeniedHandler同样以 json 信息响应。 import com.fasterxml.jackson.databind.ObjectMapper; import org.springframework.http.MediaType; import org.springframework.security.access.AccessDeniedException; import org.springframework.security.web.access.AccessDeniedHandler; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; import java.io.PrintWriter; import java.util.HashMap; /** * @author dax * @since 2019/11/6 22:19 */ public class SimpleAccessDeniedHandler implements AccessDeniedHandler &#123; @Override public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException &#123; //todo your business HashMap&lt;String, String> map = new HashMap&lt;>(2); map.put(\"uri\", request.getRequestURI()); map.put(\"msg\", \"认证失败\"); response.setStatus(HttpServletResponse.SC_FORBIDDEN); response.setCharacterEncoding(\"utf-8\"); response.setContentType(MediaType.APPLICATION_JSON_VALUE); ObjectMapper objectMapper = new ObjectMapper(); String resBody = objectMapper.writeValueAsString(map); PrintWriter printWriter = response.getWriter(); printWriter.print(resBody); printWriter.flush(); printWriter.close(); &#125; &#125; 4.3 个人实践建议其实我个人建议 Http 状态码 都返回 200 而将 401 状态在 元信息 Map 中返回。因为异常状态码在浏览器端会以 error 显示。我们只要能捕捉到 401 和 403 就能认定是认证问题还是授权问题。 4.4 配置实现了上述两个接口后，我们只需要在 WebSecurityConfigurerAdapter 的 configure(HttpSecurity http) 方法中配置即可。相关的配置片段如下： http.exceptionHandling().accessDeniedHandler(new SimpleAccessDeniedHandler()).authenticationEntryPoint(new SimpleAuthenticationEntryPoint()) 总结 https://juejin.cn/post/6844903988895154184 https://ld246.com/article/1545318463746 https://blog.csdn.net/qq_38225558/category_9395795.html","tags":[{"name":"SpringSecurity","slug":"SpringSecurity","permalink":"http://wumuwumu.github.io/tags/SpringSecurity/"}]},{"title":"SpringCloud API聚合","date":"2021-01-28T07:00:00.000Z","path":"posts/3cb9b8de.html","text":"使用原本的Swagger重写接口 @RestController public class SwaggerController &#123; @Autowired private SwaggerService swaggerService; @ApiIgnore @RequestMapping(value = \"/swagger-resources/configuration/security\") ResponseEntity&lt;SecurityConfiguration> securityConfiguration() &#123; return new ResponseEntity&lt;>(swaggerService.getSecurityConfiguration(), HttpStatus.OK); &#125; @ApiIgnore @RequestMapping(value = \"/swagger-resources/configuration/ui\") ResponseEntity&lt;UiConfiguration> uiConfiguration() &#123; return new ResponseEntity&lt;UiConfiguration>(swaggerService.getUiConfiguration(), HttpStatus.OK); &#125; /** * 获取swagger服务列表，swagger页面自动请求 * * @return list */ @ApiIgnore @RequestMapping(value = \"/swagger-resources\") ResponseEntity&lt;List&lt;SwaggerResource>> swaggerResources() &#123; return new ResponseEntity&lt;>(swaggerService.getSwaggerResource(), HttpStatus.OK); &#125; /** * 查询不包含跳过的服务的路由列表 */ @ApiIgnore @GetMapping(\"/v1/swaggers/resources\") public ResponseEntity&lt;List&lt;SwaggerResource>> resources() &#123; return new ResponseEntity&lt;>(swaggerService.getSwaggerResource(), HttpStatus.OK); &#125; &#125; 查询可以提供的接口服务，可以从注册中心中去查找，这里直接写固定的 public interface SwaggerService &#123; List&lt;SwaggerResource> getSwaggerResource(); UiConfiguration getUiConfiguration(); SecurityConfiguration getSecurityConfiguration(); &#125; @Component public class SwaggerServiceImpl implements SwaggerService &#123; @Autowired DiscoveryClient discoveryClient; @Override public List&lt;SwaggerResource> getSwaggerResource() &#123; List&lt;SwaggerResource> resources = new LinkedList&lt;>(); SwaggerResource resource = new SwaggerResource(); resource.setName(\"demo-user\"); resource.setSwaggerVersion(\"2.0\"); // 这里可以使用网关地址，获取自己手动请求，不然有跨域问题 resource.setLocation(\"http://127.0.0.1:9000/user/v2/api-docs\" ); resources.add(resource); return resources; &#125; @Override public UiConfiguration getUiConfiguration() &#123; return new UiConfiguration(null); &#125; @Override public SecurityConfiguration getSecurityConfiguration() &#123; return new SecurityConfiguration( \"\", \"unknown\", \"default\", \"default\", \"token\", ApiKeyVehicle.HEADER, \"token\", \",\"); &#125; &#125; knife4jhttps://doc.xiaominfo.com/knife4j/resources/aggregation-introduction.html 参考 https://juejin.cn/post/6854573219916201997","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"},{"name":"Swagger","slug":"Swagger","permalink":"http://wumuwumu.github.io/tags/Swagger/"}]},{"title":"SpringCloudGateway基本操作-限流（详细版）","date":"2021-01-26T08:00:00.000Z","path":"posts/d858ee63.html","text":"话说在 Spring Cloud Gateway 问世之前，Spring Cloud 的微服务世界里，网关一定非 Netflix Zuul 莫属。但是由于 Zuul 1.x 存在的一些问题，比如阻塞式的 API，不支持 WebSocket 等，一直被人所诟病，而且 Zuul 升级新版本依赖于 Netflix 公司，经过几次跳票之后，Spring 开源社区决定推出自己的网关组件，替代 Netflix Zuul。 从 18 年 6 月 Spring Cloud 发布的 Finchley 版本开始，Spring Cloud Gateway 逐渐崭露头角，它基于 Spring 5.0、Spring Boot 2.0 和 Project Reactor 等技术开发，不仅支持响应式和无阻塞式的 API，而且支持 WebSocket，和 Spring 框架紧密集成。尽管 Zuul 后来也推出了 2.x 版本，在底层使用了异步无阻塞式的 API，大大改善了其性能，但是目前看来 Spring 并没有打算继续集成它的计划。 根据官网的描述，Spring Cloud Gateway 的主要特性如下： Built on Spring Framework 5, Project Reactor and Spring Boot 2.0 Able to match routes on any request attribute Predicates and filters are specific to routes Hystrix Circuit Breaker integration Spring Cloud DiscoveryClient integration Easy to write Predicates and Filters Request Rate Limiting Path Rewriting 可以看出 Spring Cloud Gateway 可以很方便的和 Spring Cloud 生态中的其他组件进行集成（比如：断路器和服务发现），而且提供了一套简单易写的 断言（Predicates，有的地方也翻译成 谓词）和 过滤器（Filters）机制，可以对每个 路由（Routes）进行特殊请求处理。 最近在项目中使用了 Spring Cloud Gateway，并在它的基础上实现了一些高级特性，如限流和留痕，在网关的使用过程中遇到了不少的挑战，于是趁着项目结束，抽点时间系统地学习并总结下。这篇文章主要学习限流技术，首先我会介绍一些常见的限流场景和限流算法，然后介绍一些关于限流的开源项目，学习别人是如何实现限流的，最后介绍我是如何在网关中实现限流的，并分享一些实现过程中的经验和遇到的坑。 一、常见的限流场景缓存、降级 和 限流 被称为高并发、分布式系统的三驾马车，网关作为整个分布式系统中的第一道关卡，限流功能自然必不可少。通过限流，可以控制服务请求的速率，从而提高系统应对突发大流量的能力，让系统更具弹性。限流有着很多实际的应用场景，比如双十一的秒杀活动， 12306 的抢票等。 1.1 限流的对象通过上面的介绍，我们对限流的概念可能感觉还是比较模糊，到底限流限的是什么？顾名思义，限流就是限制流量，但这里的流量是一个比较笼统的概念。如果考虑各种不同的场景，限流是非常复杂的，而且和具体的业务规则密切相关，可以考虑如下几种常见的场景： 限制某个接口一分钟内最多请求 100 次 限制某个用户的下载速度最多 100KB/S 限制某个用户同时只能对某个接口发起 5 路请求 限制某个 IP 来源禁止访问任何请求 从上面的例子可以看出，根据不同的请求者和请求资源，可以组合出不同的限流规则。可以根据请求者的 IP 来进行限流，或者根据请求对应的用户来限流，又或者根据某个特定的请求参数来限流。而限流的对象可以是请求的频率，传输的速率，或者并发量等，其中最常见的两个限流对象是请求频率和并发量，他们对应的限流被称为 请求频率限流（Request rate limiting）和 并发量限流（Concurrent requests limiting）。传输速率限流 在下载场景下比较常用，比如一些资源下载站会限制普通用户的下载速度，只有购买会员才能提速，这种限流的做法实际上和请求频率限流类似，只不过一个限制的是请求量的多少，一个限制的是请求数据报文的大小。这篇文章主要介绍请求频率限流和并发量限流。 1.2 限流的处理方式在系统中设计限流方案时，有一个问题值得设计者去仔细考虑，当请求者被限流规则拦截之后，我们该如何返回结果。一般我们有下面三种限流的处理方式： 拒绝服务 排队等待 服务降级 最简单的做法是拒绝服务，直接抛出异常，返回错误信息（比如返回 HTTP 状态码 429 Too Many Requests），或者给前端返回 302 重定向到一个错误页面，提示用户资源没有了或稍后再试。但是对于一些比较重要的接口不能直接拒绝，比如秒杀、下单等接口，我们既不希望用户请求太快，也不希望请求失败，这种情况一般会将请求放到一个消息队列中排队等待，消息队列可以起到削峰和限流的作用。第三种处理方式是服务降级，当触发限流条件时，直接返回兜底数据，比如查询商品库存的接口，可以默认返回有货。 1.3 限流的架构针对不同的系统架构，需要使用不同的限流方案。如下图所示，服务部署的方式一般可以分为单机模式和集群模式： 单机模式的限流非常简单，可以直接基于内存就可以实现，而集群模式的限流必须依赖于某个“中心化”的组件，比如网关或 Redis，从而引出两种不同的限流架构：网关层限流 和 中间件限流。 网关作为整个分布式系统的入口，承担了所有的用户请求，所以在网关中进行限流是最合适不过的。网关层限流有时也被称为 接入层限流。除了我们使用的 Spring Cloud Gateway，最常用的网关层组件还有 Nginx，可以通过它的 ngx_http_limit_req_module 模块，使用 limit_conn_zone、limit_req_zone、limit_rate 等指令很容易的实现并发量限流、请求频率限流和传输速率限流。这里不对 Nginx 作过多的说明，关于这几个指令的详细信息可以 参考 Nginx 的官方文档。 另一种限流架构是中间件限流，可以将限流的逻辑下沉到服务层。但是集群中的每个服务必须将自己的流量信息统一汇总到某个地方供其他服务读取，一般来说用 Redis 的比较多，Redis 提供的过期特性和 lua 脚本执行非常适合做限流。除了 Redis 这种中间件，还有很多类似的分布式缓存系统都可以使用，如 Hazelcast、Apache Ignite、Infinispan 等。 我们可以更进一步扩展上面的架构，将网关改为集群模式，虽然这还是网关层限流架构，但是由于网关变成了集群模式，所以网关必须依赖于中间件进行限流，这和上面讨论的中间件限流没有区别。 二、常见的限流算法通过上面的学习，我们知道限流可以分为请求频率限流和并发量限流，根据系统架构的不同，又可以分为网关层限流和分布式限流。在不同的应用场景下，我们需要采用不同的限流算法。这一节将介绍一些主流的限流算法。 有一点要注意的是，利用池化技术也可以达到限流的目的，比如线程池或连接池，但这不是本文的重点。 2.1 固定窗口算法（Fixed Window）固定窗口算法是一种最简单的限流算法，它根据限流的条件，将请求时间映射到一个时间窗口，再使用计数器累加访问次数。譬如限流条件为每分钟 5 次，那么就按照分钟为单位映射时间窗口，假设一个请求时间为 11:00:45，时间窗口就是 11:00:00 ~ 11:00:59，在这个时间窗口内设定一个计数器，每来一个请求计数器加一，当这个时间窗口的计数器超过 5 时，就触发限流条件。当请求时间落在下一个时间窗口内时（11:01:00 ~ 11:01:59），上一个窗口的计数器失效，当前的计数器清零，重新开始计数。 计数器算法非常容易实现，在单机场景下可以使用 AtomicLong、LongAdder 或 Semaphore 来实现计数，而在分布式场景下可以通过 Redis 的 INCR 和 EXPIRE 等命令并结合 EVAL 或 lua 脚本来实现，Redis 官网提供了几种简单的实现方式。无论是请求频率限流还是并发量限流都可以使用这个算法。 不过这个算法的缺陷也比较明显，那就是存在严重的临界问题。由于每过一个时间窗口，计数器就会清零，这使得限流效果不够平滑，恶意用户可以利用这个特点绕过我们的限流规则。如下图所示，我们的限流条件本来是每分钟 5 次，但是恶意用户在 11:00:00 ~ 11:00:59 这个时间窗口的后半分钟发起 5 次请求，接下来又在 11:01:00 ~ 11:01:59 这个时间窗口的前半分钟发起 5 次请求，这样我们的系统就在 1 分钟内承受了 10 次请求。（图片来源） 2.2 滑动窗口算法（Rolling Window 或 Sliding Window）为了解决固定窗口算法的临界问题，可以将时间窗口划分成更小的时间窗口，然后随着时间的滑动删除相应的小窗口，而不是直接滑过一个大窗口，这就是滑动窗口算法。我们为每个小时间窗口都设置一个计数器，大时间窗口的总请求次数就是每个小时间窗口的计数器的和。如下图所示，我们的时间窗口是 5 秒，可以按秒进行划分，将其划分成 5 个小窗口，时间每过一秒，时间窗口就滑过一秒：（图片来源） rolling-window.png 每次处理请求时，都需要计算所有小时间窗口的计数器的和，考虑到性能问题，划分的小时间窗口不宜过多，譬如限流条件是每小时 N 个，可以按分钟划分为 60 个窗口，而不是按秒划分成 3600 个。当然如果不考虑性能问题，划分粒度越细，限流效果就越平滑。相反，如果划分粒度越粗，限流效果就越不精确，出现临界问题的可能性也就越大，当划分粒度为 1 时，滑动窗口算法就退化成了固定窗口算法。由于这两种算法都使用了计数器，所以也被称为 计数器算法（Counters）。 进一步思考我们发现，如果划分粒度最粗，也就是只有一个时间窗口时，滑动窗口算法退化成了固定窗口算法；那如果我们把划分粒度调到最细，又会如何呢？那么怎样才能让划分的时间窗口最细呢？时间窗口细到一定地步时，意味着每个时间窗口中只能容纳一个请求，这样我们可以省略计数器，只记录每个请求的时间，然后统计一段时间内的请求数有多少个即可。具体的实现可以参考 这里的 Redis sorted set 技巧 和 这里的 Sliding window log 算法。 2.3 漏桶算法（Leaky Bucket）除了计数器算法，另一个很自然的限流思路是将所有的请求缓存到一个队列中，然后按某个固定的速度慢慢处理，这其实就是漏桶算法（Leaky Bucket）。漏桶算法假设将请求装到一个桶中，桶的容量为 M，当桶满时，请求被丢弃。在桶的底部有一个洞，桶中的请求像水一样按固定的速度（每秒 r 个）漏出来。我们用下面这个形象的图来表示漏桶算法：（图片来源） 桶的上面是个水龙头，我们的请求从水龙头流到桶中，水龙头流出的水速不定，有时快有时慢，这种忽快忽慢的流量叫做 Bursty flow。如果桶中的水满了，多余的水就会溢出去，相当于请求被丢弃。从桶底部漏出的水速是固定不变的，可以看出漏桶算法可以平滑请求的速率。 漏桶算法可以通过一个队列来实现，如下图所示： 当请求到达时，不直接处理请求，而是将其放入一个队列，然后另一个线程以固定的速率从队列中读取请求并处理，从而达到限流的目的。注意的是这个队列可以有不同的实现方式，比如设置请求的存活时间，或将队列改造成 PriorityQueue，根据请求的优先级排序而不是先进先出。当然队列也有满的时候，如果队列已经满了，那么请求只能被丢弃了。漏桶算法有一个缺陷，在处理突发流量时效率很低，于是人们又想出了下面的令牌桶算法。 2.4 令牌桶算法（Token Bucket）令牌桶算法（Token Bucket）是目前应用最广泛的一种限流算法，它的基本思想由两部分组成：生成令牌 和 消费令牌。 生成令牌：假设有一个装令牌的桶，最多能装 M 个，然后按某个固定的速度（每秒 r 个）往桶中放入令牌，桶满时不再放入； 消费令牌：我们的每次请求都需要从桶中拿一个令牌才能放行，当桶中没有令牌时即触发限流，这时可以将请求放入一个缓冲队列中排队等待，或者直接拒绝； 令牌桶算法的图示如下：（图片来源） 在上面的图中，我们将请求放在一个缓冲队列中，可以看出这一部分的逻辑和漏桶算法几乎一模一样，只不过在处理请求上，一个是以固定速率处理，一个是从桶中获取令牌后才处理。 仔细思考就会发现，令牌桶算法有一个很关键的问题，就是桶大小的设置，正是这个参数可以让令牌桶算法具备处理突发流量的能力。譬如将桶大小设置为 100，生成令牌的速度设置为每秒 10 个，那么在系统空闲一段时间的之后（桶中令牌一直没有消费，慢慢的会被装满），突然来了 50 个请求，这时系统可以直接按每秒 50 个的速度处理，随着桶中的令牌很快用完，处理速度又会慢慢降下来，和生成令牌速度趋于一致。这是令牌桶算法和漏桶算法最大的区别，漏桶算法无论来了多少请求，只会一直以每秒 10 个的速度进行处理。当然，处理突发流量虽然提高了系统性能，但也给系统带来了一定的压力，如果桶大小设置不合理，突发的大流量可能会直接压垮系统。 通过上面对令牌桶的原理分析，一般会有两种不同的实现方式。第一种方式是启动一个内部线程，不断的往桶中添加令牌，处理请求时从桶中获取令牌，和上面图中的处理逻辑一样。第二种方式不依赖于内部线程，而是在每次处理请求之前先实时计算出要填充的令牌数并填充，然后再从桶中获取令牌。下面是第二种方式的一种经典实现，其中 capacity 表示令牌桶大小，refillTokensPerOneMillis 表示填充速度，每毫秒填充多少个，availableTokens 表示令牌桶中还剩多少个令牌，lastRefillTimestamp 表示上一次填充时间。 public class TokenBucket &#123; private final long capacity; private final double refillTokensPerOneMillis; private double availableTokens; private long lastRefillTimestamp; public TokenBucket(long capacity, long refillTokens, long refillPeriodMillis) &#123; this.capacity = capacity; this.refillTokensPerOneMillis = (double) refillTokens / (double) refillPeriodMillis; this.availableTokens = capacity; this.lastRefillTimestamp = System.currentTimeMillis(); &#125; synchronized public boolean tryConsume(int numberTokens) &#123; refill(); if (availableTokens &lt; numberTokens) &#123; return false; &#125; else &#123; availableTokens -= numberTokens; return true; &#125; &#125; private void refill() &#123; long currentTimeMillis = System.currentTimeMillis(); if (currentTimeMillis > lastRefillTimestamp) &#123; long millisSinceLastRefill = currentTimeMillis - lastRefillTimestamp; double refill = millisSinceLastRefill * refillTokensPerOneMillis; this.availableTokens = Math.min(capacity, availableTokens + refill); this.lastRefillTimestamp = currentTimeMillis; &#125; &#125; &#125; 可以像下面这样创建一个令牌桶（桶大小为 100，且每秒生成 100 个令牌）： TokenBucket limiter = new TokenBucket(100, 100, 1000); 从上面的代码片段可以看出，令牌桶算法的实现非常简单也非常高效，仅仅通过几个变量的运算就实现了完整的限流功能。核心逻辑在于 refill() 这个方法，在每次消费令牌时，计算当前时间和上一次填充的时间差，并根据填充速度计算出应该填充多少令牌。在重新填充令牌后，再判断请求的令牌数是否足够，如果不够，返回 false，如果足够，则减去令牌数，并返回 true。 在实际的应用中，往往不会直接使用这种原始的令牌桶算法，一般会在它的基础上作一些改进，比如，填充速率支持动态调整，令牌总数支持透支，基于 Redis 支持分布式限流等，不过总体来说还是符合令牌桶算法的整体框架，我们在后面学习一些开源项目时对此会有更深的体会。 三、一些开源项目有很多开源项目中都实现了限流的功能，这一节通过一些开源项目的学习，了解限流是如何实现的。 3.1 Guava 的 RateLimiterGoogle Guava 是一个强大的核心库，包含了很多有用的工具类，例如：集合、缓存、并发库、字符串处理、I/O 等等。其中在并发库中，Guava 提供了两个和限流相关的类：RateLimiter 和 SmoothRateLimiter。Guava 的 RateLimiter 基于令牌桶算法实现，不过在传统的令牌桶算法基础上做了点改进，支持两种不同的限流方式：平滑突发限流（SmoothBursty） 和 平滑预热限流（SmoothWarmingUp）。 下面的方法可以创建一个平滑突发限流器（SmoothBursty）： RateLimiter limiter = RateLimiter.create(5); RateLimiter.create(5) 表示这个限流器容量为 5，并且每秒生成 5 个令牌，也就是每隔 200 毫秒生成一个。我们可以使用 limiter.acquire() 消费令牌，如果桶中令牌足够，返回 0，如果令牌不足，则阻塞等待，并返回等待的时间。我们连续请求几次： System.out.println(limiter.acquire());``System.out.println(limiter.acquire());``System.out.println(limiter.acquire());``System.out.println(limiter.acquire()); 输出结果如下： 0.0``0.198239``0.196083``0.200609 可以看出限流器创建之后，初始会有一个令牌，然后每隔 200 毫秒生成一个令牌，所以第一次请求直接返回 0，后面的请求都会阻塞大约 200 毫秒。另外，SmoothBursty 还具有应对突发的能力，而且 还允许消费未来的令牌，比如下面的例子： RateLimiter limiter = RateLimiter.create(5); System.out.println(limiter.acquire(10)); System.out.println(limiter.acquire(1)); System.out.println(limiter.acquire(1)); 会得到类似下面的输出： 0.01.997428 0.192273 0.200616 限流器创建之后，初始令牌只有一个，但是我们请求 10 个令牌竟然也通过了，只不过看后面请求发现，第二次请求花了 2 秒左右的时间把前面的透支的令牌给补上了。 Guava 支持的另一种限流方式是平滑预热限流器（SmoothWarmingUp），可以通过下面的方法创建： RateLimiter limiter = RateLimiter.create(2, 3, TimeUnit.SECONDS); System.out.println(limiter.acquire(1)); System.out.println(limiter.acquire(1)); System.out.println(limiter.acquire(1)); System.out.println(limiter.acquire(1)); System.out.println(limiter.acquire(1)); 第一个参数还是每秒创建的令牌数量，这里是每秒 2 个，也就是每 500 毫秒生成一个，后面的参数表示从冷启动速率过渡到平均速率的时间间隔，也就是所谓的热身时间间隔（warm up period）。我们看下输出结果： 0.0 1.329289 0.994375 0.662888 0.501287 第一个请求还是立即得到令牌，但是后面的请求和上面平滑突发限流就完全不一样了，按理来说 500 毫秒就会生成一个令牌，但是我们发现第二个请求却等了 1.3s，而不是 0.5s，后面第三个和第四个请求也等了一段时间。不过可以看出，等待时间在慢慢的接近 0.5s，直到第五个请求等待时间才开始变得正常。从第一个请求到第五个请求，这中间的时间间隔就是热身阶段，可以算出热身的时间就是我们设置的 3 秒。 关于热身的算法很有意思，也比较烧脑，有兴趣的同学可以参考 这里 和 这里 的过程分析。 3.2 Bucket4jBucket4j 是一个基于令牌桶算法实现的强大的限流库，它不仅支持单机限流，还支持通过诸如 Hazelcast、Ignite、Coherence、Infinispan 或其他兼容 JCache API (JSR 107) 规范的分布式缓存实现分布式限流。 在使用 Bucket4j 之前，我们有必要先了解 Bucket4j 中的几个核心概念： Bucket Bandwidth Refill Bucket 接口代表了令牌桶的具体实现，也是我们操作的入口。它提供了诸如 tryConsume 和 tryConsumeAndReturnRemaining 这样的方法供我们消费令牌。可以通过下面的构造方法来创建 Bucket： Bucket bucket = Bucket4j.builder().addLimit(limit).build(); if(bucket.tryConsume(1)) &#123;System.out.println(\"ok\");&#125; else &#123; System.out.println(\"error\"); &#125; Bandwidth 的意思是带宽，可以理解为限流的规则。Bucket4j 提供了两种方法来创建 Bandwidth：simple 和 classic。下面是 simple 方式创建的 Bandwidth，表示桶大小为 10，填充速度为每分钟 10 个令牌： Bandwidth limit = Bandwidth.simple(10, Duration.ofMinutes(1)); simple 方式桶大小和填充速度是一样的，classic 方式更灵活一点，可以自定义填充速度，下面的例子表示桶大小为 10，填充速度为每分钟 5 个令牌： Refill filler = Refill.greedy(5, Duration.ofMinutes(1)); Bandwidth limit = Bandwidth.classic(10, filler); 其中，Refill 用于填充令牌桶，可以通过它定义填充速度，Bucket4j 有两种填充令牌的策略：间隔策略（intervally） 和 贪婪策略（greedy）。在上面的例子中我们使用的是贪婪策略，如果使用间隔策略可以像下面这样创建 Refill： Refill filler = Refill.intervally(5, Duration.ofMinutes(1)); 所谓间隔策略指的是每隔一段时间，一次性的填充所有令牌，比如上面的例子，会每隔一分钟，填充 5 个令牌，如下所示： intervally.png 而贪婪策略会尽可能贪婪的填充令牌，同样是上面的例子，会将一分钟划分成 5 个更小的时间单元，每隔 12 秒，填充 1 个令牌，如下所示： 在了解了 Bucket4j 中的几个核心概念之后，我们再来看看官网介绍的一些特性： 基于令牌桶算法 高性能，无锁实现 不存在精度问题，所有计算都是基于整型的 支持通过符合 JCache API 规范的分布式缓存系统实现分布式限流 支持为每个 Bucket 设置多个 Bandwidth 支持同步和异步 API 支持可插拔的监听 API，用于集成监控和日志 不仅可以用于限流，还可以用于简单的调度 Bucket4j 提供了丰富的文档，推荐在使用 Bucket4j 之前，先把官方文档中的 基本用法 和 高级特性 仔细阅读一遍。另外，关于 Bucket4j 的使用，推荐这篇文章 Rate limiting Spring MVC endpoints with bucket4j，这篇文章详细的讲解了如何在 Spring MVC 中使用拦截器和 Bucket4j 打造业务无侵入的限流方案，另外还讲解了如何使用 Hazelcast 实现分布式限流；另外，Rate Limiting a Spring API Using Bucket4j 这篇文章也是一份很好的入门教程，介绍了 Bucket4j 的基础知识，在文章的最后还提供了 Spring Boot Starter 的集成方式，结合 Spring Boot Actuator 很容易将限流指标集成到监控系统中。 和 Guava 的限流器相比，Bucket4j 的功能显然要更胜一筹，毕竟 Guava 的目的只是用作通用工具类，而不是用于限流的。使用 Bucket4j 基本上可以满足我们的大多数要求，不仅支持单机限流和分布式限流，而且可以很好的集成监控，搭配 Prometheus 和 Grafana 简直完美。值得一提的是，有很多开源项目譬如 JHipster API Gateway 就是使用 Bucket4j 来实现限流的。 Bucket4j 唯一不足的地方是它只支持请求频率限流，不支持并发量限流，另外还有一点，虽然 Bucket4j 支持分布式限流，但它是基于 Hazelcast 这样的分布式缓存系统实现的，不能使用 Redis，这在很多使用 Redis 作缓存的项目中就很不爽，所以我们还需要在开源的世界里继续探索。 3.3 Resilience4jResilience4j 是一款轻量级、易使用的高可用框架。用过 Spring Cloud 早期版本的同学肯定都听过 Netflix Hystrix，Resilience4j 的设计灵感就来自于它。自从 Hystrix 停止维护之后，官方也推荐大家使用 Resilience4j 来代替 Hystrix。 hystrix.png Resilience4j 的底层采用 Vavr，这是一个非常轻量级的 Java 函数式库，使得 Resilience4j 非常适合函数式编程。Resilience4j 以装饰器模式提供对函数式接口或 lambda 表达式的封装，提供了一波高可用机制：重试（Retry）、熔断（Circuit Breaker）、限流（Rate Limiter）、限时（Timer Limiter）、隔离（Bulkhead）、缓存（Caceh） 和 降级（Fallback）。我们重点关注这里的两个功能：限流（Rate Limiter） 和 隔离（Bulkhead），Rate Limiter 是请求频率限流，Bulkhead 是并发量限流。 Resilience4j 提供了两种限流的实现：SemaphoreBasedRateLimiter 和 AtomicRateLimiter。SemaphoreBasedRateLimiter 基于信号量实现，用户的每次请求都会申请一个信号量，并记录申请的时间，申请通过则允许请求，申请失败则限流，另外有一个内部线程会定期扫描过期的信号量并释放，很显然这是令牌桶的算法。AtomicRateLimiter 和上面的经典实现类似，不需要额外的线程，在处理每次请求时，根据距离上次请求的时间和生成令牌的速度自动填充。关于这二者的区别可以参考这篇文章 Rate Limiter Internals in Resilience4j。 Resilience4j 也提供了两种隔离的实现：SemaphoreBulkhead 和 ThreadPoolBulkhead，通过信号量或线程池控制请求的并发数，具体的用法参考官方文档，这里不再赘述。 下面是一个同时使用限流和隔离的例子： // 创建一个 Bulkhead，最大并发量为 150 BulkheadConfig bulkheadConfig = BulkheadConfig.custom() .maxConcurrentCalls(150) .maxWaitTime(100) .build(); Bulkhead bulkhead = Bulkhead.of(\"backendName\", bulkheadConfig); // 创建一个 RateLimiter，每秒允许一次请求 RateLimiterConfig rateLimiterConfig = RateLimiterConfig.custom() .timeoutDuration(Duration.ofMillis(100)) .limitRefreshPeriod(Duration.ofSeconds(1)) .limitForPeriod(1) .build(); RateLimiter rateLimiter = RateLimiter.of(\"backendName\", rateLimiterConfig); // 使用 Bulkhead 和 RateLimiter 装饰业务逻辑 Supplier&lt;String> supplier = () -> backendService.doSomething(); Supplier&lt;String> decoratedSupplier = Decorators.ofSupplier(supplier) .withBulkhead(bulkhead) .withRateLimiter(rateLimiter) .decorate(); // 调用业务逻辑 Try&lt;String> try = Try.ofSupplier(decoratedSupplier); assertThat(try.isSuccess()).isTrue(); Resilience4j 在功能特性上比 Bucket4j 强大不少，而且还支持并发量限流。不过最大的遗憾是，Resilience4j 不支持分布式限流。 3.4 其他网上还有很多限流相关的开源项目，不可能一一介绍，这里列出来的只是冰山之一角： https://github.com/mokies/ratelimitj https://github.com/wangzheng0822/ratelimiter4j https://github.com/wukq/rate-limiter https://github.com/marcosbarbero/spring-cloud-zuul-ratelimit https://github.com/onblog/SnowJena https://gitee.com/zhanghaiyang/spring-boot-starter-current-limiting https://github.com/Netflix/concurrency-limits 可以看出，限流技术在实际项目中应用非常广泛，大家对实现自己的限流算法乐此不疲，新算法和新实现层出不穷。但是找来找去，目前还没有找到一款开源项目完全满足我的需求。 我的需求其实很简单，需要同时满足两种不同的限流场景：请求频率限流和并发量限流，并且能同时满足两种不同的限流架构：单机限流和分布式限流。下面我们就开始在 Spring Cloud Gateway 中实现这几种限流，通过前面介绍的那些项目，我们取长补短，基本上都能用比较成熟的技术实现，只不过对于最后一种情况，分布式并发量限流，网上没有搜到现成的解决方案，在和同事讨论了几个晚上之后，想出一种新型的基于双窗口滑动的限流算法，我在这里抛砖引玉，欢迎大家批评指正，如果大家有更好的方法，也欢迎讨论。 四、在网关中实现限流在文章一开始介绍 Spring Cloud Gateway 的特性时，我们注意到其中有一条 Request Rate Limiting，说明网关自带了限流的功能，但是 Spring Cloud Gateway 自带的限流有很多限制，譬如不支持单机限流，不支持并发量限流，而且它的请求频率限流也是不尽人意，这些都需要我们自己动手来解决。 4.1 实现单机请求频率限流Spring Cloud Gateway 中定义了关于限流的一个接口 RateLimiter，如下： public interface RateLimiter&lt;C> extends StatefulConfigurable&lt;C> &#123; Mono&lt;RateLimiter.Response> isAllowed(String routeId, String id); &#125; 这个接口就一个方法 isAllowed，第一个参数 routeId 表示请求路由的 ID，根据 routeId 可以获取限流相关的配置，第二个参数 id 表示要限流的对象的唯一标识，可以是用户名，也可以是 IP，或者其他的可以从 ServerWebExchange 中得到的信息。我们看下 RequestRateLimiterGatewayFilterFactory 中对 isAllowed 的调用逻辑： @Override public GatewayFilter apply(Config config) &#123; // 从配置中得到 KeyResolver KeyResolver resolver = getOrDefault(config.keyResolver, defaultKeyResolver); // 从配置中得到 RateLimiter RateLimiter&lt;Object> limiter = getOrDefault(config.rateLimiter, defaultRateLimiter); boolean denyEmpty = getOrDefault(config.denyEmptyKey, this.denyEmptyKey); HttpStatusHolder emptyKeyStatus = HttpStatusHolder .parse(getOrDefault(config.emptyKeyStatus, this.emptyKeyStatusCode)); return (exchange, chain) -> resolver.resolve(exchange).defaultIfEmpty(EMPTY_KEY) .flatMap(key -> &#123; // 通过 KeyResolver 得到 key，作为唯一标识 id 传入 isAllowed() 方法 if (EMPTY_KEY.equals(key)) &#123; if (denyEmpty) &#123; setResponseStatus(exchange, emptyKeyStatus); return exchange.getResponse().setComplete(); &#125; return chain.filter(exchange); &#125; // 获取当前路由 ID，作为 routeId 参数传入 isAllowed() 方法 String routeId = config.getRouteId(); if (routeId == null) &#123; Route route = exchange .getAttribute(ServerWebExchangeUtils.GATEWAY_ROUTE_ATTR); routeId = route.getId(); &#125; return limiter.isAllowed(routeId, key).flatMap(response -> &#123; for (Map.Entry&lt;String, String> header : response.getHeaders() .entrySet()) &#123; exchange.getResponse().getHeaders().add(header.getKey(), header.getValue()); &#125; // 请求允许，直接走到下一个 filter if (response.isAllowed()) &#123; return chain.filter(exchange); &#125; // 请求被限流，返回设置的 HTTP 状态码（默认是 429） setResponseStatus(exchange, config.getStatusCode()); return exchange.getResponse().setComplete(); &#125;); &#125;); &#125; 从上面的逻辑可以看出，通过实现 KeyResolver 接口的 resolve 方法就可以自定义要限流的对象了。 public interface KeyResolver &#123; Mono&lt;String> resolve(ServerWebExchange exchange); &#125; 比如下面的 HostAddrKeyResolver 可以根据 IP 来限流： public class HostAddrKeyResolver implements KeyResolver &#123; @Override public Mono&lt;String> resolve(ServerWebExchange exchange) &#123; return Mono.just(exchange.getRequest().getRemoteAddress().getAddress().getHostAddress()) &#125; &#125; 我们继续看 Spring Cloud Gateway 的代码发现，RateLimiter 接口只提供了一个实现类 RedisRateLimiter： redis-rate-limiter.png 很显然是基于 Redis 实现的限流，虽说通过 Redis 也可以实现单机限流，但是总感觉有些大材小用，而且对于那些没有 Redis 的环境很不友好。所以，我们要实现真正的本地限流。 我们从 Spring Cloud Gateway 的 pull request 中发现了一个新特性 Feature/local-rate-limiter，而且看提交记录，这个新特性很有可能会合并到 3.0.0 版本中。我们不妨来看下这个 local-rate-limiter 的实现：LocalRateLimiter.java，可以看出它是基于 Resilience4j 实现的： public Mono&lt;Response> isAllowed(String routeId, String id) &#123; Config routeConfig = loadConfiguration(routeId); // How many requests per second do you want a user to be allowed to do? int replenishRate = routeConfig.getReplenishRate(); // How many seconds for a token refresh? int refreshPeriod = routeConfig.getRefreshPeriod(); // How many tokens are requested per request? int requestedTokens = routeConfig.getRequestedTokens(); final io.github.resilience4j.ratelimiter.RateLimiter rateLimiter = RateLimiterRegistry .ofDefaults() .rateLimiter(id, createRateLimiterConfig(refreshPeriod, replenishRate)); final boolean allowed = rateLimiter.acquirePermission(requestedTokens); final Long tokensLeft = (long) rateLimiter.getMetrics().getAvailablePermissions(); Response response = new Response(allowed, getHeaders(routeConfig, tokensLeft)); return Mono.just(response); &#125; 有意思的是，这个类 还有一个早期版本，是基于 Bucket4j 实现的： public Mono&lt;Response> isAllowed(String routeId, String id) &#123; Config routeConfig = loadConfiguration(routeId); // How many requests per second do you want a user to be allowed to do? int replenishRate = routeConfig.getReplenishRate(); // How much bursting do you want to allow? int burstCapacity = routeConfig.getBurstCapacity(); // How many tokens are requested per request? int requestedTokens = routeConfig.getRequestedTokens(); final Bucket bucket = bucketMap.computeIfAbsent(id, (key) -> createBucket(replenishRate, burstCapacity)); final boolean allowed = bucket.tryConsume(requestedTokens); Response response = new Response(allowed, getHeaders(routeConfig, bucket.getAvailableTokens())); return Mono.just(response); &#125; 实现方式都是类似的，在上面对 Bucket4j 和 Resilience4j 已经作了比较详细的介绍，这里不再赘述。不过从这里也可以看出 Spring 生态圈对 Resilience4j 是比较看好的，我们也可以将其引入到我们的项目中。 4.2 实现分布式请求频率限流上面介绍了如何实现单机请求频率限流，接下来再看下分布式请求频率限流。这个就比较简单了，因为上面说了，Spring Cloud Gateway 自带了一个限流实现，就是 RedisRateLimiter，可以用于分布式限流。它的实现原理依然是基于令牌桶算法的，不过实现逻辑是放在一段 lua 脚本中的，我们可以在 src/main/resources/META-INF/scripts 目录下找到该脚本文件 request_rate_limiter.lua： local tokens_key = KEYS[1] local timestamp_key = KEYS[2] local rate = tonumber(ARGV[1]) local capacity = tonumber(ARGV[2]) local now = tonumber(ARGV[3]) local requested = tonumber(ARGV[4]) local fill_time = capacity/rate local ttl = math.floor(fill_time*2) local last_tokens = tonumber(redis.call(\"get\", tokens_key)) if last_tokens == nil then last_tokens = capacity end local last_refreshed = tonumber(redis.call(\"get\", timestamp_key)) if last_refreshed == nil then last_refreshed = 0 end local delta = math.max(0, now-last_refreshed) local filled_tokens = math.min(capacity, last_tokens+(delta*rate)) local allowed = filled_tokens >= requested local new_tokens = filled_tokens local allowed_num = 0 if allowed then new_tokens = filled_tokens - requested allowed_num = 1 end if ttl > 0 then redis.call(\"setex\", tokens_key, ttl, new_tokens) redis.call(\"setex\", timestamp_key, ttl, now) end return &#123; allowed_num, new_tokens &#125; 这段代码和上面介绍令牌桶算法时用 Java 实现的那段经典代码几乎是一样的。这里使用 lua 脚本，主要是利用了 Redis 的单线程特性，以及执行 lua 脚本的原子性，避免了并发访问时可能出现请求量超出上限的现象。想象目前令牌桶中还剩 1 个令牌，此时有两个请求同时到来，判断令牌是否足够也是同时的，两个请求都认为还剩 1 个令牌，于是两个请求都被允许了。 有两种方式来配置 Spring Cloud Gateway 自带的限流。第一种方式是通过配置文件，比如下面所示的代码，可以对某个 route 进行限流： spring: cloud: gateway: routes: - id: test uri: http://httpbin.org:80/get filters: - name: RequestRateLimiter args: key-resolver: '#&#123;@hostAddrKeyResolver&#125;' redis-rate-limiter.replenishRate: 1 其中，key-resolver 使用 SpEL 表达式 #&#123;@beanName&#125; 从 Spring 容器中获取 hostAddrKeyResolver 对象，burstCapacity 表示令牌桶的大小，replenishRate 表示每秒往桶中填充多少个令牌，也就是填充速度。 第二种方式是通过下面的代码来配置： @Bean public RouteLocator myRoutes(RouteLocatorBuilder builder) &#123; return builder.routes() .route(p -> p .path(\"/get\") .filters(filter -> filter.requestRateLimiter() .rateLimiter(RedisRateLimiter.class, rl -> rl.setBurstCapacity(3).setReplenishRate(1)).and()) .uri(\"http://httpbin.org:80\")) .build(); &#125; 这样就可以对某个 route 进行限流了。但是这里有一点要注意，Spring Cloud Gateway 自带的限流器有一个很大的坑，replenishRate 不支持设置小数，也就是说往桶中填充的 token 的速度最少为每秒 1 个，所以，如果我的限流规则是每分钟 10 个请求（按理说应该每 6 秒填充一次，或每秒填充 1/6 个 token），这种情况 Spring Cloud Gateway 就没法正确的限流。网上也有人提了 issue，support greater than a second resolution for the rate limiter，但还没有得到解决。 4.3 实现单机并发量限流上面学习 Resilience4j 的时候，我们提到了 Resilience4j 的一个功能特性，叫 隔离（Bulkhead）。Bulkhead 这个单词的意思是船的舱壁，利用舱壁可以将不同的船舱隔离起来，这样如果一个船舱破损进水，那么只损失这一个船舱，其它船舱可以不受影响。借鉴造船行业的经验，这种模式也被引入到软件行业，我们把它叫做 舱壁模式（Bulkhead pattern）。舱壁模式一般用于服务隔离，对于一些比较重要的系统资源，如 CPU、内存、连接数等，可以为每个服务设置各自的资源限制，防止某个异常的服务把系统的所有资源都消耗掉。这种服务隔离的思想同样可以用来做并发量限流。 正如前文所述，Resilience4j 提供了两种 Bulkhead 的实现：SemaphoreBulkhead 和 ThreadPoolBulkhead，这也正是舱壁模式常见的两种实现方案：一种是带计数的信号量，一种是固定大小的线程池。考虑到多线程场景下的线程切换成本，默认推荐使用信号量。 在操作系统基础课程中，我们学习过两个名词：互斥量（Mutex） 和 信号量（Semaphores）。互斥量用于线程的互斥，它和临界区有点相似，只有拥有互斥对象的线程才有访问资源的权限，由于互斥对象只有一个，因此任何情况下只会有一个线程在访问此共享资源，从而保证了多线程可以安全的访问和操作共享资源。而信号量是用于线程的同步，这是由荷兰科学家 E.W.Dijkstra 提出的概念，它和互斥量不同，信号允许多个线程同时使用共享资源，但是它同时设定了访问共享资源的线程最大数目，从而可以进行并发量控制。 下面是使用信号量限制并发访问的一个简单例子： public class SemaphoreTest &#123; private static ExecutorService threadPool = Executors.newFixedThreadPool(100); private static Semaphore semaphore = new Semaphore(10); public static void main(String[] args) &#123; for (int i = 0; i &lt; 100; i++) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; semaphore.acquire(); System.out.println(\"Request processing ...\"); semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStack(); &#125; &#125; &#125;); &#125; threadPool.shutdown(); &#125; &#125; 这里我们创建了 100 个线程同时执行，但是由于信号量计数为 10，所以同时只能有 10 个线程在处理请求。说到计数，实际上，在 Java 里除了 Semaphore 还有很多类也可以用作计数，比如 AtomicLong 或 LongAdder，这在并发量限流中非常常见，只是无法提供像信号量那样的阻塞能力： public class AtomicLongTest &#123; private static ExecutorService threadPool = Executors.newFixedThreadPool(100); private static AtomicLong atomic = new AtomicLong(); public static void main(String[] args) &#123; for (int i = 0; i &lt; 100; i++) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; if(atomic.incrementAndGet() > 10) &#123; System.out.println(\"Request rejected ...\"); return; &#125; System.out.println(\"Request processing ...\"); atomic.decrementAndGet(); &#125; catch (InterruptedException e) &#123; e.printStack(); &#125; &#125; &#125;); &#125; threadPool.shutdown(); &#125; &#125; 4.4 实现分布式并发量限流通过在单机实现并发量限流，我们掌握了几种常用的手段：信号量、线程池、计数器，这些都是单机上的概念。那么稍微拓展下，如果能实现分布式信号量、分布式线程池、分布式计数器，那么实现分布式并发量限流不就易如反掌了吗？ 关于分布式线程池，是我自己杜撰的词，在网上并没有找到类似的概念，比较接近的概念是资源调度和分发，但是又感觉不像，这里直接忽略吧。 关于分布式信号量，还真有这样的东西，比如 Apache Ignite 就提供了 IgniteSemaphore 用于创建分布式信号量，它的使用方式和 Semaphore 非常类似，参考这里。使用 Redis 的 ZSet 也可以实现分布式信号量，比如 这篇博客介绍的方法，还有《Redis in Action》这本电子书中也提到了这样的例子，教你如何实现 Counting semaphores。另外，Redisson 也实现了基于 Redis 的分布式信号量 RSemaphore，用法也和 Semaphore 类似。使用分布式信号量可以很容易实现分布式并发量限流，实现方式和上面的单机并发量限流几乎是一样的。 最后，关于分布式计数器，实现方案也是多种多样。比如使用 Redis 的 INCR 就很容易实现，更有甚者，使用 MySQL 数据库也可以实现。只不过使用计数器要注意操作的原子性，每次请求时都要经过这三步操作：取计数器当前的值、判断是否超过阈值，超过则拒绝、将计数器的值自增。这其实和信号量的 P 操作是一样的，而释放就对应 V 操作。 所以，利用分布式信号量和计数器就可以实现并发量限流了吗？问题当然没有这么简单。实际上，上面通过信号量和计数器实现单机并发量限流的代码片段有一个严重 BUG： semaphore.acquire(); System.out.println(\"Request processing ...\"); semaphore.release(); 想象一下如果在处理请求时出现异常了会怎么样？很显然，信号量被该线程获取了，但是却永远不会释放，如果请求异常多了，这将导致信号量被占满，最后一个请求也进不来。在单机场景下，这个问题可以很容易解决，加一个 finally 就行了： try &#123; semaphore.acquire(); System.out.println(\"Request processing ...\"); &#125; catch (InterruptedException e) &#123; e.printStack(); &#125; finally &#123; semaphore.release(); &#125; 由于无论出现何种异常，finally 中的代码一定会执行，这样就保证了信号量一定会被释放。但是在分布式系统中，就不是加一个 finally 这么简单了。这是因为在分布式系统中可能存在的异常不一定是可被捕获的代码异常，还有可能是服务崩溃或者不可预知的系统宕机，就算是正常的服务重启也可能导致分布式信号量无法释放。 对于这个问题，我和几个同事连续讨论了几个晚上，想出了两种解决方法：第一种方法是使用带 TTL 的计数器，第二种方法是基于双窗口滑动的一种比较 tricky 的算法。 第一种方法比较容易理解，我们为每个请求赋予一个唯一 ID，并在 Redis 里写入一个键值对，key 为 requests_xxx（xxx 为请求 ID），value 为 1，并给这个 key 设置一个 TTL（如果你的应用中存在耗时非常长的请求，譬如对于一些 WebSockket 请求可能会持续几个小时，还需要开一个线程定期去刷新这个 key 的 TTL）。然后在判断并发量时，使用 KEYS 命令查询 requests_* 开头的 key 的个数，就可以知道当前一共有多少个请求，如果超过并发量上限则拒绝请求。这种方法可以很好的应对服务崩溃或重启的问题，由于每个 key 都设置了 TTL，所以经过一段时间后，这些 key 就会自动消失，就不会出现信号量占满不释放的情况了。但是这里使用 KEYS 命令查询请求个数是一个非常低效的做法，在请求量比较多的情况下，网关的性能会受到严重影响。我们可以把 KEYS 命令换成 SCAN，性能会得到些许提升，但总体来说效果还是很不理想的。 针对第一种方法，我们可以进一步优化，不用为每个请求写一个键值对，而是为每个分布式系统中的每个实例赋予一个唯一 ID，并在 Redis 里写一个键值对，key 为 instances_xxx（xxx 为实例 ID），value 为这个实例当前的并发量。同样的，我们为这个 key 设置一个 TTL，并且开启一个线程定期去刷新这个 TTL。每接受一个请求后，计数器加一，请求结束，计数器减一，这和单机场景下的处理方式一样，只不过在判断并发量时，还是需要使用 KEYS 或 SCAN 获取所有的实例，并计算出并发量的总和。不过由于实例个数是有限的，性能比之前的做法有了明显的提升。 第二种方法我称之为 双窗口滑动算法，结合了 TTL 计数器和滑动窗口算法。我们按分钟来设置一个时间窗口，在 Redis 里对应 202009051130 这样的一个 key，value 为计数器，表示请求的数量。当接受一个请求后，在当前的时间窗口中加一，当请求结束，在当前的时间窗口中减一，注意，接受请求和请求结束的时间窗口可能不是同一个。另外，我们还需要一个本地列表来记录当前实例正在处理的所有请求和请求对应的时间窗口，并通过一个小于时间窗口的定时线程（如 30 秒）来迁移过期的请求，所谓过期，指的是请求的时间窗口和当前时间窗口不一致。那么具体如何迁移呢？我们首先需要统计列表中一共有多少请求过期了，然后将列表中的过期请求时间更新为当前时间窗口，并从 Redis 中上一个时间窗口移动相应数量到当前时间窗口，也就是上一个时间窗口减 X，当前时间窗口加 X。由于迁移线程定期执行，所以过期的请求总是会被移动到当前窗口，最终 Redis 中只有当前时间窗口和上个时间窗口这两个时间窗口中有数据，再早一点的窗口时间中的数据会被往后迁移，所以可以给这个 key 设置一个 3 分钟或 5 分钟的 TTL。判断并发量时，由于只有两个 key，只需要使用 MGET 获取两个值相加即可。下面的流程图详细描述了算法的运行过程： 其中有几个需要注意的细节： 请求结束时，直接在 Redis 中当前时间窗口减一即可，就算是负数也没关系。请求列表中的该请求不用急着删除，可以打上结束标记，在迁移线程中统一删除（当然，如果请求的开始时间和结束时间在同一个窗口，可以直接删除）； 迁移的时间间隔要小于时间窗口，一般设置为 30s； Redis 中的 key 一定要设置 TTL，时间至少为 2 个时间窗口，一般设置为 3 分钟； 迁移过程涉及到“从上一个时间窗口减”和“在当前时间窗口加”两个操作，要注意操作的原子性； 获取当前并发量可以通过 MGET 一次性读取两个时间窗口的值，不用 GET 两次； 获取并发量和判断并发量是否超限，这个过程也要注意操作的原子性。 总结网关作为微服务架构中的重要一环，充当着一夫当关万夫莫开的角色，所以对网关服务的稳定性要求和性能要求都非常高。为保证网关服务的稳定性，一代又一代的程序员们前仆后继，想出了十八般武艺：限流、熔断、隔离、缓存、降级、等等等等。这篇文章从限流入手，详细介绍了限流的场景和算法，以及源码实现和可能踩到的坑。尽管限流只是网关的一个非常小的功能，但却影响到网关的方方面面，在系统架构的设计中至关重要。虽然我试着从不同的角度希望把限流介绍的更完全，但终究是管中窥豹，只见一斑，还有很多的内容没有介绍到，比如阿里开源的 Sentinel 组件也可以用于限流，因为篇幅有限未能展开。另外前文提到的 Netflix 不再维护 Hystrix 项目，这是因为他们把精力放到另一个限流项目 concurrency-limits 上了，这个项目的目标是打造一款自适应的，极具弹性的限流组件，它借鉴了 TCP 拥塞控制的算法（TCP congestion control algorithm），实现系统的自动限流，感兴趣的同学可以去它的项目主页了解更多内容。 参考 https://blog.csdn.net/weixin_38405253/article/details/108891772","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"},{"name":"SpringCloudGateway","slug":"SpringCloudGateway","permalink":"http://wumuwumu.github.io/tags/SpringCloudGateway/"}]},{"title":"SpringCloudGateway基础操作-熔断","date":"2021-01-26T07:00:00.000Z","path":"posts/9ab7b27c.html","text":"微服务系统中熔断限流环节，对保护系统的稳定性起到了很大的作用，作为网关，Spring Cloud Gateway也提供了很好的支持。先来理解下熔断限流概念： 熔断降级：在分布式系统中，网关作为流量的入口，大量请求进入网关，向后端远程系统或服务发起调用，后端服务不可避免的会产生调用失败（超时或者异常），失败时不能让请求堆积在网关上，需要快速失败并返回回去，这就需要在网关上做熔断、降级操作。 限流：网关上有大量请求，对指定服务进行限流，可以很大程度上提高服务的可用性与稳定性，限流的目的是通过对并发访问/请求进行限速，或对一个时间窗口内的请求进行限速来保护系统。一旦达到限制速率则可以拒绝服务、排队或等待、降级。 下文就网关如何进行超时熔断、异常熔断和访问限流进行示例说明。示例包含两个模块项目，一个为网关项目gateway，一个为下游业务项目downstream。 超时异常熔断构建网关目：pom.xml &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-dependencies&lt;/artifactId> &lt;version>$&#123;spring.boot.version&#125;&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>$&#123;spring.cloud.version&#125;&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>io.spring.platform&lt;/groupId> &lt;artifactId>platform-bom&lt;/artifactId> &lt;version>$&#123;spring.platform.version&#125;&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-gateway&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;/dependencies> application.yml server: port: 8089 spring: application: name: spring-cloud-gateway cloud: gateway: routes: - id: service_customer #下游服务地址 uri: http://127.0.0.1:8083/ order: 0 #网关断言匹配 predicates: - Path=/gateway/** filters: #熔断过滤器 - name: Hystrix args: name: fallbackcmd fallbackUri: forward:/defaultfallback - StripPrefix=1 #熔断器配置 hystrix: command: default: execution: isolation: strategy: SEMAPHORE thread: timeoutInMilliseconds: 3000 shareSecurityContext: true #网关日志输出 logging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUG 以上配置的意思是： 网关服务以端口8089暴露 访问http://127.0.0.1:8089/gateway/开头的请求，将都被路由到下游http://127.0.0.1:8083/下，且gateway部分将被移除（StripPrefix=1）。比如http://127.0.0.1:8089/gateway/test —-&gt; http://127.0.0.1:8083/test 超时异常熔断采用hystrix的SEMAPHORE策略，超时时间为3秒，如果下游服务不可达（异常），将由fallbackcmd处理，路由到本地http://127.0.0.1:8089/defaultfallback 处理。 构建defaultfallback处理器@RestController public class SelfHystrixController &#123; @RequestMapping(\"/defaultfallback\") public Map&lt;String,String> defaultfallback()&#123; System.out.println(\"请求被熔断.\"); Map&lt;String,String> map = new HashMap&lt;>(); map.put(\"Code\",\"fail\"); map.put(\"Message\",\"服务异常\"); map.put(\"result\",\"\"); return map; &#125; &#125; 先不构建下游服务，直接运行网关，访问地址http://127.0.0.1:8089/gateway/test，出现如下情况： 构建下游服务项目，该项目为简单的spring boot web项目，具体配置不详述，添加服务类： @RestController public class TestController &#123; @RequestMapping(\"/timeout\") public String timeout(String name) &#123; try &#123; Thread.sleep(5000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return \"timeout params:\" + name; &#125; &#125; 参考 https://www.jianshu.com/p/b58c13b227bf","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"},{"name":"SpringCloudGateway","slug":"SpringCloudGateway","permalink":"http://wumuwumu.github.io/tags/SpringCloudGateway/"}]},{"title":"SpringCloudGateway总结","date":"2021-01-25T11:00:00.000Z","path":"posts/8ca623b6.html","text":"过滤器的常用功能 黑名单、白名单 数据转换（将请求头转换成请求参数） 数据统计 限流 服务降级HystrixSentinel","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"},{"name":"SpringCloudGateway","slug":"SpringCloudGateway","permalink":"http://wumuwumu.github.io/tags/SpringCloudGateway/"}]},{"title":"SpringCloudGateway基本操作-限流","date":"2021-01-25T10:00:00.000Z","path":"posts/384ef433.html","text":"在高并发的应用中，限流是一个绕不开的话题。限流可以保障我们的 API 服务对所有用户的可用性，也可以防止网络攻击。 一般开发高并发系统常见的限流有：限制总并发数（比如数据库连接池、线程池）、限制瞬时并发数（如 nginx 的 limit_conn 模块，用来限制瞬时并发连接数）、限制时间窗口内的平均速率（如 Guava 的 RateLimiter、nginx 的 limit_req 模块，限制每秒的平均速率）；其他还有如限制远程接口调用速率、限制 MQ 的消费速率。另外还可以根据网络连接数、网络流量、CPU 或内存负载等来限流。 本文详细探讨在 Spring Cloud Gateway 中如何实现限流。 限流算法做限流 (Rate Limiting/Throttling) 的时候，除了简单的控制并发，如果要准确的控制 TPS，简单的做法是维护一个单位时间内的 Counter，如判断单位时间已经过去，则将 Counter 重置零。此做法被认为没有很好的处理单位时间的边界，比如在前一秒的最后一毫秒里和下一秒的第一毫秒都触发了最大的请求数，也就是在两毫秒内发生了两倍的 TPS。 常用的更平滑的限流算法有两种：漏桶算法和令牌桶算法。很多传统的服务提供商如华为中兴都有类似的专利，参考采用令牌漏桶进行报文限流的方法。 漏桶算法漏桶（Leaky Bucket）算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水（接口有响应速率），当水流入速度过大会直接溢出（访问频率超过接口响应速率），然后就拒绝请求，可以看出漏桶算法能强行限制数据的传输速率。 Leaky Bucket 可见这里有两个变量，一个是桶的大小，支持流量突发增多时可以存多少的水（burst），另一个是水桶漏洞的大小（rate）。因为漏桶的漏出速率是固定的参数，所以，即使网络中不存在资源冲突（没有发生拥塞），漏桶算法也不能使流突发（burst）到端口速率。因此，漏桶算法对于存在突发特性的流量来说缺乏效率。 令牌桶算法令牌桶算法（Token Bucket）和 Leaky Bucket 效果一样但方向相反的算法，更加容易理解。随着时间流逝，系统会按恒定 1/QPS 时间间隔（如果 QPS=100，则间隔是 10ms）往桶里加入 Token（想象和漏洞漏水相反，有个水龙头在不断的加水），如果桶已经满了就不再加了。新请求来临时，会各自拿走一个 Token，如果没有 Token 可拿了就阻塞或者拒绝服务。 Token Bucket 令牌桶的另外一个好处是可以方便的改变速度。一旦需要提高速率，则按需提高放入桶中的令牌的速率。一般会定时（比如 100 毫秒）往桶中增加一定数量的令牌，有些变种算法则实时的计算应该增加的令牌的数量。 Guava 中的 RateLimiter 采用了令牌桶的算法，设计思路参见 How is the RateLimiter designed, and why?，详细的算法实现参见源码。 Leakly Bucket vs Token Bucket 对比项 Leakly bucket Token bucket Token bucket 的备注 依赖 token 否 是 立即执行 是 否 有足够的 token 才能执行 堆积 token 否 是 速率恒定 是 否 可以大于设定的 QPS 限流实现在 Gateway 上实现限流是个不错的选择，只需要编写一个过滤器就可以了。有了前边过滤器的基础，写起来很轻松。（如果你对 Spring Cloud Gateway 的过滤器还不了解，请先看这里） 我们这里采用令牌桶算法，Google Guava 的RateLimiter、Bucket4j、RateLimitJ 都是一些基于此算法的实现，只是他们支持的 back-ends（JCache、Hazelcast、Redis 等）不同罢了，你可以根据自己的技术栈选择相应的实现。 这里我们使用 Bucket4j，引入它的依赖坐标，为了方便顺便引入 Lombok &lt;dependency> &lt;groupId>com.github.vladimir-bukhtoyarov&lt;/groupId> &lt;artifactId>bucket4j-core&lt;/artifactId> &lt;version>4.0.0&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;version>1.16.20&lt;/version> &lt;scope>provided&lt;/scope> &lt;/dependency> 我们来实现具体的过滤器 @CommonsLog @Builder @Data @AllArgsConstructor @NoArgsConstructor public class RateLimitByIpGatewayFilter implements GatewayFilter，Ordered &#123; int capacity; int refillTokens; Duration refillDuration; private static final Map&lt;String，Bucket> CACHE = new ConcurrentHashMap&lt;>(); private Bucket createNewBucket() &#123; Refill refill = Refill.of(refillTokens，refillDuration); Bandwidth limit = Bandwidth.classic(capacity，refill); return Bucket4j.builder().addLimit(limit).build(); &#125; @Override public Mono&lt;Void> filter(ServerWebExchange exchange，GatewayFilterChain chain) &#123; // if (!enableRateLimit)&#123; // return chain.filter(exchange); // &#125; String ip = exchange.getRequest().getRemoteAddress().getAddress().getHostAddress(); Bucket bucket = CACHE.computeIfAbsent(ip，k -> createNewBucket()); log.debug(\"IP: \" + ip + \"，TokenBucket Available Tokens: \" + bucket.getAvailableTokens()); if (bucket.tryConsume(1)) &#123; return chain.filter(exchange); &#125; else &#123; exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS); return exchange.getResponse().setComplete(); &#125; &#125; @Override public int getOrder() &#123; return -1000; &#125; &#125; 通过对令牌桶算法的了解，我们知道需要定义三个变量： capacity：桶的最大容量，即能装载 Token 的最大数量 refillTokens：每次 Token 补充量 refillDuration：补充 Token 的时间间隔 在这个实现中，我们使用了 IP 来进行限制，当达到最大流量就返回429错误。这里我们简单使用一个 Map 来存储 bucket，所以也决定了它只能单点使用，如果是分布式的话，可以采用 Hazelcast 或 Redis 等解决方案。 在 Route 中我们添加这个过滤器，这里指定了 bucket 的容量为 10 且每一秒会补充 1 个 Token。 .route(r -> r.path(\"/throttle/customer/**\") .filters(f -> f.stripPrefix(2) .filter(new RateLimitByIpGatewayFilter(10，1，Duration.ofSeconds(1)))) .uri(\"lb://CONSUMER\") .order(0) .id(\"throttle_customer_service\") ) 启动服务并多次快速刷新改接口，就会看到 Tokens 的数量在不断减小，等一会又会增加上来 2018-05-09 15:42:08.601 DEBUG 96278 --- [ctor-http-nio-2] com.yibo.filter.RateLimitByIpGatewayFilter : IP: 0:0:0:0:0:0:0:1，TokenBucket Available Tokens: 2 2018-05-09 15:42:08.958 DEBUG 96278 --- [ctor-http-nio-2] com.yibo.filter.RateLimitByIpGatewayFilter : IP: 0:0:0:0:0:0:0:1，TokenBucket Available Tokens: 1 2018-05-09 15:42:09.039 DEBUG 96278 --- [ctor-http-nio-2] com.yibo.filter.RateLimitByIpGatewayFilter : IP: 0:0:0:0:0:0:0:1，TokenBucket Available Tokens: 0 2018-05-09 15:42:10.201 DEBUG 96278 --- [ctor-http-nio-2] com.yibo.filter.RateLimitByIpGatewayFilter : IP: 0:0:0:0:0:0:0:1，TokenBucket Available Tokens: 1 RequestRateLimiter刚刚我们通过过滤器实现了限流的功能，你可能在想为什么不直接创建一个过滤器工厂呢，那样多方便。这是因为 Spring Cloud Gateway 已经内置了一个RequestRateLimiterGatewayFilterFactory，我们可以直接使用（这里有坑，后边详说）。 目前RequestRateLimiterGatewayFilterFactory的实现依赖于 Redis，所以我们还要引入spring-boot-starter-data-redis-reactive &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis-reactive&lt;/artifactId> &lt;/dependency> 因为这里有坑，所以把 application.yml 的配置再全部贴一遍，新增的部分我已经用# ---标出来了 spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true routes: - id: service_customer uri: lb://CONSUMER order: 0 predicates: - Path=/customer/** filters: - StripPrefix=1 # ------- - name: RequestRateLimiter args: key-resolver: '#&#123;@remoteAddrKeyResolver&#125;' redis-rate-limiter.replenishRate: 1 redis-rate-limiter.burstCapacity: 5 # ------- - AddResponseHeader=X-Response-Default-Foo，Default-Bar default-filters: - Elapsed=true # ------- redis: host: localhost port: 6379 database: 0 # ------- server: port: 10000 eureka: client: service-url: defaultZone: http://localhost:7000/eureka/ logging: level: org.springframework.cloud.gateway: debug com.yibo.filter: debug 默认情况下，是基于令牌桶算法实现的限流，有个三个参数需要配置： burstCapacity，令牌桶容量。 replenishRate，令牌桶每秒填充平均速率。 key-resolver，用于限流的键的解析器的 Bean 对象名字（有些绕，看代码吧）。它使用 SpEL 表达式根据#&#123;@beanName&#125;从 Spring 容器中获取 Bean 对象。默认情况下，使用PrincipalNameKeyResolver，以请求认证的java.security.Principal作为限流键。 关于filters的那段配置格式，参考这里 我们实现一个使用请求 IP 作为限流键的KeyResolver public class RemoteAddrKeyResolver implements KeyResolver &#123; public static final String BEAN_NAME = \"remoteAddrKeyResolver\"; @Override public Mono&lt;String> resolve(ServerWebExchange exchange) &#123; return Mono.just(exchange.getRequest().getRemoteAddress().getAddress().getHostAddress()); &#125; &#125; 配置RemoteAddrKeyResolver Bean 对象 @Bean(name = RemoteAddrKeyResolver.BEAN_NAME) public RemoteAddrKeyResolver remoteAddrKeyResolver() &#123; return new RemoteAddrKeyResolver(); &#125; 以上就是代码部分，我们还差一个 Redis，我就本地用 docker 来快速启动了 docker run --name redis -p 6379:6379 -d redis 万事俱备，只欠测试了。以上的代码的和配置都是 OK 的，可以自行测试。下面来说一下这里边的坑。 遇到的坑配置不生效参考这个 issue No Configuration found for route这个异常信息如下： java.lang.IllegalArgumentException: No Configuration found for route service_customer at org.springframework.cloud.gateway.filter.ratelimit.RedisRateLimiter.isAllowed(RedisRateLimiter.java:93) ~[spring-cloud-gateway-core-2.0.0.RC1.jar:2.0.0.RC1] Copy 出现在将 RequestRateLimiter 配置为 defaultFilters 的情况下，比如像这样 default-filters: - name: RequestRateLimiter args: key-resolver: '#&#123;@remoteAddrKeyResolver&#125;' redis-rate-limiter.replenishRate: 1 redis-rate-limiter.burstCapacity: 5 这时候就会导致这个异常。我通过分析源码，发现了一些端倪，感觉像是一个 bug，已经提交了 issue 我们从异常入手来看， RedisRateLimiter#isAllowed 这个方法要获取 routeId 对应的 routerConfig，如果获取不到就抛出刚才我们看到的那个异常。 public Mono&lt;Response> isAllowed(String routeId，String id) &#123; if (!this.initialized.get()) &#123; throw new IllegalStateException(\"RedisRateLimiter is not initialized\"); &#125; // 只为 defaultFilters 配置 RequestRateLimiter 的时候 // config map 里边的 key 只有 \"defaultFilters\" // 但是我们实际请求的 routeId 为 \"customer_service\" Config routeConfig = getConfig().get(routeId); if (routeConfig == null) &#123; if (defaultConfig == null) &#123; throw new IllegalArgumentException(\"No Configuration found for route \" + routeId); &#125; routeConfig = defaultConfig; &#125; // 省略若干代码... &#125; 既然这里要 get，那必然有个地方要 put。put 的相关代码在 AbstractRateLimiter#onApplicationEvent 这个方法。 @Override public void onApplicationEvent(FilterArgsEvent event) &#123; Map&lt;String，Object> args = event.getArgs(); // hasRelevantKey 检查 args 是否包含 configurationPropertyName // 只有 defaultFilters 包含 if (args.isEmpty() || !hasRelevantKey(args)) &#123; return; &#125; String routeId = event.getRouteId(); C routeConfig = newConfig(); ConfigurationUtils.bind(routeConfig，args, configurationPropertyName，configurationPropertyName，validator); getConfig().put(routeId，routeConfig); &#125; private boolean hasRelevantKey(Map&lt;String，Object> args) &#123; return args.keySet().stream() .anyMatch(key -> key.startsWith(configurationPropertyName + \".\")); &#125; 上边的 args 里是是配置参数的键值对，比如我们之前自定义的过滤器工厂Elapsed，有个参数withParams，这里就是withParams=true。关键代码在第 7 行，hasRelevantKey方法用于检测 args 里边是否包含configurationPropertyName.，具体到本例就是是否包含redis-rate-limiter.。悲剧就发生在这里，因为我们只为 defaultFilters 配置了相关 args，注定其他的 route 到这里就直接 return 了。 现在不清楚这是 bug 还是设计者有意为之，等答复吧。 基于系统负载的动态限流在实际工作中，我们可能还需要根据网络连接数、网络流量、CPU 或内存负载等来进行动态限流。在这里我们以 CPU 为栗子。 我们需要借助 Spring Boot Actuator 提供的 Metrics 能力进行实现基于 CPU 的限流——当 CPU 使用率高于某个阈值就开启限流，否则不开启限流。 我们在项目中引入 Actuator 的依赖坐标 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> 因为 Spring Boot 2.x 之后，Actuator 被重新设计了，和 1.x 的区别还是挺大的（参考这里）。我们先在配置中设置management.endpoints.web.exposure.include=*来观察一下新的 Metrics 的能力 http://localhost:10000/actuator/metrics &#123; \"names\": [ \"jvm.buffer.memory.used\", \"jvm.memory.used\", \"jvm.buffer.count\", \"jvm.gc.memory.allocated\", \"logback.events\", \"process.uptime\", \"jvm.memory.committed\", \"system.load.average.1m\", \"jvm.gc.pause\", \"jvm.gc.max.data.size\", \"jvm.buffer.total.capacity\", \"jvm.memory.max\", \"system.cpu.count\", \"system.cpu.usage\", \"process.files.max\", \"jvm.threads.daemon\", \"http.server.requests\", \"jvm.threads.live\", \"process.start.time\", \"jvm.classes.loaded\", \"jvm.classes.unloaded\", \"jvm.threads.peak\", \"jvm.gc.live.data.size\", \"jvm.gc.memory.promoted\", \"process.files.open\", \"process.cpu.usage\" ] &#125; 我们可以利用里边的系统 CPU 使用率system.cpu.usage http://localhost:10000/actuator/metrics/system.cpu.usage &#123; \"name\": \"system.cpu.usage\", \"measurements\": [ &#123; \"statistic\": \"VALUE\", \"value\": 0.5189003436426117 &#125; ], \"availableTags\": [] &#125; 最近一分钟内的平均负载system.load.average.1m也是一样的 http://localhost:10000/actuator/metrics/system.load.average.1m &#123; \"name\": \"system.load.average.1m\", \"measurements\": [ &#123; \"statistic\": \"VALUE\", \"value\": 5.33203125 &#125; ], \"availableTags\": [] &#125; 知道了 Metrics 提供的指标，我们就来看在代码里具体怎么实现吧。Actuator 2.x 里边已经没有了之前 1.x 里边提供的SystemPublicMetrics，但是经过阅读源码可以发现MetricsEndpoint这个类可以提供类似的功能。就用它来撸代码吧 @CommonsLog @Component public class RateLimitByCpuGatewayFilter implements GatewayFilter, Ordered &#123; @Autowired private MetricsEndpoint metricsEndpoint; private static final String METRIC_NAME = \"system.cpu.usage\"; private static final double MAX_USAGE = 0.50D; @Override public Mono&lt;Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; // if (!enableRateLimit)&#123; // return chain.filter(exchange); // &#125; Double systemCpuUsage = metricsEndpoint.metric(METRIC_NAME, null) .getMeasurements() .stream() .filter(Objects::nonNull) .findFirst() .map(MetricsEndpoint.Sample::getValue) .filter(Double::isFinite) .orElse(0.0D); boolean ok = systemCpuUsage &lt; MAX_USAGE; log.debug(\"system.cpu.usage: \" + systemCpuUsage + \" ok: \" + ok); if (!ok) &#123; exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS); return exchange.getResponse().setComplete(); &#125; else &#123; return chain.filter(exchange); &#125; &#125; @Override public int getOrder() &#123; return 0; &#125; &#125; 配置 Route @Autowired private RateLimitByCpuGatewayFilter rateLimitByCpuGatewayFilter; @Bean public RouteLocator customerRouteLocator(RouteLocatorBuilder builder) &#123; // @formatter:off return builder.routes() .route(r -> r.path(\"/throttle/customer/**\") .filters(f -> f.stripPrefix(2) .filter(rateLimitByCpuGatewayFilter)) .uri(\"lb://CONSUMER\") .order(0) .id(\"throttle_customer_service\") ) .build(); // @formatter:on &#125; 至于效果嘛，自己试试吧。因为 CPU 的使用率一般波动较大，测试效果还是挺明显的，实际使用就得慎重了。 示例代码可以从 Github 获取：https://github.com/zhaoyibo/spring-cloud-study 改进与提升实际项目中，除以上实现的限流方式，还可能会：一、在上文的基础上，增加配置项，控制每个路由的限流指标，并实现动态刷新，从而实现更加灵活的管理。二、实现不同维度的限流，例如： 对请求的目标 URL 进行限流（例如：某个 URL 每分钟只允许调用多少次） 对客户端的访问 IP 进行限流（例如：某个 IP 每分钟只允许请求多少次） 对某些特定用户或者用户组进行限流（例如：非 VIP 用户限制每分钟只允许调用 100 次某个 API 等） 多维度混合的限流。此时，就需要实现一些限流规则的编排机制（与、或、非等关系） 参考 https://www.haoyizebo.com/posts/ced8ea9/","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"},{"name":"SpringCloudGateway","slug":"SpringCloudGateway","permalink":"http://wumuwumu.github.io/tags/SpringCloudGateway/"}]},{"title":"SpringCloudGateway基本操作-动态路由","date":"2021-01-25T08:00:00.000Z","path":"posts/1322871c.html","text":"gateway配置路由主要有两种方式，一种是用yml配置文件，一种是写代码里，这两种方式都是不支持动态配置的。如： 下面就来看看gateway是如何加载这些配置信息的。 1 路由初始化无论是yml还是代码，这些配置最终都是被封装到RouteDefinition对象中。 一个RouteDefinition有个唯一的ID，如果不指定，就默认是UUID，多个RouteDefinition组成了gateway的路由系统。 所有路由信息在系统启动时就被加载装配好了，并存到了内存里。我们从源码来看看。 圆圈里就是装配yml文件的，它返回的是PropertiesRouteDefinitionLocator，该类继承了RouteDefinitionLocator，RouteDefinitionLocator就是路由的装载器，里面只有一个方法，就是获取路由信息的。该接口有多个实现类，分别对应不同方式配置的路由方式。 通过这几个实现类，再结合上面的AutoConfiguration里面的Primary信息，就知道加载配置信息的顺序。 PropertiesRouteDefinitionLocator–&gt;|配置文件加载初始化| CompositeRouteDefinitionLocatorRouteDefinitionRepository–&gt;|存储器中加载初始化| CompositeRouteDefinitionLocatorDiscoveryClientRouteDefinitionLocator–&gt;|注册中心加载初始化| CompositeRouteDefinitionLocator 参考：https://www.jianshu.com/p/b02c7495eb5e https://blog.csdn.net/X5fnncxzq4/article/details/80221488 这是第一顺序，就是从CachingRouteLocator中获取路由信息，我们可以打开该类进行验证。 不管发起什么请求，必然会走上面的断点处。请求一次，走一次。这是将路由信息缓存到了Map中。配置信息一旦请求过一次，就会被缓存到上图的CachingRouteLocator类中，再次发起请求后，会直接从map中读取。 如果想动态刷新配置信息，就需要发起一个RefreshRoutesEvent的事件，上图的cache会监听该事件，并重新拉取路由配置信息。 通过下图，可以看到如果没有RouteDefinitionRepository的实例，则默认用InMemoryRouteDefinitionRepository。而做动态路由的关键就在这里。即通过自定义的RouteDefinitionRepository类，来提供路由配置信息。 例如： 在getRouteDefinitions方法返回你自定义的路由配置信息即可。这里可以用数据库、nosql等等任意你喜欢的方式来提供。而且配置信息修改后，发起一次RefreshRoutesEvent事件即可让配置生效。这就是动态配置路由的核心所在，下面来看具体代码实现。 2 基于数据库、缓存的动态路由pom.xml如下 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.maimeng&lt;/groupId> &lt;artifactId>apigateway&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;packaging>jar&lt;/packaging> &lt;name>apigateway&lt;/name> &lt;description>Demo project for Spring Boot&lt;/description> &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.0.6.RELEASE&lt;/version> &lt;relativePath/> &lt;!-- lookup parent from repository --> &lt;/parent> &lt;properties> &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF-8&lt;/project.reporting.outputEncoding> &lt;java.version>1.8&lt;/java.version> &lt;spring-cloud.version>Finchley.SR1&lt;/spring-cloud.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-gateway&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-webflux&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;version>1.2.51&lt;/version> &lt;/dependency> &lt;!--&lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;scope>runtime&lt;/scope> &lt;/dependency>--> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>$&#123;spring-cloud.version&#125;&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> 注意这里是SR1，经测试SR2有bug，会出问题。 @Configuration public class RedisConfig &#123; @Bean(name = &#123;\"redisTemplate\", \"stringRedisTemplate\"&#125;) public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory factory) &#123; StringRedisTemplate redisTemplate = new StringRedisTemplate(); redisTemplate.setConnectionFactory(factory); return redisTemplate; &#125; &#125; 核心类： @Component public class RedisRouteDefinitionRepository implements RouteDefinitionRepository &#123; public static final String GATEWAY_ROUTES = \"geteway_routes\"; @Resource private StringRedisTemplate redisTemplate; @Override public Flux&lt;RouteDefinition> getRouteDefinitions() &#123; List&lt;RouteDefinition> routeDefinitions = new ArrayList&lt;>(); redisTemplate.opsForHash().values(GATEWAY_ROUTES).stream() .forEach(routeDefinition -> routeDefinitions.add(JSON.parseObject(routeDefinition.toString(), RouteDefinition.class))); return Flux.fromIterable(routeDefinitions); &#125; @Override public Mono&lt;Void> save(Mono&lt;RouteDefinition> route) &#123; return null; &#125; @Override public Mono&lt;Void> delete(Mono&lt;String> routeId) &#123; return null; &#125; &#125; 主要是在get方法里，此处从redis里获取配置好的Definition。 然后我们的工作就是将配置信息，放到redis里即可。 下面就是我模拟的一个配置，等同于在yml里 spring: cloud: gateway: routes: - id: header uri: http://localhost:8888/header filters: - AddRequestHeader=header, addHeader - AddRequestParameter=param, addParam predicates: - Path=/jd 定义好后，将其放到redis里，之后启动项目访问/jd，再启动后台的localhost:8888项目。即可进行验证。 之后如果要动态修改配置，就可以通过类似于上面的方式，来获取json字符串，然后将字符串放到redis里进行替换。替换后，需要通知gateway主动刷新一下。 刷新时，可以定义一个controller，然后调用一下notifyChanged()方法，就能完成新配置的替换了。 参考 https://blog.csdn.net/tianyaleixiaowu/article/details/83412301 https://www.haoyizebo.com/posts/1962f450/","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"},{"name":"SpringCloudGateway","slug":"SpringCloudGateway","permalink":"http://wumuwumu.github.io/tags/SpringCloudGateway/"}]},{"title":"SpringCloudGateway基本操作-过滤器","date":"2021-01-25T07:00:00.000Z","path":"posts/4db8feb0.html","text":"Spring Cloud Gateway 已经内置了很多实用的过滤器，但并不能完全满足我们的需求。本文我们就来实现自定义过滤器。虽然现在 Spring Cloud Gateway 的文档还不完善，但是我们依旧可以照猫画虎来定制自己的过滤器。 Filter 的作用其实前边在介绍 Zuul 的的时候已经介绍过 Zuul 的 Filter 的作用了，同作为网关服务，Spring Cloud Gateway 的 Filter 作用也类似。 这里就简单用两张图来解释一下吧。 当使用微服务构建整个 API 服务时，一般有许多不同的应用在运行，如上图所示的mst-user-service、mst-good-service和mst-order-service，这些服务都需要对客户端的请求的进行 Authentication。最简单粗暴的方法就是像上图一样，为每个微服务应用都实现一套用于校验的过滤器或拦截器。 对于这样的问题，更好的做法是通过前置的网关服务来完成这些非业务性质的校验，就像下图 Filter 的生命周期Spring Cloud Gateway 的 Filter 的生命周期不像 Zuul 的那么丰富，它只有两个：“pre”和“post”。 image-20180508184542206 “pre”和“post”分别会在请求被执行前调用和被执行后调用，和 Zuul Filter 或 Spring Interceptor 中相关生命周期类似，但在形式上有些不一样。 Zuul 的 Filter 是通过filterType()方法来指定，一个 Filter 只能对应一种类型，要么是“pre”要么是“post”。Spring Interceptor 是通过重写HandlerInterceptor中的三个方法来实现的。而 Spring Cloud Gateway 基于 Project Reactor 和 WebFlux，采用响应式编程风格，打开它的 Filter 的接口GatewayFilter你会发现它只有一个方法filter。 仅通过这一个方法，怎么来区分是“pre”还是“post”呢？我们下边就通过自定义过滤器来看看。 自定义过滤器现在假设我们要统计某个服务的响应时间，我们可以在代码中 long beginTime = System.currentTimeMillis(); // do something... long elapsed = System.currentTimeMillis() - beginTime; log.info(\"elapsed: &#123;&#125;ms\", elapsed); 每次都要这么写是不是很烦？Spring 告诉我们有个东西叫 AOP。但是我们是微服务啊，在每个服务里都写也很烦。这时候就该网关的过滤器登台表演了。 自定义过滤器需要实现GatewayFilter和Ordered。其中GatewayFilter中的这个方法就是用来实现你的自定义的逻辑的 Mono&lt;Void> filter(ServerWebExchange exchange, GatewayFilterChain chain); Copy 而Ordered中的int getOrder()方法是来给过滤器设定优先级别的，值越大则优先级越低。 好了，让我们来撸代码吧 import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import org.springframework.cloud.gateway.filter.GatewayFilter; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.core.Ordered; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; public class ElapsedFilter implements GatewayFilter, Ordered &#123; private static final Log log = LogFactory.getLog(GatewayFilter.class); private static final String ELAPSED_TIME_BEGIN = \"elapsedTimeBegin\"; @Override public Mono&lt;Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; exchange.getAttributes().put(ELAPSED_TIME_BEGIN, System.currentTimeMillis()); return chain.filter(exchange).then( Mono.fromRunnable(() -> &#123; Long startTime = exchange.getAttribute(ELAPSED_TIME_BEGIN); if (startTime != null) &#123; log.info(exchange.getRequest().getURI().getRawPath() + \": \" + (System.currentTimeMillis() - startTime) + \"ms\"); &#125; &#125;) ); &#125; @Override public int getOrder() &#123; return Ordered.LOWEST_PRECEDENCE; &#125; &#125; 我们在请求刚刚到达时，往ServerWebExchange中放入了一个属性elapsedTimeBegin，属性值为当时的毫秒级时间戳。然后在请求执行结束后，又从中取出我们之前放进去的那个时间戳，与当前时间的差值即为该请求的耗时。因为这是与业务无关的日志所以将Ordered设为Integer.MAX_VALUE以降低优先级。 现在再来看我们之前的问题：怎么来区分是“pre”还是“post”呢？其实就是chain.filter(exchange)之前的就是“pre”部分，之后的也就是then里边的是“post”部分。 创建好 Filter 之后我们将它添加到我们的 Filter Chain 里边 @Bean public RouteLocator customerRouteLocator(RouteLocatorBuilder builder) &#123; // @formatter:off return builder.routes() .route(r -> r.path(\"/fluent/customer/**\") .filters(f -> f.stripPrefix(2) .filter(new ElapsedFilter()) .addResponseHeader(\"X-Response-Default-Foo\", \"Default-Bar\")) .uri(\"lb://CONSUMER\") .order(0) .id(\"fluent_customer_service\") ) .build(); // @formatter:on &#125; 现在再尝试访问 http://localhost:10000/customer/hello/yibo 即可在控制台里看到请求路径与对应的耗时 2018-05-08 16:07:04.197 INFO 83726 --- [ctor-http-nio-4] o.s.cloud.gateway.filter.GatewayFilter : /hello/yibo: 40ms 实际在使用 Spring Cloud 的过程中，我们会使用 Sleuth+Zipkin 来进行耗时分析。 自定义全局过滤器前边讲了自定义的过滤器，那个过滤器只是局部的，如果我们有多个路由就需要一个一个来配置，并不能通过像下面这样来实现全局有效（也未在 Fluent Java API 中找到能设置 defaultFilters 的方法） @Bean public ElapsedFilter elapsedFilter()&#123; return new ElapsedFilter(); &#125; 这在我们要全局统一处理某些业务的时候就显得比较麻烦，比如像最开始我们说的要做身份校验，有没有简单的方法呢？这时候就该全局过滤器出场了。 有了前边的基础，我们创建全局过滤器就简单多了。只需要把实现的接口GatewayFilter换成GlobalFilter，就完事大吉了。比如下面的 Demo 就是从请求参数中获取token字段，如果能获取到就 pass，获取不到就直接返回401错误，虽然简单，但足以说明问题了。 import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.Ordered; import org.springframework.http.HttpStatus; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; public class TokenFilter implements GlobalFilter, Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; String token &#x3D; exchange.getRequest().getQueryParams().getFirst(&quot;token&quot;); if (token &#x3D;&#x3D; null || token.isEmpty()) &#123; exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); &#125; return chain.filter(exchange); &#125; @Override public int getOrder() &#123; return -100; &#125; &#125; 然后在 Spring Config 中配置这个 Bean @Bean public TokenFilter tokenFilter()&#123; return new TokenFilter(); &#125; 重启应用就能看到效果了 2018-05-08 20:41:06.528 DEBUG 87751 --- [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Mapping [Exchange: GET http://localhost:10000/customer/hello/yibo?token=1000] to Route&#123;id='service_customer', uri=lb://CONSUMER, order=0, predicate=org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory$$Lambda$334/1871259950@2aa090be, gatewayFilters=[OrderedGatewayFilter&#123;delegate=org.springframework.cloud.gateway.filter.factory.StripPrefixGatewayFilterFactory$$Lambda$337/577037372@22e84be7, order=1&#125;, OrderedGatewayFilter&#123;delegate=org.springframework.cloud.gateway.filter.factory.AddResponseHeaderGatewayFilterFactory$$Lambda$339/1061806694@1715f608, order=2&#125;]&#125; 2018-05-08 20:41:06.530 DEBUG 87751 --- [ctor-http-nio-2] o.s.c.g.handler.FilteringWebHandler : Sorted gatewayFilterFactories: [OrderedGatewayFilter&#123;delegate=GatewayFilterAdapter&#123;delegate=com.yibo.filter.TokenFilter@309028af&#125;, order=-100&#125;, OrderedGatewayFilter&#123;delegate=GatewayFilterAdapter&#123;delegate=org.springframework.cloud.gateway.filter.NettyWriteResponseFilter@70e889e9&#125;, order=-1&#125;, OrderedGatewayFilter&#123;delegate=org.springframework.cloud.gateway.filter.factory.StripPrefixGatewayFilterFactory$$Lambda$337/577037372@22e84be7, order=1&#125;, OrderedGatewayFilter&#123;delegate=org.springframework.cloud.gateway.filter.factory.AddResponseHeaderGatewayFilterFactory$$Lambda$339/1061806694@1715f608, order=2&#125;, OrderedGatewayFilter&#123;delegate=GatewayFilterAdapter&#123;delegate=org.springframework.cloud.gateway.filter.RouteToRequestUrlFilter@51351f28&#125;, order=10000&#125;, OrderedGatewayFilter&#123;delegate=GatewayFilterAdapter&#123;delegate=org.springframework.cloud.gateway.filter.LoadBalancerClientFilter@724c5cbe&#125;, order=10100&#125;, OrderedGatewayFilter&#123;delegate=GatewayFilterAdapter&#123;delegate=org.springframework.cloud.gateway.filter.AdaptCachedBodyGlobalFilter@418c020b&#125;, order=2147483637&#125;, OrderedGatewayFilter&#123;delegate=GatewayFilterAdapter&#123;delegate=org.springframework.cloud.gateway.filter.WebsocketRoutingFilter@15f2eda3&#125;, order=2147483646&#125;, OrderedGatewayFilter&#123;delegate=GatewayFilterAdapter&#123;delegate=org.springframework.cloud.gateway.filter.NettyRoutingFilter@70101687&#125;, order=2147483647&#125;, OrderedGatewayFilter&#123;delegate=GatewayFilterAdapter&#123;delegate=org.springframework.cloud.gateway.filter.ForwardRoutingFilter@21618fa7&#125;, order=2147483647&#125;] Copy 官方说，未来的版本将对这个接口作出一些调整：This interface and usage are subject to change in future milestones.from Spring Cloud Gateway - Global Filters 自定义过滤器工厂如果你还对上一篇关于路由的文章有印象，你应该还得我们在配置中有这么一段 filters: - StripPrefix&#x3D;1 - AddResponseHeader&#x3D;X-Response-Default-Foo, Default-Bar Copy StripPrefix、AddResponseHeader这两个实际上是两个过滤器工厂（GatewayFilterFactory），用这种配置的方式更灵活方便。 我们就将之前的那个ElapsedFilter改造一下，让它能接收一个boolean类型的参数，来决定是否将请求参数也打印出来。 import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import org.springframework.cloud.gateway.filter.GatewayFilter; import org.springframework.cloud.gateway.filter.factory.AbstractGatewayFilterFactory; import reactor.core.publisher.Mono; import java.util.Arrays; import java.util.List; public class ElapsedGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;ElapsedGatewayFilterFactory.Config> &#123; private static final Log log = LogFactory.getLog(GatewayFilter.class); private static final String ELAPSED_TIME_BEGIN = \"elapsedTimeBegin\"; private static final String KEY = \"withParams\"; @Override public List&lt;String> shortcutFieldOrder() &#123; return Arrays.asList(KEY); &#125; public ElapsedGatewayFilterFactory() &#123; super(Config.class); &#125; @Override public GatewayFilter apply(Config config) &#123; return (exchange, chain) -> &#123; exchange.getAttributes().put(ELAPSED_TIME_BEGIN, System.currentTimeMillis()); return chain.filter(exchange).then( Mono.fromRunnable(() -> &#123; Long startTime = exchange.getAttribute(ELAPSED_TIME_BEGIN); if (startTime != null) &#123; StringBuilder sb = new StringBuilder(exchange.getRequest().getURI().getRawPath()) .append(\": \") .append(System.currentTimeMillis() - startTime) .append(\"ms\"); if (config.isWithParams()) &#123; sb.append(\" params:\").append(exchange.getRequest().getQueryParams()); &#125; log.info(sb.toString()); &#125; &#125;) ); &#125;; &#125; public static class Config &#123; private boolean withParams; public boolean isWithParams() &#123; return withParams; &#125; public void setWithParams(boolean withParams) &#123; this.withParams = withParams; &#125; &#125; &#125; 过滤器工厂的顶级接口是GatewayFilterFactory，我们可以直接继承它的两个抽象类来简化开发AbstractGatewayFilterFactory和AbstractNameValueGatewayFilterFactory，这两个抽象类的区别就是前者接收一个参数（像StripPrefix和我们创建的这种），后者接收两个参数（像AddResponseHeader）。 GatewayFilter apply(Config config)方法内部实际上是创建了一个GatewayFilter的匿名类，具体实现和之前的几乎一样，就不解释了。 静态内部类Config就是为了接收那个boolean类型的参数服务的，里边的变量名可以随意写，但是要重写List&lt;String&gt; shortcutFieldOrder()这个方法。 这里注意一下，一定要调用一下父类的构造器把Config类型传过去，否则会报ClassCastException public ElapsedGatewayFilterFactory() &#123; super(Config.class); &#125; 工厂类我们有了，再把它注册到 Spring 当中 @Bean public ElapsedGatewayFilterFactory elapsedGatewayFilterFactory() &#123; return new ElapsedGatewayFilterFactory(); &#125; 然后添加配置（主要改动在第 8 行） spring: cloud: gateway: discovery: locator: enabled: true default-filters: - Elapsed=true routes: - id: service_customer uri: lb://CONSUMER order: 0 predicates: - Path=/customer/** filters: - StripPrefix=1 - AddResponseHeader=X-Response-Default-Foo, Default-Bar 然后我们再次访问 http://localhost:10000/customer/hello/yibo?token=1000 即可在控制台看到以下内容 2018-05-08 16:53:02.030 INFO 84423 --- [ctor-http-nio-1] o.s.cloud.gateway.filter.GatewayFilter : &#x2F;hello&#x2F;yibo: 656ms params:&#123;token&#x3D;[1000]&#125; 总结本文主要介绍了 Spring Cloud Gateway 的过滤器，我们实现了自定义局部过滤器、自定义全局过滤器和自定义过滤器工厂，相信大家对 Spring Cloud Gateway 的过滤器有了一定的了解。之后我们将继续在过滤器的基础上研究 如何使用 Spring Cloud Gateway 实现限流和 fallback。 参考 https://www.haoyizebo.com/posts/1e919f7d/ https://blog.csdn.net/forezp/article/details/85057268","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"},{"name":"SpringCloudGateway","slug":"SpringCloudGateway","permalink":"http://wumuwumu.github.io/tags/SpringCloudGateway/"}]},{"title":"SpringCloudGateway基本操作-断言","date":"2021-01-25T07:00:00.000Z","path":"posts/cbfc80cb.html","text":"基本配置配置文件spring: application: name: cloud-gateway profiles: active: dev ################################################################spring cloud gateway############################################################## cloud: gateway: discovery: locator: enabled: false #当访问http://网关地址/服务名称（大写）/**地址会自动转发到http://服务名称（大写）/**地址，如果为false就不会自动转发 lowerCaseServiceId: false #为true表示服务名称（小写） routes: - id: cloud-provider-payment #路由id，需要全局统一，建议使用对应的spring.application.name uri: http://localhost:8001 #路由到对应服务的地址 predicates: - Path=/service/**/* #断言，匹配规则，ant匹配 ############################################################ - id: cloud-provider-payment2 #路由id，需要全局统一，建议使用对应的spring.application.name uri: http://localhost:8002 #路由到对应服务的地址 predicates: - Path=/service/**/* #断言，匹配规则，ant匹配 JavaBean配置@SpringBootApplication public class DemogatewayApplication &#123; @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) &#123; return builder.routes() .route(\"path_route\", r -> r.path(\"/get\") .uri(\"http://httpbin.org\")) .route(\"host_route\", r -> r.host(\"*.myhost.org\") .uri(\"http://httpbin.org\")) .route(\"rewrite_route\", r -> r.host(\"*.rewrite.org\") .filters(f -> f.rewritePath(\"/foo/(?&lt;segment>.*)\", \"/$&#123;segment&#125;\")) .uri(\"http://httpbin.org\")) .route(\"hystrix_route\", r -> r.host(\"*.hystrix.org\") .filters(f -> f.hystrix(c -> c.setName(\"slowcmd\"))) .uri(\"http://httpbin.org\")) .route(\"hystrix_fallback_route\", r -> r.host(\"*.hystrixfallback.org\") .filters(f -> f.hystrix(c -> c.setName(\"slowcmd\").setFallbackUri(\"forward:/hystrixfallback\"))) .uri(\"http://httpbin.org\")) .route(\"limit_route\", r -> r .host(\"*.limited.org\").and().path(\"/anything/**\") .filters(f -> f.requestRateLimiter(c -> c.setRateLimiter(redisRateLimiter()))) .uri(\"http://httpbin.org\")) .build(); &#125; &#125; 自定义路由Predicate 断言在spring-cloud-gateway的官方文档中没有给出自定义Predicate ,只留下一句TODO: document writing Custom Route Predicate Factories 创建RoutePredicateFactory/** * @author WXY */ @Slf4j public class TokenRoutePredicateFactory extends AbstractRoutePredicateFactory&lt;TokenRoutePredicateFactory.Config> &#123; private static final String DATETIME_KEY = \"headerName\"; public TokenRoutePredicateFactory() &#123; super(Config.class); &#125; @Override public List&lt;String> shortcutFieldOrder() &#123; return Collections.singletonList(DATETIME_KEY); &#125; @Override public Predicate&lt;ServerWebExchange> apply(Config config) &#123; log.debug(\"TokenRoutePredicateFactory Start...\"); return exchange -> &#123; //判断header里有放token HttpHeaders headers = exchange.getRequest().getHeaders(); List&lt;String> header = headers.get(config.getHeaderName()); log.info(\"Token Predicate headers:&#123;&#125;\", header); return header.size() > 0; &#125;; &#125; public static class Config &#123; /** * 传输token header key */ private String headerName; public String getHeaderName() &#123; return headerName; &#125; public void setHeaderName(String headerName) &#123; this.headerName = headerName; &#125; &#125; &#125; 继承AbstractRoutePredicateFactory&lt;C&gt;主要实现其中的两个方法 shortcutFieldOrder()-Config对应的字段 Predicate&lt;ServerWebExchange&gt; apply(Config config)-具体的逻辑 还有就是构造方法传入用来装配置的类程序会自动把配置的value传入apply中的入参 初始化RoutePredicateFactory为beanimport org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * @author WXY * */ @Configuration public class RoutesConfiguration &#123; @Bean public TokenRoutePredicateFactory initTokenRoutePredicateFactory()&#123; return new TokenRoutePredicateFactory(); &#125; &#125; 或者直接在TokenRoutePredicateFactory类上加@Component也行 配置自定义的Predicate使用属性文件配置自定义Predicatespring.cloud.gateway.routes[1].predicates[1]=Token=Authorization 其中Toekn为命名RoutePredicateFactory时的前面部分，所以在定义RoutePredicateFactory时类名必须后缀为RoutePredicateFactory,否则找不到自定义的Predicate 使用代码配置/** * @author WXY * */ @Configuration public class RoutesConfiguration &#123; /** * 代码配置路由 */ @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) &#123; return builder.routes().route(predicateSpec -> predicateSpec.path(\"/order/**\") .and().asyncPredicate(initTokenRoutePredicateFactory().applyAsync(config -> config.setHeaderName(\"Authorization\"))) .uri(\"lb://order-service\").id(\"order-service\") ).build(); &#125; @Bean public TokenRoutePredicateFactory initTokenRoutePredicateFactory()&#123; return new TokenRoutePredicateFactory(); &#125; &#125; 使用代码配置自定义Predicate，主要使用asyncPredicate方法，把所需的自定义RoutePredicateFactory对象传进去配置applyAsync方法传入配置的属性。 参考 https://my.oschina.net/zhousc1992/blog/3194740","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://wumuwumu.github.io/tags/SpringCloud/"},{"name":"SpringCloudGateway","slug":"SpringCloudGateway","permalink":"http://wumuwumu.github.io/tags/SpringCloudGateway/"}]},{"title":"maven生成Manifest文件","date":"2021-01-22T10:00:00.000Z","path":"posts/undefined.html","text":"maven-jar-plugin常用&lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-jar-plugin&lt;/artifactId> &lt;version>3.2.0&lt;/version> &lt;configuration> &lt;archive> &lt;manifestFile>$&#123;project.build.outputDirectory&#125;/META-INF/MANIFEST.MF&lt;/manifestFile> &lt;/archive> &lt;/configuration> ... &lt;/plugin> &lt;/plugins> &lt;/build> 常用参数&lt;archive> &lt;addMavenDescriptor/> &lt;compress/> &lt;forced/> &lt;index/> &lt;pomPropertiesFile/> &lt;manifestFile/> &lt;manifest> &lt;addClasspath/> &lt;addDefaultEntries/> &lt;addDefaultImplementationEntries/> &lt;addDefaultSpecificationEntries/> &lt;addBuildEnvironmentEntries/> &lt;addExtensions/> &lt;classpathLayoutType/> &lt;classpathPrefix/> &lt;customClasspathLayout/> &lt;mainClass/> &lt;packageName/> &lt;useUniqueVersions/> &lt;/manifest> &lt;manifestEntries> &lt;key>value&lt;/key> &lt;/manifestEntries> &lt;manifestSections> &lt;manifestSection> &lt;name/> &lt;manifestEntries> &lt;key>value&lt;/key> &lt;/manifestEntries> &lt;manifestSection/> &lt;/manifestSections> &lt;/archive> 存档 元素 描述 类型 自 addMavenDescriptor 创建的归档文件是否包含这两个Maven文件: 1. pom 文件, 位于归档文件中 META-INF/maven/g r o u p I d / {groupId}/groupId/{artifactId}/pom.xml 2. pom.properties 文件, 位于归档文件中 META-INF/maven/g r o u p I d / {groupId}/groupId/{artifactId}/pom.properties 默认值为true。 boolean compress 为存档激活压缩。默认值为true。 boolean forced 是否强制重新创建存档(默认情况下)。将此选项设置为false，意味着归档程序应该将所包含文件的时间戳与目标归档的时间戳进行比较，并仅在后一个时间戳先于前一个时间戳的情况下重新构建归档。检查时间戳通常会提高性能(特别是，如果可以取消构建中的以下步骤，如果没有重新创建归档)，而不考虑您不时得到不准确结果的成本。特别是，不会检测到源文件的删除。 归档器不一定支持最新的检查。如果是，将该选项设置为true将被忽略。 默认值为true。 boolean 2.2 index 创建的存档是否包含 INDEX.LIST 文件。默认值为false。 boolean pomPropertiesFile 使用它来覆盖自动创建的 pom.properties 文件(仅当addMavenDescriptor被设置为true时) File 2.3 manifestFile 有了它，您可以提供自己的清单文件。 File manifest manifestEntries 要添加到清单中的键/值对列表。 Map manifestSections pom.properties 内容自动创建 pom.properties 文件将包含以下内容： artifactId=$&#123;project.artifactId&#125; groupId=$&#123;project.groupId&#125; version=$&#123;project.version&#125; manifest 元素 描述 类型 自 addClasspath 是否创建 Class-Path 清单项。默认值为false。 boolean addDefaultEntries 如果清单将包含以下条目: boolean 3.4.0 addDefaultImplementationEntries addDefaultSpecificationEntries addBuildEnvironmentEntries addExtensions classpathLayoutType 格式化创建的 Class-Path 中的条目时要使用的布局类型。有效值是:simple、repository(与Maven类路径布局相同)和custom。 注意:如果指定 custom 类型，还必须设置 customClasspathLayout。默认值很简单。 classpathPrefix 将作为所有Class-Path条目前缀的文本。默认值为“” customClasspathLayout 。 mainClass Main-Class清单条目 String manifestSection Element Description Type Since name The name of the section. String manifestEntries A list of key/value pairs to add to the manifest. Map 参考 https://maven.apache.org/shared/maven-archiver/examples/classpath.html https://maven.apache.org/shared/maven-archiver/ https://blog.csdn.net/ksdb0468473/article/details/110833520","tags":[]},{"title":"java队列","date":"2021-01-21T04:00:00.000Z","path":"posts/undefined.html","text":"队列的常用方法 add：增加一个元索 如果队列已满，则抛出一个IIIegaISlabEepeplian异常。 element：返回队列头部的元素 如果队列为空，则抛出一个NoSuchElementException异常 。 remove： 移除并返回队列头部的元素 如果队列为空，则抛出一个NoSuchElementException异常。 offer：添加一个元素并返回true 如果队列已满，则返回false。 poll：移除并返问队列头部的元素 如果队列为空，则返回null。 peek：返回队列头部的元素 如果队列为空，则返回null。 put：添加一个元素 如果队列满，则阻塞。 take：移除并返回队列头部的元素 如果队列为空，则阻塞 常用的队列没有实现阻塞接口 LinkList PriorityQueue ConcurrentLinkedQueue 实现阻塞接口 ArrayBlockingQueue LinkedBlockingQueue PriorityBlockingQueue DelayQueue 双向队列 类 描述 AbstractDueue 此类提供某些 Queue 方法的骨干实现，为其它类集合的实现提供方便 PriorityQueue 一个基于优先级堆的无界优先级队列。优先级队列的元素按照其自然顺序进行排序，或者根据构造队列时提供的 Comparator 进行排序，具体取决于所使用的构造方法 ArrayDeque 双端队列的一个数组实现， 数组双端队列没有容量限制；它们可根据需要增加以支持使用 LinkedLis 通过继承 AbstractSequentialList 来实现链接列表","tags":[]},{"title":"java创建自定义名称线程工厂","date":"2021-01-21T02:31:35.000Z","path":"posts/undefined.html","text":"ThreadFactoryBuilderGoogle guava 工具类 提供的 ThreadFactoryBuilder ,使用链式方法创建。 ThreadFactory guavaThreadFactory = new ThreadFactoryBuilder().setNameFormat(\"retryClient-pool-\").build(); ExecutorService exec = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable>(10),guavaThreadFactory ); exec.submit(() -> &#123; logger.info(\"--记忆中的颜色是什么颜色---\"); &#125;); 自定义ThreadFactoryclass MssThreadFactory implements ThreadFactory &#123; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; MssThreadFactory(String namePrefix) &#123; this.namePrefix = namePrefix+\"-\"; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread( r,namePrefix + threadNumber.getAndIncrement()); if (t.isDaemon()) t.setDaemon(true); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; &#125; BasicThreadFactoryApache commons-lang3 提供的 BasicThreadFactory. ThreadFactory basicThreadFactory = new BasicThreadFactory.Builder() .namingPattern(\"basicThreadFactory-\").build(); ExecutorService exec = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable>(10),basicThreadFactory ); exec.submit(() -> &#123; logger.info(\"--记忆中的颜色是什么颜色---\"); &#125;);","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"Mqtt5协议新特性","date":"2021-01-18T04:00:00.000Z","path":"posts/undefined.html","text":"格式首先，协议上，增加了一个 Property字段，正是这个字段，使得 MQTT 5.0 可以支持众多的新特性。而在MQTT 3.1.1中，MQTT没有任何可以拓展的地方，限制了MQTT拓展功能的可能性。 request/response 模式MQTT 本身是 订阅/推送 模式，不像HTTP那样 请求/响应 模式。那么MQTT是如何在 订阅/推送 模式下支持 request/response 模式呢？这里简单翻译了 http://docs.oasis-open.org/mqtt/mqtt/v5.0/cos01/mqtt-v5.0-cos01.html#_Request_/_Response 中举例的场景： （1）A publish 一个消息，消息topic假设是”topicA”，该消息 通过Property携带了Response Topic，假设该字段是”topicresponse”。（2）订阅了”topicA”的接收端B（有可能有多个）收到了该消息。（3）B处理完”topicA”后，会publish 一个 topic 名字是 “topicresponse” 的消息。该消息有可能是A订阅的，也有可能是其他人订阅的。（4）A publish 的消息，可能还会携带Correlation Data属性，假设其值是”msgresponse”，这样B发publish的消息就是(“topicresponse”, “msgresponse”)。 Server redirectionServer可以发送 CONNACK 或者 DISCONNECT，其 Reason Codes 可以是0x9c或者0x9d，表示Client需要往另一个Server发送请求。0x9C 类似 HTTP 的 302, 0x9d 类似 HTTP的 301。CONNACK 或者 DISCONNECT 可以通过 Property携带Server redirection，其值可以告诉Client往哪个Server发送请求，类似HTTP的”Location”首部。 AUTH控制报文MQTT 单纯通过 CONNECT可能无法提供足够的信息给Server进行身份认证，所以 Server 在收到 MQTT 的 CONNECT 后，回复 AUTH控制报文给Client，Client接着也用 AUTH包发送附加信息，Server直到 认证完成后，才会发送 CONNACK。 Topic Alias类似HTTP2的头部压缩效果，当然，没有同HPACK那么复杂的东西。 我们知道，PUBLISH消息的时候，需要携带 topic和message，其中topic往往是固定的，那么我们只需要第一次发送完整的 topic，并且通过Property中携带Topic Alias告知对端下次这个PUBLISH的topic会使用Topic Alias中的值代替，Topic Alias的值是一个整数类型的值。 client 通过 CONNECT 中 Topic Alias Maximum 告知 Server自己能处理的最多的 Topic Alias 个数。Server 通过 CONNACK中 Topic Alias Maximum 告知 Client自己能处理的最多的 Topic Alias 个数。 如果当前PUBLISH消息的topic长度不为0，那么接受方需要解析 Topic Alias 中的值，并且 将topic和该值进行映射。如果当前PUBLISH消息的topic为0，那么接受方需要解析 Topic Alias 中的值，用该值去查找对应的topic。 User Property自定义属性，可以添加两端约定的数据。例如可以加入类似HTTP的 “Header:value”信息。MQTT本身没有类似HTTP的HOST信息，我们可以使用User Property特性让MQTT支持。 Session Expiry Interval之前的MQTT版本，当cleansession为0时，server和client会尝试保存session信息（sub信息、PUBLISH状态等），但是有个问题，server 不知道需要保存这个session多久。MQTT 5.0 就 在 Property字段中增加了Session Expiry Interval属性来告知server这个session希望被保存多久。 如果MQTT 5.0 不携带 Session Expiry Interval或者 Session Expiry Interval设置为0，server和client则不会保存session信息。如果Session Expiry Interval设置为0xffffffff，则表示session永远不会老化。 当然，这个字段是需要配合Clean Start使用的，如果Clean Start为1，那么 Session Expiry Interval设置多大都无意义。 CONNECT、CONNACK、DISCONNECT都会发送 Session Expiry Interval字段。DISCONNECT中携带该字段可以告知Server更新老化时间。CONNACK中的Session Expiry Interval只有当CONNECT不携带该字段时才有用，当client携带该字段，server发送该字段只是表明自己最大的老化时间，不会强制client必须按照这个值。 Maximum QoSServer 可以发送 Maximum QoS属性告知Client自己支持最大的Qos是多少，Client发送的PUBLISH的Qos必然不能大于该值。 Receive Maximum告知对方自己希望处理未决的最大的 Qos1 或者 Qos2 PUBLISH消息个数，如果不存在，则默认是65535。作用：流控。因为当处理 Qos &gt; 0 的PUBLISH的时候，需要回复对端PUBACK、PUBREC PUBCOMP等。Receive Maximum属性提供了告诉对端发送Qos&gt;0的PUBLISH的速率，对端发现未决PUBLISH个数等于Receive Maximum时，不能再发送Qos &gt; 0 的PUBLISH消息了。 Maximum Packet Size顾名思义，单个 MQTT控制报文 的大小，如果不携带，表示不限制。这个大小指整个 MQTT控制报文 的大小。对端如果发现将发送的包大于该大小，就默默丢弃，不关闭连接。如果自己收到超过自己通告的Maximum Packet Size需要关闭连接。 Topic Alias Maximum作用见上文Topic Alias。 Reason CodeMQTT 3.1.1 只有CONNACK有是否成功还是失败的标志位，现在MQTT 5.0所有的ACK都有该标志位。具体各个ACK中code值得含义在规范中有定义，这里不再列举。需要注意的是，SUBACK中，MQTT 3.1.1 的 Granted Qos被取代为Reason Code，Reason Code中有状态码表示了具体的Granted Qos。如果PUBLISH是成功的，其ACK的的Reason Code可以不添加。 Reason String所有的ACK以及DISCONNECT 都可以携带 Reason String属性告知对方一些特殊的信息，一般来说是ACK失败的情况下会使用该属性告知对端为什么失败，可用来弥补Reason Code信息不够。 Clean StartClean Start取代了 MQTT3.1.1 中 CleanSession，在协议格式上，直接占用了CleanSession原本的field，这也表示Clean Start语义上和 CleanSession是一样的。 Payload Format Indicator指定了PUBLISH 消息的message部分是utf8格式的还是二进制的，接收方必须验证payload是否是该属性定义的格式。Payload Format Indicator 为 0，表示 是二进制，和不携带该属性的语义是一样的。Payload Format Indicator 为 1，表示 是utf8编码数据。 Message Expiry Interval指定了PUBLISH数据在Server的最长等待时间。超过这个时间，这个数据不能被publish到匹配topic的subscriber 参考 https://www.emqx.cn/mqtt/mqtt5 https://blog.csdn.net/mrpre/article/details/87267400","tags":[]},{"title":"rabbitmq延迟队列","date":"2021-01-05T04:00:00.000Z","path":"posts/undefined.html","text":"一、说明在上一篇中，介绍了RabbitMQ中的死信队列是什么，何时使用以及如何使用RabbitMQ的死信队列。相信通过上一篇的学习，对于死信队列已经有了更多的了解，这一篇的内容也跟死信队列息息相关，如果你还不了解死信队列，那么建议你先进行上一篇文章的阅读。 这一篇里，我们将继续介绍RabbitMQ的高级特性，通过本篇的学习，你将收获： 什么是延时队列 延时队列使用场景 RabbitMQ中的TTL 如何利用RabbitMQ来实现延时队列 二、本文大纲以下是本文大纲： 本文阅读前，需要对RabbitMQ以及死信队列有一个简单的了解。 三、什么是延时队列延时队列，首先，它是一种队列，队列意味着内部的元素是有序的，元素出队和入队是有方向性的，元素从一端进入，从另一端取出。 其次，延时队列，最重要的特性就体现在它的延时属性上，跟普通的队列不一样的是，普通队列中的元素总是等着希望被早点取出处理，而延时队列中的元素则是希望被在指定时间得到取出和处理，所以延时队列中的元素是都是带时间属性的，通常来说是需要被处理的消息或者任务。 简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。 四、延时队列使用场景那么什么时候需要用延时队列呢？考虑一下以下场景： 订单在十分钟之内未支付则自动取消。 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。 账单在一周内未支付，则自动结算。 用户注册成功后，如果三天内没有登陆则进行短信提醒。 用户发起退款，如果三天内没有得到处理则通知相关运营人员。 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议。 这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点完成某一项任务，如：发生订单生成事件，在十分钟之后检查该订单支付状态，然后将未支付的订单进行关闭；发生店铺创建事件，十天后检查该店铺上新商品数，然后通知上新数为0的商户；发生账单生成事件，检查账单支付状态，然后自动结算未支付的账单；发生新用户注册事件，三天后检查新注册用户的活动数据，然后通知没有任何活动记录的用户；发生退款事件，在三天之后检查该订单是否已被处理，如仍未被处理，则发送消息给相关运营人员；发生预定会议事件，判断离会议开始是否只有十分钟了，如果是，则通知各个与会人员。 看起来似乎使用定时任务，一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？如果数据量比较少，确实可以这样做，比如：对于“如果账单一周内未支付则进行自动结算”这样的需求，如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。但对于数据量比较大，并且时效性较强的场景，如：“订单十分钟内未支付则关闭“，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。 更重要的一点是，不！优！雅！ 没错，作为一名有追求的程序员，始终应该追求更优雅的架构和更优雅的代码风格，写代码要像写诗一样优美。【滑稽】 这时候，延时队列就可以闪亮登场了，以上场景，正是延时队列的用武之地。 既然延时队列可以解决很多特定场景下，带时间属性的任务需求，那么如何构造一个延时队列呢？接下来，本文将介绍如何用RabbitMQ来实现延时队列。 五、RabbitMQ中的TTL在介绍延时队列之前，还需要先介绍一下RabbitMQ中的一个高级特性——TTL（Time To Live）。 TTL是什么呢？TTL是RabbitMQ中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。换句话说，如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为“死信”（至于什么是死信，请翻看上一篇）。如果同时配置了队列的TTL和消息的TTL，那么较小的那个值将会被使用。 那么，如何设置这个TTL值呢？有两种方式，第一种是在创建队列的时候设置队列的“x-message-ttl”属性，如下： Map&lt;String, Object> args = new HashMap&lt;String, Object>(); args.put(\"x-message-ttl\", 6000); channel.queueDeclare(queueName, durable, exclusive, autoDelete, args); 这样所有被投递到该队列的消息都最多不会存活超过6s。 另一种方式便是针对每条消息设置TTL，代码如下： AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder(); builder.expiration(\"6000\"); AMQP.BasicProperties properties = builder.build(); channel.basicPublish(exchangeName, routingKey, mandatory, properties, \"msg body\".getBytes()); 这样这条消息的过期时间也被设置成了6s。 但这两种方式是有区别的，如果设置了队列的TTL属性，那么一旦消息过期，就会被队列丢弃，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间。 另外，还需要注意的一点是，如果不设置TTL，表示消息永远不会过期，如果将TTL设置为0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。 六、如何利用RabbitMQ实现延时队列前一篇里介绍了如果设置死信队列，前文中又介绍了TTL，至此，利用RabbitMQ实现延时队列的两大要素已经集齐，接下来只需要将它们进行调和，再加入一点点调味料，延时队列就可以新鲜出炉了。 想想看，延时队列，不就是想要消息延迟多久被处理吗，TTL则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就万事大吉了，因为里面的消息都是希望被立即处理的消息。 从下图可以大致看出消息的流向： 生产者生产一条延时消息，根据需要延时时间的不同，利用不同的routingkey将消息路由到不同的延时队列，每个队列都设置了不同的TTL属性，并绑定在同一个死信交换机中，消息过期后，根据routingkey的不同，又会被路由到不同的死信队列中，消费者只需要监听对应的死信队列进行处理即可。 下面来看代码： 先声明交换机、队列以及他们的绑定关系： @Configuration public class RabbitMQConfig &#123; public static final String DELAY_EXCHANGE_NAME = \"delay.queue.demo.business.exchange\"; public static final String DELAY_QUEUEA_NAME = \"delay.queue.demo.business.queuea\"; public static final String DELAY_QUEUEA_ROUTING_KEY = \"delay.queue.demo.business.queuea.routingkey\"; public static final String DELAY_QUEUEB_ROUTING_KEY = \"delay.queue.demo.business.queueb.routingkey\"; public static final String DEAD_LETTER_EXCHANGE = \"delay.queue.demo.deadletter.exchange\"; public static final String DEAD_LETTER_QUEUEA_ROUTING_KEY = \"delay.queue.demo.deadletter.delay_10s.routingkey\"; public static final String DEAD_LETTER_QUEUEB_ROUTING_KEY = \"delay.queue.demo.deadletter.delay_60s.routingkey\"; public static final String DEAD_LETTER_QUEUEA_NAME = \"delay.queue.demo.deadletter.queuea\"; public static final String DEAD_LETTER_QUEUEB_NAME = \"delay.queue.demo.deadletter.queueb\"; // 声明延时Exchange @Bean(\"delayExchange\") public DirectExchange delayExchange()&#123; return new DirectExchange(DELAY_EXCHANGE_NAME); &#125; // 声明死信Exchange @Bean(\"deadLetterExchange\") public DirectExchange deadLetterExchange()&#123; return new DirectExchange(DEAD_LETTER_EXCHANGE); &#125; // 声明延时队列A 延时10s // 并绑定到对应的死信交换机 @Bean(\"delayQueueA\") public Queue delayQueueA()&#123; Map&lt;String, Object> args = new HashMap&lt;>(2); // x-dead-letter-exchange 这里声明当前队列绑定的死信交换机 args.put(\"x-dead-letter-exchange\", DEAD_LETTER_EXCHANGE); // x-dead-letter-routing-key 这里声明当前队列的死信路由key args.put(\"x-dead-letter-routing-key\", DEAD_LETTER_QUEUEA_ROUTING_KEY); // x-message-ttl 声明队列的TTL args.put(\"x-message-ttl\", 6000); return QueueBuilder.durable(DEAD_LETTER_QUEUEA_NAME).withArguments(args).build(); &#125; // 声明延时队列B 延时 60s // 并绑定到对应的死信交换机 @Bean(\"delayQueueB\") public Queue delayQueueB()&#123; Map&lt;String, Object> args = new HashMap&lt;>(2); // x-dead-letter-exchange 这里声明当前队列绑定的死信交换机 args.put(\"x-dead-letter-exchange\", DEAD_LETTER_EXCHANGE); // x-dead-letter-routing-key 这里声明当前队列的死信路由key args.put(\"x-dead-letter-routing-key\", DEAD_LETTER_QUEUEB_ROUTING_KEY); // x-message-ttl 声明队列的TTL args.put(\"x-message-ttl\", 60000); return QueueBuilder.durable(DEAD_LETTER_QUEUEB_NAME).withArguments(args).build(); &#125; // 声明死信队列A 用于接收延时10s处理的消息 @Bean(\"deadLetterQueueA\") public Queue deadLetterQueueA()&#123; return new Queue(DEAD_LETTER_QUEUEA_NAME); &#125; // 声明死信队列B 用于接收延时60s处理的消息 @Bean(\"deadLetterQueueB\") public Queue deadLetterQueueB()&#123; return new Queue(DEAD_LETTER_QUEUEB_NAME); &#125; // 声明延时队列A绑定关系 @Bean public Binding delayBindingA(@Qualifier(\"delayQueueA\") Queue queue, @Qualifier(\"delayExchange\") DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DELAY_QUEUEA_ROUTING_KEY); &#125; // 声明业务队列B绑定关系 @Bean public Binding delayBindingB(@Qualifier(\"delayQueueB\") Queue queue, @Qualifier(\"delayExchange\") DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DELAY_QUEUEB_ROUTING_KEY); &#125; // 声明死信队列A绑定关系 @Bean public Binding deadLetterBindingA(@Qualifier(\"deadLetterQueueA\") Queue queue, @Qualifier(\"deadLetterExchange\") DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DEAD_LETTER_QUEUEA_ROUTING_KEY); &#125; // 声明死信队列B绑定关系 @Bean public Binding deadLetterBindingB(@Qualifier(\"deadLetterQueueB\") Queue queue, @Qualifier(\"deadLetterExchange\") DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DEAD_LETTER_QUEUEB_ROUTING_KEY); &#125; &#125; 接下来，创建两个消费者，分别对两个死信队列的消息进行消费： @Slf4j @Component public class DeadLetterQueueConsumer &#123; @RabbitListener(queues = DEAD_LETTER_QUEUEA_NAME) public void receiveA(Message message, Channel channel) throws IOException &#123; String msg = new String(message.getBody()); log.info(\"当前时间：&#123;&#125;,死信队列A收到消息：&#123;&#125;\", new Date().toString(), msg); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; @RabbitListener(queues = DEAD_LETTER_QUEUEB_NAME) public void receiveB(Message message, Channel channel) throws IOException &#123; String msg = new String(message.getBody()); log.info(\"当前时间：&#123;&#125;,死信队列B收到消息：&#123;&#125;\", new Date().toString(), msg); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; &#125; 然后是消息的生产者： @Component public class DelayMessageSender &#123; @Autowired private RabbitTemplate rabbitTemplate; public void sendMsg(String msg, DelayTypeEnum type)&#123; switch (type)&#123; case DELAY_10s: rabbitTemplate.convertAndSend(DELAY_EXCHANGE_NAME, DELAY_QUEUEA_ROUTING_KEY, msg); break; case DELAY_60s: rabbitTemplate.convertAndSend(DELAY_EXCHANGE_NAME, DELAY_QUEUEB_ROUTING_KEY, msg); break; &#125; &#125; &#125; 接下来，我们暴露一个web接口来生产消息： @Slf4j @RequestMapping(\"rabbitmq\") @RestController public class RabbitMQMsgController &#123; @Autowired private DelayMessageSender sender; @RequestMapping(\"sendmsg\") public void sendMsg(String msg, Integer delayType)&#123; log.info(\"当前时间：&#123;&#125;,收到请求，msg:&#123;&#125;,delayType:&#123;&#125;\", new Date(), msg, delayType); sender.sendMsg(msg, Objects.requireNonNull(DelayTypeEnum.getDelayTypeEnumByValue(delayType))); &#125; &#125; 准备就绪，启动！ 打开rabbitMQ的管理后台，可以看到我们刚才创建的交换机和队列信息： 接下来，我们来发送几条消息，http://localhost:8080/rabbitmq/sendmsg?msg=testMsg1&amp;delayType=1 http://localhost:8080/rabbitmq/sendmsg?msg=testMsg2&amp;delayType=2 日志如下： 2019-07-28 16:02:19.813 INFO 3860 --- [nio-8080-exec-9] c.m.d.controller.RabbitMQMsgController : 当前时间：Sun Jul 28 16:02:19 CST 2019,收到请求，msg:testMsg1,delayType:1 2019-07-28 16:02:19.815 INFO 3860 --- [nio-8080-exec-9] .l.DirectReplyToMessageListenerContainer : SimpleConsumer [queue=amq.rabbitmq.reply-to, consumerTag=amq.ctag-o-qPpkWIkRm73DIrOIVhig identity=766339] started 2019-07-28 16:02:25.829 INFO 3860 --- [ntContainer#1-1] c.m.d.mq.DeadLetterQueueConsumer : 当前时间：Sun Jul 28 16:02:25 CST 2019,死信队列A收到消息：testMsg1 2019-07-28 16:02:41.326 INFO 3860 --- [nio-8080-exec-1] c.m.d.controller.RabbitMQMsgController : 当前时间：Sun Jul 28 16:02:41 CST 2019,收到请求，msg:testMsg2,delayType:2 2019-07-28 16:03:41.329 INFO 3860 --- [ntContainer#0-1] c.m.d.mq.DeadLetterQueueConsumer : 当前时间：Sun Jul 28 16:03:41 CST 2019,死信队列B收到消息：testMsg2 第一条消息在6s后变成了死信消息，然后被消费者消费掉，第二条消息在60s之后变成了死信消息，然后被消费掉，这样，一个还算ok的延时队列就打造完成了。 不过，等等，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有6s和60s两个时间选项，如果需要一个小时后处理，那么就需要增加TTL为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？？ 嗯，仔细想想，事情并不简单。 七、RabbitMQ延时队列优化显然，需要一种更通用的方案才能满足需求，那么就只能将TTL设置在消息属性里了。我们来试一试。 增加一个延时队列，用于接收设置为任意延时时长的消息，增加一个相应的死信队列和routingkey： @Configuration public class RabbitMQConfig &#123; public static final String DELAY_EXCHANGE_NAME = \"delay.queue.demo.business.exchange\"; public static final String DELAY_QUEUEC_NAME = \"delay.queue.demo.business.queuec\"; public static final String DELAY_QUEUEC_ROUTING_KEY = \"delay.queue.demo.business.queuec.routingkey\"; public static final String DEAD_LETTER_EXCHANGE = \"delay.queue.demo.deadletter.exchange\"; public static final String DEAD_LETTER_QUEUEC_ROUTING_KEY = \"delay.queue.demo.deadletter.delay_anytime.routingkey\"; public static final String DEAD_LETTER_QUEUEC_NAME = \"delay.queue.demo.deadletter.queuec\"; // 声明延时Exchange @Bean(\"delayExchange\") public DirectExchange delayExchange()&#123; return new DirectExchange(DELAY_EXCHANGE_NAME); &#125; // 声明死信Exchange @Bean(\"deadLetterExchange\") public DirectExchange deadLetterExchange()&#123; return new DirectExchange(DEAD_LETTER_EXCHANGE); &#125; // 声明延时队列C 不设置TTL // 并绑定到对应的死信交换机 @Bean(\"delayQueueC\") public Queue delayQueueC()&#123; Map&lt;String, Object> args = new HashMap&lt;>(3); // x-dead-letter-exchange 这里声明当前队列绑定的死信交换机 args.put(\"x-dead-letter-exchange\", DEAD_LETTER_EXCHANGE); // x-dead-letter-routing-key 这里声明当前队列的死信路由key args.put(\"x-dead-letter-routing-key\", DEAD_LETTER_QUEUEC_ROUTING_KEY); return QueueBuilder.durable(DELAY_QUEUEC_NAME).withArguments(args).build(); &#125; // 声明死信队列C 用于接收延时任意时长处理的消息 @Bean(\"deadLetterQueueC\") public Queue deadLetterQueueC()&#123; return new Queue(DEAD_LETTER_QUEUEC_NAME); &#125; // 声明延时列C绑定关系 @Bean public Binding delayBindingC(@Qualifier(\"delayQueueC\") Queue queue, @Qualifier(\"delayExchange\") DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DELAY_QUEUEC_ROUTING_KEY); &#125; // 声明死信队列C绑定关系 @Bean public Binding deadLetterBindingC(@Qualifier(\"deadLetterQueueC\") Queue queue, @Qualifier(\"deadLetterExchange\") DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DEAD_LETTER_QUEUEC_ROUTING_KEY); &#125; &#125; 增加一个死信队列C的消费者： @RabbitListener(queues = DEAD_LETTER_QUEUEC_NAME) public void receiveC(Message message, Channel channel) throws IOException &#123; String msg = new String(message.getBody()); log.info(\"当前时间：&#123;&#125;,死信队列C收到消息：&#123;&#125;\", new Date().toString(), msg); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; 再次启动！然后访问：http://localhost:8080/rabbitmq/delayMsg?msg=testMsg1delayTime=5000 来生产消息，注意这里的单位是毫秒。 2019-07-28 16:45:07.033 INFO 31468 --- [nio-8080-exec-4] c.m.d.controller.RabbitMQMsgController : 当前时间：Sun Jul 28 16:45:07 CST 2019,收到请求，msg:testMsg1,delayTime:5000 2019-07-28 16:45:11.694 INFO 31468 --- [nio-8080-exec-5] c.m.d.controller.RabbitMQMsgController : 当前时间：Sun Jul 28 16:45:11 CST 2019,收到请求，msg:testMsg2,delayTime:5000 2019-07-28 16:45:12.048 INFO 31468 --- [ntContainer#1-1] c.m.d.mq.DeadLetterQueueConsumer : 当前时间：Sun Jul 28 16:45:12 CST 2019,死信队列C收到消息：testMsg1 2019-07-28 16:45:16.709 INFO 31468 --- [ntContainer#1-1] c.m.d.mq.DeadLetterQueueConsumer : 当前时间：Sun Jul 28 16:45:16 CST 2019,死信队列C收到消息：testMsg2 看起来似乎没什么问题，但不要高兴的太早，在最开始的时候，就介绍过，如果使用在消息属性上设置TTL的方式，消息可能并不会按时“死亡“，因为RabbitMQ只会检查第一个消息是否过期，如果过期则丢到死信队列，索引如果第一个消息的延时时长很长，而第二个消息的延时时长很短，则第二个消息并不会优先得到执行。 实验一下： 2019-07-28 16:49:02.957 INFO 31468 --- [nio-8080-exec-8] c.m.d.controller.RabbitMQMsgController : 当前时间：Sun Jul 28 16:49:02 CST 2019,收到请求，msg:longDelayedMsg,delayTime:20000 2019-07-28 16:49:10.671 INFO 31468 --- [nio-8080-exec-9] c.m.d.controller.RabbitMQMsgController : 当前时间：Sun Jul 28 16:49:10 CST 2019,收到请求，msg:shortDelayedMsg,delayTime:2000 2019-07-28 16:49:22.969 INFO 31468 --- [ntContainer#1-1] c.m.d.mq.DeadLetterQueueConsumer : 当前时间：Sun Jul 28 16:49:22 CST 2019,死信队列C收到消息：longDelayedMsg 2019-07-28 16:49:22.970 INFO 31468 --- [ntContainer#1-1] c.m.d.mq.DeadLetterQueueConsumer : 当前时间：Sun Jul 28 16:49:22 CST 2019,死信队列C收到消息：shortDelayedMsg 我们先发了一个延时时长为20s的消息，然后发了一个延时时长为2s的消息，结果显示，第二个消息会在等第一个消息成为死信后才会“死亡“。 八、利用RabbitMQ插件实现延迟队列上文中提到的问题，确实是一个硬伤，如果不能实现在消息粒度上添加TTL，并使其在设置的TTL时间及时死亡，就无法设计成一个通用的延时队列。 那如何解决这个问题呢？不要慌，安装一个插件即可：https://www.rabbitmq.com/community-plugins.html ，下载rabbitmq_delayed_message_exchange插件，然后解压放置到RabbitMQ的插件目录。 接下来，进入RabbitMQ的安装目录下的sbin目录，执行下面命令让该插件生效，然后重启RabbitMQ。 rabbitmq-plugins enable rabbitmq_delayed_message_exchange 然后，我们再声明几个Bean： @Configuration public class DelayedRabbitMQConfig &#123; public static final String DELAYED_QUEUE_NAME = \"delay.queue.demo.delay.queue\"; public static final String DELAYED_EXCHANGE_NAME = \"delay.queue.demo.delay.exchange\"; public static final String DELAYED_ROUTING_KEY = \"delay.queue.demo.delay.routingkey\"; @Bean public Queue immediateQueue() &#123; return new Queue(DELAYED_QUEUE_NAME); &#125; @Bean public CustomExchange customExchange() &#123; Map&lt;String, Object> args = new HashMap&lt;>(); args.put(\"x-delayed-type\", \"direct\"); return new CustomExchange(DELAYED_EXCHANGE_NAME, \"x-delayed-message\", true, false, args); &#125; @Bean public Binding bindingNotify(@Qualifier(\"immediateQueue\") Queue queue, @Qualifier(\"customExchange\") CustomExchange customExchange) &#123; return BindingBuilder.bind(queue).to(customExchange).with(DELAYED_ROUTING_KEY).noargs(); &#125; &#125; controller层再添加一个入口： @RequestMapping(\"delayMsg2\") public void delayMsg2(String msg, Integer delayTime) &#123; log.info(\"当前时间：&#123;&#125;,收到请求，msg:&#123;&#125;,delayTime:&#123;&#125;\", new Date(), msg, delayTime); sender.sendDelayMsg(msg, delayTime); &#125; 消息生产者的代码也需要修改： public void sendDelayMsg(String msg, Integer delayTime) &#123; rabbitTemplate.convertAndSend(DELAYED_EXCHANGE_NAME, DELAYED_ROUTING_KEY, msg, a ->&#123; a.getMessageProperties().setDelay(delayTime); return a; &#125;); &#125; 最后，再创建一个消费者： @RabbitListener(queues = DELAYED_QUEUE_NAME) public void receiveD(Message message, Channel channel) throws IOException &#123; String msg = new String(message.getBody()); log.info(\"当前时间：&#123;&#125;,延时队列收到消息：&#123;&#125;\", new Date().toString(), msg); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; 一切准备就绪，启动！然后分别访问以下链接： http:&#x2F;&#x2F;localhost:8080&#x2F;rabbitmq&#x2F;delayMsg2?msg&#x3D;msg1&amp;delayTime&#x3D;20000 http:&#x2F;&#x2F;localhost:8080&#x2F;rabbitmq&#x2F;delayMsg2?msg&#x3D;msg2&amp;delayTime&#x3D;2000 日志如下： 2019-07-28 17:28:13.729 INFO 25804 --- [nio-8080-exec-2] c.m.d.controller.RabbitMQMsgController : 当前时间：Sun Jul 28 17:28:13 CST 2019,收到请求，msg:msg1,delayTime:20000 2019-07-28 17:28:20.607 INFO 25804 --- [nio-8080-exec-1] c.m.d.controller.RabbitMQMsgController : 当前时间：Sun Jul 28 17:28:20 CST 2019,收到请求，msg:msg2,delayTime:2000 2019-07-28 17:28:22.624 INFO 25804 --- [ntContainer#1-1] c.m.d.mq.DeadLetterQueueConsumer : 当前时间：Sun Jul 28 17:28:22 CST 2019,延时队列收到消息：msg2 2019-07-28 17:28:33.751 INFO 25804 --- [ntContainer#1-1] c.m.d.mq.DeadLetterQueueConsumer : 当前时间：Sun Jul 28 17:28:33 CST 2019,延时队列收到消息：msg1 第二个消息被先消费掉了，符合预期。至此，RabbitMQ实现延时队列的部分就完结了。 九、总结延时队列在需要延时处理的场景下非常有用，使用RabbitMQ来实现延时队列可以很好的利用RabbitMQ的特性，如：消息可靠发送、消息可靠投递、死信队列来保障消息至少被消费一次以及未被正确处理的消息不会被丢弃。另外，通过RabbitMQ集群的特性，可以很好的解决单点故障问题，不会因为单个节点挂掉导致延时队列不可用或者消息丢失。 当然，延时队列还有很多其它选择，比如利用Java的DelayQueu，利用Redis的zset，利用Quartz或者利用kafka的时间轮，这些方式各有特点，但就像炉石传说一般，这些知识就好比手里的卡牌，知道的越多，可以用的卡牌也就越多，遇到问题便能游刃有余，所以需要大量的知识储备和经验积累才能打造出更出色的卡牌组合，让自己解决问题的能力得到更好的提升。","tags":[]},{"title":"rabbitmq基本学习1","date":"2021-01-04T07:00:00.000Z","path":"posts/undefined.html","text":"安装 https://packagecloud.io/rabbitmq/ 安装erlangcurl -s https://packagecloud.io/install/repositories/rabbitmq/erlang/script.rpm.sh | sudo bash dnf install erlang 安装rabbitmqcurl -s https:&#x2F;&#x2F;packagecloud.io&#x2F;install&#x2F;repositories&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;script.rpm.sh | sudo bash 启动后台管理界面rabbitmq-plugins enable rabbitmq_management 相关端口Listening ports：3个端口（5672,25672,15672）; 5672对应的是amqp，25672对应的是clustering，15672对应的是http（也就是我们登录RabbitMQ后台管理时用的端口）。 25672对应的是集群，15672对应的是后台管理。因为RabbitMQ遵循Ampq协议，所以5672对应的就是RabbitMQ的通信了。 rabbitMQ常用的命令启动监控管理器：rabbitmq-plugins enable rabbitmq_management 关闭监控管理器：rabbitmq-plugins disable rabbitmq_management 启动rabbitmq：rabbitmq-service start 关闭rabbitmq：rabbitmq-service stop 查看所有的队列：rabbitmqctl list_queues 清除所有的队列：rabbitmqctl reset 关闭应用：rabbitmqctl stop_app 启动应用：rabbitmqctl start_app 用户和权限设置 添加用户：rabbitmqctl add_user username password 分配角色：rabbitmqctl set_user_tags username administrator 新增虚拟主机：rabbitmqctl add_vhost vhost_name 将新虚拟主机授权给新用户：rabbitmqctl set_permissions -p vhost_name username “.*” “.*” “.*”(后面三个”*”代表用户拥有配置、写、读全部权限) 角色说明 超级管理员(administrator) 可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 监控者(monitoring) 可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 策略制定者(policymaker) 可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 普通管理者(management) 仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他 无法登陆管理控制台，通常就是普通的生产者和消费者。 创建用户guest默认不能远程登陆 #RabbitMQ新增账号密码 rabbitmqctl add_user test 123456 #设置成管理员角色 rabbitmqctl set_user_tags test administrator #设置权限 rabbitmqctl set_permissions -p \"/\" test \".*\" \".*\" \".*\" #查看用户列表 rabbitmqctl list_users 基本操作队列相关属性 queue:声明的队列名称，同一个队列在声明之后不能修改属性。 durable：是否持久化，是否将队列持久化到mnesia数据库中，有专门的表保存我们的队列声明。 exclusive：排外，①当前定义的队列是connection的channel是共享的，其他的connection是访问不到的。②当connection关闭的时候，队列将被删除。 autoDelete：自动删除，当最后一个consumer（消费者）断开之后，队列将自动删除。 arguments：参数是rabbitmq的一个扩展，功能非常强大，基本是AMPQ中没有的。 x-message-ttl：Number ，发布的消息在队列中存在多长时间后被取消（单位毫秒） 可以对单个消息设置过期时间 x-expires：Number 当Queue（队列）在指定的时间未被访问，则队列将被自动删除。 x-max-length：Number 队列所能容下消息的最大长度。当超出长度后，新消息将会覆盖最前面的消息，类似于Redis的LRU算法。 x-max-length-bytes：Number 限定队列的最大占用空间，当超出后也使用类似于Redis的LRU算法。 x-overflow：String 设置队列溢出行为。这决定了当达到队列的最大长度时，消息会发生什么。有效值为Drop Head或Reject Publish。 x-dead-letter-exchange：String 如果消息被拒绝或过期或者超出max，将向其重新发布邮件的交换的可选名称 x-dead-letter-routing-key：String 如果不定义，则默认为溢出队列的routing-key，因此，一般和6一起定义。 x-max-priority：Number 如果将一个队列加上优先级参数，那么该队列为优先级队列。 1）、给队列加上优先级参数使其成为优先级队列 x-max-priority=10【值不要太大，本质是一个树结构】 2）、给消息加上优先级属性 x-queue-mode：String 队列类型 x-queue-mode=lazy 懒队列，在磁盘上尽可能多地保留消息以减少RAM使用；如果未设置，则队列将保留内存缓存以尽可能快地传递消息。 x-queue-master-locator：String 将队列设置为主位置模式，确定在节点集群上声明时队列主位置所依据的规则。 java代码ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost(\"192.168.100.11\"); connectionFactory.setPort(5672); connectionFactory.setUsername(\"test\"); connectionFactory.setPassword(\"test\"); try(Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel()) &#123; channel.queueDeclare(QUEUE_NAME,false,false,false,null); channel.addConfirmListener(new ConfirmListener()&#123; @Override public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println(\"handleack \"+deliveryTag); &#125; @Override public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println(\"handleNack \"+deliveryTag); &#125; &#125;); channel.addReturnListener(returnMessage -> System.out.println(\"返回的消息 \"+returnMessage)); String message = RandomStringUtils.randomAlphanumeric(10)+ \" hello !!\"; System.out.println(\"发送的消息 \"+ message); channel.basicPublish(\"\",QUEUE_NAME,null,message.getBytes(StandardCharsets.UTF_8)); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; 消息发送确认机制事务机制这里首先探讨下RabbitMQ事务机制。 RabbitMQ中与事务机制有关的方法有三个：txSelect(), txCommit()以及txRollback(), txSelect用于将当前channel设置成transaction模式，txCommit用于提交事务，txRollback用于回滚事务，在通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，如果txCommit提交成功了，则消息一定到达了broker了，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务了。 关键代码： channel.txSelect(); channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes()); channel.txCommit(); 通过wirkshark抓包（ip.addr==xxx.xxx.xxx.xxx &amp;&amp; amqp），可以看到：（注意这里的Tx.Commit与Tx.Commit-Ok之间的时间间隔294ms，由此可见事务还是很耗时的。） 我们先来看看没有事务的通信过程是什么样的：可以看到带事务的多了四个步骤： client发送Tx.Select broker发送Tx.Select-Ok(之后publish) client发送Tx.Commit broker发送Tx.Commit-Ok 下面我们来看下事务回滚是什么样子的。关键代码如下： try &#123; channel.txSelect(); channel.basicPublish(exchange, routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, msg.getBytes()); int result = 1 / 0; channel.txCommit(); &#125; catch (Exception e) &#123; e.printStackTrace(); channel.txRollback(); &#125; 同样通过wireshark抓包可以看到：代码中先是发送了消息至broker中但是这时候发生了异常，之后在捕获异常的过程中进行事务回滚。 事务确实能够解决producer与broker之间消息确认的问题，只有消息成功被broker接受，事务提交才能成功，否则我们便可以在捕获异常进行事务回滚操作同时进行消息重发，但是使用事务机制的话会降低RabbitMQ的性能，那么有没有更好的方法既能保障producer知道消息已经正确送到，又能基本上不带来性能上的损失呢？从AMQP协议的层面看是没有更好的方法，但是RabbitMQ提供了一个更好的方案，即将channel信道设置成confirm模式。 Confirm模式概述上面我们介绍了RabbitMQ可能会遇到的一个问题，即生成者不知道消息是否真正到达broker，随后通过AMQP协议层面为我们提供了事务机制解决了这个问题，但是采用事务机制实现会降低RabbitMQ的消息吞吐量，那么有没有更加高效的解决方式呢？答案是采用Confirm模式。 producer端confirm模式的实现原理生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。 confirm模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。 在channel 被设置成 confirm 模式之后，所有被 publish 的后续消息都将被 confirm（即 ack） 或者被nack一次。但是没有对消息被 confirm 的快慢做任何保证，并且同一条消息不会既被 confirm又被nack 。 开启confirm模式的方法生产者通过调用channel的confirmSelect方法将channel设置为confirm模式，如果没有设置no-wait标志的话，broker会返回confirm.select-ok表示同意发送者将当前channel信道设置为confirm模式(从目前RabbitMQ最新版本3.6来看，如果调用了channel.confirmSelect方法，默认情况下是直接将no-wait设置成false的，也就是默认情况下broker是必须回传confirm.select-ok的)。 已经在transaction事务模式的channel是不能再设置成confirm模式的，即这两种模式是不能共存的。 编程模式对于固定消息体大小和线程数，如果消息持久化，生产者confirm(或者采用事务机制)，消费者ack那么对性能有很大的影响. 消息持久化的优化没有太好方法，用更好的物理存储（SAS, SSD, RAID卡）总会带来改善。生产者confirm这一环节的优化则主要在于客户端程序的优化之上。归纳起来，客户端实现生产者confirm有三种编程方式： 普通confirm模式：每发送一条消息后，调用waitForConfirms()方法，等待服务器端confirm。实际上是一种串行confirm了。 批量confirm模式：每发送一批消息后，调用waitForConfirms()方法，等待服务器端confirm。 异步confirm模式：提供一个回调方法，服务端confirm了一条或者多条消息后Client端会回调这个方法。 从编程实现的复杂度上来看：第1种普通confirm模式最简单，publish一条消息后，等待服务器端confirm,如果服务端返回false或者超时时间内未返回，客户端进行消息重传。关键代码如下： channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes()); if(!channel.waitForConfirms())&#123; System.out.println(\"send message failed.\"); &#125; wirkShark抓包可以看到如下：(注意这里的Publish与Ack的时间间隔：305ms 4ms 4ms 15ms 5ms… ) 第二种批量confirm模式稍微复杂一点，客户端程序需要定期（每隔多少秒）或者定量（达到多少条）或者两则结合起来publish消息，然后等待服务器端confirm, 相比普通confirm模式，批量极大提升confirm效率，但是问题在于一旦出现confirm返回false或者超时的情况时，客户端需要将这一批次的消息全部重发，这会带来明显的重复消息数量，并且，当消息经常丢失时，批量confirm性能应该是不升反降的。关键代码： channel.confirmSelect(); for(int i=0;i&lt;batchCount;i++)&#123; channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes()); &#125; if(!channel.waitForConfirms())&#123; System.out.println(\"send message failed.\"); &#125; 第三种异步confirm模式的编程实现最复杂，Channel对象提供的ConfirmListener()回调方法只包含deliveryTag（当前Chanel发出的消息序号），我们需要自己为每一个Channel维护一个unconfirm的消息序号集合，每publish一条数据，集合中元素加1，每回调一次handleAck方法，unconfirm集合删掉相应的一条（multiple=false）或多条（multiple=true）记录。从程序运行效率上看，这个unconfirm集合最好采用有序集合SortedSet存储结构。实际上，SDK中的waitForConfirms()方法也是通过SortedSet维护消息序号的。关键代码： SortedSet&lt;Long> confirmSet = Collections.synchronizedSortedSet(new TreeSet&lt;Long>()); channel.confirmSelect(); channel.addConfirmListener(new ConfirmListener() &#123; public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123; if (multiple) &#123; confirmSet.headSet(deliveryTag + 1).clear(); &#125; else &#123; confirmSet.remove(deliveryTag); &#125; &#125; public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println(\"Nack, SeqNo: \" + deliveryTag + \", multiple: \" + multiple); if (multiple) &#123; confirmSet.headSet(deliveryTag + 1).clear(); &#125; else &#123; confirmSet.remove(deliveryTag); &#125; &#125; &#125;); while (true) &#123; long nextSeqNo = channel.getNextPublishSeqNo(); channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes()); confirmSet.add(nextSeqNo); &#125; SDK中waitForConfirms方法实现： /** Set of currently unconfirmed messages (i.e. messages that have * not been ack'd or nack'd by the server yet. */ private final SortedSet&lt;Long> unconfirmedSet = Collections.synchronizedSortedSet(new TreeSet&lt;Long>()); public boolean waitForConfirms(long timeout) throws InterruptedException, TimeoutException &#123; if (nextPublishSeqNo == 0L) throw new IllegalStateException(\"Confirms not selected\"); long startTime = System.currentTimeMillis(); synchronized (unconfirmedSet) &#123; while (true) &#123; if (getCloseReason() != null) &#123; throw Utility.fixStackTrace(getCloseReason()); &#125; if (unconfirmedSet.isEmpty()) &#123; boolean aux = onlyAcksReceived; onlyAcksReceived = true; return aux; &#125; if (timeout == 0L) &#123; unconfirmedSet.wait(); &#125; else &#123; long elapsed = System.currentTimeMillis() - startTime; if (timeout > elapsed) &#123; unconfirmedSet.wait(timeout - elapsed); &#125; else &#123; throw new TimeoutException(); &#125; &#125; &#125; &#125; &#125; 性能测试Client端机器和RabbitMQ机器配置：CPU:24核，2600MHZ, 64G内存，1TB硬盘。Client端发送消息体大小10B，线程数为1即单线程，消息都持久化处理（deliveryMode:2）。分别采用事务模式、普通confirm模式，批量confirm模式和异步confirm模式进行producer实验，比对各个模式下的发送性能。 发送平均速率： 事务模式（tx）：1637.484 普通confirm模式(common)：1936.032 批量confirm模式(batch)：10432.45 异步confirm模式(async)：10542.06 可以看到事务模式性能是最差的，普通confirm模式性能比事务模式稍微好点，但是和批量confirm模式还有异步confirm模式相比，还是小巫见大巫。批量confirm模式的问题在于confirm之后返回false之后进行重发这样会使性能降低，异步confirm模式(async)编程模型较为复杂，至于采用哪种方式，那是仁者见仁智者见智了。 消息确认（Consumer端）为了保证消息从队列可靠地到达消费者，RabbitMQ提供消息确认机制(message acknowledgment)。消费者在声明队列时，可以指定noAck参数，当noAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息。否则，RabbitMQ会在队列中消息被消费后立即删除它。 采用消息确认机制后，只要令noAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止。 当noAck=false时，对于RabbitMQ服务器端而言，队列中的消息分成了两部分：一部分是等待投递给消费者的消息；一部分是已经投递给消费者，但是还没有收到消费者ack信号的消息。如果服务器端一直没有收到消费者的ack信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消息重新进入队列，等待投递给下一个消费者（也可能还是原来的那个消费者）。 RabbitMQ不会为未ack的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么设计的原因是RabbitMQ允许消费者消费一条消息的时间可以很久很久。 RabbitMQ管理平台界面上可以看到当前队列中Ready状态和Unacknowledged状态的消息数，分别对应上文中的等待投递给消费者的消息数和已经投递给消费者但是未收到ack信号的消息数。也可以通过命令行来查看上述信息： 代码示例（关闭自动消息确认，进行手动ack）： QueueingConsumer consumer = new QueueingConsumer(channel); channel.basicConsume(ConfirmConfig.queueName, false, consumer); while(true)&#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String msg = new String(delivery.getBody()); // do something with msg. channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; broker将在下面的情况中对消息进行confirm： broker发现当前消息无法被路由到指定的queues中（如果设置了mandatory属性，则broker会发送basic.return）非持久属性的消息到达了其所应该到达的所有queue中（和镜像queue中）持久消息到达了其所应该到达的所有queue中（和镜像中），并被持久化到了磁盘（fsync）持久消息从其所在的所有queue中被consume了（如果必要则会被ack） basicRecover：是路由不成功的消息可以使用recovery重新发送到队列中。basicReject：是接收端告诉服务器这个消息我拒绝接收,不处理,可以设置是否放回到队列中还是丢掉，而且只能一次拒绝一个消息,官网中有明确说明不能批量拒绝消息，为解决批量拒绝消息才有了basicNack。basicNack：可以一次拒绝N条消息，客户端可以设置basicNack方法的multiple参数为true，服务器会拒绝指定了delivery_tag的所有未确认的消息(tag是一个64位的long值，最大值是9223372036854775807)。 交换机有4种不同的交换机类型： 直连交换机：Direct exchange 扇形交换机：Fanout exchange 主题交换机：Topic exchange 首部交换机：Headers exchange 死信队列死信队列是什么死信，在官网中对应的单词为“Dead Letter”，可以看出翻译确实非常的简单粗暴。那么死信是个什么东西呢？ “死信”是RabbitMQ中的一种消息机制，当你在消费消息时，如果队列里的消息出现以下情况： 消息被否定确认，使用 channel.basicNack 或 channel.basicReject ，并且此时requeue 属性被设置为false。 消息在队列的存活时间超过设置的TTL时间。 消息队列的消息数量已经超过最大队列长度。 那么该消息将成为“死信”。 “死信”消息会被RabbitMQ进行特殊处理，如果配置了死信队列信息，那么该消息将会被丢进死信队列中，如果没有配置，则该消息将会被丢弃。 参考 https://www.jianshu.com/p/469f4608ce5d https://blog.csdn.net/u013256816/article/details/55515234","tags":[]},{"title":"type与interface区别","date":"2021-01-03T07:00:00.000Z","path":"posts/undefined.html","text":"interface VS type 相同点 都可以描述一个对象或者函数 interface type 都允许拓展（extends） interface extends interface type 与 type 相交 interface extends type type 与 interface 相交 不同点 type 可以而 interface 不行 interface 可以而 type 不行 总结 interface VS type大家使用 typescript 总会使用到 interface 和 type，官方规范 稍微说了下两者的区别 An interface can be named in an extends or implements clause, but a type alias for an object type literal cannot. An interface can have multiple merged declarations, but a type alias for an object type literal cannot.但是没有太具体的例子。 明人不说暗话，直接上区别。 相同点都可以描述一个对象或者函数interfaceinterface User &#123; name: string age: number &#125; interface SetUser &#123; (name: string, age: number): void; &#125; typetype User &#x3D; &#123; name: string age: number &#125;; type SetUser &#x3D; (name: string, age: number): void; 拓展（extends）与 交叉类型（Intersection Types）interface 可以 extends， 但 type 是不允许 extends 和 implement 的，但是 type 缺可以通过交叉类型 实现 interface 的 extend 行为，并且两者并不是相互独立的，也就是说 interface 可以 extends type, type 也可以 与 interface 类型 交叉 。 虽然效果差不多，但是两者语法不同。 interface extends interfaceinterface Name &#123; name: string; &#125; interface User extends Name &#123; age: number; &#125; type 与 type 交叉type Name &#x3D; &#123; name: string; &#125; type User &#x3D; Name &amp; &#123; age: number &#125;; interface extends typetype Name &#x3D; &#123; name: string; &#125; interface User extends Name &#123; age: number; &#125; type 与 interface 交叉interface Name &#123; name: string; &#125; type User &#x3D; Name &amp; &#123; age: number; &#125; 不同点type 可以而 interface 不行 type 可以声明基本类型别名，联合类型，元组等类型 &#x2F;&#x2F; 基本类型别名 type Name &#x3D; string &#x2F;&#x2F; 联合类型 interface Dog &#123; wong(); &#125; interface Cat &#123; miao(); &#125; type Pet &#x3D; Dog | Cat &#x2F;&#x2F; 具体定义数组每个位置的类型 type PetList &#x3D; [Dog, Pet] type 语句中还可以使用 typeof 获取实例的 类型进行赋值 &#x2F;&#x2F; 当你想获取一个变量的类型时，使用 typeof let div &#x3D; document.createElement(&#39;div&#39;); type B &#x3D; typeof div 其他骚操作 type StringOrNumber &#x3D; string | number; type Text &#x3D; string | &#123; text: string &#125;; type NameLookup &#x3D; Dictionary&lt;string, Person&gt;; type Callback&lt;T&gt; &#x3D; (data: T) &#x3D;&gt; void; type Pair&lt;T&gt; &#x3D; [T, T]; type Coordinates &#x3D; Pair&lt;number&gt;; type Tree&lt;T&gt; &#x3D; T | &#123; left: Tree&lt;T&gt;, right: Tree&lt;T&gt; &#125;; interface 可以而 type 不行interface 能够声明合并 interface User &#123; name: string age: number &#125; interface User &#123; sex: string &#125; &#x2F;* User 接口为 &#123; name: string age: number sex: string &#125; *&#x2F; 总结一般来说，如果不清楚什么时候用interface/type，能用 interface 实现，就用 interface , 如果不能就用 type 。其他更多详情参看 官方规范文档","tags":[{"name":"react","slug":"react","permalink":"http://wumuwumu.github.io/tags/react/"},{"name":"ts","slug":"ts","permalink":"http://wumuwumu.github.io/tags/ts/"}]},{"title":"关于Object o = new Object()","date":"2020-12-23T04:00:00.000Z","path":"posts/undefined.html","text":"1、请解释一下对象的创建过程？（半初始化） 2、加问DCL与volatile问题？（指令重排）volatile的作用：保持线程可见性，防止指令重排 DCL 是双重检查锁 3、对象在内存中的存储布局？（对象和数组的存储不同） 4、对象头具体包括什么？（markedword klasspointer） synchronized锁信息 5、对象怎么定位？（直接 间接） 6、对象怎么分配？（栈上-线程本地-eden-old） 7、Object o = new Object()在内存中占用多少字节。","tags":[]},{"title":"JVM垃圾回收模型","date":"2020-12-20T12:00:00.000Z","path":"posts/undefined.html","text":"一 JVM垃圾回收模型一. GC算法1.1 标记-清除算法（Mark-Sweep）算法分为“标记”和“清除”两个阶段首先标记出所有需要回收的对象,然后回收所有需要回收的对象。 问题：效率不高，需要扫描所有的对象，堆越大，GC越慢，并且存在严重的内存碎片问题,空间碎片太多可能会导致后续使用中无法找到足够的连续内存而提前触发另一次的垃圾搜集动作，GC次数越多，碎片越严重。 示例如下，红色的就是未被标记要回收的，并且红色的区域被回收之后，绿色的还在“原地”，并不会对内存区域进行整理。 1.2 标记-整理算法（Mark-Compact）标记过程仍然一样，但后续步骤不是进行直接清理，而是令所有存活的对象一端移动，然后直接清理掉这端边界以外的内存。 1.3 复制搜集算法（Coping）以前的复制收集算法描述：将可用的内存分为两半， 每次只使用其中的一块，当半区内存用完了，仅将还存活的对象复制到另一块上，然后就把原来整块内存空间清理 问题：这样使每次内存回收都是对整个半区的回收，内存分配时就不用考虑内存碎片等复杂情况，只需要移动堆顶指针，按顺序分配内存就可以了，实现简单，运行高效，只是这种算法将堆空间内存缩为原来的一半。 现在的复制搜集算法 描述：现在的商业虚拟机都是采用复制搜集算法来回收新生代，将内存分为一块较大的eden空间和两块较小的survivor空间，每次只是用eden和其中一块survivor空间，当回收时将eden和survivor空间中还存活的对象一次性拷贝到另一个survivor空间上，然后清理用过的eden和survivor空间，oracle hotspot虚拟机默认eden 和 survivor的比例是 8:1 ,也就是每次只有百分之十的内存被浪费。示例图如下（最开始A被引用，A引用了C，C引用了H，GC的最后清除了D和G），注意这里跟前面的标记整理和标记清除不一样哦，这里是不用标记的。 好处：1.只需要扫描存活的对象（跟前面的标记整理和标记清除不一样哦），效率更高；2.不会产生碎片 3.复制算法非常适合对象存活时间比较短的对象，因为每次GC总能回收大部分的对象，复制的开销比较小。根据IBM的专门研究,98%的Java对象只会存活1个GC周期,对这些对象很适合用复制算法。而且不用1:1的划分工作区和复制区的空间 问题：复制搜集算法在对象存活率高得时候效率有所下降，就需要有额外的空间进行分配担保用于应付内存中所有对象都百分之百存活的极端情况（在新生代中可以使用老年代进行空间分配担保），所以在老年代不能直接采用这种算法 1.4 分代算法（Generational） 描述：当前商业虚拟机的垃圾收集都是采用“分代收集”( Generational Collecting)算法根据对象不同的存活周期将内存划分为几块；一般是把Java堆分作新生代和老年代,这样就可以根据各个年代的特点采用最适当的收集算法,1. 譬如新生代每次GC都有大批对象死去,只有少量存活,那就选用复制算法只需要付出少量存活对象的复制成本就可以完成收集 2. 并且有老年代作为空间分配担保；老年代采用Mark- Sweep或者Mark- Compact算法 年轻代( Young Generation)新生成的对象都放在新生代。年轻代用复制算法进行GC(理论上年轻代对象的生命周期非常短,所以适合复制算法，因为大部分都是不存活的对象)，年轻代分三个区，一个Eden区，两个 Survivor区(可以通过参数设置 Survivor个数)。对象在Eden区中生成，在新生代垃圾回收时，Eden区和From Survivor区中还存活的对象将被复制到另一个 Survivor区(称为To Survivor区)，此次垃圾回收完成之后From Survivor和To Survivor区交换角色。下一次垃圾回收时重复上述过程，直到To Survivor 区被填满，然后一次性将To Survivor中的所有对象移动到老年代中。2个 Survivor是完全对称,轮流替换。Eden和2个 Survivor的缺省比例是8:1:1,也就是10%的空间会被浪费。可以根据 GC log的信息调整大小的比例 老年代( Old Generation)存放了经过一次或多次GC还存活的对象般采用Mark- Sweep或者Mark- Compact算法，进行GC有多种垃圾收集器可以选择。每种垃圾收集器可以看作一个GC算法的具体实现。可以根据具体应用的需求选用合适的垃圾收集器(追求吞吐量?追求最短的响应时间?) 二 垃圾回收器 GC的种类 Scavenge GC (Minor GC）：对新生代，触发时机是在新对象生成时，Eden空间满了，理论上Eden区大多数对象会在 Scavenge GC回收，复制算法的执行效率会很高， Scavenge GC时间比较短。 Full GC：对整个JVM进行整理，包括 Young、Old和Perm（永久代，jdk8没有，jdk为元空间），主要的触发时机:1)Old满了2)Perm满了3) system.gc() Full GC的执行效率很低，尽量减少 Full GC 分代模型是GC的宏观愿景，垃圾回收器是GC的具体实现，hotspot jvm提供多种垃圾回收器，我们需要根据具体的应用采用多种垃圾回收器 垃圾回收器的并行（Parallel）和并发（Concurrent），并行指的是多个收集器的线程同时工作，但是用户线程处于等待状态；并发指的是收集器在工作的同时，可以允许用户线程工作，但是并发并不代表解决了GC的停顿问题，在关键步骤该停顿的还是要停顿，比如在收集器标记垃圾的时候，但是在清除垃圾的时候用户线程可以和GC线程并发执行 2.1 serial 收集器 是最早的收集器,单线程收集器,Hotspot Client模式缺省的收集器，收集时会暂停所有工作线程(Stop The World,简称STW)，因为是单线程GC,没有多线程切换的额外开销,简单实用 New和 Old Generation都可以使用在新生代,采用复制算法，在老年代,采用Mark-Compact算法; 2.2 Serial Old 收集器Serial Old是单线程收集器,使用标记一整理算法, 是老年代的收集器 2.3 parnew收集器 Parnew收集器就是Serial收集器在新生代的多线程版本，是Server模式下新生代的缺省收集器，除了使用多个收集线程外,其余行为包括算法、STW、对象分配规则、回收策略等都与 Serial收集器一模一样。 使用复制算法(因为针对新生代，效率比较高); 只有在多CPU的环境下,效率才会比 Serial收集器高; 可以通过-XX: Parallelg Cthreads来控制GC线程数的多少，需要结合具体CPU的个数; 2.4 Parallel Scavenge收集器Parallel Scavenge 收集器也是一个多线程收集器（Parallel就是并行的意思）,也是使用复制算法，但它的对象分配规则与回收策略都与 Parnew收集器有所不同，它是以吞吐量最大化(即GC时间占总运行时间最小)为目标的收集器实现，它允许较长时间的STW换取总吞吐量最大化，jvm1.8默认在新生代使用Parallel Scavenge ，老年代使用Parallel Old收集 2.5 Parallel Old 收集器JVM1.6提供，在此之前，新生代使用PS收集器的话，老年代除了使用Serial Old外别无选择，因为PS无法和CMS配合工作。jvm1.8默认在新生代使用Parallel Scavenge ，老年代使用Parallel Old收集 Parallel Scavenge在老年代的实现； 采用多线程,Mark-Compact算法； 更注重吞吐量Parallel Scavenge+ Parallel Old = 高吞吐量,但GC停顿可能不理想 2.6 CMS收集器CMS是一种以最短停顿时间为目标的老年代收集器，使用CMS并不能达到GC效率最高（总的GC时间最小），但是它能尽可能降低服务的停顿时间 只针对老年区,一般在新生代结合Parnew使用 CMS收集器使用的是标记–清除算法 使用-XX:+ UseConcMarkSweepGC打开 收集步骤方法一CMS是基于“标记–清除”算法实现的，在老年代中的整个过程分为4个步骤： 其中，初始标记，重新标记这两个步骤任然需要“stop the world”，其它两个步骤中用户线程是一起并发执行的 初始标记（CMS initial mark），初始标记只是标记一下GC ROOTS 能直接关联到的对象，速度很快 并发标记（CMS concurrent mark），并发标记阶段就是进行GC ROOTS Tracing 的过程，此时用户线程也是在同步执行的 重新标记（CMS remark），重新标记阶段则是为了修正并发标记期间因为用户程序继续运作而导致标记产生变动的那一部分对象的标记记录（ 这部分对象是指从 GC Roots 不可达的对象，因为用户程序的并发运行，又可达了），这个阶段的停顿时间一般会比初始标记阶段稍长一些，但是远比并发标记的时间短。 并发清除（CMS concurrent sweep），收集在标记阶段被标识为不可访问的对象。The collection of a dead object adds the space for the object to a free list for later allocation. Coalescing of dead objects may occur at this point. Note that live objects are not moved.死亡对象收集为空闲列表增加了更多的空间，以便以后分配。在这一点上可能会发生死物体空间的的合并。请注意，不会移动活动对象。 CMS收集器的运作步骤如下图所示，在整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以和用户线程一起工作，因此从整体上看，CMS收集器线程的内存回收过程是与用户线程一起并发执行的。 CMS缺点 CMS以牺牲CPU资源的代价来减少用户线程的停顿。当CPU个数少于4的时候,有可能对吞吐量影响非常大； CMS收集器无法处理浮动垃圾（Floating Garbage）,即第一次标记，认为某个对象不是垃圾，但是在CMS线程和用户线程在并发执行的过程中此对象可能变成了垃圾，那么CMS无法在这次的垃圾回收中将它回收掉。无法处理这些垃圾可能出现”concurrent mode failure“失败而导致另一次Full GC的产生。如果在应用中老年代的增长速度不是太快，可以适当调高-XX:CMSInitiatingOccupancyFractio 的值来提高出发的百分比，以便降低内存回收的次数从而获取更好的性能。要是CMS运行期预留的内存无法满足程序的需要时，虚拟机将启动后备预案，临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样一来停顿的时间就更久了。所以说参数-XX:CMSInitiatingOccupancyFraction 设置太高容易导致大量的”concurrent mode failure“失败，性能反而降低 由于基于MS算法即Mark-Sweep,收集结束时会带来碎片问题，空间碎片过多会给大对象分配带来很大麻烦，望往往出现老年代还有很大的空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前进行一次Full GC。CMS收集器提供了一个参数：-XX:+UseCMSCompactAtFullConnection 开关参数，默认是开启的，用于在CMS收集器顶不住要进行 Full GC时同时开启内存碎片的合并整理过程,内存整理的过程是无法并发的并且需要stw,空间碎片问题没有了,但停顿时间不得不变长。 收集步骤方法二CMS收集器收集步骤，以下是将上面的四个步骤进一步细分为7个步骤，但是其中有stw的还是只有两个步骤，减少了stw的时间。 Phase 1: Initial Mark，这个是CMS两次stop-the-world事件的其中一次,这个阶段的目标是:标记那些直接被GCroot引用或者被年轻代存活对象所引用的所有对象（CMS是针对老年代的） Phase 2：Concurrent Mark，在这个阶段 Garbage Collector会遍历老年代,然后标记所有存活的对象,它会根据上个阶段找到的 GC Roots遍历査找。并发标记阶段，它会与用户的应用程序并发运行并不是老年代所有的存活对象都会被标记，因为在标记期间用户的程序可能会改变一些引用。在下的图中,与阶段1的图进行对比,就会发现有一个对象的引用已经发生了变化 Phase 3: Concurrent Preclean，这也是一个并发阶段,与应用的线程并发运行,并不会stop用户线程。在并发运行的过程中,一些对象的引用可能会发生变化,但是这种情况发生时,JVM会将包含这个对象的区域(Card)标记为Diy，这个动作称为Card Marking，在pre-clean阶段，那些能够从Dirty对象到达的对象也会被标记,这个标记做完之后, dirty card标记就会被清除了 Phase 4: Concurrent Abortable Preclean，这也是一个并发阶段,但是同样不会影响用户的应用线程,这个阶段是为了尽量承担STW(stop-the-world)中最终标记阶段的工作。这个阶段持续时间依赖于很多的因素由于这个阶段是在重复做很多相同的工作(比如:重复迭代的次数、完成的工作量或者时钟时间等） Phase 5: Final Remark，这是第二个STW阶段,也是CMS中的最后一个，这个阶段的目标是标记老年代所有的存活对象，由于之前的阶段是并发执行的，GC线程可能跟不上应用程序的变化为了完成标记老年代所有存活对象的目标，STW就非常有必要了，这个阶段会比前面的几个阶段更复杂一些 Phase 6: Concurrent Sweep，这里不需要STW,它是与用户的应用程序并发运行,这个阶段是:清除那些不再使用的对象,回收它们的占用空间为将来使用 Phase 7: Concurrent Reset，这个阶段也是并发执行的,它会重设CMS内部的数据结构,为下次的GC做准备 实验实验代码MyTest5.java 虚拟机参数 -verbose:gc-Xmx20M-Xms20m-Xmn10M-XX:SurvivorRatio=8-XX:+PrintGCDetails-XX:+UseConcMarkSweepGC 输出结果 [GC (Allocation Failure) [ParNew: 6104K->742K(9216K), 0.0029166 secs] 6104K->4840K(19456K), 0.0029703 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 2222222 [GC (Allocation Failure) [ParNew: 4995K->65K(9216K), 0.0034135 secs] 9093K->8973K(19456K), 0.0034413 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC (CMS Initial Mark) [1 CMS-initial-mark: 8907K(10240K)] 13069K(19456K), 0.0001747 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] # CMS-initial-mark [CMS-concurrent-mark-start] 33333333 4444444 [CMS-concurrent-mark: 0.001/0.001 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [CMS-concurrent-preclean-start] [CMS-concurrent-preclean: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [CMS-concurrent-abortable-preclean-start] [CMS-concurrent-abortable-preclean: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC (CMS Final Remark) [YG occupancy: 6531 K (9216 K)][Rescan (parallel) , 0.0001118 secs][weak refs processing, 0.0000169 secs][class unloading, 0.0003630 secs][scrub symbol table, 0.0006629 secs][scrub string table, 0.0001339 secs][1 CMS-remark: 8907K(10240K)] 15439K(19456K), 0.0013879 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap par new generation total 9216K, used 6531K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000) eden space 8192K, 78% used [0x00000000fec00000, 0x00000000ff250980, 0x00000000ff400000) # 新生代存了一个4m和一个2m的数组对象，大概是6m from space 1024K, 6% used [0x00000000ff400000, 0x00000000ff4104c8, 0x00000000ff500000) [CMS-concurrent-sweep-start] to space 1024K, 0% used [0x00000000ff500000, 0x00000000ff500000, 0x00000000ff600000) concurrent mark-sweep generation total 10240K, used 8907K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000) # 老年代里面是存了两个4m的数组对象，大概是8m Metaspace used 3239K, capacity 4496K, committed 4864K, reserved 1056768K class space used 352K, capacity 388K, committed 512K, reserved 1048576K 2.7 总结HotSpot虚拟机的组成成分 三 JVM内存分配与回收专题3.1 内存分配3.1.1 空间分配担保在发生 Minor gc之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立,那么 Minor gc可以确保是安全的。当大量对象在 Minor GC后仍然存活，Survivor区中无法容纳那么多的对象，那么就需要老年代进行空间分配担保，把 Survivor无法容纳的对象提前直接进入老年代；但是如果老年代判断到剩余空间不足(根据以往每一次回收晋升到老年代对象容量的平均值作为经验值)，则进行一次Full GC。 3.1.2 大对象直接进入老年代大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 为什么要这样呢？ 为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。 3.1.3 长期存活的对象将进入老年代既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 3.1.4 动态对象年龄判定“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。 3.2 垃圾回收3.2.1 垃圾判断算法引用计数算法（Refesrence Counting）当对象添加一个引用计数器，当有一个地方以用它，计数器加1，当引用失效，计数器减一，任何时刻计数器为0的对象j就是不可能再被使用。弊端：引用计数器可能无法解决循环引用的问题 根搜索算法( Root Tracing)在实际生产语言中（java，C#等）都使用跟搜索算法判断对象是否存活。算法的基本思路就是通过一系列被称作“GC ROOTS “ 的点作为起始进行向下搜索，当一个对象到GC ROOTS 没有任何引用链相连，则证明此对象是不可用的。 其中的GC ROOTS 包括： 在VM栈中（帧中的本地变量）中的引用 方法区中的静态引用 JNI（即一般所说的Native方法）中的引用 3.2.2 垃圾回收期的选择和实现引用类型GC要做的是将那些dead对象所占的内存回收掉，hotsopt认为没有引用的对象就是dead。hotspot将引用分成四种，strong，soft，weak，phantom。strong引用是我们最常用到的引用，即默认通过Object o = new Object() 这种方式进行的引用；soft，weak，Phantom这三种都是继承reference 在 Full GC时会对 Reference类型的引用进行特殊处理Soft:内存不够时一定会被GC，长期不用也会被GCWeak:一定会被GCPhantom:本来就没引用,当从 jvm 堆中释放时会通知具体的对比参考大佬的文章 GC的时机在分代模型的基础上,GC从时机上分为两种: Scavenge GC和Full GC Scavenge GC (Minor GC）：对新生代，触发时机是在新对象生成时，Eden空间满了，理论上Eden区大多数对象会在 Scavenge GC回收，复制算法的执行效率会很高， Scavenge GC时间比较短。 Full GC：对整个JVM进行整理，包括 Young、Old和Perm（永久代，jdk8没有，jdk为元空间），主要的触发时机:1)Old满了2)Perm满了3) system.gc() Full GC的执行效率很低，尽量减少 Full GC 3.2.3 GC时机-线程角度安全点 枚举根节点：当执行系统停顿下来后,并不需要一个不漏地检查完所有执行上下文和全局的引用位置,虚拟机应当是有办法直接得知哪些地方存放着对象引用。在 HotSpot的实现中,是使用一组称为 OopMap的数据结构来达到这个目的的 安全点在 OopMap的协助下, Hotspot可以快速且准确地完成GC Roots枚举,但一个很现实的问题随之而来:很多指令可能导致引用关系变化,或者说引起 OopMap内容变化的指令非常多,如果为每一条指令都生成对应的 OopMap,那将会要大量的额外空间,这样GC的空间成本将会变得更高实际上, Hotspot并没有为每条指令都生成 OopMap,只是在“特定的位置”记录了这些信息,这些位置称为安全点( Safepoint),即程序执行时并非在所有地方都能停顿下来开始GC,只有在达到安全点时才能暂停。 Safepoint的选定既不能太少以至于让GC等待时间太长,也不能过于频繁以至于过分增大运行时的负载。所以,安全点的选定基本上是以“是否具有让程序长时间执行的特征”为标准进行选定的因为每条指令执行的时间非常短暂,程序不太可能因为指令流长度太长这个原因而过长时间运行,“长时间执行”的最明显特征就是指令序列复用,例如方法调用、循环跳转、异常跳转等,所以具有这些功能的指令オ会产生 Safepoint 对于 Savepoint,另一个需要考虑的问题是如何在GC发生时让所有线程(这里不包括执行JNI调用的线程)都“跑”到最近的安全点再停顿下来:抢占式中断( Preemptive Suspension)和主动式中断(Voluntary Suspension) 抢占式中断抢占式中断:它不需要线程的执行代码主动去配合,在GC发生时,首先把所有线程全部中断,如果有线程中断的地方不在安全点上,就恢复线程,让它“跑”到安全点上。 主动式中断主动式中断:当GC需要中断线程的时候,不直接对线程操作,仅仅简单地设置一个标志,各个线程执行时主动去轮询这个标志,发现中断标志为真时就自己中断挂起。注意：这个轮询也只是在轮询也只是在指定的地方才进行轮询，标志的地方和安全点是重合的。现在几乎没有虚拟机采用抢占式中断来暂停线程从而响应GC事件。 安全区域在使用 SafePoint似乎已经完美地解决了如何进入GC的问题,但实际上情况却并不一定。 SafePoint机制保证了程序执行时,在不太长的时间内就会遇到可进入GC的Safepoint。但如果程序在“不执行”的时候呢?所谓程序不执行就是没有分配CPU时间,典型的例子就是处于Sleep状态或者 Blocked状态,这时候线程无法响应JVM的中断请求,JVM也显然不太可能等待线程重新分配CPU时间。对于这种情况,就需要安全区域(SafeRegion)来解决了。 在线程执行到 Safe Region中的代码时,首先标识自己已经进入了 Safe Region,那样,当在这段时间里JVM要发起GC时,就不用管标识自己为 Safe Region状态的线程了。在线程要离开 Safe Region时,它要检査系统是否已经完成了根节点枚举(或者是整个GC过程),如果完成了,那线程就继续执行,否则它就必须等待直到收到可以安全离开 Safe Region的信号为止。 3.3 一些感悟3.3.1 内存泄露的经典原因对象定义在错误的范围( Wrong Scope)； 异常( Exception)处理不当 集合数据管理不当 四 参数与实验 -verbose gc 打印出垃圾回收的详情 -XX:+PrintGCDetails -XX:+PrintGCDateStamps 打印出gc的时间戳 -XX:+PrintCommandLineFlags 在命令行打印出虚拟机的参数、 堆空间调整 -XX:SurvivorRatio=8 eden 和survivor的所占空间大小比例为 8：1 -Xms5m -Xmx5m 初始和最大的堆内存，通常设置成一样的，防止垃圾回收之后有堆抖动的问题 -Xmn10m 新生代的容量 新生代晋升老年代相关 -XX:PretenureSizeThreshold=4194304 （Tenured是老年代的意思）当创建的对象的大小已经超过这个值，那么此对象不会被放到新生代中，而是直接在老年代中。 此参数需要和参数 -XX:+UseSerialGC一起使用(虚拟机运行在 Client模式下的默认值,打开此开关后,使用Serial old的收集器组合进行内存回收) -XX:MaxTenuringThreshold=5 （Threshold是门槛的意思）设置对象晋升的到老年代对象年龄阈值的最大值，即虽然可以jvm一般是自动调节回收对象的回收年龄，但是也不能超过此值。此值的默认值是15，CMS中的默认值是6，G1中的默认值是15。 经历过多次GC后，存活的对象会在From Survivor 与 To Survivor 之间来回存放，而这里面的一个前提是有足够的空间来存放这些数据，在GC算法中，会计算每个对象年龄的大小，如果某个年龄总的大小已经大于survivor空间的百分之五十，那么这时就需要调整阈值，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值，不能再继续等到默认的15次才完成晋升，因为不调整会导致survivor的空间不足，所以需要调整阈值，让这些存活的对象尽快完成晋升。 -XX:TargetSurvivorRatio=60 设置survivor空间的占比达到百分之六十时就进行一次对象晋升 -XX:+PrintTenuringDistribution （Distribution是分配的意思）打印出各年龄阶段的对象的占有内存 实验一输入虚拟机参数执行MyTest1.java -XX:SurvivorRatio=8 -Xms20m -Xmx20m -Xmn10m -verbose：gc -XX:+PrintGCDetails [GC (Allocation Failure) [PSYoungGen: 8192K->1016K(9216K)] 8192K->5193K(19456K), 0.0066065 secs] [Times: user=0.08 sys=0.00, real=0.01 secs] # [GC (Allocation Failure) GC 代表的是一次Minor GC # [PSYoungGen: 8192K->1016K(9216K)] 代表新生代垃圾回收之前是8192k，回收之后是1016k，总的内存是9216k,即9m（这里是eden和from survivor区域相加的结果），PSYoungGen中的PS代表Parallel Scavenge,这是默认使用的收集器 # 8192K->5193K(19456K) 代表的是在执行回收之前总的堆的大小为8192K，回收之后是5193K，而总的堆的可用容量是19456K（这里是去掉了一个to survivor 区域的大小） # 0.0066065 secs 代表执行这次垃圾回收的时间是0.0066065 秒 # [Times: user=0.08 sys=0.00, real=0.01 secs] 表示在用户空间用了0.08秒，内核空间用了0.00秒，实际用了0.01秒 [Full GC (Ergonomics) [PSYoungGen: 9208K->0K(9216K)] [ParOldGen: 10232K->9951K(10240K)] 19440K->9951K(19456K), [Metaspace: 3235K->3235K(1056768K)], 0.2093485 secs] [Times: user=0.64 sys=0.00, real=0.21 secs] # [Full GC (Ergonomics) 代表这是一次Full GC # [PSYoungGen: 9208K->0K(9216K)] 同上，代表新生代回收后的内存为0k，PSYoungGen中的PS代表Parallel Scavenge,这是默认使用的收集器 # [ParOldGen: 10232K->9951K(10240K)] 表示老年代进行垃圾回收之后的空间，如果这里显示不仅没有变小，而且变大了，其中一个原因是因为部分从新生代晋升到老年代，ParOldGen 中的 ParOld代表Parallel Old,这是默认使用的收集器 # [Metaspace: 3235K->3235K(1056768K)] 代表这次垃圾回收之后，元空间的大小没变 # 以上分析可以说明，jvm1.8默认在新生代使用Parallel Scavenge ，老年代使用Parallel Old收集 Heap PSYoungGen total 9216K, used 435K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000) # PSYoungGen中的PS代表Parallel Scavenge,这是默认使用的收集器 eden space 8192K, 5% used [0x00000000ff600000,0x00000000ff66cf70,0x00000000ffe00000) from space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000) to space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000) ParOldGen total 10240K, used 675K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000) # 永久代的内存是10240K，ParOldGen 中的 ParOld代表Parallel Old,这是默认使用的收集器 object space 10240K, 6% used [0x00000000fec00000,0x00000000feca8ce0,0x00000000ff600000) Metaspace used 3268K, capacity 4496K, committed 4864K, reserved 1056768K class space used 355K, capacity 388K, committed 512K, reserved 1048576K 实验二实验代码为MyTest2.java 虚拟机参数为 -XX:SurvivorRatio=8-Xms20m-Xmx20m-Xmn10m-XX:+PrintGCDetails-verbose：gc-XX:PretenureSizeThreshold=4194304-XX:+UseSerialGC -XX:PretenureSizeThreshold = 4194304 当创建的对象的大小已经超过这个值，那么此对象不会被放到新生代中，而是直接在老年代中 此参数需要和 参数 -XX:+UseSerialGC(虚拟机运行在 Client模式下的默认值,打开此开关后,使用SeSerial+ old的收集器组合进行内存回收)一起使用 实验代码为： public static void main(String[] args) &#123; int size = 1024 * 1024; byte[] myAlloc1 = new byte[5 * size]; &#125; 输出结果 Heap def new generation total 9216K, used 2172K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000) # 此处的新生代称为 def new generation，而不是使用使用Parallel收集器时的 PSYoungGen eden space 8192K, 26% used [0x00000000fec00000, 0x00000000fee1f1b0, 0x00000000ff400000) from space 1024K, 0% used [0x00000000ff400000, 0x00000000ff400000, 0x00000000ff500000) to space 1024K, 0% used [0x00000000ff500000, 0x00000000ff500000, 0x00000000ff600000) tenured generation total 10240K, used 5120K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000) # 此处的新生代称为 tenured generation，而不是使用使用Parallel收集器时的 ParOldGen # 由于在实验代码中new了一个5m的字节数组，可以看到，字节数组对象被保存到老年代中。 the space 10240K, 50% used [0x00000000ff600000, 0x00000000ffb00010, 0x00000000ffb00200, 0x0000000100000000) Metaspace used 3236K, capacity 4496K, committed 4864K, reserved 1056768K class space used 352K, capacity 388K, committed 512K, reserved 1048576K 实验三实验参数 -XX:SurvivorRatio=8-Xms20m-Xmx20m-Xmn10m-XX:+PrintGCDetails-verbose：gc-XX:+PrintCommandLineFlags-XX:MaxTenuringThreshold=5-XX:+PrintTenuringDistribution 实验代码 public static void main(String[] args) &#123; int size = 1024 * 1024; byte[] myAlloc1 = new byte[2 * size]; byte[] myAlloc2 = new byte[2 * size]; byte[] myAlloc3 = new byte[2 * size]; byte[] myAlloc4 = new byte[2 * size]; System.out.println(\"完成了\"); &#125; 输出结果 [GC (Allocation Failure) Desired survivor size 1048576 bytes, new threshold 5 (max 5) # Desired survivor size 1048576 bytes 表示现在的survivor空间的大小，即1m；new threshold 5表示当前的jvm动态设置的对象回收的年龄，(max 5)表示回收的年龄阈值 [PSYoungGen: 8152K->840K(9216K)] 8152K->6992K(19456K), 0.0055682 secs] [Times: user=0.03 sys=0.01, real=0.01 secs] [Full GC (Ergonomics) [PSYoungGen: 840K->0K(9216K)] [ParOldGen: 6152K->6845K(10240K)] 6992K->6845K(19456K), [Metaspace: 3229K->3229K(1056768K)], 0.0142699 secs] [Times: user=0.03 sys=0.02, real=0.01 secs] 完成了 Heap PSYoungGen total 9216K, used 2289K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000) eden space 8192K, 27% used [0x00000000ff600000,0x00000000ff83c4a0,0x00000000ffe00000) from space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000) to space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000) ParOldGen total 10240K, used 6845K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000) object space 10240K, 66% used [0x00000000fec00000,0x00000000ff2af728,0x00000000ff600000) Metaspace used 3237K, capacity 4496K, committed 4864K, reserved 1056768K class space used 352K, capacity 388K, committed 512K, reserved 1048576K 实验四虚拟机参数 -verbose：gc-Xmx200m-Xmn50m-XX:TargetSurvivorRatio=60-XX:+PrintTenuringDistribution-XX:+PrintGCDetails-XX:+PrintGCDateStamps-XX:+UseParNewGC-XX:+UseConcMarkSweepGC-XX:MaxTenuringThreshold=3 实验代码 MyTest4.java 输出结果 2020-02-28T16:13:31.886+0800: [GC (Allocation Failure) 2020-02-28T16:13:31.886+0800: [ParNew Desired survivor size 3145728 bytes, new threshold 3 (max 3) - age 1: 2818384 bytes, 2818384 total : 40349K->2785K(46080K), 0.0016338 secs] 40349K->2785K(109568K), 0.0017041 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 11111111 # Desired survivor size 3145728 bytes ,其中3145728 bytes的值就是3m，是survivor乘于0.6算出来的（-XX:TargetSurvivorRatio=60），当survivor超过此大小时就会重新动态设置threshold的值，但是也不会超过3. 2020-02-28T16:13:32.891+0800: [GC (Allocation Failure) 2020-02-28T16:13:32.891+0800: [ParNew Desired survivor size 3145728 bytes, new threshold 2 (max 3) - age 1: 342328 bytes, 342328 total - age 2: 2866552 bytes, 3208880 total : 42918K->3328K(46080K), 0.0016638 secs] 42918K->3328K(109568K), 0.0017198 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 222222222 2020-02-28T16:13:33.896+0800: [GC (Allocation Failure) 2020-02-28T16:13:33.896+0800: [ParNew Desired survivor size 3145728 bytes, new threshold 3 (max 3) - age 1: 64 bytes, 64 total - age 2: 341632 bytes, 341696 total : 43843K->858K(46080K), 0.0034513 secs] 43843K->3621K(109568K), 0.0034982 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 3333333333 2020-02-28T16:13:34.905+0800: [GC (Allocation Failure) 2020-02-28T16:13:34.905+0800: [ParNew Desired survivor size 3145728 bytes, new threshold 3 (max 3) - age 1: 64 bytes, 64 total - age 2: 64 bytes, 128 total - age 3: 341856 bytes, 341984 total : 41579K->484K(46080K), 0.0006988 secs] 44342K->3247K(109568K), 0.0007548 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 4444444444 2020-02-28T16:13:35.908+0800: [GC (Allocation Failure) 2020-02-28T16:13:35.908+0800: [ParNew Desired survivor size 3145728 bytes, new threshold 1 (max 3) - age 1: 3145840 bytes, 3145840 total - age 2: 64 bytes, 3145904 total - age 3: 64 bytes, 3145968 total : 41211K->3153K(46080K), 0.0016465 secs] 43974K->6250K(109568K), 0.0016891 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 5555555 2020-02-28T16:13:36.912+0800: [GC (Allocation Failure) 2020-02-28T16:13:36.912+0800: [ParNew Desired survivor size 3145728 bytes, new threshold 3 (max 3) - age 1: 56 bytes, 56 total : 43885K->20K(46080K), 0.0020702 secs] 46982K->6189K(109568K), 0.0021193 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 666666 Heap par new generation total 46080K, used 19046K [0x00000000f3800000, 0x00000000f6a00000, 0x00000000f6a00000) eden space 40960K, 46% used [0x00000000f3800000, 0x00000000f4a947a0, 0x00000000f6000000) from space 5120K, 0% used [0x00000000f6000000, 0x00000000f6005130, 0x00000000f6500000) to space 5120K, 0% used [0x00000000f6500000, 0x00000000f6500000, 0x00000000f6a00000) concurrent mark-sweep generation total 63488K, used 6169K [0x00000000f6a00000, 0x00000000fa800000, 0x0000000100000000) Metaspace used 3748K, capacity 4536K, committed 4864K, reserved 1056768K class space used 412K, capacity 428K, committed 512K, reserved 1048576K","tags":[]},{"title":"jvm常用的命令","date":"2020-12-20T04:00:00.000Z","path":"posts/undefined.html","text":"jvm基本命令jps 显示当前运行的java进程以及相关参数 jps参数： jps -l pid -q 只显示pid，不显示class名称,jar文件名和传递给main 方法的参数。 -l 输出应用程序main class的完整package名 或者 应用程序的jar文件完整路径名。 -m 输出传递给main方法的参数 -v 输出传递给JVM的参数 备注：也可以使用ps aux | grep 项目名 查看pid jstack 用于生成java虚拟机当前时刻的线程快照。 分析CPU利用率100%问题 top 查看占CPU最多的进程 top -Hp pid 查询进程下所有线程的运行情况（shift+p 按cpu排序，shift+m 按内存排序） 用printf ‘%x’ pid 转换为16进制（加入查到的是a） jstact查看线程快照，jstack 30316 | grep -A 20 a [推荐阅读]http://jameswxx.iteye.com/blog/1041173 死锁分析java程序如下： public class JvmLock &#123; public static Object obj1 = new Object(); public static Object obj2 = new Object(); public static void main(String[] args) &#123; System.out.println(\"Default Charset=\" + Charset.defaultCharset()); System.out.println(\"file.encoding=\" + System.getProperty(\"file.encoding\")); LockA a = new LockA(); LockB b = new LockB(); new Thread(a).start(); new Thread(b).start(); &#125; &#125; class LockA implements Runnable &#123; @Override public void run() &#123; try &#123; synchronized (JvmLock.obj1) &#123; System.out.println(\"lockA 获取到obj1\"); Thread.sleep(1000); synchronized (JvmLock.obj2) &#123; System.out.println(\"lockA 获取obj2\"); Thread.sleep(60 * 1000); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; class LockB implements Runnable &#123; @Override public void run() &#123; try &#123; synchronized (JvmLock.obj2) &#123; System.out.println(\"lockb 获取到obj2\"); Thread.sleep(1000); synchronized (JvmLock.obj1) &#123; System.out.println(\"lockA 获取obj1\"); Thread.sleep(60 * 1000); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 获取到的堆栈信息，直接可以查看到死锁的存在 \"DestroyJavaVM\" #15 prio=5 os_prio=0 cpu=453.13ms elapsed=6111.89s tid=0x000002873420d800 nid=0x49c waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE \"VM Thread\" os_prio=2 cpu=15.63ms elapsed=6112.33s tid=0x00000287582ba800 nid=0x2850 runnable \"GC Thread#0\" os_prio=2 cpu=125.00ms elapsed=6112.35s tid=0x0000028734225800 nid=0x1a3c runnable \"G1 Main Marker\" os_prio=2 cpu=15.63ms elapsed=6112.35s tid=0x0000028734296000 nid=0x4b0 runnable \"G1 Conc#0\" os_prio=2 cpu=15.63ms elapsed=6112.35s tid=0x0000028734297000 nid=0x32a4 runnable \"G1 Refine#0\" os_prio=2 cpu=0.00ms elapsed=6112.33s tid=0x00000287572b2000 nid=0x2ef8 runnable \"G1 Young RemSet Sampling\" os_prio=2 cpu=203.13ms elapsed=6112.33s tid=0x00000287572b5000 nid=0x2ddc runnable \"VM Periodic Task Thread\" os_prio=2 cpu=578.13ms elapsed=6112.27s tid=0x0000028758710800 nid=0x192c waiting on condition JNI global refs: 9, weak refs: 0 Found one Java-level deadlock: ============================= \"Thread-0\": waiting to lock monitor 0x00000287582e6280 (object 0x0000000711c39548, a java.lang.Object), which is held by \"Thread-1\" \"Thread-1\": waiting to lock monitor 0x00000287582e6080 (object 0x0000000711c39538, a java.lang.Object), which is held by \"Thread-0\" Java stack information for the threads listed above: =================================================== \"Thread-0\": at top.sciento.wumu.jvm.LockA.run(JvmLock.java:35) - waiting to lock &lt;0x0000000711c39548> (a java.lang.Object) - locked &lt;0x0000000711c39538> (a java.lang.Object) at java.lang.Thread.run(java.base@11.0.2/Thread.java:834) \"Thread-1\": at top.sciento.wumu.jvm.LockB.run(JvmLock.java:55) - waiting to lock &lt;0x0000000711c39538> (a java.lang.Object) - locked &lt;0x0000000711c39548> (a java.lang.Object) at java.lang.Thread.run(java.base@11.0.2/Thread.java:834) Found 1 deadlock. jmap 用于打印指定Java进程(或核心文件、远程调试服务器)的共享对象内存映射或堆内存细节。 堆Dump是反应Java堆使用情况的内存镜像，其中主要包括系统信息、虚拟机属性、完整的线程Dump、所有类和对象的状态等。 一般，在内存不足、GC异常等情况下，我们就会怀疑有内存泄露。这个时候我们就可以制作堆Dump来查看具体情况。分析原因。 查看java堆（heap）中的对象数量及大小：jmap -histo 31846 将内存使用的详细情况输出到文件： jmap -dump:format=b,file=heapDump pid然后使用jhat -port 5000 heapDump在浏览器中访问：http://localhost:5000/查看详细信息 jinfo jinfo可以输出java进程、core文件或远程debug服务器的配置信息。可以使用jps -v替换 jstat 是用于监控虚拟机各种运行状态信息的命令行工具。他可以显示本地或远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 jstat - [-t] [-h] [ []] 参数解释： Option — 选项，我们一般使用 -gcutil 查看gc情况 vmid — VM的进程号，即当前运行的java进程号 interval– 间隔时间，单位为秒或者毫秒 count — 打印次数，如果缺省则打印无数次 例子：jstat -gc 5828 250 5 如下所示为jstat的命令格式 jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]1 如下表示分析进程id为31736 的gc情况，每隔1000ms打印一次记录，打印10次停止，每3行后打印指标头部 jstat -gc -h3 31736 1000 101 jstat -gcjstat -gc xxxx1 其对应的指标含义如下： 参数 描述 S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) S0U 年轻代中第一个survivor（幸存区）目前已使用空间 (字节) S1U 年轻代中第二个survivor（幸存区）目前已使用空间 (字节) EC 年轻代中Eden（伊甸园）的容量 (字节) EU 年轻代中Eden（伊甸园）目前已使用空间 (字节) OC Old代的容量 (字节) OU Old代目前已使用空间 (字节) PC Perm(持久代)的容量 (字节) PU Perm(持久代)目前已使用空间 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) jstat -gcutil查看gc的统计信息 jstat -gcutil xxxx1 其对应的指标含义如下： 参数 描述 S0 年轻代中第一个survivor（幸存区）已使用的占当前容量百分比 S1 年轻代中第二个survivor（幸存区）已使用的占当前容量百分比 E 年轻代中Eden（伊甸园）已使用的占当前容量百分比 O old代已使用的占当前容量百分比 P perm代已使用的占当前容量百分比 YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) jstat -gccapacityjstat -gccapacity xxxx1 其对应的指标含义如下： 参数 描述 NGCMN 年轻代(young)中初始化(最小)的大小 (字节) NGCMX 年轻代(young)的最大容量 (字节) NGC 年轻代(young)中当前的容量 (字节) S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) EC 年轻代中Eden（伊甸园）的容量 (字节) OGCMN old代中初始化(最小)的大小 (字节) OGCMX old代的最大容量 (字节) OGC old代当前新生成的容量 (字节) OC Old代的容量 (字节) PGCMN perm代中初始化(最小)的大小 (字节) PGCMX perm代的最大容量 (字节) PGC perm代当前新生成的容量 (字节) PC Perm(持久代)的容量 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 FGC 从应用程序启动到采样时old代(全gc)gc次数 4 其他命令 查看年轻代对象的信息及其占用量。 jstat -gcnewcapacity xxxx1 查看老年代对象的信息及其占用量。 jstat -gcoldcapacity xxxx1 查看年轻代对象的信息 jstat -gcnew xxxx1 查看老年代对象的信息 jstat -gcold xxxx javap 可以对代码反编译，也可以查看java编译器生成的字节码。 jhsdb(java9以上)# jhsdb clhsdb command line debugger debugd debug server hsdb ui debugger jstack --help to get more information jmap --help to get more information jinfo --help to get more information jsnap --help to get more information jhsdb是java9引入的，可以在JAVA_HOME/bin目录下找到jhsdb；它取代了jdk9之前的JAVA_HOME/lib/sa-jdi.jar jhsdb有clhsdb、debugd、hsdb、jstack、jmap、jinfo、jsnap这些mode可以使用 其中hsdb为ui debugger，就是jdk9之前的sun.jvm.hotspot.HSDB；而clhsdb即为jdk9之前的sun.jvm.hotspot.CLHSDB jhsdb jstack# jhsdb jstack --help --locks to print java.util.concurrent locks --mixed to print both java and native frames (mixed mode) --exe executable image name --core path to coredump --pid pid of process to attach –pid用于指定JVM的进程ID；–exe用于指定可执行文件；–core用于指定core dump文件 异常jhsdb jstack --mixed --pid 1 //...... Caused by: sun.jvm.hotspot.debugger.DebuggerException: get_thread_regs failed for a lwp at jdk.hotspot.agent/sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal.getThreadIntegerRegisterSet0(Native Method) at jdk.hotspot.agent/sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal$1GetThreadIntegerRegisterSetTask.doit(LinuxDebuggerLocal.java:534) at jdk.hotspot.agent/sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal$LinuxDebuggerLocalWorkerThread.run(LinuxDebuggerLocal.java:151) 复制代码 如果出现这个异常表示是采用jdk版本的问题，可以尝试一下其他jdk编译版本 debugger# jhsdb jstack --locks --pid 1 Attaching to process ID 1, please wait... Debugger attached successfully. Server compiler detected. JVM version is 12+33 Deadlock Detection: No deadlocks found. \"DestroyJavaVM\" #32 prio=5 tid=0x000055c3b5be0800 nid=0x6 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE JavaThread state: _thread_blocked Locked ownable synchronizers: - None \"http-nio-8080-Acceptor-0\" #30 daemon prio=5 tid=0x000055c3b5d71800 nid=0x2f runnable [0x00007fa0d13de000] java.lang.Thread.State: RUNNABLE JavaThread state: _thread_in_native - sun.nio.ch.ServerSocketChannelImpl.accept0(java.io.FileDescriptor, java.io.FileDescriptor, java.net.InetSocketAddress[]) @bci=0 (Interpreted frame) - sun.nio.ch.ServerSocketChannelImpl.accept(java.io.FileDescriptor, java.io.FileDescriptor, java.net.InetSocketAddress[]) @bci=4, line=525 (Interpreted frame) - sun.nio.ch.ServerSocketChannelImpl.accept() @bci=41, line=277 (Interpreted frame) - org.apache.tomcat.util.net.NioEndpoint.serverSocketAccept() @bci=4, line=448 (Interpreted frame) - org.apache.tomcat.util.net.NioEndpoint.serverSocketAccept() @bci=1, line=70 (Interpreted frame) - org.apache.tomcat.util.net.Acceptor.run() @bci=98, line=95 (Interpreted frame) - java.lang.Thread.run() @bci=11, line=835 (Interpreted frame) Locked ownable synchronizers: - &lt;0x00000000e3aab6e0>, (a java/util/concurrent/locks/ReentrantLock$NonfairSync) \"http-nio-8080-ClientPoller-0\" #29 daemon prio=5 tid=0x000055c3b5c20000 nid=0x2e runnable [0x00007fa0d14df000] java.lang.Thread.State: RUNNABLE JavaThread state: _thread_in_native - sun.nio.ch.EPoll.wait(int, long, int, int) @bci=0 (Interpreted frame) - sun.nio.ch.EPollSelectorImpl.doSelect(java.util.function.Consumer, long) @bci=96, line=120 (Interpreted frame) - sun.nio.ch.SelectorImpl.lockAndDoSelect(java.util.function.Consumer, long) @bci=42, line=124 (Interpreted frame) - locked &lt;0x00000000e392ece8> (a sun.nio.ch.EPollSelectorImpl) - locked &lt;0x00000000e392ee38> (a sun.nio.ch.Util$2) - sun.nio.ch.SelectorImpl.select(long) @bci=31, line=136 (Interpreted frame) - org.apache.tomcat.util.net.NioEndpoint$Poller.run() @bci=55, line=743 (Interpreted frame) - java.lang.Thread.run() @bci=11, line=835 (Interpreted frame) Locked ownable synchronizers: - None \"http-nio-8080-exec-10\" #28 daemon prio=5 tid=0x000055c3b48d6000 nid=0x2d waiting on condition [0x00007fa0d15e0000] java.lang.Thread.State: WAITING (parking) JavaThread state: _thread_blocked - jdk.internal.misc.Unsafe.park(boolean, long) @bci=0 (Interpreted frame) - parking to wait for &lt;0x00000000e3901670> (a java/util/concurrent/locks/AbstractQueuedSynchronizer$ConditionObject) - java.util.concurrent.locks.LockSupport.park(java.lang.Object) @bci=14, line=194 (Interpreted frame) - java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await() @bci=42, line=2081 (Interpreted frame) - java.util.concurrent.LinkedBlockingQueue.take() @bci=27, line=433 (Interpreted frame) - org.apache.tomcat.util.threads.TaskQueue.take() @bci=36, line=107 (Interpreted frame) - org.apache.tomcat.util.threads.TaskQueue.take() @bci=1, line=33 (Interpreted frame) - java.util.concurrent.ThreadPoolExecutor.getTask() @bci=147, line=1054 (Interpreted frame) - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=26, line=1114 (Interpreted frame) - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=628 (Interpreted frame) - org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run() @bci=4, line=61 (Interpreted frame) - java.lang.Thread.run() @bci=11, line=835 (Interpreted frame) //...... / # jhsdb jstack --mixed --pid 1 Attaching to process ID 1, please wait... Debugger attached successfully. Server compiler detected. JVM version is 12+33 Deadlock Detection: No deadlocks found. ----------------- 47 ----------------- \"http-nio-8080-Acceptor-0\" #30 daemon prio=5 tid=0x000055c3b5d71800 nid=0x2f runnable [0x00007fa0d13de000] java.lang.Thread.State: RUNNABLE JavaThread state: _thread_in_native 0x00007fa0ee0923ad ???????? ----------------- 46 ----------------- \"http-nio-8080-ClientPoller-0\" #29 daemon prio=5 tid=0x000055c3b5c20000 nid=0x2e runnable [0x00007fa0d14df000] java.lang.Thread.State: RUNNABLE JavaThread state: _thread_in_native 0x00007fa0ee05f3d0 epoll_pwait + 0x1d 0x00007fa0daa97810 * sun.nio.ch.EPoll.wait(int, long, int, int) bci:0 (Interpreted frame) 0x00007fa0daa91680 * sun.nio.ch.EPollSelectorImpl.doSelect(java.util.function.Consumer, long) bci:96 line:120 (Interpreted frame) 0x00007fa0db85f57c * sun.nio.ch.SelectorImpl.lockAndDoSelect(java.util.function.Consumer, long) bci:42 line:124 (Compiled frame) * sun.nio.ch.SelectorImpl.select(long) bci:31 line:136 (Compiled frame) * org.apache.tomcat.util.net.NioEndpoint$Poller.run() bci:55 line:743 (Interpreted frame) 0x00007fa0daa91c88 * java.lang.Thread.run() bci:11 line:835 (Interpreted frame) 0x00007fa0daa88849 &lt;StubRoutines> 0x00007fa0ed122952 _ZN9JavaCalls11call_helperEP9JavaValueRK12methodHandleP17JavaCallArgumentsP6Thread + 0x3c2 0x00007fa0ed1208d0 _ZN9JavaCalls12call_virtualEP9JavaValue6HandleP5KlassP6SymbolS6_P6Thread + 0x200 0x00007fa0ed1ccfc5 _ZL12thread_entryP10JavaThreadP6Thread + 0x75 0x00007fa0ed74f3a3 _ZN10JavaThread17thread_main_innerEv + 0x103 0x00007fa0ed74c3f5 _ZN6Thread8call_runEv + 0x75 0x00007fa0ed4a477e _ZL19thread_native_entryP6Thread + 0xee //...... –locks或者–mixed花费的时间可能比较长(几分钟，可能要将近6分钟)，因而进程暂停的时间也可能比较长，在使用这两个选项时要注意 jhsdb jmapjmap -heap pid# jmap -heap 1 Error: -heap option used Cannot connect to core dump or remote debug server. Use jhsdb jmap instead jdk9及以上版本使用jmap -heap pid命令查看当前heap使用情况时，发现报错，提示需要使用jhsdb jmap来替代 jhsdb jmap pid # jhsdb jmap 1 sh: jhsdb: not found 发现jlink的时候没有添加jdk.hotspot.agent这个module，添加了这个module之后可以发现JAVA_HOME/bin目录下就有了jhsdb PTRACE_ATTACH failed # jhsdb jmap 1 You have to set --pid or --exe. &lt;no option> to print same info as Solaris pmap --heap to print java heap summary --binaryheap to dump java heap in hprof binary format --dumpfile name of the dump file --histo to print histogram of java object heap --clstats to print class loader statistics --finalizerinfo to print information on objects awaiting finalization --exe executable image name --core path to coredump --pid pid of process to attach / # jhsdb jmap --heap --pid 1 Attaching to process ID 1, please wait... ERROR: ptrace(PTRACE_ATTACH, ..) failed for 1: Operation not permitted Error attaching to process: sun.jvm.hotspot.debugger.DebuggerException: Can't attach to the process: ptrace(PTRACE_ATTACH, ..) failed for 1: Operation not permitted sun.jvm.hotspot.debugger.DebuggerException: sun.jvm.hotspot.debugger.DebuggerException: Can't attach to the process: ptrace(PTRACE_ATTACH, ..) failed for 1: Operation not permitted at jdk.hotspot.agent/sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal$LinuxDebuggerLocalWorkerThread.execute(LinuxDebuggerLocal.java:176) at jdk.hotspot.agent/sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal.attach(LinuxDebuggerLocal.java:336) at jdk.hotspot.agent/sun.jvm.hotspot.HotSpotAgent.attachDebugger(HotSpotAgent.java:672) at jdk.hotspot.agent/sun.jvm.hotspot.HotSpotAgent.setupDebuggerLinux(HotSpotAgent.java:612) at jdk.hotspot.agent/sun.jvm.hotspot.HotSpotAgent.setupDebugger(HotSpotAgent.java:338) at jdk.hotspot.agent/sun.jvm.hotspot.HotSpotAgent.go(HotSpotAgent.java:305) at jdk.hotspot.agent/sun.jvm.hotspot.HotSpotAgent.attach(HotSpotAgent.java:141) at jdk.hotspot.agent/sun.jvm.hotspot.tools.Tool.start(Tool.java:185) at jdk.hotspot.agent/sun.jvm.hotspot.tools.Tool.execute(Tool.java:118) at jdk.hotspot.agent/sun.jvm.hotspot.tools.JMap.main(JMap.java:176) at jdk.hotspot.agent/sun.jvm.hotspot.SALauncher.runJMAP(SALauncher.java:326) at jdk.hotspot.agent/sun.jvm.hotspot.SALauncher.main(SALauncher.java:455) Caused by: sun.jvm.hotspot.debugger.DebuggerException: Can't attach to the process: ptrace(PTRACE_ATTACH, ..) failed for 1: Operation not permitted at jdk.hotspot.agent/sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal.attach0(Native Method) at jdk.hotspot.agent/sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal$1AttachTask.doit(LinuxDebuggerLocal.java:326) at jdk.hotspot.agent/sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal$LinuxDebuggerLocalWorkerThread.run(LinuxDebuggerLocal.java:151) 发现PTRACE_ATTACH被docker禁用了，需要在运行容器时启用PTRACE_ATTACH docker启用SYS_PTRACEdocker run --cap-add=SYS_PTRACE 之后就可以正常使用jhsdb如下： # jhsdb jmap --heap --pid 1 Attaching to process ID 1, please wait... Debugger attached successfully. Server compiler detected. JVM version is 12+33 using thread-local object allocation. Shenandoah GC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 523763712 (499.5MB) NewSize = 1363144 (1.2999954223632812MB) MaxNewSize = 17592186044415 MB OldSize = 5452592 (5.1999969482421875MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB ShenandoahRegionSize = 262144 (0.25MB) Heap Usage: Shenandoah Heap: regions = 1997 capacity = 523501568 (499.25MB) used = 70470552 (67.2059555053711MB) committed = 144441344 (137.75MB) jhsdb jinfo# jhsdb jinfo --help --flags to print VM flags --sysprops to print Java System properties &lt;no option> to print both of the above --exe executable image name --core path to coredump --pid pid of process to attach 使用jhsdb显示jinfo的sysprops如下： # jhsdb jinfo --sysprops --pid 1 Attaching to process ID 1, please wait... Debugger attached successfully. Server compiler detected. JVM version is 12+33 awt.toolkit = sun.awt.X11.XToolkit java.specification.version = 12 sun.jnu.encoding = UTF-8 //...... 这个命令其实跟jinfo -sysprops 1是等价的 jhsdb jsnap# jhsdb jsnap --pid 1 Attaching to process ID 1, please wait... Debugger attached successfully. Server compiler detected. JVM version is 12+33 java.threads.started&#x3D;27 event(s) java.threads.live&#x3D;24 java.threads.livePeak&#x3D;24 java.threads.daemon&#x3D;20 java.cls.loadedClasses&#x3D;8250 event(s) java.cls.unloadedClasses&#x3D;1 event(s) java.cls.sharedLoadedClasses&#x3D;0 event(s) java.cls.sharedUnloadedClasses&#x3D;0 event(s) java.ci.totalTime&#x3D;18236958158 tick(s) java.property.java.vm.specification.version&#x3D;12 java.property.java.vm.specification.name&#x3D;Java Virtual Machine Specification java.property.java.vm.specification.vendor&#x3D;Oracle Corporation java.property.java.vm.version&#x3D;12+33 java.property.java.vm.name&#x3D;OpenJDK 64-Bit Server VM java.property.java.vm.vendor&#x3D;Azul Systems, Inc. java.property.java.vm.info&#x3D;mixed mode java.property.jdk.debug&#x3D;release &#x2F;&#x2F;...... jhsdb jsnap的功能主要是由jdk.hotspot.agent模块中的sun.jvm.hotspot.tools.JSnap.java来提供的，它可以用于查看threads及class loading/unloading相关的event、JVM属性参数等，其中–all可以显示更多的JVM属性参数 jhsdb与jcmdjhsdb: A New Tool for JDK 9这篇文章中列出了jhsdb与jcmd的等价命令，如下图： 小结 在java9之前，JAVA_HOME/lib目录下有个sa-jdi.jar，可以通过如上命令启动HSDB(图形界面)及CLHSDB(命令行)；sa-jdi.jar中的sa的全称为Serviceability Agent，它之前是sun公司提供的一个用于协助调试HotSpot的组件，而HSDB便是使用Serviceability Agent来实现的；HSDB就是HotSpot Debugger的简称，由于Serviceability Agent在使用的时候会先attach进程，然后暂停进程进行snapshot，最后deattach进程(进程恢复运行)，所以在使用HSDB时要注意 jhsdb是java9引入的，可以在JAVA_HOME/bin目录下找到jhsdb；它取代了jdk9之前的JAVA_HOME/lib/sa-jdi.jar；jhsdb有clhsdb、debugd、hsdb、jstack、jmap、jinfo、jsnap这些mode可以使用；其中hsdb为ui debugger，就是jdk9之前的sun.jvm.hotspot.HSDB；而clhsdb即为jdk9之前的sun.jvm.hotspot.CLHSDB jhsdb在jdk.hotspot.agent这个模块中；对于jhsdb jstack的–locks或者–mixed命令花费的时间可能比较长(几分钟，可能要将近6分钟)，因而进程暂停的时间也可能比较长，在使用这两个选项时要注意；对于jdk9及以后的版本不再使用jmap -heap命令来查询heap内存情况，需要用jhsdb jmap –heap –pid来替代；使用jhsdb jmap需要在运行容器时启用PTRACE_ATTACH才可以 doc JVM信息查看 jhsdb jdk.hotspot.agent jhsdb jhsdb: A New Tool for JDK 9 jcmd: One JDK Command-Line Tool to Rule Them All JVM in Docker and PTRACE_ATTACH Serviceability in HotSpot The HotSpot™ Serviceability Agent: An out-of-process high level debugger for a Java™ virtual machine 参考 https://www.jianshu.com/p/bacc64527894 https://juejin.cn/post/6844903808057753613","tags":[]},{"title":"","date":"2020-12-16T12:59:05.006Z","path":"posts/undefined.html","text":"Description&#x3D;My Miscellaneous Service Requires&#x3D;network-online.target After&#x3D;network-online.target [Service] Type&#x3D;simple User&#x3D;anonymous WorkingDirectory&#x3D;&#x2F;home&#x2F;anonymous ExecStart&#x3D;some_can_execute --option&#x3D;123 Restart&#x3D;on-failure [Install] WantedBy&#x3D;multi-user.target","tags":[]},{"title":"Hello World","date":"2020-12-16T12:59:04.983Z","path":"posts/undefined.html","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","tags":[]},{"title":"jvm回收算法","date":"2020-12-14T04:00:00.000Z","path":"posts/undefined.html","text":"定位垃圾引用计数算法每个对象有一个计数器，每次有一个引用就添加1，清除一个引用就删除1。 根可达算法局部变量 静态变量 常量池 JNI引用 垃圾清除算法标记清除算法位置不连续，垃圾碎片 拷贝算法（复制算法）浪费空间 标记压缩算法效率偏低 JVM分代回收新的垃圾回收期不在分代了。 1、new、young: 存活数量少 使用复制算法效率高 新生代=Eden+2个suvivor区 YGC回收之后大部分的对象会被回收。 YGC回收之后，先放到eden区，回收之后就放到s0区域。 再次YGC,活着的对象eden+s0 -&gt; s1 年龄足够进入old区 s区装不下直接进入老年代 2、old: FGC :full gc 顽固分子 老年代满了FGC 3、permanent(1.7 永久代)/Metaspace(1.8 元数据区)： 永久代 元数据-class 永久代必须指定大小限制，元数据可以设置，也可以不设置，无上限（受限于物理内存） 字符串常量， 1.7-永久代，1.8- 堆 4、GC Tuning(Generation) 尽量减少FGC MinorGC = YGC MajorGC = FGC 常见的垃圾回收器 1、Serial:串行回收，用于年轻代 2、Parallel Scavenage：并行回收，年轻代 3、ParNew:配合cms的并行回收，年轻代 4、SerialOld：老年代 5、ParallelOld:老年代 6、ConcurrentMarkSweep:老年代，垃圾回收和应用同时运行，降低STW的时间 7、G1(10ms) 8、ZGC（1ms） 9、Shenandoah 10、Eplison 1.8默认的垃圾回收器：PS+ParallelOld JVM 调优1、了解生产环境下的垃圾回收器组合 JVM的命令行参数参考： JVM命令参数分类： 标准命令：-开头，所有的HotSpoot都支持 非标准：-X开头，特定版本HotSpot支持的特定命令 不稳定：-XX开头，下一个版本取消， ​ -XX:+PrintCommandLineFlags ​ -XX:+PrintFlagsFinal最终参数值 ​ -XX+PrintFlagsInitial默认参数 总结 垃圾回收器 垃圾回收的发展路线，是随着内存越来越大的过程演进 从分代算法演变到不分代算法 Serial算法 几十兆 Parallel算法 几十G CMS 几十G 承上启下 开始并发回收– 三色标记 标错 increament update -remark + 写屏障 G1 上百G内存-逻辑分代，物理不分代 三色标记+STAB + 写屏障 ZGC-Shenandoah – 4T 逻辑物理都不分代 ColoredPointers（颜色指针 着色指针） Epsilon 什么都不干，调试，确认不用GC参与就能干完活 JDK诞生Serial追随，提高效率，诞生了ps,为了配合CMS，诞生了PN,CMS是1.4后期引入，CMS是里程碑的GC,但是CMS的问题很多，没有哪一款JDK默认使用CMS,并发垃圾回收是因为无法忍受STW. 调优的基础概念 吞吐量：用户代码时间（用户代码执行时间+垃圾回收时间） 响应时间：STW阅读，","tags":[]},{"title":"ElasticSearch教程","date":"2020-12-08T07:00:00.000Z","path":"posts/undefined.html","text":"ElasticSearch概述es的基本操作 GET _analyze &#123; \"analyzer\": \"ik_max_word\", \"text\": [\"我叫做梧木\"] &#125; GET _analyze &#123; \"analyzer\": \"ik_smart\", \"text\": [\"我叫做梧木\"] &#125; PUT /test3/_doc/2 &#123; \"name\":\"wumu\", \"age\":24 &#125; PUT /test3/_doc/5 &#123; \"name\":\"wumu\", \"age\":\"123\" &#125; DELETE /test3/_doc/2 PUT /test3/_doc/5 &#123; \"name\":\"wumu1\", \"age\":122 &#125; POST /test3/_update/5 &#123; \"doc\":&#123;\"name\":\"wumu1\", \"age\":12&#125; &#125; GET /test3/_doc/5 GET /test3/_search?q=name:wumu GET _cat/indices PUT /test2 &#123; \"mappings\": &#123; \"properties\": &#123; \"name\":&#123; \"type\": \"text\" &#125;, \"age\":&#123; \"type\": \"long\" &#125;, \"birthday\":&#123; \"type\": \"date\" &#125; &#125; &#125; &#125; es复杂查询","tags":[]},{"title":"Mybatis-StatementHandler解析","date":"2020-11-15T10:00:00.000Z","path":"posts/undefined.html","text":"概述 在上篇文章中，我们学习了Executor执行器相关的操作，而接下来，我们接着来看Executor的下一步进行操作的对象：StatementHandler。 StatementHandler负责处理Mybatis与JDBC之间Statement的交互，而JDBC中的Statement，我们在学习JDBC的时候就了解过，就是负责与数据库进行交互的对象。这其中会涉及到一些对象，我们用到的时候再学习。首先，我们来看下StatementHandler的体系结构。 StatementHandlerStatementHandler接口的实现大致有四个，其中三个实现类都是和JDBC中的Statement响对应的： SimpleStatementHandler，这个很简单了，就是对应我们JDBC中常用的Statement接口，用于简单SQL的处理； PreparedStatementHandler，这个对应JDBC中的PreparedStatement，预编译SQL的接口； CallableStatementHandler，这个对应JDBC中CallableStatement，用于执行存储过程相关的接口； RoutingStatementHandler，这个接口是以上三个接口的路由，没有实际操作，只是负责上面三个StatementHandler的创建及调用。 实现接下来，我们来看下对应的源码实现，我们还是拿查询方法query来学习。 首先，我们从DefaultSqlSession中调用Executor的query方法： @Override public &lt;E> List&lt;E> selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; // 注意下这里的方法 MappedStatement ms = configuration.getMappedStatement(statement); // 调用Executor的query方法 return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; 然后，我们进入BaseExecutor的query方法： @Override public &lt;E> List&lt;E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameter); CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); return query(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; 这里涉及到了一个BoundSql 对象。BoundSql对象是用于存储sql语句及对应的参数相关的对象。 然后我们接着看下一步： @Override public &lt;E> List&lt;E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ... List&lt;E> list; try &#123; queryStack++; list = resultHandler == null ? (List&lt;E>) localCache.getObject(key) : null; if (list != null) &#123; handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; // 从数据库里查询数据 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; ... &#125; 这里涉及到了对缓存的处理，等到学习Mybatis缓存的时候再一并解释，然后接着看queryFromDatabase方法，这里面调用了doQuery方法，我们跳转到SimpleExecutor执行器进行查看对应的doQuery方法： public &lt;E> List&lt;E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); // 这里，从Configuration中获取StatementHandler StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.&lt;E>query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125; &#125; 从这里我们可以终于看到了StatementHandler的来源了，来自于Configuration对象的方法newStatementHandler，我们查看下该方法： public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; // RoutingStatementHandler对象出来了 StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler; &#125; 这里，我们终于看到了是如何获取StatementHandler的了，通过RoutingStatementHandler的构造方法来进行获取，我们再来看下RoutingStatementHandler的构造方法： public RoutingStatementHandler(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; switch (ms.getStatementType()) &#123; case STATEMENT: delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case PREPARED: delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case CALLABLE: delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; default: throw new ExecutorException(\"Unknown statement type: \" + ms.getStatementType()); &#125; &#125; 到了这一步就很明显了，根据statementType的类型来判断是哪一种StatementHandler的实现，并且RoutingStatementHandler维护了一个delegate对象，通过delegate对象来实现对实际Handler对象的调用。这里涉及到了一个对象MappedStatement。 MappedStatement而所谓的MappedStatement对象就是对mapper.xml中的某个方法select|update|delete|insert的封装，如对于下面的getAll方法，就对应一个MappedStatement： &lt;select id=\"getAll\" resultType=\"Student2\"> SELECT * FROM Student &lt;/select> MappedStatement对象的默认的statementType是PREPARED，所以默认情况下我们所生成的StatementHandler就是PreparedStatementHandler对象。那为什么默认是PREPARED呢，当然，我们也可以从代码中找到原因。 还记得我们最开始的DefaultSqlSession中的selectList方法中的： MappedStatement ms &#x3D; configuration.getMappedStatement(statement); 这里，我们获取到了MappedStatement，我们来简单看下获取的过程： public MappedStatement getMappedStatement(String id) &#123; return this.getMappedStatement(id, true); &#125; public MappedStatement getMappedStatement(String id, boolean validateIncompleteStatements) &#123; if (validateIncompleteStatements) &#123; buildAllStatements(); &#125; return mappedStatements.get(id); &#125; 这里，方法进入了buildAllStatements方法，我们看到buildAllStatements方法的如下代码： incompleteStatements.iterator().next().parseStatementNode(); 同样，我们进入parseStatementNode方法，然后进入： builderAssistant.addMappedStatement 然后进入： MappedStatement.Builder statementBuilder = new MappedStatement.Builder...... 最终，兜兜转转进入MappedStatement的内部类Builder的构造方法： mappedStatement.statementType &#x3D; StatementType.PREPARED; 最终，我们看到Builder构造方法中设置了默认的statementType类型是PREPARED。当然，如果我们不想使用PREPARED，也可以自己配置，当然配置的方式就是在mapper.xml中对应的某个方法上添加对应属性即可： &lt;select id=\"getAll\" resultType=\"Student2\" statementType=\"CALLABLE\"> SELECT * FROM Student &lt;/select> 大致了解了MappedStatement，我们接着上面的SimpleExecutor中的doQuery方法来学习。 获取到StatementHandler之后，首先进入prepareStatement方法，该方法就是为了获取Statement对象，并设置Statement对象中的参数： private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; Connection connection = getConnection(statementLog); stmt = handler.prepare(connection, transaction.getTimeout()); handler.parameterize(stmt); return stmt; &#125; 我们来看下StatementHandler的prepare和parameterize方法，prepare方法负责生成Statement实例对象，而parameterize方法用于处理Statement实例多对应的参数。 我们大致看下prepare方法，首先进入BaseStatementHandler，查看prepare方法： public Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException &#123; ErrorContext.instance().sql(boundSql.getSql()); Statement statement = null; try &#123; statement = instantiateStatement(connection); setStatementTimeout(statement, transactionTimeout); setFetchSize(statement); return statement; &#125; catch (SQLException e) &#123; closeStatement(statement); throw e; &#125; catch (Exception e) &#123; closeStatement(statement); throw new ExecutorException(\"Error preparing statement. Cause: \" + e, e); &#125; &#125; 获取实例的方法instantiateStatement，我们可以看下它在PreparedStatementHandler的实现： protected Statement instantiateStatement(Connection connection) throws SQLException &#123; String sql = boundSql.getSql(); if (mappedStatement.getKeyGenerator() instanceof Jdbc3KeyGenerator) &#123; String[] keyColumnNames = mappedStatement.getKeyColumns(); if (keyColumnNames == null) &#123; return connection.prepareStatement(sql, PreparedStatement.RETURN_GENERATED_KEYS); &#125; else &#123; return connection.prepareStatement(sql, keyColumnNames); &#125; &#125; else if (mappedStatement.getResultSetType() != null) &#123; return connection.prepareStatement(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); &#125; else &#123; return connection.prepareStatement(sql); &#125; &#125; 这里就不多说了，就是通过Connection的方法来获取Statement实例对象而已。 而对于parameterize而言，设置参数也很简单的： public void parameterize(Statement statement) throws SQLException &#123; parameterHandler.setParameters((PreparedStatement) statement); &#125; 当然，感兴趣的童鞋也可以去看下ParameterHandler的实现DefaultParameterHandler中的实现：setParameters方法。 然后，我们接着doQuery方法来看，SimpleExector的doQuery方法会调用StatementHandler的query方法，然后我们来看下PreparedStatementHandler的query实现： @Override public &lt;E> List&lt;E> query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; PreparedStatement ps = (PreparedStatement) statement; ps.execute(); return resultSetHandler.&lt;E> handleResultSets(ps); &#125; 这里又涉及到了另一个对象：ResultSetHandler。这个对象就比较简单了，就是将Statement实例执行之后返回的ResultSet结果集转换成我们需要的List结果集。而这里的PreparedStatement接口的实现则对应于JDBC中PreparedStatement类，这样，最终的调用就到了JDBC这边。 链接：https://www.jianshu.com/p/19686af69b0d","tags":[]},{"title":"Mybatis源码解析-BoundSql","date":"2020-11-15T10:00:00.000Z","path":"posts/undefined.html","text":"前提 针对mybatis的配置文件的节点解析，比如where/if/trim的节点解析可见文章Spring mybatis源码篇章-NodeHandler实现类具体解析保存Dynamic sql节点信息 针对mybatis配置文件的解析帮助类SqlSource[一般为DynamicSqlSource]的使用可见文章Spring mybatis源码篇章-XMLLanguageDriver解析sql包装为SqlSource 对BoundSql对象的调用获取可见文章Mybatis源码分析-BaseExecutor 本文将在上述的知识前提下展开对Sql语句的解析 BoundSql的引用主要是通过MappedStatement#getBoundSql()方法调用获取的。我们可以简单跟踪下其中的源码，如下 public BoundSql getBoundSql(Object parameterObject) &#123; // 通过SqlSource获取BoundSql对象 BoundSql boundSql = sqlSource.getBoundSql(parameterObject); // 校验当前的sql语句有无绑定parameterMapping属性 List&lt;ParameterMapping> parameterMappings = boundSql.getParameterMappings(); if (parameterMappings == null || parameterMappings.isEmpty()) &#123; boundSql = new BoundSql(configuration, boundSql.getSql(), parameterMap.getParameterMappings(), parameterObject); &#125; // check for nested result maps in parameter mappings (issue #30) for (ParameterMapping pm : boundSql.getParameterMappings()) &#123; String rmId = pm.getResultMapId(); if (rmId != null) &#123; ResultMap rm = configuration.getResultMap(rmId); if (rm != null) &#123; hasNestedResultMaps |= rm.hasNestedResultMaps(); &#125; &#125; &#125; return boundSql; &#125; RawSqlSource-常用的mybatis解析sql帮助类我们观察下其getBoundSql()方法，源码如下 public BoundSql getBoundSql(Object parameterObject) &#123; //此处的sqlSource为RawSqlSource的内部属性 return sqlSource.getBoundSql(parameterObject); &#125; 我们看下sqlSource是如何生成的，由此观察其构造函数 public RawSqlSource(Configuration configuration, String sql, Class&lt;?> parameterType) &#123; // 通过SqlSourceBuilder来创建sqlSource SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?> clazz = parameterType == null ? Object.class : parameterType; sqlSource = sqlSourceParser.parse(sql, clazz, new HashMap&lt;String, Object>()); &#125; #&#123;&#125;的使用这里稍微提下，一般的写法都为&#123;name,jdbcType=String，mode=out,javaType=java.lang.String...&#125;，其中jdbcType也可以不指定，系统会自动识别。上述的代码其实主要就是针对#&#123;&#125;字符内容的处理 注意：${}这样的字符是通过DynamicSqlSource来完成解析的，具体的解析读者可自行分析 我们可以继续看下SqlSourceBuilder类是如何解析获取sql语句的 SqlSourceBuilder#parse()直接上源码 public SqlSource parse(String originalSql, Class&lt;?> parameterType, Map&lt;String, Object> additionalParameters) &#123; // 对#&#123;&#125;这样的字符串内容的解析处理类 ParameterMappingTokenHandler handler = new ParameterMappingTokenHandler(configuration, parameterType, additionalParameters); GenericTokenParser parser = new GenericTokenParser(\"#&#123;\", \"&#125;\", handler); // 获取真实的可执行性的sql语句 String sql = parser.parse(originalSql); // 包装成StaticSqlSource返回 return new StaticSqlSource(configuration, sql, handler.getParameterMappings()); &#125; 简单的看下ParameterMappingTokenHandler是如何解析的，其是TokenHandler接口的实现类，我们就关注实现方法handleToken @Override public String handleToken(String content) &#123; // 此处的作用就是对`#&#123;&#125;`节点中的key值保存映射，比如javaType/jdbcType/mode等信息，限于篇幅过长，读者可自行分析 parameterMappings.add(buildParameterMapping(content)); // 将`#&#123;&#125;`替换为?，即一般包装成`select * form test where name=? and age=?`预表达式语句 return \"?\"; &#125; 上述主要通过ParameterMappingTokenHandler类来完成对#&#123;&#125;字符串的解析，其中的映射信息则保存至BoundSql的parameterMappings属性中 总结 BoundSql语句的解析主要是通过对#{}字符的解析，将其替换成?。最后均包装成预表达式供PrepareStatement调用执行 #{}中的key属性以及相应的参数映射，比如javaType、jdbcType等信息均保存至BoundSql的parameterMappings属性中供最后的预表达式对象PrepareStatement赋值使用","tags":[]},{"title":"mybatis插件原理","date":"2020-11-15T10:00:00.000Z","path":"posts/undefined.html","text":"概述 Mybatis插件又称拦截器，本篇文章中出现的拦截器都表示插件 Mybatis采用责任链模式，通过动态代理组织多个插件（拦截器），通过这些插件可以改变Mybatis的默认行为（诸如SQL重写之类的），由于插件会深入到Mybatis的核心，因此在编写自己的插件前最好了解下它的原理，以便写出安全高效的插件。 MyBatis 允许你在已映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) 总体概括为： 拦截执行器的方法 拦截参数的处理 拦截结果集的处理 拦截Sql语法构建的处理 Mybatis是通过动态代理的方式实现拦截的，阅读此篇文章需要先对Java的动态代理机制有所了解。可以参考博客《彻底理解java动态代理》 Mybatis四大接口竟然Mybatis是对四大接口进行拦截的，那我们药先要知道Mybatis的四大接口对象 Executor, StatementHandler, ResultSetHandler, ParameterHandler。 上图Mybatis框架的整个执行过程。Mybatis插件能够对则四大对象进行拦截，可以包含到了Mybatis一次会议的所有操作。可见Mybatis的的插件很强大。 Executor是 Mybatis的内部执行器，它负责调用StatementHandler操作数据库，并把结果集通过 ResultSetHandler进行自动映射，另外，他还处理了二级缓存的操作。从这里可以看出，我们也是可以通过插件来实现自定义的二级缓存的。 StatementHandler是Mybatis直接和数据库执行sql脚本的对象。另外它也实现了Mybatis的一级缓存。这里，我们可以使用插件来实现对一级缓存的操作(禁用等等)。 ParameterHandler是Mybatis实现Sql入参设置的对象。插件可以改变我们Sql的参数默认设置。 ResultSetHandler是Mybatis把ResultSet集合映射成POJO的接口对象。我们可以定义插件对Mybatis的结果集自动映射进行修改。 插件InterceptorMybatis的插件实现要实现Interceptor接口，我们看下这个接口定义的方法。 public interface Interceptor &#123; Object intercept(Invocation invocation) throws Throwable; Object plugin(Object target); void setProperties(Properties properties); &#125; 这个接口只声明了三个方法。 setProperties方法是在Mybatis进行配置插件的时候可以配置自定义相关属性，即：接口实现对象的参数配置 plugin方法是插件用于封装目标对象的，通过该方法我们可以返回目标对象本身，也可以返回一个它的代理，可以决定是否要进行拦截进而决定要返回一个什么样的目标对象，官方提供了示例：return Plugin.wrap(target, this); intercept方法就是要进行拦截的时候要执行的方法 理解这个接口的定义，先要知道java动态代理机制。plugin接口即返回参数target对象(Executor/ParameterHandler/ResultSetHander/StatementHandler)的代理对象。在调用对应对象的接口的时候，可以进行拦截并处理。 Mybatis四大接口对象创建方法Mybatis的插件是采用对四大接口的对象生成动态代理对象的方法来实现的。那么现在我们看下Mybatis是怎么创建这四大接口对象的。 public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; //确保ExecutorType不为空(defaultExecutorType有可能为空) executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; executor = (Executor) interceptorChain.pluginAll(executor); return executor; &#125; public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler; &#125; public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler; &#125; public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) &#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler; &#125; 查看源码可以发现， Mybatis框架在创建好这四大接口对象的实例后，都会调用InterceptorChain.pluginAll()**方法。InterceptorChain对象是插件执行链对象，看源码就知道里面维护了Mybatis配置的所有插件(**Interceptor)对象。 // target --> Executor/ParameterHandler/ResultSetHander/StatementHandler public Object pluginAll(Object target) &#123; for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target; &#125; 其实就是安顺序执行我们插件的plugin方法,一层一层返回我们原对象(Executor/ParameterHandler/ResultSetHander/StatementHandler)的代理对象。当我们调用四大接口对象的方法时候，实际上是调用代理对象的响应方法，代理对象又会调用十大接口对象的实例。 Plugin对象我们知道，官方推荐插件实现plugin方法为：Plugin.wrap(target, this); public static Object wrap(Object target, Interceptor interceptor) &#123; // 获取插件的Intercepts注解 Map&lt;Class&lt;?>, Set&lt;Method>> signatureMap = getSignatureMap(interceptor); Class&lt;?> type = target.getClass(); Class&lt;?>[] interfaces = getAllInterfaces(type, signatureMap); if (interfaces.length > 0) &#123; return Proxy.newProxyInstance(type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; return target; &#125; 这个方法其实是Mybatis简化我们插件实现的工具方法。其实就是根据当前拦截的对象创建了一个动态代理对象。代理对象的InvocationHandler处理器为新建的Plugin对象。 插件配置注解@InterceptsMybatis的插件都要有Intercepts注解来指定要拦截哪个对象的哪个方法。我们知道，Plugin.warp方法会返回四大接口对象的代理对象(通过new Plugin()创建的IvocationHandler处理器)，会拦截所有的执行方法。在代理对象执行对应方法的时候，会调用InvocationHandler处理器的invoke方法。Mybatis中利用了注解的方式配置指定拦截哪些方法。具体如下： public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; Set&lt;Method> methods = signatureMap.get(method.getDeclaringClass()); if (methods != null &amp;&amp; methods.contains(method)) &#123; return interceptor.intercept(new Invocation(target, method, args)); &#125; return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125; &#125; 可以看到，只有通过Intercepts注解指定的方法才会执行我们自定义插件的intercept方法。未通过Intercepts注解指定的将不会执行我们的intercept方法。 官方插件开发方式@Intercepts(&#123;@Signature(type = Executor.class, method = \"query\", args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;)&#125;) public class TestInterceptor implements Interceptor &#123; public Object intercept(Invocation invocation) throws Throwable &#123; Object target = invocation.getTarget(); //被代理对象 Method method = invocation.getMethod(); //代理方法 Object[] args = invocation.getArgs(); //方法参数 // do something ...... 方法拦截前执行代码块 Object result = invocation.proceed(); // do something .......方法拦截后执行代码块 return result; &#125; public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; &#125; 以上就是Mybatis官方推荐的插件实现的方法，通过Plugin对象创建被代理对象的动态代理对象。可以发现，Mybatis的插件开发还是很简单的。 自定义开发方式Mybatis的插件开发通过内部提供的Plugin对象可以很简单的开发。只有理解了插件实现原理，对应不采用Plugin对象我们一样可以自己实现插件的开发。下面是我个人理解之后的自己实现的一种方式。 public class TestInterceptor implements Interceptor &#123; public Object intercept(Invocation invocation) throws Throwable &#123; Object target = invocation.getTarget(); //被代理对象 Method method = invocation.getMethod(); //代理方法 Object[] args = invocation.getArgs(); //方法参数 // do something ...... 方法拦截前执行代码块 Object result = invocation.proceed(); // do something .......方法拦截后执行代码块 return result; &#125; public Object plugin(final Object target) &#123; return Proxy.newProxyInstance(Interceptor.class.getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; return intercept(new Invocation(target, method, args)); &#125; &#125;); &#125; public void setProperties(Properties properties) &#123; &#125; &#125; 当然，Mybatis插件的那这个时候Intercepts的注解起不到作用了。 小结我们在MyBatis配置了一个插件，在运行发生了什么 所有可能被拦截的处理类都会生成一个代理 处理类代理在执行对应方法时，判断要不要执行插件中的拦截方法 执行插接中的拦截方法后，推进目标的执行 如果有N个插件，就有N个代理，每个代理都要执行上面的逻辑。这里面的层层代理要多次生成动态代理，是比较影响性能的。虽然能指定插件拦截的位置，但这个是在执行方法时动态判断，初始化的时候就是简单的把插件包装到了所有可以拦截的地方。 因此，在编写插件时需注意以下几个原则： 不编写不必要的插件； 实现plugin方法时判断一下目标类型，是本插件要拦截的对象才执行Plugin.wrap方法，否者直接返回目标本省，这样可以减少目标被代理的次数。 // 假如我们只要拦截Executor对象，那么我们应该这么做 public Object plugin(final Object target) &#123; if (target instanceof Executor) &#123; return Plugin.wrap(target, this); &#125; else &#123; return target; &#125; &#125; Mybatis插件很强大，可以对Mybatis框架进行很大的扩展。当然，如果你不理解Mybatis插件的原理，开发起来只能是模拟两可。在实际开发过程中，我们可以参考别人写的插件。下面是一个Mybatis分页的插件，可以为以后开发做参考。 /** * Mybatis - 通用分页插件（如果开启二级缓存需要注意） */ @Intercepts(&#123;@Signature(type = StatementHandler.class, method = \"prepare\", args = &#123;Connection.class&#125;), @Signature(type = ResultSetHandler.class, method = \"handleResultSets\", args = &#123;Statement.class&#125;)&#125;) @Log4j public class PageHelper implements Interceptor &#123; public static final ThreadLocal&lt;Page> localPage = new ThreadLocal&lt;Page>(); /** * 开始分页 * * @param pageNum * @param pageSize */ public static void startPage(int pageNum, int pageSize) &#123; localPage.set(new Page(pageNum, pageSize)); &#125; /** * 结束分页并返回结果，该方法必须被调用，否则localPage会一直保存下去，直到下一次startPage * * @return */ public static Page endPage() &#123; Page page = localPage.get(); localPage.remove(); return page; &#125; public Object intercept(Invocation invocation) throws Throwable &#123; if (localPage.get() == null) &#123; return invocation.proceed(); &#125; if (invocation.getTarget() instanceof StatementHandler) &#123; StatementHandler statementHandler = (StatementHandler) invocation.getTarget(); MetaObject metaStatementHandler = SystemMetaObject.forObject(statementHandler); // 分离代理对象链(由于目标类可能被多个插件拦截，从而形成多次代理，通过下面的两次循环 // 可以分离出最原始的的目标类) while (metaStatementHandler.hasGetter(\"h\")) &#123; Object object = metaStatementHandler.getValue(\"h\"); metaStatementHandler = SystemMetaObject.forObject(object); &#125; // 分离最后一个代理对象的目标类 while (metaStatementHandler.hasGetter(\"target\")) &#123; Object object = metaStatementHandler.getValue(\"target\"); metaStatementHandler = SystemMetaObject.forObject(object); &#125; MappedStatement mappedStatement = (MappedStatement) metaStatementHandler.getValue(\"delegate.mappedStatement\"); //分页信息if (localPage.get() != null) &#123; Page page = localPage.get(); BoundSql boundSql = (BoundSql) metaStatementHandler.getValue(\"delegate.boundSql\"); // 分页参数作为参数对象parameterObject的一个属性 String sql = boundSql.getSql(); // 重写sql String pageSql = buildPageSql(sql, page); //重写分页sql metaStatementHandler.setValue(\"delegate.boundSql.sql\", pageSql); Connection connection = (Connection) invocation.getArgs()[0]; // 重设分页参数里的总页数等 setPageParameter(sql, connection, mappedStatement, boundSql, page); // 将执行权交给下一个插件 return invocation.proceed(); &#125; else if (invocation.getTarget() instanceof ResultSetHandler) &#123; Object result = invocation.proceed(); Page page = localPage.get(); page.setResult((List) result); return result; &#125; return null; &#125; /** * 只拦截这两种类型的 * &lt;br>StatementHandler * &lt;br>ResultSetHandler * * @param target * @return */ public Object plugin(Object target) &#123; if (target instanceof StatementHandler || target instanceof ResultSetHandler) &#123; return Plugin.wrap(target, this); &#125; else &#123; return target; &#125; &#125; public void setProperties(Properties properties) &#123; &#125; /** * 修改原SQL为分页SQL * * @param sql * @param page * @return */ private String buildPageSql(String sql, Page page) &#123; StringBuilder pageSql = new StringBuilder(200); pageSql.append(\"select * from (\"); pageSql.append(sql); pageSql.append(\" ) temp limit \").append(page.getStartRow()); pageSql.append(\" , \").append(page.getPageSize()); return pageSql.toString(); &#125; /** * 获取总记录数 * * @param sql * @param connection * @param mappedStatement * @param boundSql * @param page */ private void setPageParameter(String sql, Connection connection, MappedStatement mappedStatement, BoundSql boundSql, Page page) &#123; // 记录总记录数 String countSql = \"select count(0) from (\" + sql + \") temp\"; PreparedStatement countStmt = null; ResultSet rs = null; try &#123; countStmt = connection.prepareStatement(countSql); BoundSql countBS = new BoundSql(mappedStatement.getConfiguration(), countSql, boundSql.getParameterMappings(), boundSql.getParameterObject()); setParameters(countStmt, mappedStatement, countBS, boundSql.getParameterObject()); rs = countStmt.executeQuery(); int totalCount = 0; if (rs.next()) &#123; totalCount = rs.getInt(1); &#125; page.setTotal(totalCount); int totalPage = totalCount / page.getPageSize() + ((totalCount % page.getPageSize() == 0) ? 0 : 1); page.setPages(totalPage); &#125; catch (SQLException e) &#123; log.error(\"Ignore this exception\", e); &#125; finally &#123; try &#123; rs.close(); &#125; catch (SQLException e) &#123; log.error(\"Ignore this exception\", e); &#125; try &#123; countStmt.close(); &#125; catch (SQLException e) &#123; log.error(\"Ignore this exception\", e); &#125; &#125; &#125; /** * 代入参数值 * * @param ps * @param mappedStatement * @param boundSql * @param parameterObject * @throws SQLException */ private void setParameters(PreparedStatement ps, MappedStatement mappedStatement, BoundSql boundSql, Object parameterObject) throws SQLException &#123; ParameterHandler parameterHandler = new DefaultParameterHandler(mappedStatement, parameterObject, boundSql); parameterHandler.setParameters(ps); &#125; @Data //采用lombok插件编译 public static class Page&lt;E> &#123; private int pageNum; private int pageSize; private int startRow; private int endRow; private long total; private int pages; private List&lt;E> result; public Page(int pageNum, int pageSize) &#123; this.pageNum = pageNum; this.pageSize = pageSize; this.startRow = pageNum > 0 ? (pageNum - 1) * pageSize : 0; this.endRow = pageNum * pageSize; &#125; &#125; &#125;","tags":[]},{"title":"react Hook之useMemo、useCallback及memo","date":"2020-11-14T03:00:00.000Z","path":"posts/undefined.html","text":"react Hook之useMemo、useCallback及memo注意：hooks只能在函数(无状态组件)中使用 useMome、useCallback用法都差不多，都会在第一次渲染的时候执行，之后会在其依赖的变量发生改变时再次执行，并且这两个hooks都返回缓存的值，useMemo返回缓存的变量，useCallback返回缓存的函数。 const value = useMemo(fnM, [a]); const fnA = useCallback(fnB, [a]); 复制代码 1、memo的应用React.memo 为高阶组件。它与React.PureComponent非常相似，但它适用于函数组件，但不适用于 class 组件。 默认情况下其只会对复杂对象做浅层对比，如果你想要控制对比过程，那么请将自定义的比较函数通过第二个参数传入来实现。这与shouldComponentUpdate 方法的返回值相反。 function MyComponent(props) &#123; /* 使用 props 渲染 */ &#125; function areEqual(prevProps, nextProps) &#123; /* 如果把 nextProps 传入 render 方法的返回结果与 将 prevProps 传入 render 方法的返回结果一致则返回 true， 否则返回 false */ &#125; export default React.memo(MyComponent, areEqual); 当父组件引入子组件的情况下，往往会造成组件之间的一些不必要的浪费，下面我们通过例子来了解一下场景 const Child = (props) => &#123; console.log('子组件?') return( &lt;div>我是一个子组件&lt;/div> ); &#125; const Page = (props) => &#123; const [count, setCount] = useState(0); return ( &lt;> &lt;button onClick=&#123;(e) => &#123; setCount(count+1) &#125;&#125;>加1&lt;/button> &lt;p>count:&#123;count&#125;&lt;/p> &lt;Child /> &lt;/> ) &#125; 复制代码 每次父组件更新count，子组件都会更新。如下版本使用memo，count变化子组件没有更新 const Child = (props) => &#123; console.log('子组件?') return( &lt;div>我是一个子组件&lt;/div> ); &#125; const ChildMemo = memo(Child); const Page = (props) => &#123; const [count, setCount] = useState(0); return ( &lt;> &lt;button onClick=&#123;(e) => &#123; setCount(count+1) &#125;&#125;>加1&lt;/button> &lt;p>count:&#123;count&#125;&lt;/p> &lt;ChildMemo /> &lt;/> ) &#125; 复制代码 2、使用useCallback当父组件传递状态给子组件的时候，memo好像没什么效果，子组件还是执行了，这时候我们就要引入hooks的useCallback、useMemo这两个钩子了。 //子组件会有不必要渲染的例子 interface ChildProps &#123; name: string; onClick: Function; &#125; const Child = (&#123; name, onClick&#125;: ChildProps): JSX.Element => &#123; console.log('子组件?') return( &lt;> &lt;div>我是一个子组件，父级传过来的数据：&#123;name&#125;&lt;/div> &lt;button onClick=&#123;onClick.bind(null, '新的子组件name')&#125;>改变name&lt;/button> &lt;/> ); &#125; const ChildMemo = memo(Child); const Page = (props) => &#123; const [count, setCount] = useState(0); const [name, setName] = useState('Child组件'); return ( &lt;> &lt;button onClick=&#123;(e) => &#123; setCount(count+1) &#125;&#125;>加1&lt;/button> &lt;p>count:&#123;count&#125;&lt;/p> &lt;ChildMemo name=&#123;name&#125; onClick=&#123;(newName: string) => setName(newName)&#125;/> &lt;/> ) &#125; 复制代码 在上面代码基础上，父级调用子级时，在onClick参数上加上useCallback，参数为[]，则第一次初始化结束后，不在改变。 //子组件没有必要渲染的例子 interface ChildProps &#123; name: string; onClick: Function; &#125; const Child = (&#123; name, onClick&#125;: ChildProps): JSX.Element => &#123; console.log('子组件?') return( &lt;> &lt;div>我是一个子组件，父级传过来的数据：&#123;name&#125;&lt;/div> &lt;button onClick=&#123;onClick.bind(null, '新的子组件name')&#125;>改变name&lt;/button> &lt;/> ); &#125; const ChildMemo = memo(Child); const Page = (props) => &#123; const [count, setCount] = useState(0); const [name, setName] = useState('Child组件'); return ( &lt;> &lt;button onClick=&#123;(e) => &#123; setCount(count+1) &#125;&#125;>加1&lt;/button> &lt;p>count:&#123;count&#125;&lt;/p> &lt;ChildMemo name=&#123;name&#125; onClick=&#123; useCallback((newName: string) => setName(newName), []) &#125;/> &#123;/* useCallback((newName: string) => setName(newName),[]) */&#125; &#123;/* 这里使用了useCallback优化了传递给子组件的函数，只初始化一次这个函数，下次不产生新的函数 &lt;/> ) &#125; 复制代码 3、使用useMemo//子组件会有不必要渲染的例子 interface ChildProps &#123; name: &#123; name: string; color: string &#125;; onClick: Function; &#125; const Child = (&#123; name, onClick&#125;: ChildProps): JSX.Element => &#123; console.log('子组件?') return( &lt;> &lt;div style=&#123;&#123; color: name.color &#125;&#125;>我是一个子组件，父级传过来的数据：&#123;name.name&#125;&lt;/div> &lt;button onClick=&#123;onClick.bind(null, '新的子组件name')&#125;>改变name&lt;/button> &lt;/> ); &#125; const ChildMemo = memo(Child); const Page = (props) => &#123; const [count, setCount] = useState(0); const [name, setName] = useState('Child组件'); return ( &lt;> &lt;button onClick=&#123;(e) => &#123; setCount(count+1) &#125;&#125;>加1&lt;/button> &lt;p>count:&#123;count&#125;&lt;/p> &lt;ChildMemo name=&#123;&#123; name, color: name.indexOf('name') !== -1 ? 'red' : 'green'&#125;&#125; onClick=&#123; useCallback((newName: string) => setName(newName), []) &#125; /> &lt;/> ) &#125; 复制代码 更新属性name为对象类型，这时子组件还是一样的执行了，在父组件更新其它状态的情况下，子组件的name对象属性会一直发生重新渲染改变，从而导致一直执行,这也是不必要的性能浪费。 解决这个问题，使用name参数使用useMemo，依赖于State.name数据的变化进行更新 interface ChildProps &#123; name: &#123; name: string; color: string &#125;; onClick: Function; &#125; const Child = (&#123; name, onClick&#125;: ChildProps): JSX.Element => &#123; console.log('子组件?') return( &lt;> &lt;div style=&#123;&#123; color: name.color &#125;&#125;>我是一个子组件，父级传过来的数据：&#123;name.name&#125;&lt;/div> &lt;button onClick=&#123;onClick.bind(null, '新的子组件name')&#125;>改变name&lt;/button> &lt;/> ); &#125; const ChildMemo = memo(Child); const Page = (props) => &#123; const [count, setCount] = useState(0); const [name, setName] = useState('Child组件'); return ( &lt;> &lt;button onClick=&#123;(e) => &#123; setCount(count+1) &#125;&#125;>加1&lt;/button> &lt;p>count:&#123;count&#125;&lt;/p> &lt;ChildMemo //使用useMemo，返回一个和原本一样的对象，第二个参数是依赖性，当name发生改变的时候，才产生一个新的对象 name=&#123; useMemo(()=>(&#123; name, color: name.indexOf('name') !== -1 ? 'red' : 'green' &#125;), [name]) &#125; onClick=&#123; useCallback((newName: string) => setName(newName), []) &#125; &#123;/* useCallback((newName: string) => setName(newName),[]) */&#125; &#123;/* 这里使用了useCallback优化了传递给子组件的函数，只初始化一次这个函数，下次不产生新的函数 /> &lt;/> ) &#125; 复制代码 4、总结在子组件不需要父组件的值和函数的情况下，只需要使用memo函数包裹子组件即可。而在使用函数的情况，需要考虑有没有函数传递给子组件使用useCallback。而在值有所依赖的项，并且是对象和数组等值的时候而使用useMemo（当返回的是原始数据类型如字符串、数字、布尔值，就不要使用useMemo了）。不要盲目使用这些hooks。 参考链接：React Hook 最佳实践 React.memo React进阶用法和hooks的个人使用见解(Typescript版本) - 3.useCallback+useMemo+memo性能优化","tags":[]},{"title":"学习React Hooks系列 - useMemo","date":"2020-11-14T03:00:00.000Z","path":"posts/undefined.html","text":"学习React Hooks系列 - useMemo一个场景：父组件改变自身数据，不涉及子组件数据变化，就会在父组件每次render时都渲染子组件。 1、了解一下React.PureComponent组件先说一下shouldComponentUpdate这个生命周期函数，这个函数是通过返回true或false来控制组件是否渲染的，可以有效的避免组件的一些无意义或者重复的渲染，和避免不必要的重复计算，减少资源浪费，提高性能。 shouldComponentUpdate(nextProps, nextState) &#123; if(this.props.value === nextProps.value) &#123; return false; // 判断props接收的参数value有无变化，无变化则返回false，组件不渲染 &#125; &#125; 类组件由继承Component组件改为继承PureComponent组件，就不用再写shouldComponentUpdate生命周期函数判断参数有无变化来控制组件的渲染。 子组件继承PureComponent组件，会判断传进的参有没有变化，无变化则阻止子组件渲染。 PureComponent组件的不足： 只提供了简单的对比算法。 复杂的数据结构传值，PureComponent组件做不出正确的判断。 函数组件不能继承PureComponent组件。 2、了解一下React.memo()React 16.6.0 正式发布React.memo()，React.memo()是一个高阶组件。 import React, &#123; memo &#125; from 'react'; const Child = memo(function Child(props) &#123; return( &lt;h1>&#123;props.value&#125;&lt;/h1> ) &#125;); export default Child;复制代码 React.memo()和React.PureComponent组件异同： 异：React.memo()是函数组件，React.PureComponent是类组件。 同：都是对接收的props参数进行浅比较，解决组件在运行时的效率问题，优化组件的重渲染行为。 3、再说说useMemoReact 16.8.0中发布useMemo()。 React.memo()是判断一个函数组件的渲染是否重复执行。 useMemo()是定义一段函数逻辑是否重复执行。 import React, &#123; memo, useState, useMemo &#125; from \"react\"; function App() &#123; const [value, setValue] = useState(0); const increase = useMemo(() => &#123; if(value > 2) return value + 1; &#125;, [value]); return ( &lt;div> &lt;Child value=&#123;value&#125; /> &lt;button type=\"button\" onClick=&#123;() => &#123; setValue(value + 1); &#125;&#125; > value:&#123;value&#125;,increase:&#123;increase || 0&#125; &lt;/button> &lt;/div> ); &#125; const Child = memo(function Child(props) &#123; console.log('Child render') return &lt;h1>value:&#123;props.value&#125;&lt;/h1>; &#125;); export default App;复制代码 useMemo()依赖value值定义参数increase：const increase &#x3D; useMemo(() &#x3D;&gt; &#123; if(value &gt; 2) return value + 1; &#125;, [value]);复制代码 value的初始值为0，当value的值递增到大于2时，increase才会开始被赋值，且被赋值后increase永远比value大1 子组件Child：const Child = memo(function Child(props) &#123; console.log('Child render') return &lt;h1>value:&#123;props.value&#125;&lt;/h1>; &#125;)复制代码 memo组件判断props传的值是否更新，若有更新则子组件显示的value值更新，且控制台会打印 Child render 为了能明显看到memo的作用，可以把传给Child组件的值改为increase，&lt;Child value=&#123;increase&#125; /&gt; increase为0时，Child组件不会渲染。 点击button递增value，当value &gt; 2时 ，increase参数更新，所以子组件Child会渲染，控制台会打印出 Child render 4、useMemo()的参数用过useEffect()大概会知道useEffect()的第二个参数的作用。useMemo()和useEffect()是一样的。 useEffect()第一个参数是执行函数，那……第二个参数： 若第二个参数为空，则每次渲染组件该段逻辑都会被执行，就不会根据传入的属性值来判断逻辑是否重新执行，这样写useMemo()也就毫无意义。 若第二个参数为空数组，则只会在渲染组件时执行一次，传入的属性值的更新也不会有作用。 所以useMemo()的第二个参数，数组中需要传入依赖的参数。 useMemo(() => &#123; // to do somthing... &#125;, [value])复制代码 5、useMemo()的执行时间useMemo()是需要有返回值的，并且返回值是直接参与渲染，因此useMemo()是在渲染期间完成的。","tags":[]},{"title":"学习React Hooks系列-useRef","date":"2020-11-14T03:00:00.000Z","path":"posts/undefined.html","text":"useRef使用总结父组件知识点总结 useRef是一个方法，且useRef返回一个可变的ref对象（对象！！！） initialValue被赋值给其返回值的.current对象 可以保存任何类型的值:dom、对象等任何可辨值 ref对象与自建一个{current：‘’}对象的区别是：useRef会在每次渲染时返回同一个ref对象，即返回的ref对象在组件的整个生命周期内保持不变。自建对象每次渲染时都建立一个新的。 ref对象的值发生改变之后，不会触发组件重新渲染。有一个窍门，把它的改边动作放到useState()之前。 本质上，useRef就是一个其.current属性保存着一个可变值“盒子”。目前我用到的是pageRef和sortRef分别用来保存分页信息和排序信息。 代码示例import React, &#123; useRef, useEffect, useImperativeHandle, forwardRef, &#125; from \"react\"; const RefDemo = () => &#123; const domRef = useRef(1); const childRef = useRef(null); useEffect(() => &#123; console.log(\"ref:deom-init\", domRef, domRef.current); console.log(\"ref:child-init\", childRef, childRef.current); &#125;); const showChild = () => &#123; console.log(\"ref:child\", childRef, childRef.current); childRef.current.say(); &#125;; return ( &lt;div style=&#123;&#123; margin: \"100px\", border: \"2px dashed\", padding: \"20px\" &#125;&#125;> &lt;h2>这是外层组件&lt;/h2> &lt;div onClick=&#123;() => &#123; console.log(\"ref:deom\", domRef, domRef.current); domRef.current.focus(); domRef.current.value = 'hh'; &#125;&#125; > &lt;label>这是一个dom节点&lt;/label>&lt;input ref=&#123;domRef&#125; /> &lt;/div> &lt;br /> &lt;p onClick=&#123;showChild&#125; style=&#123;&#123; marginTop: \"20px\" &#125;&#125;> 这是子组件 &lt;/p> &lt;div style=&#123;&#123; border: \"1px solid\", padding: \"10px\" &#125;&#125;> &lt;Child ref=&#123;childRef&#125; /> &lt;/div> &lt;/div> ); &#125;; export default RefDemo; 子组件知识点总结 useImperativeHandle(ref,createHandle,[deps])可以自定义暴露给父组件的实例值。如果不使用，父组件的ref(chidlRef)访问不到任何值（childRef.current==null） useImperativeHandle应该与forwradRef搭配使用 React.forwardRef会创建一个React组件，这个组件能够将其接受的ref属性转发到其组件树下的另一个组件中。 React.forward接受渲染函数作为参数，React将使用prop和ref作为参数来调用此函数。 代码示例 const Child = forwardRef((props, ref) => &#123; useImperativeHandle(ref, () => (&#123; say: sayHello, &#125;)); const sayHello = () => &#123; alert(\"hello,我是子组件\"); &#125;; return &lt;h3>子组件&lt;/h3>; &#125;); 等同于 => const ChildComponent = (props, ref) => &#123; useImperativeHandle(ref, () => (&#123; say: sayHello, &#125;)); const sayHello = () => &#123; alert(\"hello,我是子组件\"); &#125;; return &lt;h3>子组件&lt;/h3>; &#125;; const Child = forwardRef(ChildComponent);","tags":[]},{"title":"优雅管理代码提交","date":"2020-11-13T07:00:00.000Z","path":"posts/undefined.html","text":"一、优雅的提交1.commitizen &amp;&amp; cz-lerna-changelog commitizen 是用来格式化 git commit message 的工具，它提供了一种问询式的方式去获取所需的提交信息。 cz-lerna-changelog 是专门为 Lerna 项目量身定制的提交规范，在问询的过程，会有类似影响哪些 package 的选择。如下： 我们使用 commitizen 和 cz-lerna-changelog 来规范提交，为后面自动生成日志作好准备。 因为这是整个工程的开发依赖，所以在根目录安装： npm i -D commitizen npm i -D cz-lerna-changelog 安装完成后，在 package.json 中增加 config 字段，把 cz-lerna-changelog 配置给 commitizen。同时因为commitizen不是全局安全的，所以需要添加 scripts 脚本来执行 git-cz &#123; &quot;name&quot;: &quot;root&quot;, &quot;private&quot;: true, &quot;scripts&quot;: &#123; &quot;c&quot;: &quot;git-cz&quot; &#125;, &quot;config&quot;: &#123; &quot;commitizen&quot;: &#123; &quot;path&quot;: &quot;.&#x2F;node_modules&#x2F;cz-lerna-changelog&quot; &#125; &#125;, &quot;devDependencies&quot;: &#123; &quot;commitizen&quot;: &quot;^3.1.1&quot;, &quot;cz-lerna-changelog&quot;: &quot;^2.0.2&quot;, &quot;lerna&quot;: &quot;^3.15.0&quot; &#125; &#125; 之后在常规的开发中就可以使用 npm run c 来根据提示一步一步输入，来完成代码的提交。 2.commitlint &amp;&amp; husky 上面我们使用了 commitizen 来规范提交，但这个要靠开发自觉使用 npm run c 。万一忘记了，或者直接使用 git commit 提交怎么办？答案就是在提交时对提交信息进行校验，如果不符合要求就不让提交，并提示。校验的工作由 commitlint 来完成，校验的时机则由 husky 来指定。husky 继承了 Git 下所有的钩子，在触发钩子的时候，husky 可以阻止不合法的 commit,push 等等。 &#x2F;&#x2F; 安装 commitlint 以及要遵守的规范 npm i -D @commitlint&#x2F;cli @commitlint&#x2F;config-conventional &#x2F;&#x2F; 在工程根目录为 commitlint 增加配置文件 &#x2F;&#x2F; commitlint.config.js 为commitlint 指定相应的规范 module.exports &#x3D; &#123; extends: [&#39;@commitlint&#x2F;config-conventional&#39;] &#125; &#x2F;&#x2F; 安装 husky npm i -D husky &#x2F;&#x2F; 在 package.json 中增加如下配置 &quot;husky&quot;: &#123; &quot;hooks&quot;: &#123; &quot;commit-msg&quot;: &quot;commitlint -E HUSKY_GIT_PARAMS&quot; &#125; &#125; “commit-msg”是git提交时校验提交信息的钩子，当触发时便会使用 commitlit 来校验。安装配置完成后，想通过 git commit 或者其它第三方工具提交时，只要提交信息不符合规范就无法提交。从而约束开发者使用 npm run c 来提交。 3.standardjs &amp;&amp; lint-staged 除了规范提交信息，代码本身肯定也少了靠规范来统一风格。 standardjs就是完整的一套 JavaScript 代码规范，自带 linter &amp; 代码自动修正。它无需配置，自动格式化代码并修正，提前发现风格以及程序问题。 lint-staged staged 是 Git 里的概念，表示暂存区，lint-staged 表示只检查并矫正暂存区中的文件。一来提高校验效率，二来可以为老的项目带去巨大的方便。 &#x2F;&#x2F; 安装 npm i -D standard lint-staged &#x2F;&#x2F; package.json &#123; &quot;name&quot;: &quot;root&quot;, &quot;private&quot;: true, &quot;scripts&quot;: &#123; &quot;c&quot;: &quot;git-cz&quot; &#125;, &quot;config&quot;: &#123; &quot;commitizen&quot;: &#123; &quot;path&quot;: &quot;.&#x2F;node_modules&#x2F;cz-lerna-changelog&quot; &#125; &#125;, &quot;husky&quot;: &#123; &quot;hooks&quot;: &#123; &quot;pre-commit&quot;: &quot;lint-staged&quot;, &quot;commit-msg&quot;: &quot;commitlint -E HUSKY_GIT_PARAMS&quot; &#125; &#125;, &quot;lint-staged&quot;: &#123; &quot;*.js&quot;: [ &quot;standard --fix&quot;, &quot;git add&quot; ] &#125;, &quot;devDependencies&quot;: &#123; &quot;@commitlint&#x2F;cli&quot;: &quot;^8.1.0&quot;, &quot;@commitlint&#x2F;config-conventional&quot;: &quot;^8.1.0&quot;, &quot;commitizen&quot;: &quot;^3.1.1&quot;, &quot;cz-lerna-changelog&quot;: &quot;^2.0.2&quot;, &quot;husky&quot;: &quot;^3.0.0&quot;, &quot;lerna&quot;: &quot;^3.15.0&quot;, &quot;lint-staged&quot;: &quot;^9.2.0&quot;, &quot;standard&quot;: &quot;^13.0.2&quot; &#125; &#125; 安装完成后，在 package.json 增加 lint-staged 配置，如上所示表示对暂存区中的 js 文件执行 standard –fix 校验并自动修复。那什么时候去校验呢，就又用到了上面安装的 husky ，husky的配置中增加’pre-commit’的钩子用来执行 lint-staged 的校验操作，如上所示。 此时提交 js 文件时，便会自动修正并校验错误。即保证了代码风格统一，又能提高代码质量。 二、自动生成日志有了之前的规范提交，自动生成日志便水到渠成了。再详细看下 lerna publish 时做了哪些事情： 1.调用 lerna version 找出从上一个版本发布以来有过变更的 package 提示开发者确定要发布的版本号 将所有更新过的的 package 中的package.json的version字段更新 将依赖更新过的 package 的 包中的依赖版本号更新 更新 lerna.json 中的 version 字段 提交上述修改，并打一个 tag 推送到 git 仓库 2.使用 npm publish 将新版本推送到 npm CHANGELOG 很明显是和 version 一一对应的，所以需要在 lerna version 中想办法，查看 lerna version 命令的详细说明后，会看到一个配置参数 –conventional-commits。没错，只要我们按规范提交后，在 lerna version 的过程中会便会自动生成当前这个版本的 CHANGELOG。为了方便，不用每次输入参数，可以配置在 lerna.json中，如下： &#123; &quot;packages&quot;: [ &quot;packages&#x2F;*&quot; ], &quot;command&quot;: &#123; &quot;bootstrap&quot;: &#123; &quot;hoist&quot;: true &#125;, &quot;version&quot;: &#123; &quot;conventionalCommits&quot;: true &#125; &#125;, &quot;ignoreChanges&quot;: [ &quot;**&#x2F;*.md&quot; ], &quot;version&quot;: &quot;0.0.1-alpha.1&quot; &#125;","tags":[]},{"title":"react优秀组件库","date":"2020-11-08T02:00:00.000Z","path":"posts/undefined.html","text":"图片react-zmage","tags":[]},{"title":"lerna教程","date":"2020-11-04T04:00:00.000Z","path":"posts/undefined.html","text":"参考： monorepo 新浪潮 用lerna-changelog 来梳理 changelog 使用 monorepo 结构，管理多个 repo(示例) lerna管理前端packages的最佳实践 lerna 中文文档 常见问题 https://lernajs.io/ lerna-wizard lerna的命令行向导 使用lerna管理大型前端项目 lerna-yarn-workspaces-example 独立模式 lerna-semantic-release 管理多个 repo ： 单个 lint、build、test 和 release 流程 统一的地方处理 issue 不用到处去找自己项目的 repo 方便管理版本和 dependencies 跨项目的操作和修改变得容易 方便生成总的 changelog useWorkspaces 应该是只针对 yarn 的 WorkspacesUsing yarn workspace feature, configure the following files: /package.json Append the workspaces key. ​json &#123; &quot;private&quot;: true, &quot;workspaces&quot;: [ ​ &quot;packages/*&quot; ] &#125; ​ lerna.json Set npmClient &quot;yarn&quot; and turn useWorkspaces on. ​json &#123; &quot;lerna&quot;: &quot;2.2.0&quot;, &quot;packages&quot;: [ ​ &quot;packages/*&quot; ], &quot;npmClient&quot;: &quot;yarn&quot;, &quot;useWorkspaces&quot;: true, &quot;version&quot;: &quot;1.0.0&quot; &#125; ​ Exec yarn install(or lerna bootstrap). After successful running, all dependency packages are downloaded under the repository root node_modules directory. 其他建议使用 npx, 如 npx lerna init ​```bash 全局安装工具，除了 Lerna,Builder，还可以像Andre Staltz 一样自己用脚本（通过Bash s）来实现 monoreponpm install -g lerna 创建\\初始化.git仓库git init lerna-repo cd lerna-repo 或mkdir lerna-repo &amp;&amp; cd $_ 初始化管理目录，同时之后手动配置子 package 间的调用关系：dependencies lerna init 会为各个 package 执行 npm install 所有的外部依赖； 并为内部依赖的 package 建立 symlink，对所有的 package 执行 npm prepublish bootstrap 将把repo中的依赖关系链接在一起.lerna bootstrap lerna bootstrap –hoist ? 这个是什么 更新版本(不用主动去更新，直接执行发布，根据提示选择操作即可) 使用与 npm version 相同的语法，更新版本号，如lerna version patch Changes: @xmini/package-1: 0.0.1 =&gt; 0.0.2 @xmini/package-2: 0.0.1 =&gt; 0.0.2 可以为指定包添加依赖lerna add @types&#x2F;node --scope&#x3D;@xmini&#x2F;package-1 lerna add --dev typescript --scope&#x3D;@xmini&#x2F;package-1 npm install jest --only&#x3D;dev updated 可以查看哪些包发生了改变lerna updated 发布到 npmpublish将帮助发布任何更新的包（如果包未更新，会忽略）lerna publish​``` Set up yarn的workspaces模式 https://juejin.im/post/5ced1609e51d455d850d3a6c lerna init 初始化项目 lerna bootstrap 安装依赖 默认是npm, 而且每个子package都有自己的node_modules 配置 yarn+workspaces 后，只有顶层有一个node_modules lerna list 列出所有的包 lerna create &lt;name&gt; [loc] 创建一个包 默认放在 workspaces[0]所指位置 lerna run &lt;script&gt; 运行所有包里面的有这个script的命令 lerna exec 运行任意命令在每个包 lerna clean 删除所有包的node_modules目录 lerna changed 列出下次发版lerna publish 要更新的包。 lerna publish 会打tag，上传git,上传npm。 需要在packages.json添加 “publishConfig”: { “access”: “public” }, 配置 yarn + workspaces ​```bash package.json 文件加入true,&quot;workspaces&quot;: [ &quot;packages&#x2F;*&quot; ], lerna.json 文件加入&quot;useWorkspaces&quot;: true, &quot;npmClient&quot;: &quot;yarn&quot;,","tags":[]},{"title":"centos8安装minio","date":"2020-10-24T08:00:00.000Z","path":"posts/undefined.html","text":"docker run -p 9228:9000 --name miniostorage -di -e \"MINIO_ACCESS_KEY=AKIAIOSFODNN7EXAMPLE\" -e \"MINIO_SECRET_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" -v /opt/minio/storage/data:/data -v /opt/minio/storage/config:/root/.minio --restart=always minio/minio server /data","tags":[]},{"title":"SkyWalking安装使用","date":"2020-10-24T04:00:00.000Z","path":"posts/36626760.html","text":"1、SkyWalkingSkyWalking是国内开源的基于字节码注入的调用链分析以及应用监控分析工具。特点是支持多种插件，UI功能较强，接入端无代码侵入。目前使用厂商最多，版本更新较快，已成为 Apache 基金会顶级项目。 官网：https://skywalking.apache.org/downloads/ GitHub: https://github.com/apache/skywalking 2、安装1、下载SkyWalking注意版本的不同，有些是用es6当作数据库，有些使用es7当作数据库，他们的功能不一样。 image.png 2、安装下载加压后目录如下 image.png 3、启动在bin目录下执行startup.bat即可启动服务 说明：执行startup.bat之后会启动如下两个服务： （1）Skywalking-Collector：追踪信息收集器，通过 gRPC/Http 收集客户端的采集信息 ，Http默认端口 12800，gRPC默认端口 11800。 （2）Skywalking-Webapp：管理平台页面 默认端口 8080 4、配置信息a、application.yml 主要配置SkyWakling集群方式、数据存储，配置文件内容如下 core: default: restHost: $&#123;SW_CORE_REST_HOST:0.0.0.0&#125; restPort: $&#123;SW_CORE_REST_PORT:12800&#125; restContextPath: $&#123;SW_CORE_REST_CONTEXT_PATH:/&#125; gRPCHost: $&#123;SW_CORE_GRPC_HOST:0.0.0.0&#125; gRPCPort: $&#123;SW_CORE_GRPC_PORT:11800&#125; downsampling: - Hour - Day - Month # Set a timeout on metric data. After the timeout has expired, the metric data will automatically be deleted. recordDataTTL: $&#123;SW_CORE_RECORD_DATA_TTL:90&#125; # Unit is minute minuteMetricsDataTTL: $&#123;SW_CORE_MINUTE_METRIC_DATA_TTL:90&#125; # Unit is minute hourMetricsDataTTL: $&#123;SW_CORE_HOUR_METRIC_DATA_TTL:36&#125; # Unit is hour dayMetricsDataTTL: $&#123;SW_CORE_DAY_METRIC_DATA_TTL:45&#125; # Unit is day monthMetricsDataTTL: $&#123;SW_CORE_MONTH_METRIC_DATA_TTL:18&#125; # Unit is month storage: h2: driver: $&#123;SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource&#125; url: $&#123;SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db&#125; user: $&#123;SW_STORAGE_H2_USER:sa&#125; # elasticsearch: # # nameSpace: $&#123;SW_NAMESPACE:\"\"&#125; # clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:9200&#125; # indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2&#125; # indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0&#125; # # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html # bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:2000&#125; # Execute the bulk every 2000 requests # bulkSize: $&#123;SW_STORAGE_ES_BULK_SIZE:20&#125; # flush the bulk every 20mb # flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # flush the bulk every 10 seconds whatever the number of requests # concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; # the number of concurrent requests receiver-register: default: receiver-trace: default: bufferPath: $&#123;SW_RECEIVER_BUFFER_PATH:../trace-buffer/&#125; # Path to trace buffer files, suggest to use absolute path bufferOffsetMaxFileSize: $&#123;SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100&#125; # Unit is MB bufferDataMaxFileSize: $&#123;SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500&#125; # Unit is MB bufferFileCleanWhenRestart: $&#123;SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false&#125; sampleRate: $&#123;SW_TRACE_SAMPLE_RATE:10000&#125; # The sample rate precision is 1/10000. 10000 means 100% sample in default. receiver-jvm: default: #service-mesh: # default: # bufferPath: $&#123;SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/&#125; # Path to trace buffer files, suggest to use absolute path # bufferOffsetMaxFileSize: $&#123;SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100&#125; # Unit is MB # bufferDataMaxFileSize: $&#123;SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500&#125; # Unit is MB # bufferFileCleanWhenRestart: $&#123;SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false&#125; #istio-telemetry: # default: #receiver_zipkin: # default: # host: $&#123;SW_RECEIVER_ZIPKIN_HOST:0.0.0.0&#125; # port: $&#123;SW_RECEIVER_ZIPKIN_PORT:9411&#125; # contextPath: $&#123;SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/&#125; 3、IDEA 部署探针修改项目启动的 VM 运行参数 1、点击菜单栏中的 Run -&gt; EditConfigurations… image.png 2、增加如下参数到VM options中：-javaagent:C:\\Users\\ke\\Desktop\\apache-skywalking-apm-6.6.0\\apache- skywalking-apm-bin\\agent\\skywalking-agent.jar -Dskywalking.agent.service_name&#x3D;service-eureka -Dskywalking.collector.backend_service&#x3D;localhost:8761 -javaagent：用于指定探针路径 -Dskywalking.agent.service_name：用于重写 agent/config/agent.config 配置文件中的服务名 -Dskywalking.collector.backend_service：用于重写 agent/config/agent.config 配置文件中的服务地址 启动后看到如下启动日志： INFO 2020-02-13 14:57:36:310 main SnifferConfigInitializer : Config file found in C:\\Users\\ke\\Desktop\\apache-skywalking-apm-6.6.0\\apache-skywalking-apm-bin\\agent\\config\\agent.config. 4、Java 命令行启动方式java -javaagent:C:\\Users\\ke\\Desktop\\apache-skywalking-apm-6.6.0\\apache-skywalking-apm-bin\\agent&#x2F;skywalking-agent.jar&#x3D;-Dskywalking.agent.service_name&#x3D;ijep-eureka-provider,-Dskywalking.collector.backend_service&#x3D;localhost:11800 -jar ijep-registry-eureka.jar 注：-javaagent配置参数一定要在 -jar 之前。 附: 配置文件详解# 当前的应用编码，最终会显示在webui上。 # 建议一个应用的多个实例，使用有相同的application_code。请使用英文 agent.application_code=Your_ApplicationName # 每三秒采样的Trace数量 # 默认为负数，代表在保证不超过内存Buffer区的前提下，采集所有的Trace # agent.sample_n_per_3_secs=-1 # 设置需要忽略的请求地址 # 默认配置如下 # agent.ignore_suffix=.jpg,.jpeg,.js,.css,.png,.bmp,.gif,.ico,.mp3,.mp4,.html,.svg # 探针调试开关，如果设置为true，探针会将所有操作字节码的类输出 到/debugging目录下 # skywalking团队可能在调试，需要此文件 # agent.is_open_debugging_class = true # 对应Collector的config/application.yml配置文件中 agent_server/jetty/port 配置内容 # 例如： # 单节点配置：SERVERS=\"127.0.0.1:8080\" # 集群配置：SERVERS=\"10.2.45.126:8080,10.2.45.127:7600\" collector.servers=127.0.0.1:10800 # 日志文件名称前缀 logging.file_name=skywalking-agent.log # 日志文件最大大小 # 如果超过此大小，则会生成新文件。 # 默认为300M logging.max_file_size=314572800 # 日志级别，默认为DEBUG。 logging.level=DEBUG 3、Centos 7使用教程1、环境准备● 系统版本：Centos 7 ● 内存配置：2G ● JDK版本：1.8.0_51 ● IP为：192.168.1.180 2、下载解压# 下载SkyWalking wget http://mirrors.tuna.tsinghua.edu.cn/apache/skywalking/6.5.0/apache-skywalking-apm-6.5.0.tar.gz # 解压 tar -zxf apache-skywalking-apm-6.5.0.tar.gz mkdir /usr/local/skywalking mv apache-skywalking-apm-bin /usr/local/skywalking 3、配置SkyWakling共有三个配置文件，分别为： ● agent/config/agent.config ● conf/application.yml ● webapp/webapp.yml 其中application.yml和webapp.yml配置是服务器运行相关，agent.config是在代理节点上进行配置的。 a、application.yml主要配置SkyWakling集群方式、数据存储，配置文件内容如下； # 配置skywalking集群 cluster: # 这里采用zk，需要注意的是，在skywalking6.5版本中要求zk版本也必须大于3.5 zookeeper: namespace: skywalking_brief # zk集群以\",\"进行分割 hostPort: 192.168.1.180:2283 # 配置重试次数以及重试间隔 baseSleepTimeMs: 3000 maxRetries: 5 # 核心配置 core: default: role: $&#123;SW_CORE_ROLE:Mixed&#125; # backend配置，如果是Mixed或者Receiver类型，那么下面的配置将会生效，服务启动之后将会作为collector收集agent发送过来的链路数据 restHost: $&#123;SW_CORE_REST_HOST:0.0.0.0&#125; restPort: $&#123;SW_CORE_REST_PORT:12800&#125; restContextPath: $&#123;SW_CORE_CONTEXT_PATH: /&#125; # gRPC配置 gRPCHost: $&#123;SW_CORE_GRPC_HOST:0.0.0.0&#125; gRPCPort: $&#123;SW_CORE_GRPC_PORT:11800&#125; downsampling: - Hour - Day - Month # 是否允许删除度量数据 enableDataKeeperExecutor: $&#123;SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR: true&#125; # datakeeper删除数据执行间隔，单位为分钟 dataKeeperExecutePeriod: $&#123;SW_CORE_DATA_KEEPER_EXECUTE_PERIOD: 5&#125; # 单位是分钟 recordDataTTL: $&#123;SW_CORE_RECORD_DATA_TTL:90&#125; minuteMetricsDataTTL: $&#123;SW_CORE_MINUTE_METRIC_DATA_TTL:90&#125; hourMetricsDataTTL: $&#123;SW_CORE_HOUR_METRIC_DATA_TTL:36&#125; dayMetricsDataTTL: $&#123;SW_CORE_DAY_METRIC_DATA_TTL:45&#125; monthMetricsDataTTL: $&#123;SW_CORE_MONTH_METRIC_DATA_TTL:18&#125; enableDatabaseSession: $&#123;SW_CORE_ENABLE_DATABASE_SESSION: true&#125; # 配置数据存储方式，默认为H2，这里修改为宿主机上的ES storage: elasticsearch: namespace: elasticsearch #es地址，多master之间以\",\"分割 clusterNodes: 192.168.1.151:9800 protocol: http # 配置index # index分片，es中默认为5，在skywalking中默认为2 indexShardsNumber: 2 # 分片备份数量，默认为0 indexReplicasNumber: 0 recordDataTTL: 7 otherMetricsDataTTL: 45 monthMetricsDataTTL: 18 # 批量操作配置 bulkActions: 2000 # 每2000个请求执行一次bulk操作 flushsInterval: 5 # 每5s执行一次bulk操作，skywalking将会在至少一个条件满足的时候执行bulk操作 concurrentRequests: 2 resultWindowMaxSize: 10000 metadataQueryMaxSize: 5000 segmentQueryMaxSize: 200 receiver-sharing-server: default: receiver-register: default: receiver-trace: default: bufferPath: $&#123;SW_RECEIVER_BUFFER_PATH:../trace-buffer/&#125; # 单位为MB bufferOffsetMaxFileSize: $&#123;SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE: 100&#125; bufferDataMaxFileSize: $&#123;SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE: 500&#125; bufferFileCleanWhenRestart: $&#123;SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false&#125; # 实际采样率=1/10000 * sampleRate，默认为全采样 sampleRate: $&#123;SW_TRACE_SAMPLE_RATE: 10000&#125; receiver-jvm: default: receiver-clr: default: # service-mesh是6.0.0之后添加的新功能 service-mesh: default: bufferPath: $&#123;SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/&#125; bufferOffsetMaxFileSize: $&#123;SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE: 100&#125; bufferDataMaxFileSize: $&#123;SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE: 500&#125; bufferFileCleanWhenRestart: $&#123;SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART: false&#125; istio-telemetry: default: envoy-metric: default: query: graphql: path: $&#123;SW_QUERY_GRAPHQL_PATH:/graphql&#125; # 告警配置的具体配置在同级目录下的alarm-settings.xml中 alarm: default: telemetry: none: # 配置webapp服务的注册中心 configuration: none: 注：一般情况下，只需要配置cluster和storage部分，其它部分保持默认即可。 b、webapp.yml主要是配置SkyWalking Webapp的。 # 配置服务端口 server: port: 8888 # 配置collector地址以及路径 collector: # 和前面的config/application.yml中的query.path相对应 path: /graphql ribbon: ReadTimeout: 10000 # 配置collector服务集群地址，以\",\"进行分割 listOfServers: 127.0.0.1:12800 注：服务运行后，SkyWalking UI监控端口为 8888，访问地址: http://localhost:8888 c、agent.confagent需要从SkyWalking 的安装包中拷贝出来，拷贝至需要监控的服务所在的服务器中(例如：我的服务启动在宿主机上，就需要将agent目录拷贝F:\\tools\\skywalking-agent中，最好一个服务一个目录一个配置)。 # 代理的命名空间，默认为default-namespace agent.namespace=skywalking_brief # 服务名，推荐一个服务一个名称，这个将会在界面的拓补图中显示 agent.service_name=ijep-service-sys # 每三秒追踪链采样数量，负数表示尽可能的多采集，默认为-1 agent.sample_n_per_3_secs=-1 # 配置认证，需要和backend服务中的认证配置相符 # agent.authentication=$&#123;SW_AGENT_AUTHENTICATION:XXX&#125; # 配置在单个segment中出现的span的最大数量，skywalking将用这个配置来估计应用的内存开销 # agent.span_limit_per_segment=$&#123;SW_AGENT_SPAN_LIMIT:300&#125; # 配置哪些资源不会被skywalking所捕获 # agent.ignore_suffix=$&#123;SW_AGENT_IGNORE_SUFFIX:.jpg,.jpeg,.js,.css,.png,.bmp,.gif,.ico,.mp3,.mp4,.html,.svg&#125; # 操作名称最大长度 # agent.operation_name_threshold=$&#123;SW_AGENT_OPERATION_NAME_THRESHOLD:500&#125; # 配置collector的地址，多个地址之间以“,”隔开 collector.backend_service=192.168.1.180:11800 ### agent相关配置 logging.file_name=skywalking_luke.log # 日志级别，默认为DEBUG logging.level=INFO logging.dir=F:\\\\logs\\\\skywalking # 日志文件最大为300M一个 logging.max_file_size=$&#123;SW_LOGGING_MAX_FILE_SIZE:314572800&#125; # 历史日志文件的最大数量，当数量超过配置上限的时候，旧的日志文件将会被删除。负数或者0意味着该功能将关闭，默认为-1 # logging.max_history_files=$&#123;SW_LOGGING_MAX_HISTORY_FILES:-1&#125; # mysql插件配置 # 配置追踪sql参数，这样可以在sql错误的时候查看是否是参数所引起的 plugin.mysql.trace_sql_parameters=true 4、运行SkyWalking服务端# 首先打开collector的监听端口 sudo firewall-cmd --zone=public --add-port=11800/tcp --permanent # 然后打开webapp的服务端口 sudo firewall-cmd --zone=public --add-port=8888/tcp --permanent # 然后重启防火墙 sudo systemctl restart firewalld # 运行服务 sh /usr/local/skywalking/bin/startup.sh # 查看日志 tail -f /usr/local/skywalking/logs/webapp.log 5、运行SkyWalking代理端java -javaagent:F:\\\\skywalking-agent\\\\agent-sys\\\\skywalking-agent.jar -jar F:\\\\services\\\\ijep-service-sys.jar 注：-javaagent配置参数一定要在 -jar 之前。 4、访问SkyWalking● 地址：http://192.168.1.180:8888/ ● 功能：仪表盘、拓扑图、追踪、告警以及指标对比","tags":[]},{"title":"skywalking基本使用","date":"2020-10-24T03:00:00.000Z","path":"posts/3c53c85c.html","text":"目录： 1. 概述 2. 搭建 SkyWalking 单机环境 3. 搭建 SkyWalking 集群环境 4. 告警 5. 注意事项 6. Spring Boot 使用示例 6. Spring Cloud 使用示例 作者：芋道源码 原文地址 1. 概述1.1 概念SkyWalking 是什么？ FROM http://skywalking.apache.org/ 分布式系统的应用程序性能监视工具，专为微服务、云原生架构和基于容器（Docker、K8s、Mesos）架构而设计。 提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。 1.2 功能列表SkyWalking 有哪些功能？ FROM http://skywalking.apache.org/ 多种监控手段。可以通过语言探针和 service mesh 获得监控是数据。 多个语言自动探针。包括 Java，.NET Core 和 Node.JS。 轻量高效。无需大数据平台，和大量的服务器资源。 模块化。UI、存储、集群管理都有多种机制可选。 支持告警。 优秀的可视化解决方案。 1.3 整体架构SkyWalking 整体架构如何？ FROM http://skywalking.apache.org/ 整个架构，分成上、下、左、右四部分： 考虑到让描述更简单，我们舍弃掉 Metric 指标相关，而着重在 Tracing 链路相关功能。 上部分 Agent ：负责从应用中，收集链路信息，发送给 SkyWalking OAP 服务器。目前支持 SkyWalking、Zikpin、Jaeger 等提供的 Tracing 数据信息。而我们目前采用的是，SkyWalking Agent 收集 SkyWalking Tracing 数据，传递给服务器。 下部分 SkyWalking OAP ：负责接收 Agent 发送的 Tracing 数据信息，然后进行分析(Analysis Core) ，存储到外部存储器( Storage )，最终提供查询( Query )功能。 右部分 Storage ：Tracing 数据存储。目前支持 ES、MySQL、Sharding Sphere、TiDB、H2 多种存储器。而我们目前采用的是 ES ，主要考虑是 SkyWalking 开发团队自己的生产环境采用 ES 为主。 左部分 SkyWalking UI ：负责提供控台，查看链路等等。 1.4 官方文档在 https://github.com/apache/skywalking/tree/master/docs 地址下，提供了 SkyWalking 的英文文档。 考虑到大多数胖友的英语水平和艿艿不相伯仲，再加上胖友一开始对 SkyWalking 比较陌生，所以比较推荐先阅读 https://github.com/SkyAPM/document-cn-translation-of-skywalking 地址，提供了 SkyWalking 的中文文档。 考虑到胖友使用 SkyWalking 的目的，是实现分布式链路追踪的功能，所以最好去了解下相关的知识。这里推荐阅读两篇文章： 《OpenTracing 官方标准 —— 中文版》 Google 论文 《Dapper，大规模分布式系统的跟踪系统》 2. 搭建 SkyWalking 单机环境考虑到让胖友更快的入门，我们来搭建一个 SkyWalking 单机环境，步骤如下： 第一步，搭建一个 Elasticsearch 服务。 第二步，下载 SkyWalking 软件包。 第三步，搭建一个 SkyWalking OAP 服务。 第四步，启动一个 Spring Boot 应用，并配置 SkyWalking Agent。 第五步，搭建一个 SkyWalking UI 服务。 仅仅五步，按照艿艿标题党的性格，应该给本文取个《10 分钟快速搭建 SkyWalking 服务》标题才对，哈哈哈。 2.1 Elasticsearch 搭建 FROM https://www.elastic.co/cn/products/elasticsearch Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 参考《Elasticsearch 极简入门》的「1. 单机部署」小节，搭建一个 Elasticsearch 单机服务。 不过要注意，本文使用的是 Elasticsearch 7.5.1 版本。因为 SkyWalking 6.6.0 版本，增加了对 Elasticsearch 7.X 版本的支持。当然，如果胖友使用 Elasticsearch 6.X 版本也是可以的。 2.2 下载 SkyWalking 软件包对于 SkyWalking 的软件包，有两种方式获取： 手动编译 官方包 一般情况下，我们建议使用官方包。手动编译，更多是尝鲜或者等着急修复的 BUG 的版本。 2.2.1 官方包在 http://skywalking.apache.org/downloads/ 下，我们下载操作系统对应的发布版。 这里，我们选择 Binary Distribution for ElasticSearch 7 (Linux) 版本，因为艿艿是 Mac 环境，再加上想使用 Elasticsearch 7.X 版本作为存储。如果胖友想用 Elasticsearch 6.X 版本作为存储，记得下载 Binary Distribution (Linux) 版本。 ① 下载： # 创建目录 $ mkdir -p &#x2F;Users&#x2F;yunai&#x2F;skywalking $ cd &#x2F;Users&#x2F;yunai&#x2F;skywalking # 下载 $ wget http:&#x2F;&#x2F;mirror.bit.edu.cn&#x2F;apache&#x2F;skywalking&#x2F;6.6.0&#x2F;apache-skywalking-apm-es7-6.6.0.tar.gz ② 解压： # 解压 $ tar -zxvf apache-skywalking-apm-es7-6.6.0.tar.gz $ cd apache-skywalking-apm-bin-es7 $ ls -ls 4 drwxr-xr-x 8 root root 4096 Sep 9 15:09 agent # SkyWalking Agent 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 bin # 执行脚本 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 config # SkyWalking OAP Server 配置文件 32 -rwxr-xr-x 1 root root 28903 Sep 9 14:32 LICENSE 4 drwxr-xr-x 3 root root 4096 Sep 9 15:44 licenses 32 -rwxr-xr-x 1 root root 31850 Sep 9 14:32 NOTICE 16 drwxr-xr-x 2 root root 16384 Sep 9 15:22 oap-libs # SkyWalking OAP Server 4 -rw-r--r-- 1 root root 1978 Sep 9 14:32 README.txt 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 webapp # SkyWalking UI 2.2.2 手动编译 友情提示：如果胖友没有编译 SkyWalking 源码的诉求，可以跳过本小节。 参考 How to build project 文章。 需要前置安装如下： GIT JDK 8+ Maven ① 克隆代码： $ git clone https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;skywalking.git 因为网络问题，可能克隆会有点久。 ② 初始化子模块： $ cd skywalking $ git submodule init $ git submodule update ③ 编译 $ .&#x2F;mvnw clean package -DskipTests 编译过程，如果机子比较差，花费时间会比较久。 ④ 查看编译结果 $ cd apm-dist # 编译结果目录 $ cd target $ tar -zxvf apache-skywalking-apm-bin.tar.gz # 解压 Linux 包 $ cd apache-skywalking-apm-bin $ ls -ls 4 drwxr-xr-x 8 root root 4096 Sep 9 15:09 agent # SkyWalking Agent 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 bin # 执行脚本 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 config # SkyWalking OAP Server 配置文件 32 -rwxr-xr-x 1 root root 28903 Sep 9 14:32 LICENSE 4 drwxr-xr-x 3 root root 4096 Sep 9 15:44 licenses 32 -rwxr-xr-x 1 root root 31850 Sep 9 14:32 NOTICE 16 drwxr-xr-x 2 root root 16384 Sep 9 15:22 oap-libs # SkyWalking OAP Server 4 -rw-r--r-- 1 root root 1978 Sep 9 14:32 README.txt 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 webapp # SkyWalking UI 2.3 SkyWalking OAP 搭建① 修改 OAP 配置文件 友情提示：如果配置文件，适合 SkyWalking 6.X 版本。 $ vi config/application.yml storage: elasticsearch7: nameSpace: $&#123;SW_NAMESPACE:\"elasticsearch\"&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:9200&#125; protocol: $&#123;SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"&#125; # trustStorePath: $&#123;SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"&#125; # trustStorePass: $&#123;SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"&#125; user: $&#123;SW_ES_USER:\"\"&#125; password: $&#123;SW_ES_PASSWORD:\"\"&#125; indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2&#125; indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0&#125; # Those data TTL settings will override the same settings in core module. recordDataTTL: $&#123;SW_STORAGE_ES_RECORD_DATA_TTL:7&#125; # Unit is day otherMetricsDataTTL: $&#123;SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45&#125; # Unit is day monthMetricsDataTTL: $&#123;SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18&#125; # Unit is month # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:1000&#125; # Execute the bulk every 1000 requests flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; # the number of concurrent requests resultWindowMaxSize: $&#123;SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000&#125; metadataQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_MAX_SIZE:5000&#125; segmentQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200&#125; # h2: # driver: $&#123;SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource&#125; # url: $&#123;SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db&#125; # user: $&#123;SW_STORAGE_H2_USER:sa&#125; # metadataQueryMaxSize: $&#123;SW_STORAGE_H2_QUERY_MAX_SIZE:5000&#125; storage.elasticsearch7 配置项，设置使用 Elasticsearch 7.X 版本作为存储器。 - 这里，我们打开注释，并记得通过 &#96;nameSpace&#96; 设置 Elasticsearch 集群名。 - &#96;&#96;&#96; storage.elasticsearch 配置项，设置使用 Elasticsearch 6.X 版本作为存储器。 这里，我们无需做任何改动。 如果胖友使用 Elasticsearch 6.X 版本作为存储器，记得设置这个配置项，而不是 storage.elasticsearch7 配置项。 storage.h2 配置项，设置使用 H2 作为存储器。 - 这里，我们需要手动注释掉，因为 H2 是默认配置的存储器。 &gt; 友情提示：如果配置文件，适合 SkyWalking 7.X 版本。 ![配置文件](http:&#x2F;&#x2F;www.iocoder.cn&#x2F;images&#x2F;SkyWalking&#x2F;2017-01-01&#x2F;08.png) - 重点修改 &#96;storage&#96; 配置项，通过 &#96;storage.selector&#96; 配置项来设置具体使用的存储器。 - &#96;storage.elasticsearch&#96; 配置项，设置使用 Elasticsearch 6.X 版本作为存储器。胖友可以主要修改 &#96;nameSpace&#96;、&#96;clusterNodes&#96; 两个配置项即可，设置使用的 Elasticsearch 的集群和命名空间。 - &#96;storage.elasticsearch7&#96; 配置项，设置使用 Elasticsearch 7.X 版本作为存储器。 - 还有 MySQL、H2、InfluxDB 等等存储器的配置可以选择，胖友自己根据需要去选择哈~ **② 启动 SkyWalking OAP 服务** &#96;&#96;&#96;bash $ bin&#x2F;oapService.sh SkyWalking OAP started successfully! 是否真正启动成功，胖友打开 logs/skywalking-oap-server.log 日志文件，查看是否有错误日志。首次启动时，因为 SkyWalking OAP 会创建 Elasticsearch 的索引，所以会“疯狂”的打印日志。最终，我们看到如下日志，基本可以代表 SkyWalking OAP 服务启动成功： 友情提示：因为首次启动会创建 Elasticsearch 索引，所以可能会比较慢。 2020-01-02 18:22:53,635 - org.eclipse.jetty.server.Server - 444 [main] INFO [] - Started @35249ms 2.4 SkyWalking UI 搭建① 启动 SkyWalking UI 服务 bin/webappService.sh SkyWalking Web Application started successfully! 是否真正启动成功，胖友打开 logs/logs/webapp.log 日志文件，查看是否有错误日志。最终，我们看到如下日志，基本可以代表 SkyWalking UI 服务启动成功： 2020-01-02 18:27:02.824 INFO 48250 --- [main] o.a.s.apm.webapp.ApplicationStartUp : Started ApplicationStartUp in 7.774 seconds (JVM running for 8.316) 如果想要修改 SkyWalking UI 服务的参数，可以编辑 webapp/webapp.yml 配置文件。例如说： server.port ：SkyWalking UI 服务端口。 collector.ribbon.listOfServers ：SkyWalking OAP 服务地址数组。因为 SkyWalking UI 界面的数据，是通过请求 SkyWalking OAP 服务来获得的。 ② 访问 UI 界面： 浏览器打开 http://127.0.0.1:8080 。界面如下图： 2.5 SkyWalking Agent大多数情况下，我们在启动项目的 Shell 脚本上，通过 -javaagent 参数进行配置 SkyWalking Agent 。我们在 「2.3.1 Shell」 小节来看。 考虑到偶尔我们需要在 IDE 中，也希望使用 SkyWalking Agent ，所以我们在 「2.3.2 IDEA」 小节来看。 2.3.1 Shell① Agent 软件包 我们需要将 apache-skywalking-apm-bin/agent 目录，拷贝到 Java 应用所在的服务器上。这样，Java 应用才可以配置使用该 SkyWalking Agent。我们来看看 Agent 目录下有哪些： $ ls -ls total 35176 0 drwxr-xr-x@ 7 yunai staff 224 Dec 24 14:20 activations 0 drwxr-xr-x@ 4 yunai staff 128 Dec 24 14:21 bootstrap-plugins 0 drwxr-xr-x@ 3 yunai staff 96 Dec 24 14:12 config # SkyWalking Agent 配置 0 drwxr-xr-x@ 3 yunai staff 96 Jan 2 19:29 logs # SkyWalking Agent 日志 0 drwxr-xr-x@ 13 yunai staff 416 Dec 24 14:22 optional-plugins # 可选插件 0 drwxr-xr-x@ 68 yunai staff 2176 Dec 24 14:20 plugins # 插件 35176 -rw-r--r--@ 1 yunai staff 18006420 Dec 24 14:12 skywalking-agent.jar # SkyWalking Agent 关于 SkyWalking Agent 提供的插件列表，可以看看《SkyWalking 文档 —— 插件支持列表》。 因为艿艿是在本机测试，所以无需拷贝，SkyWalking Agent 目录是 /Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/。 考虑到方便胖友，艿艿这里提供了一个最简的 Spring Boot 应用 lab-39-demo-2.2.2.RELEASE.jar。对应 Github 仓库是 lab-39-demo。 ② 配置 Java 启动脚本 # SkyWalking Agent 配置 export SW_AGENT_NAME=demo-application # 配置 Agent 名字。一般来说，我们直接使用 Spring Boot 项目的 `spring.application.name` 。 export SW_AGENT_COLLECTOR_BACKEND_SERVICES=127.0.0.1:11800 # 配置 Collector 地址。 export SW_AGENT_SPAN_LIMIT=2000 # 配置链路的最大 Span 数量。一般情况下，不需要配置，默认为 300 。主要考虑，有些新上 SkyWalking Agent 的项目，代码可能比较糟糕。 export JAVA_AGENT=-javaagent:/Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar # SkyWalking Agent jar 地址。 # Jar 启动 java -jar $JAVA_AGENT -jar lab-39-demo-2.2.2.RELEASE.jar 通过环境变量，进行配置。 更多的变量，可以在 /work/programs/skywalking/apache-skywalking-apm-bin/agent/config/agent.config 查看。要注意，可能有些变量是被注释掉的，例如说 SW_AGENT_SPAN_LIMIT 对应的 agent.span_limit_per_segment 。 ③ 执行脚本： 直接执行上述的 Shell 脚本，启动 Java 项目。在启动日志中，我们可以看到 SkyWalking Agent 被加载的日志。日志示例如下： DEBUG 2020-01-02 19:29:29:400 main AgentPackagePath : The beacon class location is jar:file:/Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar!/org/apache/skywalking/apm/agent/core/boot/AgentPackagePath.class. INFO 2020-01-02 19:29:29:402 main SnifferConfigInitializer : Config file found in /Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/config/agent.config. 同时，也可以在 /Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/agent/logs/skywalking-api.log 查看对应的 SkyWalking Agent 日志。日志示例如下： DEBUG 2020-01-02 19:37:22:539 SkywalkingAgent-5-ServiceAndEndpointRegisterClient-0 ServiceAndEndpointRegisterClient : ServiceAndEndpointRegisterClient running, status:CONNECTED. 这里，我们看到 status:CONNECTED ，表示 SkyWalking Agent 连接 SkyWalking OAP 服务成功。 ④ 简单测试 完事，可以去 SkyWalking UI 查看是否链路收集成功。 1、首先，使用浏览器，访问下 http://127.0.0.1:8079/demo/echo 地址，请求下 Spring Boot 应用提供的 API。因为，我们要追踪下该链路。 2、然后，继续使用浏览器，打开 http://127.0.0.1:8080/ 地址，进入 SkyWalking UI 界面。如下图所示： 这里，我们会看到 SkyWalking 中非常重要的三个概念： 服务(Service) ：表示对请求提供相同行为的一系列或一组工作负载。在使用 Agent 或 SDK 的时候，你可以定义服务的名字。如果不定义的话，SkyWalking 将会使用你在平台（例如说 Istio）上定义的名字。 这里，我们可以看到 Spring Boot 应用的服务为 &quot;demo-application&quot;，就是我们在环境变量 SW_AGENT_NAME 中所定义的。 服务实例(Service Instance) ：上述的一组工作负载中的每一个工作负载称为一个实例。就像 Kubernetes 中的 pods 一样, 服务实例未必就是操作系统上的一个进程。但当你在使用 Agent 的时候, 一个服务实例实际就是操作系统上的一个真实进程。 这里，我们可以看到 Spring Boot 应用的服务为 &#123;agent_name&#125;-pid:&#123;pid&#125;@&#123;hostname&#125;，由 Agent 自动生成。关于它，我们在「5.1 hostname」小节中，有进一步的讲解，胖友可以瞅瞅。 端点(Endpoint) ：对于特定服务所接收的请求路径, 如 HTTP 的 URI 路径和 gRPC 服务的类名 + 方法签名。 这里，我们可以看到 Spring Boot 应用的一个端点，为 API 接口 /demo/echo。 3、之后，点击「拓扑图」菜单，进入查看拓扑图的界面。如下图所示： 4、再之后，点击「追踪」菜单，进入查看链路数据的界面。如下图所示： 2.3.2 IDEA我们统一使用 IDEA 作为开发 IDE ，所以忽略 Eclipse 的配置方式。 具体参考下图，比较简单： 3. 搭建 SkyWalking 集群环境在生产环境下，我们一般推荐搭建 SkyWalking 集群环境。😈 当然，如果公司比较抠门，也可以在生产环境下使用 SkyWalking 单机环境，毕竟 SkyWalking 挂了之后，不影响业务的正常运行。 搭建一个 SkyWalking 集群环境，步骤如下： 第一步，搭建一个 Elasticsearch 服务的集群。 第二步，搭建一个注册中心的集群。目前 SkyWalking 支持 Zookeeper、Kubernetes、Consul、Nacos 作为注册中心。 第三步，搭建一个 SkyWalking OAP 服务的集群，同时参考《SkyWalking 文档 —— 集群管理》，将 SkyWalking OAP 服务注册到注册中心上。 第四步，启动一个 Spring Boot 应用，并配置 SkyWalking Agent。另外，在设置 SkyWaling Agent 的 SW_AGENT_COLLECTOR_BACKEND_SERVICES 地址时，需要设置多个 SkyWalking OAP 服务的地址数组。 第五步，搭建一个 SkyWalking UI 服务的集群，同时使用 Nginx 进行负载均衡。另外，在设置 SkyWalking UI 的 collector.ribbon.listOfServers 地址时，也需要设置多个 SkyWalking OAP 服务的地址数组。 😈 具体的搭建过程，并不复杂，胖友自己去尝试下。 4. 告警在 SkyWaling 中，已经提供了告警功能，具体可见《SkyWalking 文档 —— 告警》。 默认情况下，SkyWalking 已经内置告警规则。同时，我们可以参考告警规则，进行自定义。 在满足 SkyWalking 告警规则的触发规则时，我们在 SkyWaling UI 的告警界面，可以看到告警内容。如下图所示： 同时，我们自定义 Webhook ，对接 SkyWalking 的告警请求。而具体的邮箱、钉钉等告警方式，需要自己进行开发。至于自定义 WebHook 如何实现，可以参考： Java 语言： 《基于 SkyWalking 的分布式跟踪系统 - 异常告警》 Go 语言： dingding-notify-for-skywalking infra-skywalking-webhook 5. 注意事项5.1 hostname 配置在 SkyWalking 中，每个被监控的实例的名字，会包含 hostname 。格式为：&#123;agent_name&#125;-pid:&#123;pid&#125;@&#123;hostname&#125; ，例如说：&quot;scrm-scheduler-pid:27629@iZbp1e2xlyvr7fh67qi59oZ&quot; 。 因为有些服务器未正确设置 hostname ，所以我们一定要去修改，不然都不知道是哪个服务器上的实例（😈 鬼知道 &quot;iZbp1e2xlyvr7fh67qi59oZ&quot; 一串是哪个服务器啊）。 修改方式如下： 1、修改 /etc/hosts 的 hostname ： 127.0.0.1 localhost ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 10.80.62.151 pre-app-01 # 就是这个，其中 10.80.62.151 是本机内网 IP ，pre-app-01 是 hostname 。 2、修改本机 hostname ： 参考 《CentOS7 修改主机名（hostname）》 $ hostname pre-app-01 # 其中 pre-app-01 就是你希望的 hostname 。 $ hostnamectl set-hostname pre-app-01 # 其中 pre-app-01 就是你希望的 hostname 。 6. Spring Boot 使用示例在 《芋道 Spring Boot 链路追踪 SkyWalking 入门》 中，我们来详细学习如何在 Spring Boot 中，整合并使用 SkyWalking 收集链路数据。😈 相比「2.5 SkyWaling Agent」来说，我们会提供更加丰富的示例哟。 7. Spring Cloud 使用示例在 《芋道 Spring Cloud 链路追踪 SkyWalking 入门》 中，我们来详细学习如何在 Spring Cloud 中，整合并使用 SkyWalking 收集链路数据。😈 相比「2.5 SkyWaling Agent」来说，我们会提供更加丰富的示例哟。 666. 彩蛋本文仅仅是简单的 SkyWalking 入门文章，如果胖友想要更好的使用 SkyWalking，推荐通读下《SkyWalking 文档》。 想要进一步深入的胖友，也可以阅读如下资料： 《SkyWalking 源码解析》 《APM 巅峰对决：Apache Skywalking P.K. Pinpoint》 《SkyWalking 官方 —— 博客合集》 😈 最后弱弱的问一句，上完 SkyWaling 之后，有没发现自己系统各种地方慢慢慢！嘻嘻。","tags":[]},{"title":"docker安装portainer","date":"2020-10-23T07:00:00.000Z","path":"posts/undefined.html","text":"$ docker volume create portainer_data $ docker run -d -p 9220:8000 -p 9221:9000 --name&#x3D;portainer --restart&#x3D;always -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock -v portainer_data:&#x2F;data portainer&#x2F;portainer-ce","tags":[]},{"title":"Docker或Podman容器内无法解析DNS问题多种解决方案","date":"2020-10-23T07:00:00.000Z","path":"posts/undefined.html","text":"Docker或Podman容器内无法解析DNS问题多种解决方案开机防火墙IP地址伪装（IP地址转发）功能如果使用的是Centos(RHEL)，并且没有关闭Firewalld防火墙，你需要留意是否开启了IP转发功能。 sudo firewall-cmd --query-masquerade返回的结果为no，则没有开启。yes则为已经开启了IP地址转发，如果问题没有解决，请继续往下看。 sudo firewall-cmd --add-masquerade --permanent &amp;&amp; sudo firewall-cmd --reload开启IP地址转发并生效。开启后请再次尝试容器内是否可以正常解析域名。 如果你想了解更多关于firewalld，请看我的另一篇博文这可能是最全的firewalld防火墙常用指令教程 开启内核IP地址转发cat /proc/sys/net/ipv4/ip_forward查看是否已经开启，0为关闭状态，1为开启状态。如果已经开启请尝试其他解决方案。 如果返回值为0，则为关闭状态。切换到root用户执行echo &quot;net.ipv4.ip_forward = 1&quot; &gt;&gt; /etc/sysctl.conf，继续执行sysctl -p /etc/sysctl.conf使之永久生效。 之后需要重新启动网络服务来使IP地址转发功能生效： 如果你是Centos(RHEL)系，需要重新启动network服务。执行systemctl restart network重启服务后生效。 如果是Debian/Ubuntu系列的发行版，执行/etc/init.d/procps restart或/etc/init.d/procps.sh restart生效。 配置一个正确的DNS正常情况下，运行的容器会与主机使用相同的resolv.conf文件来进行DNS解析，也就是说如果在本机上可以正常解析域名，那么只要开启了IP地址转发的情况下，容器中也可以正常解析。 你可以先查看你的resolv.conf文件文件配置的是否正确。 cat &#x2F;etc&#x2F;resolv.conf 如果发现DNS服务器地址有误，你可以手动编辑此文件，但是NetworkManager会在下次启动时网卡时对该文件还原为它的配置。所以，我们直接使用NetworkManager来更改我们的DNS比较妥当些。如果你的网络不是由NetworkManager管理。你可以试试看直接修改/etc/resolv.conf文件。 执行sudo nmcli connection来查看当前所有网络连接。 sudo nmcli connection modify ethernet-eth0(你的网卡连接名) ipv4.dns&#x3D;114.114.114.114 sudo nmcli connection up ethernet-eth0(你的网卡连接名)重启网卡，使手动配置的DNS生效。 强制Docker使用自定义的DNS地址vim /etc/docker/daemon.json修改该文件，如果没有该文件的话直接新建即可。 # 修改该文件内容为如下全部文本，注意花括号也包括在内。DNS服务器我使用的是114DNS，你也可以进行更换。 &#123; &quot;dns&quot;: [&quot;114.114.114.114&quot;] &#125; 希望这篇文章能解决你的问题！如果还是不行，请在评论区留言，将你的大致情况说说看，我们一起研究研究看。 https://blog.yeefire.com/2020_03/docker_DNS_resolve.html ## 不知道有没有用 [root@RicenOS ~]# nmcli connection modify docker0 connection.zone trusted [root@RicenOS ~]# systemctl stop NetworkManager.service [root@RicenOS ~]# firewall-cmd --permanent --zone=trusted --change-interface=docker0 [root@RicenOS ~]# systemctl start NetworkManager.service [root@RicenOS ~]# nmcli connection modify docker0 connection.zone trusted [root@RicenOS ~]# systemctl restart docker.service","tags":[]},{"title":"事务隔离级别","date":"2020-10-19T06:00:00.000Z","path":"posts/undefined.html","text":"事务隔离级别(图文详解)什么是事务?事务是逻辑上的一组操作，要么都执行，要么都不执行。 事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。 事务的特性(ACID) 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 并发事务带来的问题在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对统一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。 脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。 不可重复读（Unrepeatableread）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 不可重复度和幻读区别： 不可重复读的重点是修改，幻读的重点在于新增或者删除。 例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导 致A再读自己的工资时工资变为 2000；这就是不可重复读。 例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。 事务隔离级别SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻影读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。我们可以通过SELECT @@tx_isolation;命令来查看,MySQL 8.0 该命令改为SELECT @@transaction_isolation; ​sql mysql&gt; SELECT @@tx_isolation; +-----------------+ | @@tx_isolation | +-----------------+ | REPEATABLE-READ | +-----------------+ ​ 这里需要注意的是：与 SQL 标准不同的地方在于InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下，允许应用使用 Next-Key Lock 锁算法来避免幻读的产生。这与其他数据库系统(如 SQL Server)是不同的。所以说虽然 InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读），但是可以通过应用加锁读（例如 select * from table for update 语句）来保证不会产生幻读，而这个加锁度使用到的机制就是 Next-Key Lock 锁算法。从而达到了 SQL 标准的 SERIALIZABLE(可串行化) 隔离级别。 因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读取提交内容):**，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）并不会有任何性能损失。 InnoDB 存储引擎在 分布式事务 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别。 实际情况演示在下面我会使用 2 个命令行mysql ，模拟多线程（多事务）对同一份数据的脏读问题。 MySQL 命令行的默认配置中事务都是自动提交的，即执行SQL语句后就会马上执行 COMMIT 操作。如果要显式地开启一个事务需要使用命令：START TARNSACTION。 我们可以通过下面的命令来设置隔离级别。 ​sql SET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL [READ UNCOMMITTED|READ COMMITTED|REPEATABLE READ|SERIALIZABLE] ​ 我们再来看一下我们在下面实际操作中使用到的一些并发控制语句: START TARNSACTION |BEGIN：显式地开启一个事务。 COMMIT：提交事务，使得对数据库做的所有修改成为永久性。 ROLLBACK：回滚会结束用户的事务，并撤销正在进行的所有未提交的修改。 脏读(读未提交) 避免脏读(读已提交) 不可重复读还是刚才上面的读已提交的图，虽然避免了读未提交，但是却出现了，一个事务还没有结束，就发生了 不可重复读问题。 可重复读 防止幻读(可重复读) 一个事务对数据库进行操作，这种操作的范围是数据库的全部行，然后第二个事务也在对这个数据库操作，这种操作可以是插入一行记录或删除一行记录，那么第一个是事务就会觉得自己出现了幻觉，怎么还有没有处理的记录呢? 或者 怎么多处理了一行记录呢? 幻读和不可重复读有些相似之处 ，但是不可重复读的重点是修改，幻读的重点在于新增或者删除。 参考 《MySQL技术内幕：InnoDB存储引擎》 https://dev.mysql.com/doc/refman/5.7/en/ Mysql 锁：灵魂七拷问 Innodb 中的事务隔离级别和锁的关系","tags":[]},{"title":"spring cloud zipkin链路追踪","date":"2020-10-17T10:00:00.000Z","path":"posts/undefined.html","text":"下载zipkindocker run -d -p 9411:9411 openzipkin/zipkin curl -sSL https://zipkin.io/quickstart.sh | bash -s java -jar zipkin.jar 依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; 配置 spring.zipkin.base-url指定了Zipkin服务器的地址 spring.sleuth.sampler.percentage将采样比例设置为1.0，说明全部都需要。 spring: zipkin: base-url: http:&#x2F;&#x2F;localhost:9000 sleuth: sampler: percentage: 1.0","tags":[]},{"title":"Seata TCC模式","date":"2020-10-17T06:00:00.000Z","path":"posts/undefined.html","text":"事务单机的事务我们一般使用事务，其中就包括ACID特性。 A:atomic 原子性 C:Consistency 一致性 I: Isolation 隔离性 D:Durability 持久性 事务的隔离级别SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻影读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × AT模式","tags":[]},{"title":"Spring优秀工具类Resource","date":"2020-10-11T16:00:00.000Z","path":"posts/undefined.html","text":"http://www.blogjava.net/coolingverse/articles/149364.html 文件资源的操作是应用程序中常见的功能，如当上传一个文件后将其保存在特定目录下，从指定地址加载一个配置文件等等。我们一般使用 JDK 的 I/O 处理类完成这些操作，但对于一般的应用程序来说，JDK 的这些操作类所提供的方法过于底层，直接使用它们进行文件操作不但程序编写复杂而且容易产生错误。相比于 JDK 的 File，Spring 的 Resource 接口（资源概念的描述接口）抽象层面更高且涵盖面更广，Spring 提供了许多方便易用的资源操作工具类，它们大大降低资源操作的复杂度，同时具有更强的普适性。这些工具类不依赖于 Spring 容器，这意味着您可以在程序中象一般普通类一样使用它们。 加载文件资源 Spring 定义了一个 org.springframework.core.io.Resource 接口，Resource 接口是为了统一各种类型不同的资源而定义的，Spring 提供了若干 Resource 接口的实现类，这些实现类可以轻松地加载不同类型的底层资源，并提供了获取文件名、URL 地址以及资源内容的操作方法。 访问文件资源 假设有一个文件地位于 Web 应用的类路径下，您可以通过以下方式对这个文件资源进行访问： 通过 FileSystemResource 以文件系统绝对路径的方式进行访问； 通过 ClassPathResource 以类路径的方式进行访问； 通过 ServletContextResource 以相对于Web应用根目录的方式进行访问。 相比于通过 JDK 的 File 类访问文件资源的方式，Spring 的 Resource 实现类无疑提供了更加灵活的操作方式，您可以根据情况选择适合的 Resource 实现类访问资源。下面，我们分别通过 FileSystemResource 和 ClassPathResource 访问同一个文件资源： 清单 1. FileSourceExample &#96;package com.baobaotao.io; import java.io.IOException; import java.io.InputStream; import org.springframework.core.io.ClassPathResource; import org.springframework.core.io.FileSystemResource; import org.springframework.core.io.Resource; public class FileSourceExample &#123; public static void main(String[] args) &#123; try &#123; String filePath &#x3D; &quot;D:&#x2F;masterSpring&#x2F;chapter23&#x2F;webapp&#x2F;WEB-INF&#x2F;classes&#x2F;conf&#x2F;file1.txt&quot;; &#x2F;&#x2F; ① 使用系统文件路径方式加载文件 Resource res1 &#x3D; new FileSystemResource(filePath); &#x2F;&#x2F; ② 使用类路径方式加载文件 Resource res2 &#x3D; new ClassPathResource(&quot;conf&#x2F;file1.txt&quot;); InputStream ins1 &#x3D; res1.getInputStream(); InputStream ins2 &#x3D; res2.getInputStream(); System.out.println(&quot;res1:&quot;+res1.getFilename()); System.out.println(&quot;res2:&quot;+res2.getFilename()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#96; 在获取资源后，您就可以通过 Resource 接口定义的多个方法访问文件的数据和其它的信息：如您可以通过 getFileName() 获取文件名，通过 getFile() 获取资源对应的 File 对象，通过 getInputStream() 直接获取文件的输入流。此外，您还可以通过 createRelative(String relativePath) 在资源相对地址上创建新的资源。 在 Web 应用中，您还可以通过 ServletContextResource 以相对于 Web 应用根目录的方式访问文件资源，如下所示： &#96;&lt;%@ page language&#x3D;&quot;java&quot; contentType&#x3D;&quot;text&#x2F;html; charset&#x3D;utf-8&quot; pageEncoding&#x3D;&quot;utf-8&quot;%&gt; &lt;jsp:directive.page import&#x3D;&quot; org.springframework.web.context.support.ServletContextResource&quot;&#x2F;&gt; &lt;jsp:directive.page import&#x3D;&quot;org.springframework.core.io.Resource&quot;&#x2F;&gt; &lt;% &#x2F;&#x2F; ① 注意文件资源地址以相对于 Web 应用根路径的方式表示 Resource res3 &#x3D; new ServletContextResource(application, &quot;&#x2F;WEB-INF&#x2F;classes&#x2F;conf&#x2F;file1.txt&quot;); out.print(res3.getFilename()); %&gt; &#96; 对于位于远程服务器（Web 服务器或 FTP 服务器）的文件资源，您则可以方便地通过 UrlResource 进行访问。 为了方便访问不同类型的资源，您必须使用相应的 Resource 实现类，是否可以在不显式使用 Resource 实现类的情况下，仅根据带特殊前缀的资源地址直接加载文件资源呢？Spring 提供了一个 ResourceUtils 工具类，它支持”classpath:”和”file:”的地址前缀，它能够从指定的地址加载文件资源，请看下面的例子： 清单 2. ResourceUtilsExample &#96;package com.baobaotao.io; import java.io.File; import org.springframework.util.ResourceUtils; public class ResourceUtilsExample &#123; public static void main(String[] args) throws Throwable&#123; File clsFile &#x3D; ResourceUtils.getFile(&quot;classpath:conf&#x2F;file1.txt&quot;); System.out.println(clsFile.isFile()); String httpFilePath &#x3D; &quot;file:D:&#x2F;masterSpring&#x2F;chapter23&#x2F;src&#x2F;conf&#x2F;file1.txt&quot;; File httpFile &#x3D; ResourceUtils.getFile(httpFilePath); System.out.println(httpFile.isFile()); &#125; &#125; &#96; ResourceUtils 的 getFile(String resourceLocation) 方法支持带特殊前缀的资源地址，这样，我们就可以在不和 Resource 实现类打交道的情况下使用 Spring 文件资源加载的功能了。 本地化文件资源 本地化文件资源是一组通过本地化标识名进行特殊命名的文件，Spring 提供的 LocalizedResourceHelper 允许通过文件资源基名和本地化实体获取匹配的本地化文件资源并以 Resource 对象返回。假设在类路径的 i18n 目录下，拥有一组基名为 message 的本地化文件资源，我们通过以下实例演示获取对应中国大陆和美国的本地化文件资源： 清单 3. LocaleResourceTest &#96;package com.baobaotao.io; import java.util.Locale; import org.springframework.core.io.Resource; import org.springframework.core.io.support.LocalizedResourceHelper; public class LocaleResourceTest &#123; public static void main(String[] args) &#123; LocalizedResourceHelper lrHalper &#x3D; new LocalizedResourceHelper(); &#x2F;&#x2F; ① 获取对应美国的本地化文件资源 Resource msg_us &#x3D; lrHalper.findLocalizedResource(&quot;i18n&#x2F;message&quot;, &quot;.properties&quot;, Locale.US); &#x2F;&#x2F; ② 获取对应中国大陆的本地化文件资源 Resource msg_cn &#x3D; lrHalper.findLocalizedResource(&quot;i18n&#x2F;message&quot;, &quot;.properties&quot;, Locale.CHINA); System.out.println(&quot;fileName(us):&quot;+msg_us.getFilename()); System.out.println(&quot;fileName(cn):&quot;+msg_cn.getFilename()); &#125; &#125; &#96; 虽然 JDK 的 java.util.ResourceBundle 类也可以通过相似的方式获取本地化文件资源，但是其返回的是 ResourceBundle 类型的对象。如果您决定统一使用 Spring 的 Resource 接表征文件资源，那么 LocalizedResourceHelper 就是获取文件资源的非常适合的帮助类了。 文件操作 在使用各种 Resource 接口的实现类加载文件资源后，经常需要对文件资源进行读取、拷贝、转存等不同类型的操作。您可以通过 Resource 接口所提供了方法完成这些功能，不过在大多数情况下，通过 Spring 为 Resource 所配备的工具类完成文件资源的操作将更加方便。 文件内容拷贝 第一个我们要认识的是 FileCopyUtils，它提供了许多一步式的静态操作方法，能够将文件内容拷贝到一个目标 byte[]、String 甚至一个输出流或输出文件中。下面的实例展示了 FileCopyUtils 具体使用方法： 清单 4. FileCopyUtilsExample 往往我们都通过直接操作 InputStream 读取文件的内容，但是流操作的代码是比较底层的，代码的面向对象性并不强。通过 FileCopyUtils 读取和拷贝文件内容易于操作且相当直观。如在 ① 处，我们通过 FileCopyUtils 的 copyToByteArray(File in) 方法就可以直接将文件内容读到一个 byte[] 中；另一个可用的方法是 copyToByteArray(InputStream in)，它将输入流读取到一个 byte[] 中。 如果是文本文件，您可能希望将文件内容读取到 String 中，此时您可以使用 copyToString(Reader in) 方法，如 ② 所示。使用 FileReader 对 File 进行封装，或使用 InputStreamReader 对 InputStream 进行封装就可以了。 FileCopyUtils 还提供了多个将文件内容拷贝到各种目标对象中的方法，这些方法包括： 方法 说明 static void copy(byte[] in, File out) 将 byte[] 拷贝到一个文件中 static void copy(byte[] in, OutputStream out) 将 byte[] 拷贝到一个输出流中 static int copy(File in, File out) 将文件拷贝到另一个文件中 static int copy(InputStream in, OutputStream out) 将输入流拷贝到输出流中 static int copy(Reader in, Writer out) 将 Reader 读取的内容拷贝到 Writer 指向目标输出中 static void copy(String in, Writer out) 将字符串拷贝到一个 Writer 指向的目标中 在实例中，我们虽然使用 Resource 加载文件资源，但 FileCopyUtils 本身和 Resource 没有任何关系，您完全可以在基于 JDK I/O API 的程序中使用这个工具类。 属性文件操作 我们知道可以通过 java.util.Properties的load(InputStream inStream) 方法从一个输入流中加载属性资源。Spring 提供的 PropertiesLoaderUtils 允许您直接通过基于类路径的文件地址加载属性资源，请看下面的例子： &#96;package com.baobaotao.io; import java.util.Properties; import org.springframework.core.io.support.PropertiesLoaderUtils; public class PropertiesLoaderUtilsExample &#123; public static void main(String[] args) throws Throwable &#123; &#x2F;&#x2F; ① jdbc.properties 是位于类路径下的文件 Properties props &#x3D; PropertiesLoaderUtils.loadAllProperties(&quot;jdbc.properties&quot;); System.out.println(props.getProperty(&quot;jdbc.driverClassName&quot;)); &#125; &#125; &#96; 一般情况下，应用程序的属性文件都放置在类路径下，所以 PropertiesLoaderUtils 比之于 Properties#load(InputStream inStream) 方法显然具有更强的实用性。此外，PropertiesLoaderUtils 还可以直接从 Resource 对象中加载属性资源： 方法 说明 static Properties loadProperties(Resource resource) 从 Resource 中加载属性 static void fillProperties(Properties props, Resource resource) 将 Resource 中的属性数据添加到一个已经存在的 Properties 对象中 特殊编码的资源 当您使用 Resource 实现类加载文件资源时，它默认采用操作系统的编码格式。如果文件资源采用了特殊的编码格式（如 UTF-8），则在读取资源内容时必须事先通过 EncodedResource 指定编码格式，否则将会产生中文乱码的问题。 清单 5. EncodedResourceExample &#96;package com.baobaotao.io; import org.springframework.core.io.ClassPathResource; import org.springframework.core.io.Resource; import org.springframework.core.io.support.EncodedResource; import org.springframework.util.FileCopyUtils; public class EncodedResourceExample &#123; public static void main(String[] args) throws Throwable &#123; Resource res &#x3D; new ClassPathResource(&quot;conf&#x2F;file1.txt&quot;); &#x2F;&#x2F; ① 指定文件资源对应的编码格式（UTF-8） EncodedResource encRes &#x3D; new EncodedResource(res,&quot;UTF-8&quot;); &#x2F;&#x2F; ② 这样才能正确读取文件的内容，而不会出现乱码 String content &#x3D; FileCopyUtils.copyToString(encRes.getReader()); System.out.println(content); &#125; &#125; &#96; EncodedResource 拥有一个 getResource() 方法获取 Resource，但该方法返回的是通过构造函数传入的原 Resource 对象，所以必须通过 EncodedResource#getReader() 获取应用编码后的 Reader 对象，然后再通过该 Reader 读取文件的内容。","tags":[]},{"title":"springboot启动执行sql文件","date":"2020-10-10T16:00:00.000Z","path":"posts/undefined.html","text":"import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.Resource; import org.springframework.jdbc.datasource.init.DataSourceInitializer; import org.springframework.jdbc.datasource.init.DatabasePopulator; import org.springframework.jdbc.datasource.init.ResourceDatabasePopulator; import javax.sql.DataSource; /** * 自定义初始化数据源 */ @Configuration public class CustomizeDataSourceInitializer &#123; @Value(\"classpath:sql/mail_comment.sql\") private Resource functionScriptFarms; @Bean public DataSourceInitializer dataSourceInitializer(final DataSource dataSource) &#123; final DataSourceInitializer initializer = new DataSourceInitializer(); // 设置数据源 initializer.setDataSource(dataSource); initializer.setDatabasePopulator(databasePopulator()); return initializer; &#125; private DatabasePopulator databasePopulator() &#123; final ResourceDatabasePopulator populator = new ResourceDatabasePopulator(); populator.addScripts(functionScriptFarms); return populator; &#125; &#125;","tags":[]},{"title":"maven修改默认的jdk版本","date":"2020-10-09T17:00:00.000Z","path":"posts/undefined.html","text":"当系统中装有多个 JDK 版本时，如果控制 Maven 能够指定到正确的版本 出现的问题 在使用 mvn clean package -Dmaven.test.skip=true 对项目进行打包时 发现进度一直卡在编译无法继续执行 待编译项目 pom.xml 中指定的 JDK 版本是 1.8 通过 mvn -version 发现 Maven 获取的 JDK 版本是 11 这就是导致 Maven 无法顺利编译项目的根本原因 查看当前 Maven 版本 下图中可以看到，Maven 当前指定的是 JDK 11 查看当前 JDK 版本 下图中可以看到，当前 JDK 版本是 1.8 ，很明显和上图 Maven 获取到的版本不一致 查看当前系统配置的所有 JDK 版本 下图中可以看到，当前系统配置了三个版本的 JDK ，而系统默认的是 JDK 11 ，与 Maven 获取到的一致 查看通过 JENV 管理的 JDK 版本 下图中可以看到，通过 JENV 切换到的 JDK 版本是 1.8 ，与 java -version 获取到的一致 这就说明 JENV 虽然可以管理当前 JDK 版本，但是无法切换当前系统的默认 JDK 终极解决方案 在终端输入以下脚本，强制指定 JAVA_HOME 的默认版本是 1.8 这样虽然无法改变当前系统的默认 JDK 版本 但是可以控制其他软件获取到的 JDK 版本，这就已经满足需求了 echo export &quot;JAVA_HOME&#x3D;\\$(&#x2F;usr&#x2F;libexec&#x2F;java_home -v 1.8)&quot; &gt;&gt; ~&#x2F;.bash_profile source ~&#x2F;.bash_profile 再次查看当前 Maven 版本 下图中可以看到，Maven 当前指定的 JDK 已经替换成了 1.8 再次查看当前系统配置的所有 JDK 版本 下图中可以看到，当前系统默认的 JDK 版本依旧是 11","tags":[]},{"title":"nexus 使用","date":"2020-10-09T07:00:00.000Z","path":"posts/undefined.html","text":"使用账号密码&lt;!-- 在servers标签下配置server, 包括: 私服的用户名和密码, 在deploy项目时需要用到 --> &lt;server> &lt;id>releases&lt;/id> &lt;username>admin&lt;/username> &lt;password>admin123&lt;/password> &lt;/server> &lt;server> &lt;id>snapshots&lt;/id> &lt;username>admin&lt;/username> &lt;password>admin123&lt;/password> &lt;/server> 使用&lt;repository> &lt;id>StongPublic&lt;/id> &lt;name>StongCentral&lt;/name> &lt;url>http://xxxx/repository/maven-public/&lt;/url> &lt;releases> &lt;enabled>true&lt;/enabled> &lt;/releases> &lt;snapshots> &lt;enabled>true&lt;/enabled> &lt;/snapshots> &lt;/repository> 发布1.查看当前正在使用的settings.xmlmvn help:effective-settings 在pom文件中加入如下配置： &lt;!--使用分发上传将项目打成jar包，上传到nexus私服上--> &lt;distributionManagement> &lt;!--发布版本仓库--> &lt;repository> &lt;!--nexus服务器中用户名：在settings.xml中和&lt;server>的id一致--> &lt;id>releases&lt;/id> &lt;!--自定义名称--> &lt;name>RELEASES PUBLISH&lt;/name> &lt;!--仓库地址--> &lt;url>http://xx.xx.xx.xx:xxxx/repository/maven-releases/&lt;/url> &lt;/repository> &lt;!--快照版本仓库--> &lt;snapshotRepository> &lt;!--nexus服务器中用户名：在settings.xml中和&lt;server>的id一致--> &lt;id>snapshots&lt;/id> &lt;!--自定义名称--> &lt;name>SNAPSHOTS PUBLISH&lt;/name> &lt;!--仓库地址--> &lt;url>http://xx.xx.xx.xx:xxxx/repository/maven-snapshots/&lt;/url> &lt;/snapshotRepository> &lt;/distributionManagement> 2.在settings.xml文件中加入如下配置： &lt;servers> &lt;server> &lt;id>releases&lt;/id> &lt;username>admin&lt;/username> &lt;password>####@123&lt;/password> &lt;/server> &lt;server> &lt;id>snapshots&lt;/id> &lt;username>admin&lt;/username> &lt;password>####@123&lt;/password> &lt;/server> &lt;/servers> 123456789101112 3.发生如下错误可能是配置的账号信息有误的原因：[ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy (default-deploy) on project demo-childA: Failed to deploy artifacts: Could not transfer artifact com.ecp:demo-childA:jar:1.0-20190625.082808- 1 from&#x2F;to maven-snapshots (http:&#x2F;&#x2F;xx.xxx.xx.xx:xxxx&#x2F;repository&#x2F;maven-snapshots&#x2F;): Failed to transfer file http:&#x2F;&#x2F;xx.xxx.xx.xx:xxxx&#x2F;repository&#x2F;maven-snapshots&#x2F;com&#x2F;ecp&#x2F;demo-childA&#x2F;1.0-SNAPSHOT&#x2F;demo-childA-1.0-20190625.082808-1 .jar with status code 401 -&gt; [Help 1] 123 可以使用：mvn help:effective-settings命令查看settings.xml配置文件查看配置信息 4.将本地项目发布到Nexus私服：mvn clean deploy ## 跳过javadoc mvn deploy -Dmaven.javadoc.skip=true","tags":[]},{"title":"nexus仓库分类","date":"2020-10-09T07:00:00.000Z","path":"posts/undefined.html","text":"Nexus仓库分类Nexus包含了各种类型的仓库类型。在登录后的Nexus界面，单击左边的“Repositories”链接 四种仓库类型： 1）group（仓库组） 2）hosted（宿主） 3）proxy（代理） 4）virtual（虚拟） 说明： 1）每种类型的Format有Maven1或者Maven2，maven1是老版本，现在一般使用maven2。 2）仓库的Policy（策略）表示该仓库为发布（Release）版本还是快照（Snapshot）版本仓库。 3）虚拟仓库其实也是为maven1服务的，所以意义不大。 4）宿主仓库指的就是我们自己项目所构建组成的仓库。 5）代理仓库指的是远程仓库，比如中央仓库等，因为私服需要完全替代中央仓库，那么他必须拥有中央仓库的功能，所以nexus的仓库会有各种代理仓库 6）仓库组，他是整合以上所有的仓库于一体，那么他就是我们项目私服的地址，因为他把所有仓库都容纳为一个个体，所以我们下载资源时，他都能在对应的仓库中找到。 http://localhost:8081/nexus/content/groups/public/ Nexus列出了默认的几个仓库： 1）Public Repositories：仓库组，将所有策略为Release的仓库聚合并通过一致的地址提供服务。 2）3rd party：一个策略为Release的宿主类型仓库，用来部署无法从公共仓库获得的第三方发布版本构件。 3）Apache Snapshots：策略为Snapshots的代理仓库，用来代理Apache Maven仓库的快照版本构件。 4）Central：该仓库代理Maven的中央仓库，策略为Release，只会下载和缓存中央仓库中的发布版本构件。 5）Central M1 shadow：maven1格式的虚拟类型仓库。 6）Codehaus Snapshots：代理Codehaus Maven仓库快照版本的代理仓库。 7）Release：策略为Release的宿主类型仓库，用来部署组织内部的发布版本构件。 8）Snapshots：策略为Snapshots的宿主类型仓库，用来部署组织内部的快照版本构件。 仓库之间的关系 2、Nexus的索引与构件搜索点击列表上的“Central”行，在下方的“Configuration”中我们可以看到，在“Ordered Group Repositories”中包含了Release、Snapshots、3rd party、Central等仓库。为了构建Nexus的Maven中央库索引，首先需要设置Nexus中Maven Cencal代理仓库下载远程索引，将“Download Remote Indexes”的值从默认值false改为true。然而，由于其他索引库，因为他们要么依赖中央库，要么是本地库，所以，只需要右键update index即可。 点击“Save”后，点击update now 更新索引，Nexus后台在下载Maven中央仓库的索引。 保存过后点击Browser Remote 然后看看远程索引库是否更新下来了 如果没有出现远程索引信息，那么要在“Public Repositories”行右击，点击“Update Index”","tags":[]},{"title":"手动创建FeignCliet","date":"2020-09-29T16:00:00.000Z","path":"posts/undefined.html","text":"前言在Feign-请求不同注册中心的服务中，提到，如果需要请求不同注册中心的服务，可以设置@FeignClient的url属性。 这种做法有个缺点，需要服务消费者，配置各个环境的url。 如果服务提供方url变更，需要通知到服务消费者，如果消费者很多，变更通知也是件麻烦事。 基于java的封装特性，作为独立的服务提供者，如果能封装url，岂不是更好？ 解决方案服务提供者//@FeignClient(name = \"feign-provider\") public interface CustomizeFeignApi &#123; @RequestMapping(value = \"/customize\", method = RequestMethod.GET) String queryCustomize(); &#125; @FeignClient，不需要。加上的话，会自动创建对应bean，达不到手动创建的目的。 自定义配置 @Configuration @Import(FeignClientsConfiguration.class) public class FeignClientConfig &#123; @Bean public CustomizeFeignApi customizeFeignApi(Contract contract, Decoder decoder, Encoder encoder) &#123; return Feign.builder().contract(contract).encoder(encoder).decoder(decoder).target(CustomizeFeignApi.class, \"http://localhost:8004\"); &#125; &#125; @Configuration：需要被消费者应用扫描到。 @Import(FeignClientsConfiguration.class)：如果消费者上下文不存在Contract, Decoder, Encoder，由FeignClientsConfiguration提供默认bean。 以上，可封装为jar，上传到公司nexus私服，有消费者下载使用。 服务消费者依赖上文的jar。 &lt;!--服务提供者--> &lt;dependency> &lt;groupId>com.wxs.springcloud&lt;/groupId> &lt;artifactId>springcloud-sample-feign-provider-spi&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;/dependency> 注入使用。 @RestController public class CustomizeFeignTestController &#123; @Autowired private CustomizeFeignApi customizeFeignApi; @GetMapping(\"/customize\") public String query() &#123; return customizeFeignApi.queryCustomize(); &#125; &#125; 启动类，添加扫描。 @ComponentScan(&quot;com.wxs.feign.provider.api&quot;) 验证 遇到的问题Method not annotated with HTTP method type (ex. GET, POST) Caused by: java.lang.IllegalStateException: Method queryCustomize not annotated with HTTP method type (ex. GET, POST) at feign.Util.checkState(Util.java:128) ~[feign-core-9.5.0.jar:na] at feign.Contract$BaseContract.parseAndValidateMetadata(Contract.java:97) ~[feign-core-9.5.0.jar:na] at feign.Contract$BaseContract.parseAndValidatateMetadata(Contract.java:64) ~[feign-core-9.5.0.jar:na] at feign.ReflectiveFeign$ParseHandlersByName.apply(ReflectiveFeign.java:146) ~[feign-core-9.5.0.jar:na] at feign.ReflectiveFeign.newInstance(ReflectiveFeign.java:53) ~[feign-core-9.5.0.jar:na] at feign.Feign$Builder.target(Feign.java:218) ~[feign-core-9.5.0.jar:na] at feign.Feign$Builder.target(Feign.java:214) ~[feign-core-9.5.0.jar:na] at com.wxs.feign.consumer.config.FeignClientConfig.customizeFeignApi(FeignClientConfig.java:38) ~[classes&#x2F;:na] feign.Feign.Builder默认提供的是：new Contract.Default()。 需要指定Contract为SpringMvcContract。 Feign.builder().contract(new SpringMvcContract()).target(CustomizeFeignApi.class, &quot;http:&#x2F;&#x2F;localhost:8004&quot;) 参考Creating Feign Clients Manually Feign: Method not annotated with HTTP method type (ex. GET, POST)","tags":[]},{"title":"centos修改成阿里云仓库","date":"2020-09-28T08:00:00.000Z","path":"posts/undefined.html","text":"DNF/YUM源配置文件替换为阿里家的由于系统安装的包管理配置文件链接的国外的服务器，导致我们安装软件、升级内核和升级软件的时候会从国外的服务器下载相关文件。由于众所周知的原因，国外服务器的网速真的不敢恭维，所以我们要把他们替换为国内的服务器，这样安装和升级软件的速度就会提高，降低维护人员在等待上所花费的时间。因为阿里源文件里面已经包含了AppStream、Base、centosplus、Extras和PowerTools的相关内容，所以需要把这些文件改名为bak，不让系统执行。 cd /etc/yum.repos.d/ mv /etc/yum.repos.d/CentOS-AppStream.repo /etc/yum.repos.d/CentOS-AppStream.repo.bak mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak mv /etc/yum.repos.d/CentOS-centosplus.repo /etc/yum.repos.d/CentOS-centosplus.repo.bak mv /etc/yum.repos.d/CentOS-Extras.repo /etc/yum.repos.d/CentOS-Extras.repo.bak mv /etc/yum.repos.d/CentOS-PowerTools.repo /etc/yum.repos.d/CentOS-PowerTools.repo.bak 做完以上修改以后，就可以下载新的阿里源文件了，因为默认没有装wget，我们可以用curl来执行以下命令： curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo 如果有wget也可以执行以下命令 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo 如果没有安装wget，运行这个命令会提示“bash: wget: 未找到命令”，那就用curl的那个命令来执行好了。或者你也可以先安装wget，很简单，只需要下面一个命令即可（前提是在将上面的文件改为“.bak”之前，如果已经改了，先改回去再执行下述命令） yum -y install wget","tags":[]},{"title":"centos安装jenkins","date":"2020-09-28T08:00:00.000Z","path":"posts/undefined.html","text":"下载sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key yum install jenkins 2.配置vim /etc/sysconfig/jenkins #监听端口 JENKINS_PORT=\"8080\" 3.配置权限为了不因为权限出现各种问题，这里直接使用root 修改用户为root vim /etc/sysconfig/jenkins #修改配置 $JENKINS_USER=\"root\" 修改目录权限 chown -R root:root /var/lib/jenkins chown -R root:root /var/cache/jenkins chown -R root:root /var/log/jenkins 重启 service jenkins restart ps -ef | grep jenkins 4.启动systemctl start jenkins 我这里启动失败了： 错误信息为Starting Jenkins bash: /usr/bin/java: No such file or directory是java环境配置的问题。 找到你的jdk目录，我是在 usr/local/java/jdk1.8.0_171/下，创建软链接即可： ln -s /usr/local/java/jdk1.8.0_171/bin/java /usr/bin/java 然后重新启动 5.安装访问jenkins地址 http:&lt;ip或者域名&gt;:8080 执行命令查看密码： cat /var/lib/jenkins/secrets/initialAdminPassword 插件安装选择推荐插件 安装进行中 插件安装完成以后将会创建管理员账户 安装完成： 运行截图：","tags":[]},{"title":"centos安装nexus","date":"2020-09-25T03:00:00.000Z","path":"posts/24033b1e.html","text":"下载cd /opt sudo curl -O https://sonatype-download.global.ssl.fastly.net/nexus/3/nexus-3.3.1-01-unix.tar.gz sudo tar -xzvf nexus-3.3.1-01-unix.tar.gz sudo ln -s nexus-3.3.1-01 nexus 配置sudo useradd nexus sudo chown -R nexus:nexus /opt/nexus sudo chown -R nexus:nexus /opt/sonatype-work/ 修改运行用户 sudo vi /opt/nexus/bin/nexus.rc run_as_user=\"nexus\" 开机启动sudo ln -s /usr/local/nexus-3.13.0-01/bin/nexus /etc/init.d/nexus #查看nexus服务状态、启动服务、停止服务等 service nexus status/start/stop #设置为开机自启动/关闭等 chkconfig nexus on/off","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos安装mongdb","date":"2020-09-22T07:00:00.000Z","path":"posts/undefined.html","text":"","tags":[]},{"title":"java动态代理","date":"2020-09-20T04:00:00.000Z","path":"posts/undefined.html","text":"Java 动态代理详解](https://www.cnblogs.com/whirly/p/10154887.html)动态代理在Java中有着广泛的应用，比如Spring AOP、Hibernate数据查询、测试框架的后端mock、RPC远程调用、Java注解对象获取、日志、用户鉴权、全局性异常处理、性能监控，甚至事务处理等。 本文主要介绍Java中两种常见的动态代理方式：JDK原生动态代理和CGLIB动态代理。 由于Java动态代理与java反射机制关系紧密，请读者确保已经了解了Java反射机制，可参考上一篇文章《Java反射机制详解》 代理模式本文将介绍的Java动态代理与设计模式中的代理模式有关，什么是代理模式呢？ 代理模式：给某一个对象提供一个代理，并由代理对象来控制对真实对象的访问。代理模式是一种结构型设计模式。 代理模式角色分为 3 种： Subject（抽象主题角色）：定义代理类和真实主题的公共对外方法，也是代理类代理真实主题的方法； RealSubject（真实主题角色）：真正实现业务逻辑的类； Proxy（代理主题角色）：用来代理和封装真实主题； 代理模式的结构比较简单，其核心是代理类，为了让客户端能够一致性地对待真实对象和代理对象，在代理模式中引入了抽象层 代理模式按照职责（使用场景）来分类，至少可以分为以下几类：1、远程代理。 2、虚拟代理。 3、Copy-on-Write 代理。 4、保护（Protect or Access）代理。 5、Cache代理。 6、防火墙（Firewall）代理。 7、同步化（Synchronization）代理。 8、智能引用（Smart Reference）代理等等。 如果根据字节码的创建时机来分类，可以分为静态代理和动态代理： 所谓静态也就是在程序运行前就已经存在代理类的字节码文件，代理类和真实主题角色的关系在运行前就确定了。 而动态代理的源码是在程序运行期间由JVM根据反射等机制动态的生成，所以在运行前并不存在代理类的字节码文件 静态代理我们先通过实例来学习静态代理，然后理解静态代理的缺点，再来学习本文的主角：动态代理 编写一个接口 UserService ，以及该接口的一个实现类 UserServiceImpl public interface UserService &#123; public void select(); public void update(); &#125; public class UserServiceImpl implements UserService &#123; public void select() &#123; System.out.println(\"查询 selectById\"); &#125; public void update() &#123; System.out.println(\"更新 update\"); &#125; &#125; 我们将通过静态代理对 UserServiceImpl 进行功能增强，在调用 select 和 update 之前记录一些日志。写一个代理类 UserServiceProxy，代理类需要实现 UserService public class UserServiceProxy implements UserService &#123; private UserService target; // 被代理的对象 public UserServiceProxy(UserService target) &#123; this.target = target; &#125; public void select() &#123; before(); target.select(); // 这里才实际调用真实主题角色的方法 after(); &#125; public void update() &#123; before(); target.update(); // 这里才实际调用真实主题角色的方法 after(); &#125; private void before() &#123; // 在执行方法之前执行 System.out.println(String.format(\"log start time [%s] \", new Date())); &#125; private void after() &#123; // 在执行方法之后执行 System.out.println(String.format(\"log end time [%s] \", new Date())); &#125; &#125; 客户端测试 public class Client1 &#123; public static void main(String[] args) &#123; UserService userServiceImpl = new UserServiceImpl(); UserService proxy = new UserServiceProxy(userServiceImpl); proxy.select(); proxy.update(); &#125; &#125; 输出 log start time [Thu Dec 20 14:13:25 CST 2018] 查询 selectById log end time [Thu Dec 20 14:13:25 CST 2018] log start time [Thu Dec 20 14:13:25 CST 2018] 更新 update log end time [Thu Dec 20 14:13:25 CST 2018] 通过静态代理，我们达到了功能增强的目的，而且没有侵入原代码，这是静态代理的一个优点。 静态代理的缺点虽然静态代理实现简单，且不侵入原代码，但是，当场景稍微复杂一些的时候，静态代理的缺点也会暴露出来。 1、 当需要代理多个类的时候，由于代理对象要实现与目标对象一致的接口，有两种方式： 只维护一个代理类，由这个代理类实现多个接口，但是这样就导致代理类过于庞大 新建多个代理类，每个目标对象对应一个代理类，但是这样会产生过多的代理类 2、 当接口需要增加、删除、修改方法的时候，目标对象与代理类都要同时修改，不易维护。 如何改进？当然是让代理类动态的生成啦，也就是动态代理。 为什么类可以动态的生成？ 这就涉及到Java虚拟机的类加载机制了，推荐翻看《深入理解Java虚拟机》7.3节 类加载的过程。 Java虚拟机类加载过程主要分为五个阶段：加载、验证、准备、解析、初始化。其中加载阶段需要完成以下3件事情： 通过一个类的全限定名来获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据访问入口 由于虚拟机规范对这3点要求并不具体，所以实际的实现是非常灵活的，关于第1点，获取类的二进制字节流（class字节码）就有很多途径： 从ZIP包获取，这是JAR、EAR、WAR等格式的基础 从网络中获取，典型的应用是 Applet 运行时计算生成，这种场景使用最多的是动态代理技术，在 java.lang.reflect.Proxy 类中，就是用了 ProxyGenerator.generateProxyClass 来为特定接口生成形式为 *$Proxy 的代理类的二进制字节流 由其它文件生成，典型应用是JSP，即由JSP文件生成对应的Class类 从数据库中获取等等 所以，动态代理就是想办法，根据接口或目标对象，计算出代理类的字节码，然后再加载到JVM中使用。但是如何计算？如何生成？情况也许比想象的复杂得多，我们需要借助现有的方案。 常见的字节码操作类库 这里有一些介绍：https://java-source.net/open-source/bytecode-libraries Apache BCEL (Byte Code Engineering Library)：是Java classworking广泛使用的一种框架，它可以深入到JVM汇编语言进行类操作的细节。 ObjectWeb ASM：是一个Java字节码操作框架。它可以用于直接以二进制形式动态生成stub根类或其他代理类，或者在加载时动态修改类。 CGLIB(Code Generation Library)：是一个功能强大，高性能和高质量的代码生成库，用于扩展JAVA类并在运行时实现接口。 Javassist：是Java的加载时反射系统，它是一个用于在Java中编辑字节码的类库; 它使Java程序能够在运行时定义新类，并在JVM加载之前修改类文件。 … 实现动态代理的思考方向为了让生成的代理类与目标对象（真实主题角色）保持一致性，从现在开始将介绍以下两种最常见的方式： 通过实现接口的方式 -&gt; JDK动态代理 通过继承类的方式 -&gt; CGLIB动态代理 注：使用ASM对使用者要求比较高，使用Javassist会比较麻烦 JDK动态代理JDK动态代理主要涉及两个类：java.lang.reflect.Proxy 和 java.lang.reflect.InvocationHandler，我们仍然通过案例来学习 编写一个调用逻辑处理器 LogHandler 类，提供日志增强功能，并实现 InvocationHandler 接口；在 LogHandler 中维护一个目标对象，这个对象是被代理的对象（真实主题角色）；在 invoke 方法中编写方法调用的逻辑处理 import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.util.Date; public class LogHandler implements InvocationHandler &#123; Object target; // 被代理的对象，实际的方法执行者 public LogHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; before(); Object result = method.invoke(target, args); // 调用 target 的 method 方法 after(); return result; // 返回方法的执行结果 &#125; // 调用invoke方法之前执行 private void before() &#123; System.out.println(String.format(\"log start time [%s] \", new Date())); &#125; // 调用invoke方法之后执行 private void after() &#123; System.out.println(String.format(\"log end time [%s] \", new Date())); &#125; &#125; 编写客户端，获取动态生成的代理类的对象须借助 Proxy 类的 newProxyInstance 方法，具体步骤可见代码和注释 import proxy.UserService; import proxy.UserServiceImpl; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Proxy; public class Client2 &#123; public static void main(String[] args) throws IllegalAccessException, InstantiationException &#123; // 设置变量可以保存动态代理类，默认名称以 $Proxy0 格式命名 // System.getProperties().setProperty(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); // 1. 创建被代理的对象，UserService接口的实现类 UserServiceImpl userServiceImpl = new UserServiceImpl(); // 2. 获取对应的 ClassLoader ClassLoader classLoader = userServiceImpl.getClass().getClassLoader(); // 3. 获取所有接口的Class，这里的UserServiceImpl只实现了一个接口UserService， Class[] interfaces = userServiceImpl.getClass().getInterfaces(); // 4. 创建一个将传给代理类的调用请求处理器，处理所有的代理对象上的方法调用 // 这里创建的是一个自定义的日志处理器，须传入实际的执行对象 userServiceImpl InvocationHandler logHandler = new LogHandler(userServiceImpl); /* 5.根据上面提供的信息，创建代理对象 在这个过程中， a.JDK会通过根据传入的参数信息动态地在内存中创建和.class 文件等同的字节码 b.然后根据相应的字节码转换成对应的class， c.然后调用newInstance()创建代理实例 */ UserService proxy = (UserService) Proxy.newProxyInstance(classLoader, interfaces, logHandler); // 调用代理的方法 proxy.select(); proxy.update(); // 保存JDK动态代理生成的代理类，类名保存为 UserServiceProxy // ProxyUtils.generateClassFile(userServiceImpl.getClass(), \"UserServiceProxy\"); &#125; &#125; 运行结果 log start time [Thu Dec 20 16:55:19 CST 2018] 查询 selectById log end time [Thu Dec 20 16:55:19 CST 2018] log start time [Thu Dec 20 16:55:19 CST 2018] 更新 update log end time [Thu Dec 20 16:55:19 CST 2018] InvocationHandler 和 Proxy 的主要方法介绍如下： java.lang.reflect.InvocationHandler Object invoke(Object proxy, Method method, Object[] args) 定义了代理对象调用方法时希望执行的动作，用于集中处理在动态代理类对象上的方法调用 java.lang.reflect.Proxy static InvocationHandler getInvocationHandler(Object proxy) 用于获取指定代理对象所关联的调用处理器 static Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;... interfaces) 返回指定接口的代理类 static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) 构造实现指定接口的代理类的一个新实例，所有方法会调用给定处理器对象的 invoke 方法 static boolean isProxyClass(Class&lt;?&gt; cl) 返回 cl 是否为一个代理类 代理类的调用过程生成的代理类到底长什么样子呢？借助下面的工具类，把代理类保存下来再探个究竟（通过设置环境变量sun.misc.ProxyGenerator.saveGeneratedFiles=true也可以保存代理类） import sun.misc.ProxyGenerator; import java.io.FileOutputStream; import java.io.IOException; public class ProxyUtils &#123; /** * 将根据类信息动态生成的二进制字节码保存到硬盘中，默认的是clazz目录下 * params: clazz 需要生成动态代理类的类 * proxyName: 为动态生成的代理类的名称 */ public static void generateClassFile(Class clazz, String proxyName) &#123; // 根据类信息和提供的代理类名称，生成字节码 byte[] classFile = ProxyGenerator.generateProxyClass(proxyName, clazz.getInterfaces()); String paths = clazz.getResource(\".\").getPath(); System.out.println(paths); FileOutputStream out = null; try &#123; //保留到硬盘中 out = new FileOutputStream(paths + proxyName + \".class\"); out.write(classFile); out.flush(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 然后在 Client2 测试类的main的最后面加入一行代码 // 保存JDK动态代理生成的代理类，类名保存为 UserServiceProxy ProxyUtils.generateClassFile(userServiceImpl.getClass(), \"UserServiceProxy\"); IDEA 再次运行之后就可以在 target 的类路径下找到 UserServiceProxy.class，双击后IDEA的反编译插件会将该二进制class文件 UserServiceProxy 的代码如下所示： import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; import proxy.UserService; public final class UserServiceProxy extends Proxy implements UserService &#123; private static Method m1; private static Method m2; private static Method m4; private static Method m0; private static Method m3; public UserServiceProxy(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; // 省略... &#125; public final String toString() throws &#123; // 省略... &#125; public final void select() throws &#123; try &#123; super.h.invoke(this, m4, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int hashCode() throws &#123; // 省略... &#125; public final void update() throws &#123; try &#123; super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m4 = Class.forName(\"proxy.UserService\").getMethod(\"select\"); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); m3 = Class.forName(\"proxy.UserService\").getMethod(\"update\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125; &#125; 从 UserServiceProxy 的代码中我们可以发现： UserServiceProxy 继承了 Proxy 类，并且实现了被代理的所有接口，以及equals、hashCode、toString等方法 由于 UserServiceProxy 继承了 Proxy 类，所以每个代理类都会关联一个 InvocationHandler 方法调用处理器 类和所有方法都被 public final 修饰，所以代理类只可被使用，不可以再被继承 每个方法都有一个 Method 对象来描述，Method 对象在static静态代码块中创建，以 m + 数字 的格式命名 调用方法的时候通过 super.h.invoke(this, m1, (Object[])null); 调用，其中的 super.h.invoke 实际上是在创建代理的时候传递给 Proxy.newProxyInstance 的 LogHandler 对象，它继承 InvocationHandler 类，负责实际的调用处理逻辑 而 LogHandler 的 invoke 方法接收到 method、args 等参数后，进行一些处理，然后通过反射让被代理的对象 target 执行方法 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; before(); Object result = method.invoke(target, args); // 调用 target 的 method 方法 after(); return result; // 返回方法的执行结果 &#125; JDK动态代理执行方法调用的过程简图如下： 代理类的调用过程相信大家都明了了，而关于Proxy的源码解析，还请大家另外查阅其他文章或者直接看源码 CGLIB动态代理maven引入CGLIB包，然后编写一个UserDao类，它没有接口，只有两个方法，select() 和 update() public class UserDao &#123; public void select() &#123; System.out.println(\"UserDao 查询 selectById\"); &#125; public void update() &#123; System.out.println(\"UserDao 更新 update\"); &#125; &#125; 编写一个 LogInterceptor ，继承了 MethodInterceptor，用于方法的拦截回调 import java.lang.reflect.Method; import java.util.Date; public class LogInterceptor implements MethodInterceptor &#123; /** * @param object 表示要进行增强的对象 * @param method 表示拦截的方法 * @param objects 数组表示参数列表，基本数据类型需要传入其包装类型，如int-->Integer、long-Long、double-->Double * @param methodProxy 表示对方法的代理，invokeSuper方法表示对被代理对象方法的调用 * @return 执行结果 * @throws Throwable */ @Override public Object intercept(Object object, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; before(); Object result = methodProxy.invokeSuper(object, objects); // 注意这里是调用 invokeSuper 而不是 invoke，否则死循环，methodProxy.invokesuper执行的是原始类的方法，method.invoke执行的是子类的方法 after(); return result; &#125; private void before() &#123; System.out.println(String.format(\"log start time [%s] \", new Date())); &#125; private void after() &#123; System.out.println(String.format(\"log end time [%s] \", new Date())); &#125; &#125; 测试 import net.sf.cglib.proxy.Enhancer; public class CglibTest &#123; public static void main(String[] args) &#123; DaoProxy daoProxy = new DaoProxy(); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Dao.class); // 设置超类，cglib是通过继承来实现的 enhancer.setCallback(daoProxy); Dao dao = (Dao)enhancer.create(); // 创建代理类 dao.update(); dao.select(); &#125; &#125; 运行结果 log start time [Fri Dec 21 00:06:40 CST 2018] UserDao 查询 selectById log end time [Fri Dec 21 00:06:40 CST 2018] log start time [Fri Dec 21 00:06:40 CST 2018] UserDao 更新 update log end time [Fri Dec 21 00:06:40 CST 2018] 还可以进一步多个 MethodInterceptor 进行过滤筛选 public class LogInterceptor2 implements MethodInterceptor &#123; @Override public Object intercept(Object object, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; before(); Object result = methodProxy.invokeSuper(object, objects); after(); return result; &#125; private void before() &#123; System.out.println(String.format(\"log2 start time [%s] \", new Date())); &#125; private void after() &#123; System.out.println(String.format(\"log2 end time [%s] \", new Date())); &#125; &#125; // 回调过滤器: 在CGLib回调时可以设置对不同方法执行不同的回调逻辑，或者根本不执行回调。 public class DaoFilter implements CallbackFilter &#123; @Override public int accept(Method method) &#123; if (\"select\".equals(method.getName())) &#123; return 0; // Callback 列表第1个拦截器 &#125; return 1; // Callback 列表第2个拦截器，return 2 则为第3个，以此类推 &#125; &#125; 再次测试 public class CglibTest2 &#123; public static void main(String[] args) &#123; LogInterceptor logInterceptor = new LogInterceptor(); LogInterceptor2 logInterceptor2 = new LogInterceptor2(); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(UserDao.class); // 设置超类，cglib是通过继承来实现的 enhancer.setCallbacks(new Callback[]&#123;logInterceptor, logInterceptor2, NoOp.INSTANCE&#125;); // 设置多个拦截器，NoOp.INSTANCE是一个空拦截器，不做任何处理 enhancer.setCallbackFilter(new DaoFilter()); UserDao proxy = (UserDao) enhancer.create(); // 创建代理类 proxy.select(); proxy.update(); &#125; &#125; 运行结果 log start time [Fri Dec 21 00:22:39 CST 2018] UserDao 查询 selectById log end time [Fri Dec 21 00:22:39 CST 2018] log2 start time [Fri Dec 21 00:22:39 CST 2018] UserDao 更新 update log2 end time [Fri Dec 21 00:22:39 CST 2018] CGLIB 创建动态代理类的模式是： 查找目标类上的所有非final 的public类型的方法定义； 将这些方法的定义转换成字节码； 将组成的字节码转换成相应的代理的class对象； 实现 MethodInterceptor接口，用来处理对代理类上所有方法的请求 JDK动态代理与CGLIB动态代理对比JDK动态代理：基于Java反射机制实现，必须要实现了接口的业务类才能用这种办法生成代理对象。 cglib动态代理：基于ASM机制实现，通过生成业务类的子类作为代理类。 JDK Proxy 的优势： 最小化依赖关系，减少依赖意味着简化开发和维护，JDK 本身的支持，可能比 cglib 更加可靠。 平滑进行 JDK 版本升级，而字节码类库通常需要进行更新以保证在新版 Java 上能够使用。 代码实现简单。 基于类似 cglib 框架的优势： 无需实现接口，达到代理类无侵入 只操作我们关心的类，而不必为其他相关类增加工作量。 高性能 面试题 来源于网上，用于帮助理解和掌握，欢迎补充 描述动态代理的几种实现方式？分别说出相应的优缺点代理可以分为 “静态代理” 和 “动态代理”，动态代理又分为 “JDK动态代理” 和 “CGLIB动态代理” 实现。 静态代理：代理对象和实际对象都继承了同一个接口，在代理对象中指向的是实际对象的实例，这样对外暴露的是代理对象而真正调用的是 Real Object 优点：可以很好的保护实际对象的业务逻辑对外暴露，从而提高安全性。 缺点：不同的接口要有不同的代理类实现，会很冗余 JDK 动态代理： 为了解决静态代理中，生成大量的代理类造成的冗余； JDK 动态代理只需要实现 InvocationHandler 接口，重写 invoke 方法便可以完成代理的实现， jdk的代理是利用反射生成代理类 Proxyxx.class 代理类字节码，并生成对象 jdk动态代理之所以只能代理接口是因为代理类本身已经extends了Proxy，而java是不允许多重继承的，但是允许实现多个接口 优点：解决了静态代理中冗余的代理实现类问题。 缺点：JDK 动态代理是基于接口设计实现的，如果没有接口，会抛异常。 CGLIB 代理： 由于 JDK 动态代理限制了只能基于接口设计，而对于没有接口的情况，JDK方式解决不了； CGLib 采用了非常底层的字节码技术，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑，来完成动态代理的实现。 实现方式实现 MethodInterceptor 接口，重写 intercept 方法，通过 Enhancer 类的回调方法来实现。 但是CGLib在创建代理对象时所花费的时间却比JDK多得多，所以对于单例的对象，因为无需频繁创建对象，用CGLib合适，反之，使用JDK方式要更为合适一些。 同时，由于CGLib由于是采用动态创建子类的方法，对于final方法，无法进行代理。 优点：没有接口也能实现动态代理，而且采用字节码增强技术，性能也不错。 缺点：技术实现相对难理解些。 CGlib 对接口实现代理？import net.sf.cglib.proxy.Enhancer; import net.sf.cglib.proxy.MethodInterceptor; import net.sf.cglib.proxy.MethodProxy; import proxy.UserService; import java.lang.reflect.Method; /** * 创建代理类的工厂 该类要实现 MethodInterceptor 接口。 * 该类中完成三样工作： * （1）声明目标类的成员变量，并创建以目标类对象为参数的构造器。用于接收目标对象 * （2）定义代理的生成方法，用于创建代理对象。方法名是任意的。代理对象即目标类的子类 * （3）定义回调接口方法。对目标类的增强这在这里完成 */ public class CGLibFactory implements MethodInterceptor &#123; // 声明目标类的成员变量 private UserService target; public CGLibFactory(UserService target) &#123; this.target = target; &#125; // 定义代理的生成方法,用于创建代理对象 public UserService myCGLibCreator() &#123; Enhancer enhancer = new Enhancer(); // 为代理对象设置父类，即指定目标类 enhancer.setSuperclass(UserService.class); /** * 设置回调接口对象 注意，只所以在setCallback()方法中可以写上this， * 是因为MethodIntecepter接口继承自Callback，是其子接口 */ enhancer.setCallback(this); return (UserService) enhancer.create();// create用以生成CGLib代理对象 &#125; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(\"start invoke \" + method.getName()); Object result = method.invoke(target, args); System.out.println(\"end invoke \" + method.getName()); return result; &#125; &#125; 参考：《Java核心技术》卷1《深入理解Java虚拟机》7.3java docs: https://docs.oracle.com/javase/8/docs/api/java/lang/reflect/Proxy.htmlJava三种代理模式：静态代理、动态代理和cglib代理描述动态代理的几种实现方式 分别说出相应的优缺点JDK动态代理详解Java动态代理机制详解（JDK 和CGLIB，Javassist，ASM）静态代理和动态代理的理解 https://www.jianshu.com/p/9bcac608c714","tags":[]},{"title":"java动态代理","date":"2020-09-20T04:00:00.000Z","path":"posts/undefined.html","text":"自己的基本理解1、mybtis的核心代理类是MapperProxy,这是mybatis的代理类，具体的逻辑可以从这里看下去，前面是相关配置文件的读取。 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else &#123; //调用XxxMapper接口自定义的方法，进行代理 //首先将当前被调用的方法Method构造成一个MapperMethod对象，然后掉用其execute方法真正的开始执行。 return cachedInvoker(method).invoke(proxy, method, args, sqlSession); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; &#125; 2、接着使用MethodInvoker的实现类去执行，核心是实现类中的一个变量就是MapperMethod，真正执行的是这个类，他包含我们需要的所有内容 private static class PlainMethodInvoker implements MapperMethodInvoker &#123; private final MapperMethod mapperMethod; public PlainMethodInvoker(MapperMethod mapperMethod) &#123; super(); this.mapperMethod = mapperMethod; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args, SqlSession sqlSession) throws Throwable &#123; return mapperMethod.execute(sqlSession, args); &#125; &#125; 3、执行MapperMethod的execute方法就开始执行我们的的相关逻辑,获取statement,使用sqlSession去执行相关的sql。 public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; switch (command.getType()) &#123; case INSERT: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &#125; case UPDATE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &#125; case DELETE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; &#125; case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123; result = executeForCursor(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); if (method.returnsOptional() &amp;&amp; (result == null || !method.getReturnType().equals(result.getClass()))) &#123; result = Optional.ofNullable(result); &#125; &#125; break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(\"Unknown execution method for: \" + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException(\"Mapper method '\" + command.getName() + \" attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\"); &#125; return result; &#125;","tags":[]},{"title":"centos安装nacos","date":"2020-09-19T10:00:00.000Z","path":"posts/undefined.html","text":"下载不同版本有点配置有点差别 https:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;nacos&#x2F;releases https:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;nacos&#x2F;releases&#x2F;download&#x2F;1.3.2&#x2F;nacos-server-1.3.2.zip 配置数据库#*************** Config Module Related Configurations ***************# ### If use MySQL as datasource: # spring.datasource.platform=mysql ### Count of DB: # db.num=1 ### Connect URL of DB: # db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTC # db.user=nacos # db.password=nacos 初始化数据库mysqldump -h -u -p nacos &lt; xx.sql 启动./startup.sh -m standalone 编写service [Unit] Description&#x3D;nacos After&#x3D;network.target [Service] Type&#x3D;forking ExecStart&#x3D;&#x2F;opt&#x2F;nacos&#x2F;bin&#x2F;startup.sh -m standalone ExecReload&#x3D;&#x2F;opt&#x2F;nacos&#x2F;bin&#x2F;shutdown.sh ExecStop&#x3D;&#x2F;opt&#x2F;nacos&#x2F;bin&#x2F;shutdown.sh PrivateTmp&#x3D;true [Install] WantedBy&#x3D;multi-user.target systemctl start nacos systemctl enable nacos 参考https://blog.csdn.net/weihuaya/article/details/108060847","tags":[]},{"title":"centos安装rockermq","date":"2020-09-19T10:00:00.000Z","path":"posts/undefined.html","text":"一、安装jdk 1.8 jdk1.8 资源下载 上传至服务器目录，解压（以上传至root 目录为例） tar -zxvf jdk-8u221-linux-x64.tar.gz 将解压后的文件夹移动到/usr/local目录下 mv jdk1.8.0_221 &#x2F;usr&#x2F;local&#x2F; 编辑以下文件，配置java 环境 vim &#x2F;etc&#x2F;profile 具体java 环境配置: export JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk1.8.0_221 export JRE_HOME&#x3D;$&#123;JAVA_HOME&#125;&#x2F;jre export CLASSPATH&#x3D;.:$&#123;JAVA_HOME&#125;&#x2F;lib&#x2F;dt.JAVA_HOME&#x2F;lib&#x2F;tools.jar:$&#123;JRE_HOME&#125;&#x2F;lib export PATH&#x3D;$&#123;JAVA_HOME&#125;&#x2F;bin:$&#123;PATH&#125; 此处顺便配置rocketmq 环境export NAMESRV_ADDR=127.0.0.1:9876 6.刷新文件，使配置立即生效 source &#x2F;etc&#x2F;profile 查看是否安装成功 java -version 8.配置成功,将会看到以下类似信息 java version \"1.8.0_221\" Java(TM) SE Runtime Environment (build 1.8.0_221-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode) 注意：使用openjdk 安装的话在配置rocketMq时候会出现（JAVA_HOME）问题，当时使用了很多方法，都没有成功，最好还是推荐使用这种方式吧。二、安装rocketMQ 直接下载安装包（以4.5.1为例） 官网：https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.5.1/rocketmq-all-4.5.1-bin-release.zip 注意：不要下载源码包，否则是没有bin目录的wget http://mirrors.tuna.tsinghua.edu.cn/apache/rocketmq/4.5.1/rocketmq-all-4.5.1-bin-release.zip 2.解压,将会得到 rocketmq-all-4.5.1-bin-release 文件夹 unzip rocketmq-all-4.5.1-bin-release.zip 3.进入bin 目录 修改配置(分别修改runserver.sh 以及 runbroker.sh，因为默认配置内存过大，可能导致启动失败) cd /root/rocketmq-all-4.5.1-bin-release/bin/ 修改 runserver.sh 文件 修改位置 vim runbroker.sh ##使用快捷键 i 开启编辑模式 ##找到以下配置，将xms/xmx/xmn 分别修改成以下数值（视机器配置而定） JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms512m -Xmx512m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" ##保存 wq 修改 runbroker.sh 修改位置 vim runbroker.sh ##使用快捷键 i 开启编辑模式 ##具体数值视机器而定 JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms128m -Xmx256m -Xmn256m\" ##保存 wq 修改配置文件 vim broker.conf 新增如下选项 brokerIP1=xxxxxx(你的服务器公网ip) 分别后台启动 runserver.sh 以及 runbroker.sh ##启动runserver nohup sh mqnamesrv &amp; ##以配置文件启动runbroker nohup sh mqbroker -n localhost:9876 -c /root/rocketmq-all-4.5.1-bin-release/conf/broker.conf &amp; 7.查看启动是否成功 jps 启动成功(可以看到NamesrvStartup以及BrokerStartup) 16065 Jps 9679 NamesrvStartup 7887 jar 11279 BrokerStartup 10.启动成功日志 tail -f ~/logs/rocketmqlogs/namesrv.log tail -f ~/logs/rocketmqlogs/broker.log 11.如果启动失败，请查看失败日志 cat nohup.out 三、关于防火墙以及安全组规则配置首先，请在你的云服务器配置安全组规则通道 9876 端口 其次，centos7默认使用firewalld防火墙，而不是iptables，卸载firewalld，再安装iptables ##卸载firewalld yum remove firewalld ##安装iptables yum install iptables-services ##查看防火墙状态 service iptables status ##停止防火墙 service iptables stop 四、SpringBoot整合监视台（rocketmq-externals插件）GITHUB地址 下载rocketmq-console模块即可 修改配置文件 rocketmq.config.namesrvAddr=你的公网IP:9876 ##如果你版本小于3.5.8，下面应该配置为false rocketmq.config.isVIPChannel=false 启动即可 Description&#x3D;rockermq name service Requires&#x3D;network-online.target After&#x3D;network-online.target [Service] Type&#x3D;simple User&#x3D;anonymous WorkingDirectory&#x3D;&#x2F;opt&#x2F;rocketmq ExecStart&#x3D;&#x2F;opt&#x2F;rocketmq&#x2F;bin&#x2F;mqnamesrv Restart&#x3D;on-failure [Install] WantedBy&#x3D;multi-user.target","tags":[]},{"title":"mybatis拦截器","date":"2020-09-19T08:00:00.000Z","path":"posts/undefined.html","text":"基本知识拦截器注解的规则：具体规则如下： @Intercepts(&#123; @Signature(type = StatementHandler.class, method = \"query\", args = &#123;Statement.class, ResultHandler.class&#125;), @Signature(type = StatementHandler.class, method = \"update\", args = &#123;Statement.class&#125;), @Signature(type = StatementHandler.class, method = \"batch\", args = &#123;Statement.class&#125;) &#125;) @Intercepts：标识该类是一个拦截器； @Signature：指明自定义拦截器需要拦截哪一个类型，哪一个方法； 2.1 type：对应四种类型中的一种； 2.2 method：对应接口中的哪类方法（因为可能存在重载方法）； 2.3 args：对应哪一个方法； 5. 拦截器可拦截的方法： 拦截的类 拦截的方法 Executor update, query, flushStatements, commit, rollback,getTransaction, close, isClosed ParameterHandler getParameterObject, setParameters StatementHandler prepare, parameterize, batch, update, query ResultSetHandler handleResultSets, handleOutputParameters @Intercepts(&#123;@Signature(type = Executor.class, method = \"query\", args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;)&#125;) public class TestInterceptor implements Interceptor &#123; public Object intercept(Invocation invocation) throws Throwable &#123; Object target = invocation.getTarget(); //被代理对象 Method method = invocation.getMethod(); //代理方法 Object[] args = invocation.getArgs(); //方法参数 // do something ...... 方法拦截前执行代码块 Object result = invocation.proceed(); // do something .......方法拦截后执行代码块 return result; &#125; public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; &#125; setProperties方法如果我们的拦截器需要一些变量对象，而且这个对象是支持可配置的。 类似于Spring中的@Value(“${}”)从application.properties文件中获取。 使用方法： &lt;plugin interceptor=\"com.plugin.mybatis.MyInterceptor\"> &lt;property name=\"username\" value=\"xxx\"/> &lt;property name=\"password\" value=\"xxx\"/> &lt;/plugin> plugin方法这个方法的作用是就是让mybatis判断，是否要进行拦截，然后做出决定是否生成一个代理。 @Override public Object plugin(Object target) &#123; if (target instanceof StatementHandler) &#123; return Plugin.wrap(target, this); &#125; return target; &#125; 需要注意的是：每经过一个拦截器对象都会调用插件的plugin方法，也就是说，该方法会调用4次。根据@Intercepts注解来决定是否进行拦截处理。 问题1：**Plugin.wrap(target, this)**方法的作用？ 解答：判断是否拦截这个类型对象（根据@Intercepts注解决定），然后决定是返回一个代理对象还是返回原对象。 故我们在实现plugin方法时，要判断一下目标类型，是本插件要拦截的对象时才执行Plugin.wrap方法，否则的话，直接返回目标本身。 问题2：拦截器代理对象可能经过多层代理，如何获取到真实的拦截器对象？ /** * &lt;p> * 获得真正的处理对象,可能多层代理. * &lt;/p> */ @SuppressWarnings(\"unchecked\") public static &lt;T> T realTarget(Object target) &#123; if (Proxy.isProxyClass(target.getClass())) &#123; MetaObject metaObject = SystemMetaObject.forObject(target); return realTarget(metaObject.getValue(\"h.target\")); &#125; return (T) target; 配置&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"> &lt;configuration> &lt;properties resource=\"top/sciento/wumu/jdbc/mybatis/db.properties\">&lt;/properties> &lt;plugins> &lt;plugin interceptor=\"top.sciento.wumu.jdbc.mybatis.plugin.ExamplePlugin\"> &lt;/plugin> &lt;plugin interceptor=\"top.sciento.wumu.jdbc.mybatis.plugin.PagePlugin\"/> &lt;/plugins> &lt;environments default=\"development\"> &lt;environment id=\"development\"> &lt;transactionManager type=\"JDBC\"/> &lt;dataSource type=\"POOLED\"> &lt;property name=\"driver\" value=\"$&#123;driver&#125;\"/> &lt;property name=\"url\" value=\"$&#123;url&#125;\"/> &lt;property name=\"username\" value=\"$&#123;username&#125;\"/> &lt;property name=\"password\" value=\"$&#123;password&#125;\"/> &lt;/dataSource> &lt;/environment> &lt;/environments> &lt;mappers> &lt;package name=\"top.sciento.wumu.jdbc.mybatis.mapper\"/> &lt;/mappers> &lt;/configuration> 实战 @Intercepts(&#123;@Signature( type= Executor.class, method = \"update\", args = &#123;MappedStatement.class,Object.class&#125;)&#125;) public class ExamplePlugin implements Interceptor &#123; public Object intercept(Invocation invocation) throws Throwable &#123; System.out.println(\"被拦截方法执行之前，做的辅助服务······\"); Object[] args = invocation.getArgs(); Method method = invocation.getMethod(); Object target = invocation.getTarget(); MappedStatement mappedStatement = (MappedStatement) args[0]; Object proceed = invocation.proceed(); System.out.println(\"被拦截方法执行之后，做的辅助服务······\"); return proceed; &#125; public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; public void setProperties(Properties properties) &#123; &#125; &#125; @Slf4j @Intercepts( @Signature(type = Executor.class, method = \"query\", args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;) ) public class PagePlugin implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; Object[] args = invocation.getArgs(); MappedStatement mappedStatement = (MappedStatement) args[0]; //获取参数 Object param = invocation.getArgs()[1]; BoundSql boundSql = mappedStatement.getBoundSql(param); Object parameterObject = boundSql.getParameterObject(); /** * 判断是否是继承PageVo来判断是否需要进行分页 */ if (parameterObject instanceof Page) &#123; //强转 为了拿到分页数据 Page pagevo = (Page) param; String sql = boundSql.getSql(); //获取相关配置 Configuration config = mappedStatement.getConfiguration(); Connection connection = config.getEnvironment().getDataSource().getConnection(); //拼接查询当前条件的sql的总条数 String countSql = \"select count(*) from (\" + sql + \") a\"; PreparedStatement preparedStatement = connection.prepareStatement(countSql); BoundSql countBoundSql = new BoundSql(config, countSql, boundSql.getParameterMappings(), boundSql.getParameterObject()); ParameterHandler parameterHandler = new DefaultParameterHandler(mappedStatement, parameterObject, countBoundSql); parameterHandler.setParameters(preparedStatement); //执行获得总条数 ResultSet rs = preparedStatement.executeQuery(); int count = 0; if (rs.next()) &#123; count = rs.getInt(1); &#125; //拼接分页sql String pageSql = sql + \" limit \" + pagevo.getOffset() + \" , \" + pagevo.getSize(); //重新执行新的sql doNewSql(invocation, pageSql); Object result = invocation.proceed(); connection.close(); // 这是使用了两种不同的方式返回最终的结果 pagevo.setList((List)result); pagevo.setTotal(count); //处理新的结构 PageResult&lt;?> pageResult = new PageResult&lt;List>((List) result,pagevo.getPage(), pagevo.getSize(), count ); return new ArrayList&lt;PageResult>()&#123;&#123;add(pageResult);&#125;&#125; ; &#125; return invocation.proceed(); &#125; private void doNewSql(Invocation invocation, String sql)&#123; final Object[] args = invocation.getArgs(); MappedStatement statement = (MappedStatement) args[0]; Object parameterObject = args[1]; BoundSql boundSql = statement.getBoundSql(parameterObject); MappedStatement newStatement = newMappedStatement(statement, new BoundSqlSqlSource(boundSql)); MetaObject msObject = MetaObject.forObject(newStatement, new DefaultObjectFactory(), new DefaultObjectWrapperFactory(), new DefaultReflectorFactory()); msObject.setValue(\"sqlSource.boundSql.sql\", sql); args[0] = newStatement; &#125; private MappedStatement newMappedStatement(MappedStatement ms, SqlSource newSqlSource) &#123; MappedStatement.Builder builder = new MappedStatement.Builder(ms.getConfiguration(), ms.getId(), newSqlSource, ms.getSqlCommandType()); builder.resource(ms.getResource()); builder.fetchSize(ms.getFetchSize()); builder.statementType(ms.getStatementType()); builder.keyGenerator(ms.getKeyGenerator()); if (ms.getKeyProperties() != null &amp;&amp; ms.getKeyProperties().length != 0) &#123; StringBuilder keyProperties = new StringBuilder(); for (String keyProperty : ms.getKeyProperties()) &#123; keyProperties.append(keyProperty).append(\",\"); &#125; keyProperties.delete(keyProperties.length() - 1, keyProperties.length()); builder.keyProperty(keyProperties.toString()); &#125; builder.timeout(ms.getTimeout()); builder.parameterMap(ms.getParameterMap()); builder.resultMaps(ms.getResultMaps()); builder.resultSetType(ms.getResultSetType()); builder.cache(ms.getCache()); builder.flushCacheRequired(ms.isFlushCacheRequired()); builder.useCache(ms.isUseCache()); return builder.build(); &#125; /** * 新的SqlSource需要实现 */ class BoundSqlSqlSource implements SqlSource &#123; private BoundSql boundSql; public BoundSqlSqlSource(BoundSql boundSql) &#123; this.boundSql = boundSql; &#125; @Override public BoundSql getBoundSql(Object parameterObject) &#123; return boundSql; &#125; &#125; &#125; 参考https://www.jianshu.com/p/0a72bb1f6a21","tags":[]},{"title":"mybatis入门","date":"2020-09-19T06:00:00.000Z","path":"posts/undefined.html","text":"添加依赖&lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis&lt;/artifactId> &lt;version>x.x.x&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>5.1.44&lt;/version> &lt;/dependency> 创建配置文件mybatis-config.xml 配置文件的标签顺序不能打乱，不然会报错。 &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?> &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"> &lt;configuration> &lt;properties resource=\"top/sciento/wumu/jdbc/mybatis/db.properties\">&lt;/properties> &lt;environments default=\"development\"> &lt;environment id=\"development\"> &lt;transactionManager type=\"JDBC\"/> &lt;dataSource type=\"POOLED\"> &lt;property name=\"driver\" value=\"$&#123;driver&#125;\"/> &lt;property name=\"url\" value=\"$&#123;url&#125;\"/> &lt;property name=\"username\" value=\"$&#123;username&#125;\"/> &lt;property name=\"password\" value=\"$&#123;password&#125;\"/> &lt;/dataSource> &lt;/environment> &lt;/environments> &lt;mappers> &lt;package name=\"top.sciento.wumu.jdbc.mybatis.mapper\"/> &lt;/mappers> &lt;/configuration> db.properties driver=com.mysql.jdbc.Driver url=jdbc:mysql://:3306/test username= password= 编写执行文件 package top.sciento.wumu.jdbc.mybatis; import org.apache.ibatis.io.Resources; import org.apache.ibatis.session.Configuration; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import top.sciento.wumu.jdbc.mybatis.entity.User; import top.sciento.wumu.jdbc.mybatis.mapper.UserMapper; import java.io.IOException; import java.io.InputStream; import java.io.Reader; import java.util.List; public class MybatisRunner &#123; public static void main(String[] args) throws IOException &#123; System.out.println(MybatisRunner.class.getResource(\"\")); InputStream reader = MybatisRunner.class.getResourceAsStream(\"mybatis-config.xml\"); SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(reader); Configuration configuration = sessionFactory.getConfiguration(); // 默认是不会提交的，需要手动提交 SqlSession sqlSession = sessionFactory.openSession(); UserMapper userMapper = sqlSession.getMapper(UserMapper.class); List&lt;User> userList = userMapper.selectList(); System.out.println(userList); User user = new User(); user.setName(\"wumu\"); user.setAge(12); int id = userMapper.insert(user); System.out.println(id); System.out.println(user); &#125; &#125; public interface UserMapper &#123; List&lt;User> list(); @SelectProvider(value = UserSqlBuilder.class,method = \"selectList\") List&lt;User> selectList(); // 这里使用动态sql @InsertProvider(value = UserSqlBuilder.class,method = \"insert\") // @Options(useGeneratedKeys = true, keyProperty = \"id\", keyColumn = \"id\") @SelectKey(statement = \"select last_insert_id()\", keyProperty = \"id\", before = false, resultType = int.class) int insert(User user); &#125; public class UserSqlBuilder &#123; public static String selectList() &#123; return new SQL().SELECT(\"id\",\"name\",\"age\").FROM(\"base_user\").toString(); &#125; public static String insert(User user)&#123; // return new SQL().INSERT_INTO(\"base_user\").INTO_COLUMNS(\"name\",\"age\") // .INTO_VALUES(user.getName(),String.valueOf(user.getAge())).toString(); return new SQL().INSERT_INTO(\"base_user\").VALUES(\"name\",\"#&#123;name&#125;\") .VALUES(\"age\",\"#&#123;age&#125;\").toString(); &#125; &#125; @Data public class User &#123; private Integer id; private String name; private Integer age; &#125; &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?> &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"> &lt;!-- namespace属性是名称空间，必须唯一 --> &lt;mapper namespace=\"top.sciento.wumu.jdbc.mybatis.mapper.UserMapper\"> &lt;!-- resultMap标签:映射实体与表 type属性：表示实体全路径名 id属性：为实体与表的映射取一个任意的唯一的名字 --> &lt;resultMap type=\"top.sciento.wumu.jdbc.mybatis.entity.User\" id=\"UserMap\"> &lt;!-- id标签:映射主键属性 result标签：映射非主键属性 property属性:实体的属性名 column属性：表的字段名 --> &lt;id property=\"id\" column=\"id\"/> &lt;result property=\"name\" column=\"name\"/> &lt;result property=\"age\" column=\"age\"/> &lt;/resultMap> &lt;select id=\"list\" resultMap=\"UserMap\"> select * from base_user &lt;/select> &lt;/mapper> 知识分析返回主键1、使用options options可以配置sql的大部分属性，对应着我们标签&lt;select&gt;上写的相关属性。 – – 描述 @Options 方法 映射语句的属性 该注解允许你指定大部分开关和配置选项，它们通常在映射语句上作为属性出现。与在注解上提供大量的属性相比，Options 注解提供了一致、清晰的方式来指定选项。属性：useCache=true、flushCache=FlushCachePolicy.DEFAULT、resultSetType=DEFAULT、statementType=PREPARED、fetchSize=-1、timeout=-1、useGeneratedKeys=false、keyProperty=&quot;&quot;、keyColumn=&quot;&quot;、resultSets=&quot;&quot;, databaseId=&quot;&quot;。注意，Java 注解无法指定 null 值。因此，一旦你使用了 Options 注解，你的语句就会被上述属性的默认值所影响。要注意避免默认值带来的非预期行为。 The databaseId(Available since 3.5.5), in case there is a configured DatabaseIdProvider, the MyBatis use the Options with no databaseId attribute or with a databaseId that matches the current one. If found with and without the databaseId the latter will be discarded. 注意：keyColumn 属性只在某些数据库中有效（如 Oracle、PostgreSQL 等）。要了解更多关于 keyColumn 和 keyProperty 可选值信息，请查看“insert, update 和 delete”一节。 2、使用SelectKey 对应着SelectKey标签 – – – - @SelectKey 方法 &lt;selectKey&gt; 这个注解的功能与 &lt;selectKey&gt; 标签完全一致。该注解只能在 @Insert 或 @InsertProvider 或 @Update 或 @UpdateProvider 标注的方法上使用，否则将会被忽略。如果标注了 @SelectKey 注解，MyBatis 将会忽略掉由 @Options 注解所设置的生成主键或设置（configuration）属性。属性：statement 以字符串数组形式指定将会被执行的 SQL 语句，keyProperty 指定作为参数传入的对象对应属性的名称，该属性将会更新成新的值，before 可以指定为 true 或 false 以指明 SQL 语句应被在插入语句的之前还是之后执行。resultType 则指定 keyProperty 的 Java 类型。statementType 则用于选择语句类型，可以选择 STATEMENT、PREPARED 或 CALLABLE 之一，它们分别对应于 Statement、PreparedStatement 和 CallableStatement。默认值是 PREPARED。 The databaseId(Available since 3.5.5), in case there is a configured DatabaseIdProvider, the MyBatis will use a statement with no databaseId attribute or with a databaseId that matches the current one. If found with and without the databaseId the latter will be discarded. 描述： @SelctKey(statement=”SQL语句”,keyProperty=”将SQL语句查询结果存放到keyProperty中去”,before=”true表示先查询再插入，false反之”,resultType=int.class)其中： statement是要运行的SQL语句，它的返回值通过resultType来指定 before表示查询语句statement运行的时机 keyProperty表示查询结果赋值给代码中的哪个对象，keyColumn表示将查询结果赋值给数据库表中哪一列 keyProperty和keyColumn都不是必需的，有没有都可以 before=true，插入之前进行查询，可以将查询结果赋给keyProperty和keyColumn，赋给keyColumn相当于更改数据库 befaore=false，先插入，再查询，这时只能将结果赋给keyProperty 赋值给keyProperty用来“读”数据库，赋值给keyColumn用来写数据库 selectKey的两大作用：1、生成主键；2、获取刚刚插入数据的主键。 使用selectKey，并且使用MySQL的last_insert_id()函数时，before必为false，也就是说必须先插入然后执行last_insert_id()才能获得刚刚插入数据的ID。 maven打包xml文件&lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;configuration> &lt;source>8&lt;/source> &lt;target>8&lt;/target> &lt;/configuration> &lt;/plugin> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-war-plugin&lt;/artifactId> &lt;version>2.1.1&lt;/version> &lt;/plugin> &lt;/plugins> &lt;resources> &lt;resource> &lt;directory>src/main/java&lt;/directory> &lt;includes> &lt;include>**/*.properties&lt;/include> &lt;include>**/*.xml&lt;/include> &lt;/includes> &lt;filtering>false&lt;/filtering> &lt;/resource> &lt;resource> &lt;directory>src/main/resources&lt;/directory> &lt;/resource> &lt;/resources> &lt;/build>","tags":[]},{"title":"centos8安装mysql","date":"2020-09-17T08:55:17.000Z","path":"posts/undefined.html","text":"以root身份或具有sudo特权的用户身份使用CentOS软件包管理器安装MySQL 8.0服务器： sudo dnf install @mysql @mysql模块安装MySQL及其所有依赖项。 安装完成后，通过运行以下命令来启动MySQL服务并使其在启动时自动启动： sudo systemctl enable --now mysqld 要检查MySQL服务器是否正在运行，请输入： sudo systemctl status mysqld ● mysqld.service - MySQL 8.0 database server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2019-10-17 22:09:39 UTC; 15s ago ... 保护MySQL运行mysql_secure_installation脚本，该脚本执行一些与安全性相关的操作并设置MySQL根密码： sudo mysql_secure_installation 将要求您配置 VALIDATE PASSWORD PLUGIN ，该工具用于测试MySQL用户密码的强度并提高安全性。密码验证策略分为三个级别：低，中和强。如果您不想设置验证密码插件，请按ENTER。 在下一个提示符下，将要求您为MySQL根用户设置密码。完成此操作后，脚本还将要求您删除匿名用户，限制root用户对本地计算机的访问，并删除测试数据库。您应该对所有问题回答“是”。 要从命令行与MySQL服务器进行交互，请使用MySQL客户端实用程序，它作为依赖项安装。通过键入以下内容测试根访问权限： mysql -u root -p 出现提示时输入 root密码，将为您提供MySQL shell，如下所示： Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 12 Server version: 8.0.17 Source distribution 就是这样！您已经在CentOS服务器上安装并保护了MySQL 8.0，并准备使用它。 身份验证方法由于CentOS 8中的某些客户端工具和库与caching_sha2_password方法不兼容，CentOS 8存储库中包含的MySQL 8.0服务器被设置为使用旧的mysql_native_password身份验证插件。上游MySQL 8.0版本。 mysql_native_password方法适用于大多数设置。但是，如果您想将默认身份验证插件更改为caching_sha2_password，这会更快并提供更好的安全性，请打开以下配置文件： sudo vim /etc/my.cnf.d/mysql-default-authentication-plugin.cnf 将default_authentication_plugin的值更改为caching_sha2_password： [mysqld] default_authentication_plugin=caching_sha2_password 关闭并保存文件，然后重新启动MySQL服务器以使更改生效： sudo systemctl restart mysqld","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"}]},{"title":"postgresql账号管理","date":"2020-09-16T10:37:46.000Z","path":"posts/undefined.html","text":"注意：创建好用户（角色）之后需要连接的话，还需要修改2个权限控制的配置文件（pg_hba.conf、pg_ident.conf）。并且创建用户（user）和创建角色（role）一样，唯一的区别是用户默认可以登录，而创建的角色默认不能登录。创建用户和角色的各个参数选项是一样的。 Tip：安装PostgreSQL会自动创建一个postgres用户，需要切换到该用户下访问PostgreSQL。 创建用户/角色 CREATE USER&#x2F;ROLE name [ [ WITH ] option [ ... ] ] : 关键词 USER,ROLE； name 用户或角色名； where option can be: SUPERUSER | NOSUPERUSER :超级权限，拥有所有权限，默认nosuperuser。 | CREATEDB | NOCREATEDB :建库权限，默认nocreatedb。 | CREATEROLE | NOCREATEROLE :建角色权限，拥有创建、修改、删除角色，默认nocreaterole。 | INHERIT | NOINHERIT :继承权限，可以把除superuser权限继承给其他用户&#x2F;角色，默认inherit。 | LOGIN | NOLOGIN :登录权限，作为连接的用户，默认nologin，除非是create user（默认登录）。 | REPLICATION | NOREPLICATION :复制权限，用于物理或则逻辑复制（复制和删除slots），默认是noreplication。 | BYPASSRLS | NOBYPASSRLS :安全策略RLS权限，默认nobypassrls。 | CONNECTION LIMIT connlimit :限制用户并发数，默认-1，不限制。正常连接会受限制，后台连接和prepared事务不受限制。 | [ ENCRYPTED ] PASSWORD &#39;password&#39; | PASSWORD NULL :设置密码，密码仅用于有login属性的用户，不使用密码身份验证，则可以省略此选项。可以选择将空密码显式写为PASSWORD NULL。 加密方法由配置参数password_encryption确定，密码始终以加密方式存储在系统目录中。 | VALID UNTIL &#39;timestamp&#39; :密码有效期时间，不设置则用不失效。 | IN ROLE role_name [, ...] :新角色将立即添加为新成员。 | IN GROUP role_name [, ...] :同上 | ROLE role_name [, ...] :ROLE子句列出一个或多个现有角色，这些角色自动添加为新角色的成员。 （这实际上使新角色成为“组”）。 | ADMIN role_name [, ...] :与ROLE类似，但命名角色将添加到新角色WITH ADMIN OPTION，使他们有权将此角色的成员资格授予其他人。 | USER role_name [, ...] :同上 | SYSID uid :被忽略，但是为向后兼容性而存在。 ​ 示例： 创建不需要密码登陆的用户zjy： postgres&#x3D;# CREATE ROLE zjy LOGIN; CREATE ROLE 创建该用户后，还不能直接登录。需要修改 pg_hba.conf 文件（后面会对该文件进行说明），加入： ①：本地登陆：local all all trust②：远程登陆：host all all 192.168.163.132/32 trust 创建需要密码登陆的用户zjy1： postgres&#x3D;# CREATE USER zjy1 WITH PASSWORD &#39;zjy1&#39;; CREATE ROLE 和ROLE的区别是：USER带LOGIN属性。也需要修改 pg_hba.conf 文件（后面会对该文件进行说明），加入：host all all 192.168.163.132/32 md5 创建有时间限制的用户zjy2： postgres&#x3D;# CREATE ROLE zjy2 WITH LOGIN PASSWORD &#39;zjy2&#39; VALID UNTIL &#39;2019-05-30&#39;; CREATE ROLE 和2的处理方法一样，修改 pg_hba.conf 文件，该用户会的密码在给定的时间之后过期不可用。 创建有创建数据库和管理角色权限的用户admin： postgres&#x3D;# CREATE ROLE admin WITH CREATEDB CREATEROLE; CREATE ROLE 注意：拥有创建数据库，角色的用户，也可以删除和修改这些对象。 创建具有超级权限的用户：admin postgres&#x3D;# CREATE ROLE admin WITH SUPERUSER LOGIN PASSWORD &#39;admin&#39;; CREATE ROLE 创建复制账号：repl postgres&#x3D;# CREATE USER repl REPLICATION LOGIN ENCRYPTED PASSWORD &#39;repl&#39;; CREATE ROLE 其他说明 授权，定义访问权限 GRANT &#123; &#123; SELECT | INSERT | UPDATE | DELETE | TRUNCATE | REFERENCES | TRIGGER &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON &#123; [ TABLE ] table_name [, ...] | ALL TABLES IN SCHEMA schema_name [, ...] &#125; TO role_specification [, ...] [ WITH GRANT OPTION ] ##单表授权：授权zjy账号可以访问schema为zjy的zjy表 grant select,insert,update,delete on zjy.zjy to zjy; ##所有表授权： grant select,insert,update,delete on all tables in schema zjy to zjy; GRANT &#123; &#123; SELECT | INSERT | UPDATE | REFERENCES &#125; ( column_name [, ...] ) [, ...] | ALL [ PRIVILEGES ] ( column_name [, ...] ) &#125; ON [ TABLE ] table_name [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] ##列授权，授权指定列(zjy schema下的zjy表的name列)的更新权限给zjy用户 grant update (name) on zjy.zjy to zjy; ##指定列授不同权限，zjy schema下的zjy表，查看更新name、age字段，插入name字段 grant select (name,age),update (name,age),insert(name) on zjy.xxx to zjy; GRANT &#123; &#123; USAGE | SELECT | UPDATE &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON &#123; SEQUENCE sequence_name [, ...] | ALL SEQUENCES IN SCHEMA schema_name [, ...] &#125; TO role_specification [, ...] [ WITH GRANT OPTION ] ##序列（自增键）属性授权，指定zjy schema下的seq_id_seq 给zjy用户 grant select,update on sequence zjy.seq_id_seq to zjy; ##序列（自增键）属性授权，给用户zjy授权zjy schema下的所有序列 grant select,update on all sequences in schema zjy to zjy; GRANT &#123; &#123; CREATE | CONNECT | TEMPORARY | TEMP &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON DATABASE database_name [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] ##连接数据库权限，授权cc用户连接数据库zjy grant connect on database zjy to cc; GRANT &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON DOMAIN domain_name [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] ## GRANT &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON FOREIGN DATA WRAPPER fdw_name [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] \\## GRANT &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON FOREIGN SERVER server_name [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] ## GRANT &#123; EXECUTE | ALL [ PRIVILEGES ] &#125; ON &#123; &#123; FUNCTION | PROCEDURE | ROUTINE &#125; routine_name [ ( [ [ argmode ] [ arg_name ] arg_type [, ...] ] ) ] [, ...] | ALL &#123; FUNCTIONS | PROCEDURES | ROUTINES &#125; IN SCHEMA schema_name [, ...] &#125; TO role_specification [, ...] [ WITH GRANT OPTION ] ## GRANT &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON LANGUAGE lang_name [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] \\## GRANT &#123; &#123; SELECT | UPDATE &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON LARGE OBJECT loid [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] ## GRANT &#123; &#123; CREATE | USAGE &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON SCHEMA schema_name [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] ##连接schema权限，授权cc访问zjy schema权限 grant usage on schema zjy to cc; GRANT &#123; CREATE | ALL [ PRIVILEGES ] &#125; ON TABLESPACE tablespace_name [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] GRANT &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON TYPE type_name [, ...] TO role_specification [, ...] [ WITH GRANT OPTION ] where role_specification can be: [ GROUP ] role_name | PUBLIC | CURRENT_USER | SESSION_USER GRANT role_name [, ...] TO role_name [, ...] [ WITH ADMIN OPTION ] ##把zjy用户的权限授予用户cc。 grant zjy to cc; 权限说明： SELECT：允许从指定表，视图或序列的任何列或列出的特定列进行SELECT。也允许使用COPY TO。在UPDATE或DELETE中引用现有列值也需要此权限。对于序列，此权限还允许使用currval函数。对于大对象，此权限允许读取对象。 INSERT：允许将新行INSERT到指定的表中。如果列出了特定列，则只能在INSERT命令中为这些列分配（因此其他列将接收默认值）。也允许COPY FROM。 UPDATE：允许更新指定表的任何列或列出的特定列，需要SELECT权限。 DELETE：允许删除指定表中的行，需要SELECT权限。 TRUNCATE：允许在指定的表上创建触发器。 REFERENCES：允许创建引用指定表或表的指定列的外键约束。 TRIGGER：允许在指定的表上创建触发器。 CREATE：对于数据库，允许在数据库中创建新的schema、table、index。 CONNECT：允许用户连接到指定的数据库。在连接启动时检查此权限。 TEMPORARY、TEMP：允许在使用指定数据库时创建临时表。 EXECUTE：允许使用指定的函数或过程以及在函数。 USAGE：对于schema，允许访问指定模式中包含的对象；对于sequence，允许使用currval和nextval函数。对于类型和域，允许在创建表，函数和其他模式对象时使用类型或域。 ALL PRIVILEGES：一次授予所有可用权限。 撤销权限 REVOKE [ GRANT OPTION FOR ] &#123; &#123; SELECT | INSERT | UPDATE | DELETE | TRUNCATE | REFERENCES | TRIGGER &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON &#123; [ TABLE ] table_name [, ...] | ALL TABLES IN SCHEMA schema_name [, ...] &#125; FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ##移除用户zjy在schema zjy上所有表的select权限 revoke select on all tables in schema zjy from zjy; REVOKE [ GRANT OPTION FOR ] &#123; &#123; SELECT | INSERT | UPDATE | REFERENCES &#125; ( column_name [, ...] ) [, ...] | ALL [ PRIVILEGES ] ( column_name [, ...] ) &#125; ON [ TABLE ] table_name [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ##移除用户zjy在zjy schema的zjy表的age列的查询权限 revoke select (age) on zjy.zjy from zjy; REVOKE [ GRANT OPTION FOR ] &#123; &#123; USAGE | SELECT | UPDATE &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON &#123; SEQUENCE sequence_name [, ...] | ALL SEQUENCES IN SCHEMA schema_name [, ...] &#125; FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ##序列 REVOKE [ GRANT OPTION FOR ] &#123; &#123; CREATE | CONNECT | TEMPORARY | TEMP &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON DATABASE database_name [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ##库 REVOKE [ GRANT OPTION FOR ] &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON DOMAIN domain_name [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT] ## REVOKE [ GRANT OPTION FOR ] &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON FOREIGN DATA WRAPPER fdw_name [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT] ## REVOKE [ GRANT OPTION FOR ] &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON FOREIGN SERVER server_name [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT] ## REVOKE [ GRANT OPTION FOR ] &#123; EXECUTE | ALL [ PRIVILEGES ] &#125; ON &#123; &#123; FUNCTION | PROCEDURE | ROUTINE &#125; function_name [ ( [ [ argmode ] [ arg_name ] arg_type [, ...] ] ) ] [, ...] | ALL &#123; FUNCTIONS | PROCEDURES | ROUTINES &#125; IN SCHEMA schema_name [, ...] &#125; FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ## REVOKE [ GRANT OPTION FOR ] &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON LANGUAGE lang_name [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ## REVOKE [ GRANT OPTION FOR ] &#123; &#123; SELECT | UPDATE &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON LARGE OBJECT loid [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ## REVOKE [ GRANT OPTION FOR ] &#123; &#123; CREATE | USAGE &#125; [, ...] | ALL [ PRIVILEGES ] &#125; ON SCHEMA schema_name [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ##schena权限 REVOKE [ GRANT OPTION FOR ] &#123; CREATE | ALL [ PRIVILEGES ] &#125; ON TABLESPACE tablespace_name [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ## REVOKE [ GRANT OPTION FOR ] &#123; USAGE | ALL [ PRIVILEGES ] &#125; ON TYPE type_name [, ...] FROM &#123; [ GROUP ] role_name | PUBLIC &#125; [, ...] [ CASCADE | RESTRICT ] ## REVOKE [ ADMIN OPTION FOR ] role_name [, ...] FROM role_name [, ...] [ CASCADE | RESTRICT ] ## 注意：任何用户对public的schema都有all的权限，为了安全可以禁止用户对public schema ##移除所有用户（public），superuser除外，对指定DB下的public schema的create 权限。 zjy&#x3D;# revoke create on schema public from public; REVOKE 修改用户属性 ALTER USER role_specification [ WITH ] option [ ... ] where option can be: SUPERUSER | NOSUPERUSER | CREATEDB | NOCREATEDB | CREATEROLE | NOCREATEROLE | INHERIT | NOINHERIT | LOGIN | NOLOGIN | REPLICATION | NOREPLICATION | BYPASSRLS | NOBYPASSRLS | CONNECTION LIMIT connlimit | [ ENCRYPTED ] PASSWORD &#39;password&#39; | PASSWORD NULL | VALID UNTIL &#39;timestamp&#39; ALTER USER name RENAME TO new_name ALTER USER &#123; role_specification | ALL &#125; [ IN DATABASE database_name ] SET configuration_parameter &#123; TO | &#x3D; &#125; &#123; value | DEFAULT &#125; ALTER USER &#123; role_specification | ALL &#125; [ IN DATABASE database_name ] SET configuration_parameter FROM CURRENT ALTER USER &#123; role_specification | ALL &#125; [ IN DATABASE database_name ] RESET configuration_parameter ALTER USER &#123; role_specification | ALL &#125; [ IN DATABASE database_name ] RESET ALL where role_specification can be: role_name | CURRENT_USER | SESSION_USER 示例： 注意：option选项里的用户都可以通过alter role进行修改 修改用户为超级/非超级用户 alter role caocao with superuser&#x2F;nosuperuser; 修改用户为可/不可登陆用户 alter role caocao with nologin&#x2F;login; 修改用户名： alter role caocao rename to youxing; 修改用户密码，移除密码用NULL alter role youxing with password &#39;youxing&#39;; 修改用户参数，该用户登陆后的以该参数为准 alter role zjy in database zjy SET geqo to 0&#x2F;default; 控制访问文件 pg_hba.conf local database user auth-method [auth-options] host database user address auth-method [auth-options] hostssl database user address auth-method [auth-options] hostnossl database user address auth-method [auth-options] host database user IP-address IP-mask auth-method [auth-options] hostssl database user IP-address IP-mask auth-method [auth-options] hostnossl database user IP-address IP-mask auth-method [auth-options] local：匹配使用Unix域套接字的连接，如果没有此类型的记录，则不允许使用Unix域套接字连接。 host：匹配使用TCP/IP进行的连接，主机记录匹配SSL或非SSL连接，需要配置listen_addresses。 hostssl：匹配使用TCP/IP进行的连接，仅限于使用SSL加密进行连接，需要配置ssl参数。 hostnossl：匹配通过TCP/IP进行的连接，不使用SSL的连接。 database：匹配的数据库名称，all指定它匹配所有数据库。如果请求的数据库与请求的用户具有相同的名称则可以使用samerole值。复制（replication）不指定数据库，多个数据库可以用逗号分隔。 user：匹配的数据库用户名，值all指定它匹配所有用户。 可以通过用逗号分隔来提供多个用户名。 address：匹配的客户端计算机地址，可以包含主机名，IP地址范围。如：172.20.143.89/32、172.20.143.0/24、10.6.0.0/16、:: 1/128。 0.0.0.0/0表示所有IPv4地址，:: 0/0表示所有IPv6地址。要指定单个主机，请使用掩码长度32（对于IPv4）或128（对于IPv6）。all以匹配任何IP地址。 IP-address、IP-mask：这两个字段可用作IP地址/掩码长度，如：127.0.0.1 255.255.255.255。 auth-method：指定连接与此记录匹配时要使用的身份验证方法：trust、reject、scram-sha-256、md5、password、gss、sspi、ident、peer、ldap、radius、cert、pam、bsd。 trust：允许无条件连接，允许任何PostgreSQL用户身份登录，而无需密码或任何其他身份验证。 reject：拒绝任何条件连接，这对于从组中“过滤掉”某些主机非常有用。 scram-sha-256：执行SCRAM-SHA-256身份验证以验证用户的密码。 md5：执行SCRAM-SHA-256或MD5身份验证以验证用户的密码。 password：要提供未加密的密码以进行身份验证。由于密码是通过网络以明文形式发送的，因此不应在不受信任的网络上使用。 gss：使用GSSAPI对用户进行身份验证，这仅适用于TCP &#x2F; IP连接。 sspi：使用SSPI对用户进行身份验证，这仅适用于Windows。 ident：通过联系客户端上的ident服务器获取客户端的操作系统用户名，并检查它是否与请求的数据库用户名匹配。 Ident身份验证只能用于TCP &#x2F; IP连接。为本地连接指定时，将使用对等身份验证。 peer：从操作系统获取客户端的操作系统用户名，并检查它是否与请求的数据库用户名匹配。这仅适用于本地连接。 ldap：使用LDAP服务器进行身份验证。 radius：使用RADIUS服务器进行身份验证。 cert：使用SSL客户端证书进行身份验证。 pam：使用操作系统提供的可插入身份验证模块（PAM）服务进行身份验证。 bsd：使用操作系统提供的BSD身份验证服务进行身份验证。 auth-options：在auth-method字段之后，可以存在name = value形式的字段，用于指定认证方法的选项。 例子： # TYPE DATABASE USER ADDRESS METHOD local all all trust --在本地允许任何用户无密码登录 local all all peer --操作系统的登录用户和pg的用户是否一致，一致则可以登录 local all all ident --操作系统的登录用户和pg的用户是否一致，一致则可以登录 host all all 192.168.163.0&#x2F;24 md5 --指定客户端IP访问通过md5身份验证进行登录 host all all 192.168.163.132&#x2F;32 password --指定客户端IP通过passwotd身份验证进行登录 host all all 192.168.54.1&#x2F;32 reject host all all 192.168.0.0&#x2F;16 ident host all all 127.0.0.1 255.255.255.255 trust ... 设置完之后可以通过查看表来查看hba： zjy&#x3D;# select * from pg_hba_file_rules; line_number | type | database | user_name | address | netmask | auth_method | options | error -------------+-------+---------------+-----------+---------------+-----------------------------------------+-------------+---------+------- 87 | host | &#123;all&#125; | &#123;all&#125; | 192.168.163.0 | 255.255.255.0 | md5 | | 92 | local | &#123;all&#125; | &#123;all&#125; | | | peer | | 94 | host | &#123;all&#125; | &#123;all&#125; | 127.0.0.1 | 255.255.255.255 | md5 | | 96 | host | &#123;all&#125; | &#123;all&#125; | ::1 | ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff | md5 | | 99 | local | &#123;replication&#125; | &#123;all&#125; | | | peer | | 100 | host | &#123;replication&#125; | &#123;all&#125; | 127.0.0.1 | 255.255.255.255 | md5 | | 101 | host | &#123;replication&#125; | &#123;all&#125; | ::1 | ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff | md5 | | 当然，修改完pg_hba.conf文件之后，需要重新加载配置，不用重启数据库： postgres&#x3D;# select pg_reload_conf(); pg_reload_conf ---------------- t 日常使用 用户权限管理涉及到的东西很多，本文也只是大致说明了一小部分，大部分的还得继续学习。那么现在按照一个正常项目上线的流程来创建一个应用账号为例，看看需要怎么操作。 比如一个项目zjy上线：用管理账号来操作 创建数据库： postgres&#x3D;# create database zjy; CREATE DATABASE 创建账号：账号和数据库名字保持一致（search_path） postgres&#x3D;# create user zjy with password &#39;zjy&#39;; CREATE ROLE 创建schema：不能用默认的public的schma postgres&#x3D;# \\c zjy You are now connected to database &quot;zjy&quot; as user &quot;postgres&quot;. zjy&#x3D;# create schema zjy; CREATE SCHEMA 授权： #访问库 zjy&#x3D;# grant connect on database zjy to zjy; GRANT #访问schmea zjy&#x3D;# grant usage on schema zjy to zjy; GRANT #访问表 zjy&#x3D;# grant select,insert,update,delete on all tables in schema zjy to zjy; GRANT #如果访问自增序列，需要授权 zjy&#x3D;# grant select,update on all sequences in schema zjy to zjy; GRANT 注意：上面的授权只对历史的一些对象授权，后期增加的对象是没有权限的，需要给个默认权限 #默认表权限 zjy&#x3D;# ALTER DEFAULT PRIVILEGES IN SCHEMA zjy GRANT select,insert,update,delete ON TABLES TO zjy; ALTER DEFAULT PRIVILEGES #默认自增序列权限 zjy&#x3D;# ALTER DEFAULT PRIVILEGES IN SCHEMA zjy GRANT select,update ON sequences TO zjy; ALTER DEFAULT PRIVILEGES 常用命令 查看当前用户javascript:void(0);) zjy&#x3D;# \\du List of roles Role name | Attributes | Member of -----------+------------------------------------------------------------+----------- admin | Superuser, Cannot login | &#123;&#125; postgres | Superuser, Create role, Create DB, Replication, Bypass RLS | &#123;&#125; zjy | | &#123;&#125; zjy&#x3D;# select * from pg_roles; rolname | rolsuper | rolinherit | rolcreaterole | rolcreatedb | rolcanlogin | rolreplication | rolconnlimit | rolpassword | rolvaliduntil | rolbypassrls | rolconfig | oid ----------------------+----------+------------+---------------+-------------+-------------+----------------+--------------+-------------+---------------+--------------+-----------+------- pg_signal_backend | f | t | f | f | f | f | -1 | ******** | | f | | 4200 postgres | t | t | t | t | t | t | -1 | ******** | | t | | 10 admin | t | t | f | f | f | f | -1 | ******** | | f | | 16456 pg_read_all_stats | f | t | f | f | f | f | -1 | ******** | | f | | 3375 zjy | f | t | f | f | t | f | -1 | ******** | | f | | 16729 pg_monitor | f | t | f | f | f | f | -1 | ******** | | f | | 3373 pg_read_all_settings | f | t | f | f | f | f | -1 | ******** | | f | | 3374 pg_stat_scan_tables | f | t | f | f | f | f | -1 | ******** | | f | | 3377 (8 rows) 查看用户权限javascript:void(0);) zjy&#x3D;# select * from information_schema.table_privileges where grantee&#x3D;&#39;zjy&#39;; grantor | grantee | table_catalog | table_schema | table_name | privilege_type | is_grantable | with_hierarchy ----------+---------+---------------+--------------+------------+----------------+--------------+---------------- postgres | zjy | zjy | zjy | zjy | INSERT | NO | NO postgres | zjy | zjy | zjy | zjy | SELECT | NO | YES postgres | zjy | zjy | zjy | zjy | UPDATE | NO | NO postgres | zjy | zjy | zjy | zjy | DELETE | NO | NO postgres | zjy | zjy | zjy | zjy1 | INSERT | NO | NO postgres | zjy | zjy | zjy | zjy1 | SELECT | NO | YES postgres | zjy | zjy | zjy | zjy1 | UPDATE | NO | NO postgres | zjy | zjy | zjy | zjy1 | DELETE | NO | NO postgres | zjy | zjy | zjy | zjy2 | INSERT | NO | NO postgres | zjy | zjy | zjy | zjy2 | SELECT | NO | YES postgres | zjy | zjy | zjy | zjy2 | UPDATE | NO | NO postgres | zjy | zjy | zjy | zjy2 | DELETE | NO | NO postgres | zjy | zjy | zjy | zjy3 | INSERT | NO | NO postgres | zjy | zjy | zjy | zjy3 | SELECT | NO | YES postgres | zjy | zjy | zjy | zjy3 | UPDATE | NO | NO postgres | zjy | zjy | zjy | zjy3 | DELETE | NO | NO","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos安装vnc","date":"2020-09-15T01:32:57.000Z","path":"posts/undefined.html","text":"","tags":[]},{"title":"centos8扩容root分区","date":"2020-09-05T13:40:23.000Z","path":"posts/undefined.html","text":"扩展磁盘最近使用虚拟机的方式弄了个centos8的虚拟机，体验最新centos系统，分配了127g的空间，由于实际需要，发现home空间有好几十g的空间，而我都是使用root用户，无需home空间，因此找到在centos8中把home空间调整到root的方法，这里跟网上找到的centos7是有差别的。 步骤： 使用usb系统进入修复 使用df-h查看空间使用情况，备份home 卸载home文件系统 删除/home所在的lv 扩展/root所在的lv 扩展/root文件系统 重新创建home lv并挂载home 查看最终调整结果 使用df-lh查看空间使用情况，备份home首先登陆ssh，使用df -lh查看空间使用情况 df -lh root已经不够了，而vps也就自己一个人用，根本不需要用到home，home设置1个g就够了，其余的都给root，这样就可以给root多出来73个g的空间。 这因为一开始没有截图，所以看到的是后面的1g大小，一开始home是74g大小的。 备份home文件到/tmp目录 tar cvf /tmp/home.tar /home # zip -r /tmp/home.zip /home 卸载home文件系统fuser -km /home/ umount /home 解除home目录的占用，卸载home目录 删除/home所在的lv这一步centos8有很大不同，因为centos7中目录是/dev/mapper/centos-home,而在centos8中为 /dev/mapper/cl-home，因此注意卸载设备名称 lvremove /dev/mapper/cl-home 扩展/root所在的lv扩展root空间lv lvextend -L +73G /dev/mapper/cl-root 扩展/root文件系统这一步是真正增加root空间，centos7和centos8具有非常大的差别，centos7中是使用xfs_growfs /dev/mapper/centos-root，按逻辑centos8就应该是 xfs_growfs /dev/mapper/cl-root，但是结果就是 xfs_growfs /dev/mapper/cl-root 经过摸索发现应该直接使用/就可以了 xfs_growfs / 重新创建home lv并挂载home创建1g空间的home lvcreate -L 1G -n home cl 文件系统类型设置 mkfs.xfs /dev/cl/home 挂载到home目录 mount /dev/cl/home /home 恢复home目录下文件 mv /tmp/home.tar /home cd /home tar xvf home.tar mv home/* . rm -rf home* 查看最终调整结果查看各分区大小 df -lh 总结：本文主要介绍了在centos8系统下调整各分区大小，这里就是/home分区和/root分区，介绍在centos7和centos8下参数差异。熟悉linux系统下的文件系统的分区调整。对于刚装系统分区不合适需要调整centos各分区大小的用户起到指导作用，有疑问再邮件联系吧。 lvm修改根分区大小 参考： 减小lvm根分区容量: http://kwokchivu.blog.51cto.com/1128937/724128 CentOS 5 LVM逻辑卷管理: http://sunshyfangtian.blog.51cto.com/1405751/860018 目标home、根各为50GB空间，根空间不足，需缩小home至10GB、扩大根为90GB。 lvm&gt; lvscan ACTIVE &#39;&#x2F;dev&#x2F;vg_db&#x2F;lv_root&#39; [50.00 GiB] inherit ACTIVE &#39;&#x2F;dev&#x2F;vg_db&#x2F;lv_home&#39; [50.00 GiB] inherit ACTIVE &#39;&#x2F;dev&#x2F;vg_db&#x2F;lv_swap&#39; [9.83 GiB] inherit 缩小home、增大根分区进入rescue模式增大root分区是否可以在线完成、不用进rescue状态？找机会试试... 从Linux安装光盘启动进入rescue模式； 选择相关的语言，键盘模式，当系统提示启用网络设备时，选择“NO”； 然后在提示允许rescue模式挂载本地Linux系统到/mnt/sysimage下时选择“Skip”，文件系统必须不被挂载才可以对/分区减小容量操作。 最后系统会提示选择进入shell终端还是reboot机器，选择进入shell终端。 激活分区输入lvm命令，进入lvm界面，依次输入pvscan、vgscan、lvscan三个命令扫描pv、vg、lv相关信息。 然后输入lvchange -ay /dev/vg_db/lv_root（上文提到的/分区名称）此命令是激活/分区所在的逻辑卷，输入 quit返回到bash shell界面。 lvchange -ay &#x2F;dev&#x2F;vg_db&#x2F;lv_home lvchange -ay &#x2F;dev&#x2F;vg_db&#x2F;lv_root 缩小home分区 先检查下分区: e2fsck -f /dev/vg_db/lv_home 缩小文件系统大小：resize2fs /dev/vg_db/lv_home 10G 缩小逻辑卷 输入lvm命令进入lvm模式 缩小逻辑卷：lvreduce -L 10G /dev/vg_db/lv_home 系统会询问是否缩小逻辑卷，输入 y 确定。 查看修改结果: vgdisplay，lvdisplay 减小LVM中的文件系统必须离线操作(处于umount装态)，要减小文件系统和LV: # Unmount相应的文件系统 # 运行磁盘检查确保卷的完整 # 减小文件系统 # 减小LV 扩大根分区 先检查下分区: e2fsck -f /dev/vg_db/lv_root 扩大逻辑卷: 输入lvm命令进入lvm模式 扩大逻辑卷：lvresize -L +40G /dev/vg_db/lv_root 更改文件系统大小 resize2fs -p /dev/vg_db/lv_root 查看修改结果: lvscan 其他操作修改swap卷大小 取消激活swap空间: swapoff 修改swap分区大小: lvresize -L 4G /dev/vg_db/lv_swap 重新格区化: mkswap -f /dev/vb_db/lv_swap 激活swap空间: swapon 新建逻辑卷lv_develop 创建逻辑卷 : lvcreate -L 2.8G -n lv_develop /dev/vb_db 创建文件系统 : mkfs.ext3 /dev/vg_db/lv_develop 增加物理盘 fdisk分区，并将分区类型为0×8e(Linux LVM) 创建物理卷PV: pvcreate /dev/hdb1 创建卷组VG: vgcreate vgtest /dev/hdb1 添加PV到VG: vgextend 创建逻辑卷LV: lvcreate -L 6000M -n mysql vgtest 创建文件系统: mkfs -t ext3 /dev/vgtest/mysql 建立新分区卷标: tune2fs –L /mysql /dev/vgtest/mysql 加载新分区: mount –t ext3 /dev/vgtest/mysql /mysql 卸载卷的顺序: umount 卸载逻辑卷:lvremove LVDEVICE 卸载卷组:vgremove VGNAME 卸载物理卷:pvremove PVDEVICE LVM分区在线扩容2011-12-19 15:24:16 http://share.blog.51cto.com/278008/745479 今天对三台服务器的LV分区进行了一次扩容。本文有点标题党嫌疑，因为只有一台服务器是在线扩容，其它两台都是先卸载再扩容的。 在线扩容的这台服务器，LV分区格式为xfs，原大小1.2TB。增加了一块硬盘，大小为1.8TB。 &#96;fdisk&#96; &#96;&#x2F;dev&#x2F;cciss&#x2F;c0d1&#96; &#96;# 创建分区，并指定分区类型为LVM (8e) &#96;&#96;pvcreate &#96;&#96;&#x2F;dev&#x2F;cciss&#x2F;c0d1p1&#96; &#96;# 创建pv&#96;&#96;vgextend VolGroup00 &#96;&#96;&#x2F;dev&#x2F;cciss&#x2F;c0d1p1&#96; &#96;# 添加新创建的pv到原有vg&#96;&#96;lvextend -L +1.8T &#96;&#96;&#x2F;dev&#x2F;mapper&#x2F;VolGroup00-LogVol05&#96; &#96;# 在线扩容指定lv分区&#96;&#96;xfs_growfs &#96;&#96;&#x2F;dev&#x2F;mapper&#x2F;VolGroup00-LogVol05&#96; &#96;# 使扩容生效。注意xfs文件系统的生效命令！ &#96; 其它两台服务器也是新增了一个1.8TB的硬盘，要扩容的LV分区格式为ext3。之所以没有进行在线扩容，是因为没有找到ext2online命令；后来发现，resize2fs也是支持在线扩容的！ &#96;lvextend -l +100%FREE &#96;&#96;&#x2F;dev&#x2F;mapper&#x2F;VolGroup00-LogVol05&#96;&#96;umount&#96; &#96;-l &#96;&#96;&#x2F;dev&#x2F;mapper&#x2F;VolGroup00-LogVol05&#96;&#96;e2fsck -f &#96;&#96;&#x2F;dev&#x2F;mapper&#x2F;VolGroup00-LogVol05&#96; &#96;# 过程比较长 &#96;&#96;resize2fs &#96;&#96;&#x2F;dev&#x2F;mapper&#x2F;VolGroup00-LogVol05&#96; &#96;# 也要几分钟时间 &#96;&#96;mount&#96; &#96;&#x2F;dev&#x2F;mapper&#x2F;VolGroup00-LogVol05&#96; &#96;&#x2F;hdfs&#96; 虽然resize2fs可以在线使用，但是对在线lv分区执行e2fsck有点风险！","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos8安装kvm","date":"2020-09-05T13:40:23.000Z","path":"posts/undefined.html","text":"如何在CentOS/RHEL 8上安装KVM虚拟化基于内核的虚拟机（简称KVM）是一种开源的标准虚拟化解决方案，已紧密集成到Linux中。它是一个可加载的内核模块，将Linux转换为Type-1（裸机）虚拟机管理程序，该虚拟机管理程序创建了用于运行虚拟机（VM）的虚拟操作平台。 精选回答在KVM下，每个VM是一个Linux进程，由内核调度和管理，并具有专用的虚拟化硬件（即CPU，网卡，磁盘等）。它还支持嵌套虚拟化，使您可以在另一个VM内运行一个VM。 它的一些主要功能包括支持广泛的Linux支持的硬件平台（带有虚拟化扩展的x86硬件（Intel VT或AMD-V）），它使用SELinux和安全虚拟化（sVirt）提供增强的VM安全性和隔离，它继承了内核内存管理功能，并且支持脱机和实时迁移（在物理主机之间迁移正在运行的VM）。 在本文中，您将学习如何在CentOS 8和RHEL 8 Linux中安装KVM虚拟化，创建和管理虚拟机。 准备工作： 全新安装的CentOS 8服务器 全新安装的RHEL 8服务器 在RHEL 8服务器上启用了RedHat订阅 此外，通过运行以下命令，确保您的硬件平台支持虚拟化。 # grep -e &#39;vmx&#39; &#x2F;proc&#x2F;cpuinfo #Intel systems # grep -e &#39;svm&#39; &#x2F;proc&#x2F;cpuinfo #AMD systems 另外，请确认内核中已加载KVM模块（默认情况下应为KVM模块）。 ＃lsmod | grep kvm 这是基于英特尔的测试系统上的示例输出： 在以前的KVM指南系列中，我们展示了如何使用KVM（基于内核的虚拟机）在Linux中创建虚拟机，并展示了如何使用virt-manager GUI工具（根据RHEL已弃用）创建和管理VM。8个文档）。对于本指南，我们将采用不同的方法，我们将使用Cockpit Web控制台。 步骤1：在CentOS 8上设置Cockpit Web控制台 1.在Cockpit是一个易于使用的集成和可扩展的基于Web的界面在网页浏览器来管理Linux服务器。它使您能够执行系统任务，例如配置网络，管理存储，创建VM和使用鼠标检查日志。它使用系统的普通用户登录名和特权，但也支持其他身份验证方法。 它是预先安装的，并已在新安装的CentOS 8和RHEL 8系统上启用，如果尚未安装，请使用以下dnf命令进行安装。应安装cockpit-machines扩展程序以管理基于Libvirt的 VM 。 # dnf install cockpit cockpit-machines 2.软件包安装完成后，启动座舱插座，使其在系统启动时自动启动，并检查其状态以确认其已启动并正在运行。 # systemctl start cockpit.socket # systemctl enable cockpit.socket # systemctl status cockpit.socket 3.接下来，使用firewall-cmd命令将cockpit服务添加到默认启用的系统防火墙中，然后重新加载防火墙配置以应用新更改。 # firewall-cmd –add-service=cockpit –permanent # firewall-cmd –reload 4.要访问CockpitWeb控制台，请打开Web浏览器并使用以下URL进行导航。 https://FQDN:9090/或者https://SERVER_IP:9090/ 该Cockpit采用的是自签名证书启用HTTPS，只需使用该连接，当你在浏览器的警告。在登录页面上，使用您的服务器用户帐户凭据。 步骤2：安装KVM虚拟化CentOS 8 5.接下来，如下安装虚拟化模块和其他虚拟化软件包。所述的virt安装包提供用于从所述命令行界面进行安装的虚拟机的工具，和一个的virt查看器用于查看虚拟机。 # dnf module install virt # dnf install virt-install virt-viewer 6.接下来，运行virt-host-validate命令以验证主机是否设置为运行libvirt系统管理程序驱动程序。 # virt-host-validate 7.接下来，启动libvirtd守护程序（libvirtd），并使它在每次引导时自动启动。然后检查其状态以确认它已启动并正在运行。 # systemctl start libvirtd.service # systemctl enable libvirtd.service # systemctl status libvirtd.service 步骤3：通过Cockpit设置网桥（虚拟网络交换机） 8.现在创建一个网桥（虚拟网络交换机），将虚拟机集成到与主机相同的网络中。默认情况下，一旦启动libvirtd守护程序，它将激活默认网络接口virbr0，该接口代表以NAT模式运行的虚拟网络交换机。 在本指南中，我们将以桥接模式创建名为br0的网络接口。这将使虚拟机可在主机网络上访问。 在座舱主界面中，单击“ 网络”，然后单击“ 添加网桥”，如以下屏幕截图所示。 9.从弹出窗口中，输入网桥名称，然后选择网桥从站或端口设备（例如，代表以太网接口的enp2s0），如以下屏幕截图所示。然后单击“ 应用”。 10.现在，当您查看“ 接口 ”列表时，新的网桥应显示在此处，几秒钟后，应禁用以太网接口（关闭）。 步骤4：通过Cockpit Web控制台创建和管理虚拟机 11.在座舱主界面中，单击“ 虚拟机”选项，如以下屏幕快照中突出显示。在“ 虚拟机”页面上，单击创建虚拟机。 12.将显示一个带有用于创建新VM的选项的窗口。输入连接，名称（例如ubuntu18.04），安装源类型（在测试系统上，我们已将ISO映像存储在存储池下，即/ var / lib / libvirt / images /），安装源，存储，大小，内存如下图所示。输入安装源后，应自动选择OS供应商和操作系统。 还要选中立即启动VM的选项，然后单击“ 创建”。 13.在上一步中单击“ 创建”后，应自动启动VM，并使用提供的ISO映像启动VM。继续安装客户机操作系统（在本例中为Ubuntu 18.04）。 如果你点击网络接口的的虚拟机，网络源应注明新建桥网络接口。 并且在安装过程中，在配置网络接口的步骤中，您应该能够注意到VM以太网接口从主机网络的DHCP服务器接收IP地址。 请注意，您需要安装OpenSSH软件包才能从主机网络上的任何计算机通过SSH访问来宾OS，如上一节所述。 14.客户机操作系统安装完成后，请重新引导VM，然后转到“ 磁盘”并分离/除去VM磁盘下的cdrom设备。然后单击“运行”以启动VM。 15.现在，在Consoles（控制台）下，您可以使用在OS安装期间创建的用户帐户登录来宾OS。 步骤5：通过SSH访问虚拟机访客操作系统 16.要通过SSH从主机网络访问新安装的来宾OS，请运行以下命令（将10.42.0.197替换为来宾的IP地址）。 $ ssh &#x74;&#101;&#99;&#109;&#105;&#x6e;&#x74;&#64;&#49;&#48;&#x2e;&#52;&#50;&#46;&#x30;&#x2e;&#49;&#57;&#x37; 17.要关闭，重新启动或删除VM，请从VM列表中单击它，然后使用以下屏幕快照中突出显示的按钮。 在本文中，介绍了如何安装KVM虚拟化软件包以及如何通过cockpit Web控制台创建和管理VM。","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos使用cockpit","date":"2020-09-05T13:40:23.000Z","path":"posts/undefined.html","text":"sudo systemctl enable --now cockpit.socket [leiakun@centos8 ~]$ sudo systemctl enable --now cockpit.socket [sudo] leiakun 的密码： Created symlink /etc/systemd/system/sockets.target.wants/cockpit.socket → /usr/lib/systemd/system/cockpit.socket. [leiakun@centos8 ~]$ [leiakun@centos8 ~]$ sudo firewall-cmd --get-services |grep cockpit RH-Satellite-6 amanda-client amanda-k5-client amqp amqps apcupsd audit bacula bacula-client bb bgp bitcoin bitcoin-rpc bitcoin-testnet bitcoin-testnet-rpc bittorrent-lsd ceph ceph-mon cfengine cockpit condor-collector ctdb dhcp dhcpv6 dhcpv6-client distcc dns dns-over-tls docker-registry docker-swarm dropbox-lansync elasticsearch etcd-client etcd-server finger freeipa-4 freeipa-ldap freeipa-ldaps freeipa-replication freeipa-trust ftp ganglia-client ganglia-master git grafana gre high-availability http https imap imaps ipp ipp-client ipsec irc ircs iscsi-target isns jenkins kadmin kdeconnect kerberos kibana klogin kpasswd kprop kshell ldap ldaps libvirt libvirt-tls lightning-network llmnr managesieve matrix mdns memcache minidlna mongodb mosh mountd mqtt mqtt-tls ms-wbt mssql murmur mysql nfs nfs3 nmea-0183 nrpe ntp nut openvpn ovirt-imageio ovirt-storageconsole ovirt-vmconsole plex pmcd pmproxy pmwebapi pmwebapis pop3 pop3s postgresql privoxy prometheus proxy-dhcp ptp pulseaudio puppetmaster quassel radius rdp redis redis-sentinel rpc-bind rsh rsyncd rtsp salt-master samba samba-client samba-dc sane sip sips slp smtp smtp-submission smtps snmp snmptrap spideroak-lansync spotify-sync squid ssdp ssh steam-streaming svdrp svn syncthing syncthing-gui synergy syslog syslog-tls telnet tentacle tftp tftp-client tile38 tinc tor-socks transmission-client upnp-client vdsm vnc-server wbem-http wbem-https wsman wsmans xdmcp xmpp-bosh xmpp-client xmpp-local xmpp-server zabbix-agent zabbix-server sudo firewall-cmd --add-service=cockpit --permanent sudo firewall-cmd --reload 多主机管理yum install -y cockpit-dashboard","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos创建用户","date":"2020-09-05T13:40:23.000Z","path":"posts/undefined.html","text":"创建用户useradd wumu ## 给用户添加组，一定要加a (FC4: usermod -G groupA,groupB,groupC user) -a 代表 append， 也就是 将自己添加到 用户组groupA 中，而不必离开 其他用户组。 #命令的所有的选项，及其含义： Options: -c, --comment COMMENT new value of the GECOS field -d, --home HOME_DIR new home directory for the user account -e, --expiredate EXPIRE_DATE set account expiration date to EXPIRE_DATE -f, --inactive INACTIVE set password inactive after expiration to INACTIVE -g, --gid GROUP force use GROUP as new primary group -G, --groups GROUPS new list of supplementary GROUPS -a, --append append the user to the supplemental GROUPS mentioned by the -G option without removing him/her from other groups -h, --help display this help message and exit -l, --login NEW_LOGIN new value of the login name -L, --lock lock the user account -m, --move-home move contents of the home directory to the new location (use only with -d) -o, --non-unique allow using duplicate (non-unique) UID -p, --password PASSWORD use encrypted password for the new password -s, --shell SHELL new login shell for the user account -u, --uid UID new UID for the user account -U, --unlock unlock the user account usermod -a -G wumugroup wumu passwd wumu 添加sudo权限visudo #找到如下行数 root ALL=(ALL) ALL #添加 username ALL=(ALL) ALL 免密码登录ssh-keygen ssh-copy-id -i .ssh/id_rsa.pub 用户名字@192.168.x.xxx ssh 用户名字@192.168.x.xxx 使用pem登录#在本地生成公钥私钥 ssh-keygen #输入命令后，一路回车，即可。 #将本地的公钥传到服务器上 ssh-copy-id -i ~/.ssh/id_rsa.pub remote-host #会提示你输入密码，成功之后，会帮助你把公钥放在服务器上，供登录使用。 #把本地的私钥转为 pem 格式，供windows上的 ssh 客户端使用 openssl rsa -in ~/.ssh/id_rsa -outform pem > id_rsa.pem chmod 700 id_rsa.pem #这样就导出了pem格式的私钥，因为公钥已经在服务器了，所以只要服务器上的公钥不删除，用这把私钥就能登录服务器,一般来说，经过这样设置之后，可以把ssh 密码登录的方式禁用掉，使得服务器更加安全。 #关闭 ssh 密码登录 vi /etc/ssh/sshd_config #修改 PasswordAuthentication no #重启 ssh 服务 service sshd restart","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"sudoer文件解析","date":"2020-09-05T13:40:23.000Z","path":"posts/undefined.html","text":"sudo的权限控制可以在/etc/sudoers文件中查看到。 如果想要控制某个用户(或某个组用户)只能执行root权限中的一部分命令, 或者允许某些用户使用sudo时不需要输入密码,就需要对该文件有所了解。 一般来说，通过cat /etc/sudoers指令来查看该文件, 会看到如下几行代码: root ALL=(ALL:ALL) ALL %wheel ALL=(ALL) ALL %sudo ALL=(ALL:ALL) ALL 对/etc/sudoers文件进行编辑的代码公式可以概括为: 授权用户/组 主机=[(切换到哪些用户或组)] [是否需要输入密码验证] 命令1,命令2,... 凡是[ ]中的内容, 都能省略; 命令和命令之间用,号分隔; 为了方便说明, 将公式的各个部分称呼为字段1 - 字段5: 授权用户/组 主机 =[(切换到哪些用户或组)] [是否需要输入密码验证] 命令1,命令2,... 字段1 字段2 =[(字段3)] [字段4] 字段5 字段3、字段4，是可以省略的。 在上面的默认例子中, “字段1”不以%号开头的表示”将要授权的用户”, 比如例子中的root；以%号开头的表示”将要授权的组”, 比如例子中的%wheel组 和 %sudo组。 “字段2”表示允许登录的主机, ALL表示所有; 如果该字段不为ALL,表示授权用户只能在某些机器上登录本服务器来执行sudo命令. 比如: jack mycomputer=/usr/sbin/reboot,/usr/sbin/shutdown 表示: 普通用户jack在主机(或主机组)mycomputer上, 可以通过sudo执行reboot和shutdown两个命令。”字段3”和”字段4”省略。 “字段3”如果省略, 相当于(root:root)，表示可以通过sudo提权到root; 如果为(ALL)或者(ALL:ALL), 表示能够提权到(任意用户:任意用户组)。 请注意，”字段3”如果没省略,必须使用( )双括号包含起来。这样才能区分是省略了”字段3”还是省略了”字段4”。 “字段4”的可能取值是NOPASSWD:。请注意NOPASSWD后面带有冒号:。表示执行sudo时可以不需要输入密码。比如: lucy ALL=(ALL) NOPASSWD: /bin/useradd 表示: 普通用户lucy可以在任何主机上, 通过sudo执行/bin/useradd命令, 并且不需要输入密码. 又比如: peter ALL=(ALL) NOPASSWD: ALL 表示: 普通用户peter可以在任何主机上, 通过sudo执行任何命令, 并且不需要输入密码。 “字段5”是使用逗号分开一系列命令,这些命令就是授权给用户的操作; ALL表示允许所有操作。 你可能已经注意到了, 命令都是使用绝对路径, 这是为了避免目录下有同名命令被执行，从而造成安全隐患。 如果你将授权写成如下安全性欠妥的格式: lucy ALL&#x3D;(ALL) chown,chmod,useradd 那么用户就有可能创建一个他自己的程序, 也命名为userad, 然后放在它的本地路径中, 如此一来他就能够使用root来执行这个”名为useradd的程序”。这是相当危险的! 命令的绝对路径可通过which指令查看到: 比如which useradd可以查看到命令useradd的绝对路径: /usr/sbin/useradd 公式还要扩充例子1: papi ALL=(root) NOPASSWD: /bin/chown,/usr/sbin/useradd 表示: 用户papi能在所有可能出现的主机上, 提权到root下执行/bin/chown, 不必输入密码; 但运行/usr/sbin/useradd 命令时需要密码. 这是因为NOPASSWD:只影响了其后的第一个命令: 命令1. 上面给出的公式只是简化版，完整的公式如下: 授权用户/组 主机=[(切换到哪些用户或组)] [是否需要输入密码验证] 命令1, [(字段3)] [字段4] 命令2, ... 在具有sudo操作的用户下, 执行sudo -l可以查看到该用户被允许和被禁止运行的命令. 通配符和取消命令例子2: papi ALL&#x3D;&#x2F;usr&#x2F;sbin&#x2F;*,&#x2F;sbin&#x2F;*,!&#x2F;usr&#x2F;sbin&#x2F;fdisk 用例子2来说明通配符*的用法, 以及命令前面加上!号表示取消该命令。 该例子的意思是: 用户papi在所有可能出现的主机上, 能够运行目录/usr/sbin和/sbin下所有的程序, 但fdisk除外. 开始编辑“你讲了这么多,但是在实践中,我去编辑/etc/sudoers文件，系统提示我没权限啊，怎么办?” 这是因为/etc/sudoers的内容如此敏感，以至于该文件是只读的。所以，编辑该文件前，请确认清楚你知道自己正在做什么。 强烈建议通过visudo命令来修改该文件，通过visudo修改，如果配置出错，会有提示。 不过，系统文档推荐的做法，不是直接修改/etc/sudoers文件，而是将修改写在/etc/sudoers.d/目录下的文件中。 如果使用这种方式修改sudoers，需要在/etc/sudoers文件的最后行，加上#includedir /etc/sudoers.d一行(默认已有): #includedir &#x2F;etc&#x2F;sudoers.d 注意了，这里的指令#includedir是一个整体, 前面的#号不能丢，并非注释，也不能在#号后有空格。 任何在/etc/sudoers.d/目录下，不以~号结尾的文件和不包含.号的文件，都会被解析成/etc/sudoers的内容。 文档中是这么说的: # This will cause sudo to read and parse any files in the /etc/sudoers.d # directory that do not end in '~' or contain a '.' character. # Note that there must be at least one file in the sudoers.d directory (this # one will do), and all files in this directory should be mode 0440. # Note also, that because sudoers contents can vary widely, no attempt is # made to add this directive to existing sudoers files on upgrade. # Finally, please note that using the visudo command is the recommended way # to update sudoers content, since it protects against many failure modes. 其他小知识输入密码时有反馈当使用sudo后输入密码，并不会显示任何东西 —— 甚至连常规的星号都没有。有个办法可以解决该问题。 打开/etc/sudoers文件找到下述一行: Defaults env_reset 修改成: Defaults env_reset,pwfeedback 修改sudo会话时间如果你经常使用sudo 命令，你肯定注意到过当你成功输入一次密码后，可以不用再输入密码就可以运行几次sudo命令。但是一段时间后，sudo 命令会再次要求你输入密码。默认是15分钟，该时间可以调整。添加timestamp_timeout=分钟数即可。时间以分钟为单位，-1表示永不过期，但强烈不推荐。 比如我希望将时间延长到1小时，还是打开/etc/sudoers文件找到下述一行: Defaults env_reset 修改成: Defaults env_reset,pwfeedback,timestamp_timeout=60","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos配置网络","date":"2020-09-05T13:40:23.000Z","path":"posts/undefined.html","text":"centos8已经发布了，下载了一个体验一下，新安装好的centos8默认网卡是没有启动的，安装好后需要先配置网络。在/etc/sysconfig/network-scripts目录下存放着网卡的配置文件，文件名称是ifcfg- 网卡名称。 一 修改配置文件设置网络时首先打开配置文件，配置文件默认如下所示，如果使用dhcp自动获取ip，只需将ONBOOT=no修改为ONBOOT=no即可。 # 网卡配置文件按默认配置 TYPE&#x3D;Ethernet PROXY_METHOD&#x3D;none BROWSER_ONLY&#x3D;no BOOTPROTO&#x3D;dhcp DEFROUTE&#x3D;yes IPV4_FAILURE_FATAL&#x3D;no IPV6INIT&#x3D;yes IPV6_AUTOCONF&#x3D;yes IPV6_DEFROUTE&#x3D;yes IPV6_FAILURE_FATAL&#x3D;no IPV6_ADDR_GEN_MODE&#x3D;stable-privacy NAME&#x3D;ens33 UUID&#x3D;e4987998-a4ce-4cef-96f5-a3106a97f5bf DEVICE&#x3D;ens33 ONBOOT&#x3D;no #如果使用dhcp分配ip的话，只需要将这里no改为yes，然后重启网络服务就行 如果需要配置静态ip，则按照以下修改方法修改 TYPE&#x3D;Ethernet PROXY_METHOD&#x3D;none BROWSER_ONLY&#x3D;no BOOTPROTO&#x3D;static #将dhcp修改为stati表示使用静态ip DEFROUTE&#x3D;yes IPADDR&#x3D;192.168.128.129 #设置IP地址 NETMASK&#x3D;255.255.255.0 #设置子网掩码 GATEWAY&#x3D;192.168.128.1 #设置网关 DNS1&#x3D;114.114.114.114 #设置dns IPV4_FAILURE_FATAL&#x3D;no IPV6INIT&#x3D;yes IPV6_AUTOCONF&#x3D;yes IPV6_DEFROUTE&#x3D;yes IPV6_FAILURE_FATAL&#x3D;no IPV6_ADDR_GEN_MODE&#x3D;stable-privacy NAME&#x3D;ens33 UUID&#x3D;e4987998-a4ce-4cef-96f5-a3106a97f5bf DEVICE&#x3D;ens33 ONBOOT&#x3D;yes #将no改为yes 二 重启网络服务使用nmcli c reload命令重启网络服务，网络这块算是centos8改动较大的一块了，nmcli命令的参数如下所示： [hk@localhost network-scripts]$ nmcli -h Usage: nmcli [OPTIONS] OBJECT &#123; COMMAND | help &#125; OPTIONS -o[verview] overview mode (hide default values) -t[erse] terse output -p[retty] pretty output -m[ode] tabular|multiline output mode -c[olors] auto|yes|no whether to use colors in output -f[ields] &lt;field1,field2,...&gt;|all|common specify fields to output -g[et-values] &lt;field1,field2,...&gt;|all|common shortcut for -m tabular -t -f -e[scape] yes|no escape columns separators in values -a[sk] ask for missing parameters -s[how-secrets] allow displaying passwords -w[ait] &lt;seconds&gt; set timeout waiting for finishing operations -v[ersion] show program version -h[elp] print this help OBJECT g[eneral] NetworkManager&#39;s general status and operations n[etworking] overall networking control r[adio] NetworkManager radio switches c[onnection] NetworkManager&#39;s connections # 网络管理一般使用 nmcli c d[evice] devices managed by NetworkManager a[gent] NetworkManager secret agent or polkit agent m[onitor] monitor NetworkManager changes [hk@localhost network-scripts]$ 网络管理一般使用 nmclli c，用法如下： [hk@localhost network-scripts]$ nmcli c -h Usage: nmcli connection &#123; COMMAND | help &#125; COMMAND :&#x3D; &#123; show | up | down | add | modify | clone | edit | delete | monitor | reload | load | import | export &#125; show [--active] [--order &lt;order spec&gt;] show [--active] [id | uuid | path | apath] &lt;ID&gt; ... up [[id | uuid | path] &lt;ID&gt;] [ifname &lt;ifname&gt;] [ap &lt;BSSID&gt;] [passwd-file &lt;file with passwords&gt;] down [id | uuid | path | apath] &lt;ID&gt; ... add COMMON_OPTIONS TYPE_SPECIFIC_OPTIONS SLAVE_OPTIONS IP_OPTIONS [-- ([+|-]&lt;setting&gt;.&lt;property&gt; &lt;value&gt;)+] modify [--temporary] [id | uuid | path] &lt;ID&gt; ([+|-]&lt;setting&gt;.&lt;property&gt; &lt;value&gt;)+ clone [--temporary] [id | uuid | path ] &lt;ID&gt; &lt;new name&gt; edit [id | uuid | path] &lt;ID&gt; edit [type &lt;new_con_type&gt;] [con-name &lt;new_con_name&gt;] delete [id | uuid | path] &lt;ID&gt; monitor [id | uuid | path] &lt;ID&gt; ... reload load &lt;filename&gt; [ &lt;filename&gt;... ] import [--temporary] type &lt;type&gt; file &lt;file to import&gt; export [id | uuid | path] &lt;ID&gt; [&lt;output file&gt;] [hk@localhost network-scripts]$","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos8安装docker","date":"2020-09-05T13:40:23.000Z","path":"posts/undefined.html","text":"下载docker-ce的repo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo 安装 dnf install docker-ce --nobest -y 运行 systemctl start docker systemctl enable docker docker --version 安装docker-compose dnf install curl -y curl -L https://github.com/docker/compose/releases/download/1.25.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose docker-compose --version","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"网络配置三种模式对比（桥接模式，主机模式，网络地址转换）","date":"2020-08-27T10:29:58.000Z","path":"posts/undefined.html","text":"VMware三种网络模式简介​ VMWare提供了三种工作模式，它们是bridged(桥接模式)、NAT(网络地址转换模式)和host-only(主机模式)。安装好虚拟机以后，在网络连接里面可以看到多了两块网卡。如下图。 1 bridged(桥接模式)1.1 模式简介 在这种模式下，VMWare虚拟出来的操作系统就像是局域网中的一台独立的主机，它可以访问网内任何一台机器。 在桥接模式下，你需要手工为虚拟系统配置IP地址、子网掩码，而且还要和宿主机器处于同一网段，这样虚拟系统才能和宿主机器进行通信。同时，由 于这个虚拟系统是局域网中的一个独立的主机系统，那么就可以手工配置它的TCP/IP配置信息，以实现通过局域网的网关或路由器访问互联网。 使用桥接模式的虚拟系统和宿主机器的关系，就像连接在同一个Hub上的两台电脑。想让它们相互通讯，你就需要为虚拟系统配置IP地址和子网掩码，否则就无法通信。 1.2 工作的虚拟网卡​ bridged模式下的VMnet0虚拟网络 1.3 架构图1）使用VMnet0虚拟交换机，此时虚拟机相当与网络上的一台独立计算机与主机一样，拥有一个独立的IP地址。使用桥接方式，A，A1，A2，B可互访。 2）虚拟机就像一台真正的计算机一样，直接连接到实际的网络上，可以理解为与宿主机没有任何联系。 1.4 使用范围​ 1）如果你想利用VMWare在局域网内新建一个虚拟服务器，为局域网用户提供网络服务，就应该选择桥接模式。 2）如果你有路由器的话，那么就可以使用桥接方式上网，因为此时你申请的IP地址是写在了路由器上，而不是你的机器上，这样包括你的主机，虚拟机，也包括 连在路由器上的其他人的机器，都将可以上网，使用着由路由器分配的IP地址。 2 host-only(主机模式)2.1 模式简介​ 在某些特殊的网络调试环境中，要求将真实环境和虚拟环境隔离开，这时你就可采用host-only模式。在host-only模式中，所有的虚拟系统是可以相互通信的，但虚拟系统和真实的网络是被隔离开的。 提示：在host-only模式下，虚拟系统和宿主机器系统是可以相互通信的，相当于这两台机器通过双绞线互连。 在host-only模式下，虚拟系统的TCP/IP配置信息(如IP地址、网关地址、DNS服务器等)，都是由VMnet1(host-only)虚拟网络的DHCP服务器来动态分配的。 如果你想利用VMWare创建一个与网内其他机器相隔离的虚拟系统，进行某些特殊的网络调试工作，可以选择host-only模式。 Linux虚拟机实现Host-only方式上网 2.2 工作的虚拟网卡 host-only模式下的 VMnet1虚拟网络 2.3 架构图1）使用Vmnet1虚拟交换机，此时虚拟机只能与虚拟机、主机互访。也就是不能上Internet。使用Host方式，A，A1，A2可以互访，但A1，A2不能访问B，也不能被B访问。 2）这种方式下，虚拟机的网卡连接到宿主的 VMnet1 上，但系统并不为虚拟机提供任何路由服务，因此虚拟机只能和宿主机进行通信，而不能连接到实际网络上。 2.4 使用范围 如果你想利用VMWare创建一个与网内其他机器相隔离的虚拟系统，进行某些特殊的网络调试工作，可以选择host-only模式。 3 NAT(网络地址转换模式)3.1 模式简介​ 使用NAT模式，就是让虚拟系统借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。也就是说，使用NAT模式可以实现在虚拟 系统里访问互联网。NAT模式下的虚拟系统的TCP/IP配置信息是由VMnet8(NAT)虚拟网络的DHCP服务器提供的，无法进行手工修改，因此虚拟系统也就无法和本局域网中的其他真实主机进行通讯。采用NAT模式最大的优势是虚拟系统接入互联网非常简单，你不需要进行任何其他的配置，只需要宿主机 器能访问互联网即可。 3.2 工作的虚拟网卡 NAT模式下的VMnet8虚拟网络 3.3 架构图1） 使用Vmnet8虚拟交换机，此时虚拟机可以通过主机单向网络上的其他工作站，其他工作站不能访问虚拟机。用NAT方式，A1，A2可以访问B，但B不可以访问A1，A2。但A，A1，A2可以互访。 2） 这种方式下，虚拟机的网卡连接到宿主的 VMnet8 上。此时系统的 VMWare NAT Service 服务就充当了路由器的作用，负责将虚拟机发到 VMnet8 的包进行地址转换之后发到实际的网络上，再将实际网络上返回的包进行地址转换后通过 VMnet8 发送给虚拟机。VMWare DHCP Service 负责为虚拟机提供 DHCP 服务。 3.4 使用范围​ 如果你想利用VMWare安装一个新的虚拟系统，在虚拟系统中不用进行任何手工配置就能直接访问互联网，建议你采用NAT模式。 参考https://blog.csdn.net/CleverCode/article/details/45934233","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"docker-compose文件编写","date":"2020-08-27T10:10:37.000Z","path":"posts/undefined.html","text":"","tags":[]},{"title":"SpringBoot+Quartz框架的实现","date":"2020-08-14T10:39:29.000Z","path":"posts/undefined.html","text":"定时任务 想必做程序的都或多或少的接触过,以便于我们以某个特定的 时间/频率 去执行所需要的程序,Quartz 是一个优秀的框架,可以根据我们的配置将 定时任务的执行 时间/频率 持久化至数据库, 我们通过修改数据库中的任务下次执行时间,达到不需要等到任务配置执行的原始 时间/频率,随时地运行定时任务; 并且可以看到任务的运行状态 WATING BLOCKING等 1.导入依赖 quartz自定义配置的数据源会使用C3P0创建连接,所以要引入C3P0依赖 &lt;!-- Quartz定时任务 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-quartz&lt;/artifactId> &lt;/dependency> &lt;!--C3P0 --> &lt;dependency> &lt;groupId>com.mchange&lt;/groupId> &lt;artifactId>c3p0&lt;/artifactId> &lt;version>0.9.5.5&lt;/version> &lt;/dependency> 2.quartz 配置文件,yml方式 创建定时任务表的sql太长,这里就不贴了,我会将sql上传至GitHub,文末我会贴地址 ## quartz定时任务 spring: quartz: #jdbc 采用数据库方式 memory 采用内存方式 job-store-type: jdbc initialize-schema: embedded #设置自动启动，默认为 true auto-startup: true #启动时更新己存在的Job overwrite-existing-jobs: true properties: org: quartz: scheduler: instanceName: MyScheduler instanceId: AUTO jobStore: #指定使用的JobStore class: org.quartz.impl.jdbcjobstore.JobStoreTX driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate #数据库前缀 tablePrefix: QRTZ_ #是否为集群 isClustered: false #检测任务执行时间的间隔 毫秒 misfireThreshold: 5000 clusterCheckinInterval: 10000 #数据源名称 dataSource: myDS #线程池配置 threadPool: class: org.quartz.simpl.SimpleThreadPool threadCount: 20 threadPriority: 5 threadsInheritContextClassLoaderOfInitializingThread: true #数据源 dataSource: myDS: driver: com.mysql.cj.jdbc.Driver URL: jdbc:mysql://localhost:3306/test?characterEncoding=UTF-8&amp;useUnicode=true&amp;useSSL=false&amp;tinyInt1isBit=false&amp;serverTimezone=Asia/Shanghai user: root password: root maxConnections: 5 有同学可能会问了,配置文件是配置好了,是在哪引用的呢? 别急, 且听我娓娓道来 spring-boot-starter-quartz (为方便诉说,下文中使用 bootquartz代替) 这个包下的QuartzProperties会帮我们自动加载配置文件,且看以下部分截图 可以看到, QuartzProperties 使用了 @ConfigurationProperties 加载了 spring.quartz 前缀的配置,也就是上面我们的配置文件中的配置;加载之后呢, bootquartz包下有 类 QuartzAutoConfiguration, 看名字就可以知道,这个就是自动配置 quartz的类了. 所以我们不需要再去通过代码去配置 SchedulerFactoryBean 了,这是后话 QuartzAutoConfiguration 类注释 通过上面的截图我们发现,这里引用了 QuartzProperties 其中的 quartzScheduler()方法帮助我们创建了 SchedulerFactoryBean 并使用了** **QuartzProperties 中的自定义配置,以下是quartzScheduler()部分代码 @Bean @ConditionalOnMissingBean public SchedulerFactoryBean quartzScheduler() &#123; SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); if (!this.properties.getProperties().isEmpty()) &#123; schedulerFactoryBean .setQuartzProperties(asProperties(this.properties.getProperties())); &#125; customize(schedulerFactoryBean); return schedulerFactoryBean; &#125; 姑且一提,方法中调用了 customize(SchedulerFactoryBean schedulerFactoryBean) 方法,这个方法会寻找实现了 SchedulerFactoryBeanCustomizer 接口的配置类,在其实现方法 customize(SchedulerFactoryBean schedulerFactoryBean)中 可对 SchedulerFactoryBean 使用代码自定义配置 坑那么到这里结束了吗?不! 这里还有本文中最大的一个坑,作者深受其扰,扒了两天的源码才找到这个问题!!! 如果我们的项目中有其它的默认数据源,那么quartz会忽略配置文件中自定义数据源,使用默认数据源,原因看以下源码 首先是 QuartzAutoConfiguration 中的 静态内部类 JdbcStoreTypeConfiguration @Configuration @ConditionalOnSingleCandidate(DataSource.class) protected static class JdbcStoreTypeConfiguration &#123; @Bean @Order(0) public SchedulerFactoryBeanCustomizer dataSourceCustomizer( QuartzProperties properties, DataSource dataSource, @QuartzDataSource ObjectProvider&lt;DataSource> quartzDataSource, ObjectProvider&lt;PlatformTransactionManager> transactionManager) &#123; return (schedulerFactoryBean) -> &#123; if (properties.getJobStoreType() == JobStoreType.JDBC) &#123; //重点在这里 begin DataSource dataSourceToUse = getDataSource(dataSource, quartzDataSource); schedulerFactoryBean.setDataSource(dataSourceToUse); //重点在这里 end PlatformTransactionManager txManager = transactionManager.getIfUnique(); if (txManager != null) &#123; schedulerFactoryBean.setTransactionManager(txManager); &#125; &#125; &#125;; &#125; private DataSource getDataSource(DataSource dataSource, ObjectProvider&lt;DataSource> quartzDataSource) &#123; DataSource dataSourceIfAvailable = quartzDataSource.getIfAvailable(); return (dataSourceIfAvailable != null) ? dataSourceIfAvailable : dataSource; &#125; 其中的getDataSource 方法判断了我们项目中的 quartzDataSource是否为空,如果为空,那么就使用默认的数据源;quartzDataSource怎么才能不为空呢? 可以看到dataSourceCustomizer 方法参数中有 @QuartzDataSource 注解, 这个注解会去寻找我们项目中使用@QuartzDataSource配置的数据源,但是 我都已经在配置文件中自定义了数据源,再去手动配置一遍不是多此一举吗? 接着往下看 SchedulerFactoryBean 的初始化方法部分源码▼ private void initSchedulerFactory(StdSchedulerFactory schedulerFactory) throws SchedulerException, IOException &#123; Properties mergedProps = new Properties(); if (this.dataSource != null) &#123; mergedProps.setProperty(StdSchedulerFactory.PROP_JOB_STORE_CLASS, LocalDataSourceJobStore.class.getName()); &#125; &#125; 我们在静态内部类设置过了数据源,初始化方法只要发现数据源不为空,那么就使用会使用 LocalDataSourceJobStore 覆盖我们quartz配置文件中设置的 org.quartz.jobStore.class: org.quartz.impl.jdbcjobstore.JobStoreTX 而LocalDataSourceJobStore 中的初始化方法使用的是 SchedulerFactoryBean 中设置的数据源,所以我们quartz配置文件中的数据源才不会生效!!! 怎么解决呢? 我们上面提到了customize(SchedulerFactoryBean schedulerFactoryBean) 方法,这个方法会寻找实现了 SchedulerFactoryBeanCustomizer 接口的配置类,在其实现方法 customize(SchedulerFactoryBean schedulerFactoryBean)中 可对 SchedulerFactoryBean 使用代码自定义配置 所以 我们只要在SchedulerFactoryBean 创建后调用初始化方法之前,再将DataSource设置为null,那么SchedulerFactoryBean 初始化时,将会使用我们配置文件中的JobStoreTX去寻找我们配置的数据源了,至此,填坑完毕▼ import org.springframework.boot.autoconfigure.quartz.SchedulerFactoryBeanCustomizer; import org.springframework.context.annotation.Configuration; import org.springframework.scheduling.quartz.SchedulerFactoryBean; /** * @author Demo-Liu * @create 2020-06-12 11:20 * @description 配置定时任务 */ @Configuration public class SchedulerConfig implements SchedulerFactoryBeanCustomizer &#123; /** * @Author Demo-Liu * @Date 20200614 12:44 * 自定义 quartz配置 * @param schedulerFactoryBean */ @Override public void customize(SchedulerFactoryBean schedulerFactoryBean) &#123; schedulerFactoryBean.setDataSource(null); &#125; &#125; 以上 在文末附上我的GitHub小demo,其中包含了quartz的数据库建表sql,并提供了一种可以更加灵活便捷的通过yml文件配置定时任务的方式 地址: GitHub-BootQuartzYml 以下是yml配置文件配置定时任务的例子 #通过加载此配置文件实现动态创建Job 旨在通过一种更灵活便捷的方式来控制定时任务 #20200611 by Demo-Liu #jobs: # jobList: # - jobConf: # name: 测试任务 #任务名 可选 # job: com.example.demo.quartz.DemoJob #任务类包路径 必须 # param: #可为job类注入参数(可配置多项) 可选 # jtbs: test # cron: 10 * * * * ? #任务执行频率 必须 # active: true #任务激活状态 必须 jobs: jobList: - jobConf: name: 测试任务 job: com.example.demo.quartz.DemoJob param: jtbs: test ss: test2 cron: 0/10 * * * * ? active: true - jobConf: name: 测试任务2 job: com.example.demo.quartz.DemoJob2 param: jtbs: test ss: test2 cron: 0/10 * * * * ? active: false","tags":[{"name":"springboot","slug":"springboot","permalink":"http://wumuwumu.github.io/tags/springboot/"},{"name":"quartz","slug":"quartz","permalink":"http://wumuwumu.github.io/tags/quartz/"}]},{"title":"框架的实现","date":"2020-08-14T10:39:21.000Z","path":"posts/undefined.html","text":"","tags":[]},{"title":"","date":"2020-06-05T07:54:05.000Z","path":"posts/undefined.html","text":"简述frp是有个内网穿透的工具，分为客户端和服务端。客户端的程序名称是frpc，服务端的程序名称是frps。 服务器下载&#x2F;&#x2F; lorawan gateway 下载mipsle版本 https:&#x2F;&#x2F;github.com&#x2F;fatedier&#x2F;frp&#x2F;releases 配置文件# frps.ini [common] bind_port = 7000 # 用于与客户端之间通信 运行程序./frps -c ./frps.ini 客户端配置文件详细看https://github.com/fatedier/frp/blob/master/README_zh.md#dashboard # frpc.ini [common] server_addr = x.x.x.x server_port = 7000 # frp multi user 插件 user = user1 meta_token = 123 [web] type = http local_port = 80 custom_domains = www.yourdomain.com [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 运行程序./frpc -c ./frpc.ini openwrt开机启动 配置服务 ## &#x2F;etc&#x2F;init.d&#x2F;frpc #!&#x2F;bin&#x2F;sh &#x2F;etc&#x2F;rc.common # &quot;new&quot; style init script # Look at &#x2F;lib&#x2F;functions&#x2F;service.sh on a running system for explanations of what other SERVICE_ # options you can use, and when you might want them. START&#x3D;80 APP&#x3D;frpc start() &#123; service_start &#x2F;usr&#x2F;sbin&#x2F;$APP -c &#x2F;etc&#x2F;frpc.ini &gt; &#x2F;usr&#x2F;frpc.log &amp; &#125; stop() &#123; service_stop &#x2F;usr&#x2F;sbin&#x2F;$APP &#125; 开机启动 chmod +x &#x2F;etc&#x2F;init.d&#x2F;frpc &#x2F;etc&#x2F;init.d&#x2F;frpc enable &#x2F;etc&#x2F;init.d&#x2F;frpc start","tags":[{"name":"frp","slug":"frp","permalink":"http://wumuwumu.github.io/tags/frp/"}]},{"title":"域名不能解析","date":"2020-05-28T07:00:00.000Z","path":"posts/undefined.html","text":"DNS有问题，之前手动配置DNS导致，执行如下内容(8.8.8.8是谷歌提供的) echo ‘nameserver 8.8.8.8’&gt;&gt;/etc/resolv.conf 也可使用阿里巴巴提供的DNS域名解析 nameserver 223.5.5.5 nameserver 223.6.6.6 阿里巴巴DNS介绍 https://opsx.alibaba.com/service?lang=zh-CN","tags":[]},{"title":"Vue3工程搭建","date":"2020-05-09T06:23:23.000Z","path":"posts/undefined.html","text":"创建工程npm i -g @vue/cli vue create test","tags":[{"name":"vue","slug":"vue","permalink":"http://wumuwumu.github.io/tags/vue/"}]},{"title":"编写自己的Springboot-starter","date":"2020-04-18T07:53:46.000Z","path":"posts/undefined.html","text":"前言我们都知道可以使用SpringBoot快速的开发基于Spring框架的项目。由于围绕SpringBoot存在很多开箱即用的Starter依赖，使得我们在开发业务代码时能够非常方便的、不需要过多关注框架的配置，而只需要关注业务即可。 例如我想要在SpringBoot项目中集成Redis，那么我只需要加入spring-data-redis-starter的依赖，并简单配置一下连接信息以及Jedis连接池配置就可以。这为我们省去了之前很多的配置操作。甚至有些功能的开启只需要在启动类或配置类上增加一个注解即可完成。 那么如果我们想要自己实现自己的Starter需要做些什么呢？下面就开始介绍如何实现自己的SpringBoot-xxx-starter。 原理首先说说原理，我们知道使用一个公用的starter的时候，只需要将相应的依赖添加的Maven的配置文件当中即可，免去了自己需要引用很多依赖类，并且SpringBoot会自动进行类的自动配置。那么 SpringBoot 是如何知道要实例化哪些类，并进行自动配置的呢？ 下面简单说一下。 首先，SpringBoot 在启动时会去依赖的starter包中寻找 resources/META-INF/spring.factories 文件，然后根据文件中配置的Jar包去扫描项目所依赖的Jar包，这类似于 Java 的 SPI 机制。 第二步，根据 spring.factories配置加载AutoConfigure类。 最后，根据 @Conditional注解的条件，进行自动配置并将Bean注入Spring Context 上下文当中。 我们也可以使用@ImportAutoConfiguration(&#123;MyServiceAutoConfiguration.class&#125;) 指定自动配置哪些类。 实现终于到了代码实现的步骤，接下来就开始编码我们自己的SpringBoot-starter。 第一步创建一个SpringBoot 项目，并添加下面两个依赖到pom.xml文件当中&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;&#x2F;artifactId&gt; &lt;optional&gt;true&lt;&#x2F;optional&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; 其中 spring-boot-configuration-processor 的作用是编译时生成 spring-configuration-metadata.json ，此文件主要给IDE使用。如当配置此jar相关配置属性在 application.yml ，你可以用ctlr+鼠标左键点击属性名，IDE会跳转到你配置此属性的类中。 我们日常使用的Spring官方的Starter一般采取spring-boot-starter-&#123;name&#125; 的命名方式，如 spring-boot-starter-web 。 而非官方的Starter，官方建议 artifactId 命名应遵循&#123;name&#125;-spring-boot-starter 的格式。 例如：ysc-spring-boot-starter 。 &lt;groupId&gt;com.ysc&lt;&#x2F;groupId&gt; &lt;artifactId&gt;simple-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;&#x2F;version&gt; &lt;packaging&gt;jar&lt;&#x2F;packaging&gt; 第二步编写我们的Service类这里讲一下我们的Starter要实现的功能，很简单，提供一个Service，包含一个能够将配置文件中配置的字符串根据传入的字符进行分割的方法String[] split(String separatorChar)。 public class StarterService &#123; private String config; public StarterService(String config) &#123; this.config &#x3D; config; &#125; public String[] split(String separatorChar) &#123; return StringUtils.split(this.config, separatorChar); &#125; &#125; 第三步编写配置文件读取类@ConfigurationProperties(\"example.service\") public class StarterServiceProperties &#123; private String config; public void setConfig(String config) &#123; this.config = config; &#125; public String getConfig() &#123; return config; &#125; &#125; 第四步，编写AutoConfigure类 ，这步是关键点@Configuration @ConditionalOnClass(StarterService.class) @EnableConfigurationProperties(StarterServiceProperties.class) public class StarterAutoConfigure &#123; @Autowired private StarterServiceProperties properties; @Bean @ConditionalOnMissingBean @ConditionalOnProperty(prefix = \"example.service\", value = \"enabled\", havingValue = \"true\") StarterService starterService ()&#123; return new StarterService(properties.getConfig()); &#125; &#125; 解释一下代码中用到的几个注解： @ConditionalOnClass，当classpath下发现该类的情况下进行自动配置。 @ConditionalOnMissingBean，当Spring Context中不存在该Bean时。 @ConditionalOnProperty(prefix = &quot;example.service&quot;,value = &quot;enabled&quot;,havingValue = &quot;true&quot;)，当配置文件中example.service.enabled=true时。 下面列举SpringBoot中的所有@Conditional注解及作用@ConditionalOnBean:当容器中有指定的Bean的条件下 @ConditionalOnClass：当类路径下有指定的类的条件下 @ConditionalOnExpression:基于SpEL表达式作为判断条件 @ConditionalOnJava:基于JVM版本作为判断条件 @ConditionalOnJndi:在JNDI存在的条件下查找指定的位置 @ConditionalOnMissingBean:当容器中没有指定Bean的情况下 @ConditionalOnMissingClass:当类路径下没有指定的类的条件下 @ConditionalOnNotWebApplication:当前项目不是Web项目的条件下 @ConditionalOnProperty:指定的属性是否有指定的值 @ConditionalOnResource:类路径下是否有指定的资源 @ConditionalOnSingleCandidate:当指定的Bean在容器中只有一个，或者在有多个Bean的情况下，用来指定首选的Bean @ConditionalOnWebApplication:当前项目是Web项目的条件下 最后一步，在resources/META-INF/下创建spring.factories文件，并添加如下内容：org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.example.autocinfigure.StarterAutoConfigure 至此，我们的一个Starter代码部分就是完成了，下面将项目安装到本地Maven仓库中。 发布在项目根目录执行 mvn install 进行打包安装。 测试将Starter项目的依赖添加到我们自己的SpringBoot项目中 &lt;dependency> &lt;groupId>com.ysc&lt;/groupId> &lt;artifactId>simple-spring-boot-starter&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/dependency> 在application.yml 配置文件中添加配置信息： example service enabled: true config： abc-des-dde,SSS-DRS-RE,SDR-SDFR-XXX 在本地使用JUnit进行代码测试 @Autowired private StarterService starterService; @Test public void starterTest() &#123; String[] splitArray = starterService.split(\",\"); System.out.println(splitArray); &#125;","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"},{"name":"sprintboot","slug":"sprintboot","permalink":"http://wumuwumu.github.io/tags/sprintboot/"}]},{"title":"hivemq源码学习-启动","date":"2020-01-14T06:00:00.000Z","path":"posts/undefined.html","text":"hivemq技术选型 使用Guice做DI 使用Netty 4做网络框架 使用JGroups做Cluster Node之间的集群通讯 使用Exodus做Broker信息文件持久化存储 使用Dropwizard Metrics做Broker的统计、监控 使用Kryo做序列化/反序列化 使用Jetty做Broker端servlet容器 使用Resteasy做Broker端restfull框架 使用Quartz/做Broker端任务的调度 程序启动main函数 final long startTime = System.nanoTime(); final MetricRegistry metricRegistry = new MetricRegistry(); metricRegistry.addListener(new MetricRegistryLogger()); final SystemInformationImpl systemInformation; LoggingBootstrap.prepareLogging(); log.info(\"Starting HiveMQ Community Edition Server\"); log.trace(\"Initializing HiveMQ home directory\"); //Create SystemInformation this early because logging depends on it systemInformation = new SystemInformationImpl(true); log.trace(\"Initializing Logging\"); LoggingBootstrap.initLogging(systemInformation.getConfigFolder()); log.trace(\"Initializing Exception handlers\"); HiveMQExceptionHandlerBootstrap.addUnrecoverableExceptionHandler(); log.trace(\"Initializing configuration\"); final FullConfigurationService configService = ConfigurationBootstrap.bootstrapConfig(systemInformation); final HivemqId hiveMQId = new HivemqId(); log.info(\"This HiveMQ ID is &#123;&#125;\", hiveMQId.get()); //ungraceful shutdown does not delete tmp folders, so we clean them up on broker start log.trace(\"Cleaning up temporary folders\"); TemporaryFileUtils.deleteTmpFolder(systemInformation.getDataFolder()); //must happen before persistence injector bootstrap as it creates the persistence folder. log.trace(\"Checking for migrations\"); final Map&lt;MigrationUnit, PersistenceType> migrations = Migrations.checkForTypeMigration(systemInformation); final Set&lt;MigrationUnit> valueMigrations = Migrations.checkForValueMigration(systemInformation); log.trace(\"Initializing persistences\"); final Injector persistenceInjector = GuiceBootstrap.persistenceInjector(systemInformation, metricRegistry, hiveMQId, configService); //blocks until all persistences started persistenceInjector.getInstance(PersistenceStartup.class).finish(); if (ShutdownHooks.SHUTTING_DOWN.get()) &#123; return; &#125; if (configService.persistenceConfigurationService().getMode() != PersistenceMode.IN_MEMORY) &#123; if (migrations.size() + valueMigrations.size() > 0) &#123; if(migrations.size() > 0) &#123; log.info(\"Persistence types has been changed, migrating persistent data.\"); &#125; else &#123; log.info(\"Persistence values has been changed, migrating persistent data.\"); &#125; for (final MigrationUnit migrationUnit : migrations.keySet()) &#123; log.debug(\"&#123;&#125; needs to be migrated.\", StringUtils.capitalize(migrationUnit.toString())); &#125; for (final MigrationUnit migrationUnit : valueMigrations) &#123; log.debug(\"&#123;&#125; needs to be migrated.\", StringUtils.capitalize(migrationUnit.toString())); &#125; Migrations.migrate(persistenceInjector, migrations, valueMigrations); &#125; Migrations.afterMigration(systemInformation); &#125; else &#123; log.info(\"Starting with in memory persistences\"); &#125; log.trace(\"Initializing Guice\"); final Injector injector = GuiceBootstrap.bootstrapInjector(systemInformation, metricRegistry, hiveMQId, configService, persistenceInjector); if (injector == null) &#123; return; &#125; if (ShutdownHooks.SHUTTING_DOWN.get()) &#123; return; &#125; // 创建hivemq服务器进行相关逻辑操作 final HiveMQServer instance = injector.getInstance(HiveMQServer.class); if (InternalConfigurations.GC_AFTER_STARTUP) &#123; log.trace(\"Starting initial garbage collection after startup\"); final long start = System.currentTimeMillis(); //Start garbage collection of objects we don't need anymore after starting up System.gc(); log.trace(\"Finished initial garbage collection after startup in &#123;&#125;ms\", System.currentTimeMillis() - start); &#125; if (ShutdownHooks.SHUTTING_DOWN.get()) &#123; return; &#125; /* It's important that we are modifying the log levels after Guice is initialized, otherwise this somehow interferes with Singleton creation */ LoggingBootstrap.addLoglevelModifiers(); instance.start(null); if (ShutdownHooks.SHUTTING_DOWN.get()) &#123; return; &#125; log.info(\"Started HiveMQ in &#123;&#125;ms\", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime)); if (ShutdownHooks.SHUTTING_DOWN.get()) &#123; return; &#125; // 发送hivemq官方使用数据，不用管 final UsageStatistics usageStatistics = injector.getInstance(UsageStatistics.class); usageStatistics.start();","tags":[]},{"title":"redis开启远程连接","date":"2019-12-16T09:44:28.000Z","path":"posts/undefined.html","text":"1、修改redis服务器的配置文件vi redis.conf 注释以下绑定的主机地址 # bind 127.0.0.1 或vim redis.conf bind 0.0.0.0 protected-mode no 2、修改redis服务器的参数配置修改redis的守护进程为no，不启用 127.0.0.1:6379&gt; config set daemonize “no” OK 修改redis的保护模式为no，不启用 127.0.0.1:6379&gt; config set protected-mode”no” OK 或者 config set requirepass 123 -&gt;123是密码 注意：开启 6379端口","tags":[{"name":"redis","slug":"redis","permalink":"http://wumuwumu.github.io/tags/redis/"}]},{"title":"nginx的servername配置","date":"2019-12-16T09:42:19.000Z","path":"posts/undefined.html","text":"编译自： server_names 目录： 通配符主机名 正则表达式主机名 混杂主机名 对主机名的优化 兼容性 nginx 的 server names 由 server_name 指令定义，server name 是 nginx 用于选择以哪个 server 区块处理访问请求的依据参数。可参考 《nginx 是如何处理请求的》 的描述。 server name 可以用三种方式定义： 定义准确的名字 定义通配符名字 定义正则表达式名字 例如： server &#123; listen 80; server_name example.org www.example.org; ... &#125; server &#123; listen 80; server_name *.example.org; ... &#125; server &#123; listen 80; server_name mail.*; ... &#125; server &#123; listen 80; server_name ~^(?&lt;user>.+)\\.example\\.net$; ... &#125; 当 nginx 以请求的 server name 查找匹配的虚拟主机时，如果匹配的 server 区块不止一个，nginx 按照如下的优先顺序选择 server 区块： 准确的主机名 以 “*” 起始的最长的通配主机名 以 “*” 结尾的最长的通配主机名 第一个匹配的正则表达式（按照配置文件中的顺序） 所以，如果同时有一个通配主机名和正则表达式主机名与访问请求的 server name 匹配，nginx 会选择通配主机名的 server 区块处理请求。 通配主机名 通配主机名只能在起始和末尾使用 “*” 字符，而且必须以 “.” 分隔。形如 “www.*.example.org” 或者 “w*.example.org” 的通配主机名是无效的。要达到这个匹配效果，只有使用正则表达式： “www.*.example.org” -> “~^www\\..+\\.example\\.org$” “w*.example.org” -> “~^w.*\\.example\\.org$” “*” 号可以匹配多个名字区域，“*.example.org” 不仅可以匹配 www.example.org，也能够匹配 www.sub.example.org。 正则表达式主机名 nginx 使用的正则表达式与 Perl 语言的正则表达式（PCRE）兼容。使用正则表达式主机名，server name 必须以 “~” 字符为起始字符。 server_name ~^www\\d+\\.example\\.net$; 如果不以 “~” 字符为起始字符，该 server name 将被视为 “准确的主机名” 或者当 server name 包含 “*” 时被视为 “通配主机名” (多数情况是非法通配主机名，因为只有当 “*” 在 server name 的起始或结尾时才合法)。 不要忘记设置 “^” 和 “$” 锚定符对主机名进行界定，这不是 nginx 的配置语法要求，而是为了使正则表达式能正确匹配。 同时也要注意，域名的分隔符 “.” 在正则表达式中应该以 “\\” 引用。如果在正则表达式中使用了 “&#123;” 和 “&#125;” 字符，应该将整个正则表达式引用起来，因为花括弧在 nginx 配置中也有特殊意义，引用起来以避免被 nginx 错误解析。例如： server_name \"~^(?&lt;name>\\w\\d&#123;1,3&#125;+)\\.example\\.net$\"; 如果不引用起来，nginx 会启动失败，并显示如下错误信息： directive \"server_name\" is not terminated by \";\" in ... 正则表达式的 named capture （使用一个名字对匹配的字符串进行引用）可被视为一个变量，在后面的配置中使用： server &#123; server_name ~^(www\\.)?(?&lt;domain>.+)$; location / &#123; root /sites/$domain; &#125; &#125; PCRE 库支持 named capture，有如下几种语法： ?&lt;name> Perl 5.10 compatible syntax, supported since PCRE-7.0 ?'name' Perl 5.10 compatible syntax, supported since PCRE-7.0 ?P&lt;name> Python compatible syntax, supported since PCRE-4.0 可参考：pcre2pattern： \\d any decimal digit \\D any character that is not a decimal digit \\h any horizontal white space character \\H any character that is not a horizontal white space character \\s any white space character \\S any character that is not a white space character \\v any vertical white space character \\V any character that is not a vertical white space character \\w any \"word\" character \\W any \"non-word\" character 如果 nginx 启动失败，并显示如下信息： pcre_compile() failed: unrecognized character after (?&lt; in ... 这表示 PCRE 库太老旧，可尝试使用 “?P&lt;name&gt;” 替代 “?&lt;name&gt;”。 named capture 也能以数字形式使用： server &#123; server_name ~^(www\\.)?(.+)$; location / &#123; root /sites/$2; &#125; &#125; 无论如何，数字形式的使用应尽量简单，因为数字是只是顺序标识，而不是被匹配的字符串的标识，这导致数字引用很容易被覆盖。 混杂主机名 有一些主机名是被特殊对待的。 对于未定义 “Host” 请求首部的请求，如果希望在某个 server 区块中处理这样的请求，应在 server_name 指令的参数中添加 “” 空字符串参数： server &#123; listen 80; server_name example.org www.example.org \"\"; ... &#125; 在《nginx 是如何处理访问请求的》一文中曾经介绍过，如果 server 区块中没有定义 server_name 指令，便如同定义了 server_name “”。 Note: 在 0.8.48 版以前，遇到 server 区块中没有定义 server_name 指令的情况， 会将系统的主机名设置为 server 区块的 server name，而不是自动设置 \"\" 为 server name。 在 0.9.4 版本，如果设置：server_name $hostname，会将系统的主机名设置为 server name。 如果某个访问使用了 IP 地址 而不是 server name，“Host” 请求首部会包含 IP 地址。对于这样的请求，可使用如下的配置： server &#123; listen 80; server_name example.org www.example.org \"\" 192.168.1.1 ; ... &#125; 下面是一个 catch-all server 区块的配置，使用了 “_” 作为 server name: server &#123; listen 80 default_server; server_name _; return 444; &#125; 这个 server name 并没有什么特殊之处，它仅是一个无效的域名而已，也可以使用其他类似的名字，如 “–” and “!@#” 。 0.6.25 版以前的 nginx 曾经支持一个特殊的 server name: “*”，这个特殊主机名被错误的解释成一个 catch-all 主机名。但它从未以一个 catch-all 或者 通配主机名工作，它的功能实际上与现在的 server_name_in_redirect 指令的功能相同：server_name_in_redirect 特殊的 server name “*” 现在已经被弃用，应使用 server_name_in_redirect 指令。 要注意的是，使用 server_name 指令无法指定 defalt server 或是 catch-all name，这是 listen 指令的属性，不是 server_name 指令的属性。可参考《nginx 是如何处理访问请求的》。 我们可以定义两个 server，它们都同时监听于 *:80 端口 和 *:8080 端口，将其中一个设置为 *:80 端口的默认 server，将另一个设置为 *:8080 端口的默认 server： server &#123; listen 80; listen 8080 default_server; server_name example.net; ... &#125; server &#123; listen 80 default_server; listen 8080; server_name example.org; ... &#125; 对主机名的优化 准确的主机名、以 “*” 起始的通配主机名、以 “*” 结尾的通配主机名，这三种主机名被存放在三个 hash table 中。这三个 hash table 是与监听端口绑定的。hash table 的大小在配置阶段被优化，优化的目的是努力降低这些名字在 CPU 缓存中命中失败的几率。关于设置 hash table 的详细讨论请参考：hash 在匹配主机名时，首先查找“准确主机名”的 hash table，如果没有找到，会查找以 “*” 起始的“通配主机名”的 hash table，如果没有仍未找到，会查找以 “*” 结尾的“通配主机名”的 hash table。 对于“通配主机名”的 hash table 的检索会更慢，因为是以主机名的域名部分去检索的。 注意，对于特殊的通配主机名，形如 “.example.org”，这样的主机名是存放在“通配主机名”的 hash table 中，而不是存放在“准确主机名”的 hash table 中。 如果前面都未找到，正则表达式会按写在配置文件中的顺序被测试，因此正则表达式是最慢的方法，并且没有可扩展性。 因为以上这些原因，在可能的情况下最好使用 “准确的主机名”。例如，如果对于 example.org 和 www.example.org 的请求最为频繁，对他们进行显式的定义会更有效率： server &#123; listen 80; server_name example.org www.example.org *.example.org; ... &#125; 下面的定义方法不如上面的配置有效率： server &#123; listen 80; server_name .example.org; ... &#125; 如果定义了大量的主机名，或者使用了很长的主机名，应在配置文件的 http context 中调整这个两个参数： server_names_hash_max_size server_names_hash_bucket_size server_names_hash_bucket_size 指令的默认值可能为 32 或 64 或 其他数字，这是根据 CPU 缓存线大小而定的。如果默认值为 32，而且定义了一个 server name 为：“too.long.server.name.example.org” 这时 nginx 就不能启动，而且显示如下的错误信息： could not build the server_names_hash, you should increase server_names_hash_bucket_size: 32 遇到这种情况，应将默认值设置为原来的两倍： http &#123; server_names_hash_bucket_size 64; ... 如果定义了大量的主机名，可能显示如下的错误信息： could not build the server_names_hash, you should increase either server_names_hash_max_size: 512 or server_names_hash_bucket_size: 32 遇到这种情况，首先尝试调整 server_names_hash_max_size 的值，设置为大于 server name 总数的值。如果这样设置仍不能让 nginx 正常启动，或者 nginx 启动的时间变得过长，再尝试增加 server_names_hash_bucket_size 的值。 如果一个 server 是某个监听端口唯一的 server，这时 nginx 根本不会去测试 server name，同时也不会为该监听端口构建 hash table。但其中又有一个例外，如果 server name 是正则表达式，而且正则表达式中包含了 captures，这时 nginx 不得不执行该正则表达式以获取 captures。（正则表达式的 capture 是指被圆括号引用的表达式部分，它们所匹配的字符串，可通过名字或数字引用） 兼容性 从 0.9.4 开始支持特殊主机名 “$hostname” 从 0.8.48 开始，如果 server 区块中未定义 server_name 指令，nginx 默认设定空字符串为主机名，如同定义了 server_name “” 从 0.8.25 开始支持在“正则表达式主机名”中使用 named capture 特性 从 0.7.40 开始支持在“正则表达式主机名”中使用 capture 特性 从 0.7.12 开始支持 “” 空字符串主机名 从 0.6.25 开始，支持使用“正则表达式主机名”或者“通配主机名”作为第一个主机名。 从 0.6.7 开始支持“正则表达式主机名” 从 0.6.0 开始支持形如 example.* 的“通配主机名” 从 0.3.18 开始支持形如 .example.org 的特殊“通配主机名” 从 0.1.13 开始支持形如 *.example.org 的“通配主机名” 参考https://www.jianshu.com/p/1430e4046fd9","tags":[{"name":"nginx","slug":"nginx","permalink":"http://wumuwumu.github.io/tags/nginx/"}]},{"title":"odoo的dbfilter配置","date":"2019-12-16T09:37:50.000Z","path":"posts/undefined.html","text":"关于 Odoo 的 dbfilter 配置项概述默认情况下首次访问odoo页面时，会要求选择要访问的数据库，db中的所有库都会被列出来供选择，这种在生产环境下通常是不希望的看到，如果在启动时指定连接的数据库名可以解决这个问题 .conf文件中指定 db_name = xxx 或者启动命令加参数-d xxx dbfilter当我们需要根据域名来匹配数据库时（比如saas环境）这样就不适用了，这个时候就可以用 dbfilter 这个配置项来实现 dbfilter 默认值为 .* eg: dbfilter = ^%h$ 表示按域名精确匹配数据库服务器中名称为域名的数据库 启动参数 --db-filter=&#39;^%d$&#39; 表示按二级域名前缀精确匹配对应名称的数据库（注意：127.0.0.1访问时会被匹配为 127 库名） 可用的匹配替代符号有 %h 和 %d %h%h 代表访问访问的域名，比如 www.abc.com %d当访问地址为 www.abc.com 时 %d 为 abc当访问地址为 shop.abc.com 时 %d 为 shop 相关源代码odoo中的相应的解析代码 def db_filter(dbs, httprequest=None): httprequest = httprequest or request.httprequest h = httprequest.environ.get('HTTP_HOST', '').split(':')[0] d, _, r = h.partition('.') if d == \"www\" and r: d = r.partition('.')[0] r = openerp.tools.config['dbfilter'].replace('%h', h).replace('%d', d) dbs = [i for i in dbs if re.match(r, i)] return dbs","tags":[{"name":"odoo","slug":"odoo","permalink":"http://wumuwumu.github.io/tags/odoo/"}]},{"title":"postgresql配置文件","date":"2019-12-09T08:29:39.000Z","path":"posts/undefined.html","text":"1、配置文件配置文件控制着一个PostgreSQL服务器实例的基本行为，主要包含postgresql.conf、pg_hba.conf、pg_ident.conf （1）postgresql.conf 该文件包含一些通用设置，比如内存分配，新建database的默认存储位置，PostgreSQL服务器的IP地址，日志的位置以及许多其他设置。9.4版引入了 一个新的postgresql.auto.conf文件，任何时候执行Altersystem SQL命令，都会创建或重写该文件。该文件中的设置会替代postgresql.conf文件中的设置。 （2）pg_hba.conf ​ 该文件用于控制访问安全性，管理客户端对Postgresql服务器的访问权限，内容包括：允许哪些用户连接到哪个数据库，允许哪些IP或者哪个网段的IP连 ​ 接到本服务器，以及指定连接时使用的身份验证模式 （3）pg_ident.conf pg_hba.conf的权限控制信息中的身份验证模式字段如果指定为ident方式，则用户连接时系统会尝试访问pg_ident文件，如果该文件存在，则系统会基于 ​ 文件内容将当前执行登录操作的操作系统用户映射为一个PostgreSQL数据库内部用户的身份来登录。 2、查看配置文件的位置：postgres=# selectname,setting from pg_settings where category='File Locations'; name | setting -------------------+----------------------------------------- config_file |/var/lib/pgsql/9.6/data/postgresql.conf data_directory | /var/lib/pgsql/9.6/data external_pid_file | hba_file | /var/lib/pgsql/9.6/data/pg_hba.conf ident_file | /var/lib/pgsql/9.6/data/pg_ident.conf 3、postgresql.conf3.1、关键的设置 postgres=# selectname,context,unit,setting,boot_val,reset_val from pg_settings where namein('listen_addresses','max_connections','shared_buffers','effective_cache_size','work_mem','maintenance_work_mem')order by context,name; name | context | unit | setting |boot_val | reset_val ----------------------+------------+------+---------+-----------+----------- listen_addresses | postmaster | | * | localhost | * max_connections | postmaster | | 100 | 100 | 100 shared_buffers | postmaster | 8kB | 16384 | 1024 | 16384 effective_cache_size | user | 8kB | 524288 | 524288 | 524288 maintenance_work_mem | user | kB | 65536 | 65536 | 65536 work_mem | user | kB | 4096 | 4096 | 4096 (6 rows) context 设置为postmaster，更改此形参后需要重启PostgreSQL服务才能生效； 设置为user，那么只需要执行一次重新加载即可全局生效。重启数据库服务会终止活动连接，但重新加载不会。 unit 字段表示这些设置的单位 setting是指当前设置；boot_val是指默认设置；reset_val是指重新启动服务器或重新加载设置之后的新设置 在postgresql.conf中修改了设置后，一定记得查看一下setting和reset_val并确保二者是一致，否则说明设置并未生效，需要重新启动服务器或者重新加载设置 3.2、postgresql.auto.conf与postgresql.conf区别 对于9.4版及之后的版本来说，Postgresql.auto.conf的优先级是高于postgresql.conf的，如果这两个文件中存在同名配置项，则系统会优先选择前者设定的值。 3.3、postgresql.conf以下网络设置，修改这些值是一定要重新启动数据库服务的 listen_addresses 一般设定为localhost或者local，但也有很多人会设为*，表示使用本机任一IP地址均可连接到Postgresql服务 port 默认值 为5432 max_connections 3.4、以下四个设置对系统性能有着全局性的影响，建议你在实际环境下通过实测来找到最优值 (1)share_buffers ​ 用于缓存最近访问过的数据页的内存区大小，所有用户会话均可共享此缓存区 ​ 一般来说越大越好，至少应该达到系统总内存的25%，但不宜超过8GB，因为超过后会出现“边际收益递减”效应。 ​ 需重启postgreSQL服务 （2）effective_cache_size 一个查询执行过程中可以使用的最大缓存，包括操作系统使用的部分以及PostgreSQL使用部分，系统并不会根据这个值来真实地分配这么多内存，但是规划器会根据这个值来判断系统能否提供查询执行过程中所需的内存。如果将此设置设得过小，远远小于系统真实可用内存量，那么可能会给规划器造成误导，让规划器认为系统可用内存有限，从而选择不使用索引而是走全表扫描（因为使用索引虽然速度快，但需要占用更多的中间内存）。 在一台专用于运行PostgreSQL数据库服务的服务器上，建议将effective_cache_size的值设为系统总内存的一半或者更多。 此设置可动态生效，执行重新加载即可。 （3）work_mem 此设置指定了用于执行排序，哈希关联，表扫描等操作的最大内存量。 此设置可动态生效，执行重新加载即可。 （4）mintenance_work_mem ​ 此设置指定可用于vaccum操作（即清空已标记为“被删除”状态的记录）这类系统内部维护操作的内存总量。 ​ 其值不应大于1GB 此设置可动态生效，执行重新加载即可。 3.5修改参数命令 Alter system set work_mem=8192; 设置重新加载命令 Select pg_reload_conf(); 3.6、遇到修改了postgresql.conf文件，结果服务器崩溃了这种情况 定位这种问题最简单的方法是查看日志文件，该文件位于postgresql数据文件夹的根目录或者pg_log子文件夹下。 4、pg_hba.confcat /var/lib/pgsql/9.6/data/pg_hba.conf # TYPE DATABASE USER ADDRESS METHOD # \"local\" isfor Unix domain socket connections only local all all peer # IPv4 localconnections: host all all 0.0.0.0/0 trust # IPv6 localconnections: host all all ::1/128 ident # Allow replicationconnections from localhost, by a user with the # replication privilege. #local replication postgres peer #host replication postgres 127.0.0.1/32 ident #host replication postgres ::1/128 ident (1) 身份验证模式，一般以下几种常用选项：ident、trust、md5以及password 1版本开始引入了peer身份验证模式。 Ident和peer模式公适用于Linux，Unix和Mac,不适用于windwos Reject模式，其作用是拒绝所有请求。 (2) 如果你将+0.0.0./0 reject+规则放到+127.0.0.1/32 trust+的前面，那么此时本地用户全都无法连接，即使下面有规则允许也不行。 （3）各模式 trust最不安全的身份验证模式，该模式允许用户“自证清白”，即可以不用密码就连到数据库 md5该模式最常用，要求连接发起者携带用md5算法加密的密码 password 不推荐，因为该模式使用明文密码进行身份验证，不安全 ident：该身份验证模式下，系统会将请求发起的操作系统用户映射为PostgreSQL数据库内部用户，并以该内部用户的权限登录，且此时无需提供登录密码。操作系统用户与数据库内部用户之间的映射关系会记录在pg_ident.conf文件中。 peer使用发起端的操作系统名进行身份验证 5、配置文件的重新加载/usr/pgsql-9.6/bin/pg_ctlreload -D /var/lib/pgsql/9.6/data/ systemctlreload postgresql-9.6.service selectpg_reload_conf();","tags":[{"name":"postgresql","slug":"postgresql","permalink":"http://wumuwumu.github.io/tags/postgresql/"}]},{"title":"postgresql安装","date":"2019-12-09T07:53:51.000Z","path":"posts/undefined.html","text":"# Install the repository RPM: dnf install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm # Disable the built-in PostgreSQL module: dnf -qy module disable postgresql # Install PostgreSQL: dnf install -y postgresql12-server # Optionally initialize the database and enable automatic start: /usr/pgsql-12/bin/postgresql-12-setup initdb systemctl enable postgresql-12 systemctl start postgresql-12","tags":[]},{"title":"mysql连接外网安装","date":"2019-12-09T07:24:23.000Z","path":"posts/undefined.html","text":"添加 MySQL YUM 源根据自己的操作系统选择合适的安装源，和其他公司一样，总会让大家注册账号获取更新，注意是 Oracle 的账号，如果不想注册，下方有直接下载的地址，下载之后通过 rpm -Uvh 安装。 $wget 'https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm' $sudo rpm -Uvh mysql57-community-release-el7-11.noarch.rpm $yum repolist all | grep mysql mysql-connectors-community/x86_64 MySQL Connectors Community 36 mysql-tools-community/x86_64 MySQL Tools Community 47 mysql57-community/x86_64 MySQL 5.7 Community Server 187 先解释下为什么下载的是 5.7 版本的，现在最新的是 5.7 版本的，当然官网默认都是最新版本的，但是下载的页面也有说明 The MySQL Yum repository includes the latest versions of: MySQL 8.0 (Development) MySQL 5.7 (GA) MySQL 5.6 (GA) MySQL 5.5 (GA - Red Hat Enterprise Linux and Oracle Linux Only) MySQL Cluster 7.5 (GA) MySQL Cluster 7.6 (Development) MySQL Workbench MySQL Fabric MySQL Router (GA) MySQL Utilities MySQL Connector / ODBC MySQL Connector / Python MySQL Shell (GA) 也就是说这个安装源包含了上面列举的这些版本，当然包括 5.6 版本的。 选择安装版本如果想安装最新版本的，直接使用 yum 命令即可 $sudo yum install mysql-community-server 如果想要安装 5.6 版本的，有2个方法。命令行支持 yum-config-manager 命令的话，可以使用如下命令： $ sudo dnf config-manager --disable mysql57-community $ sudo dnf config-manager --enable mysql56-community $ yum repolist | grep mysql mysql-connectors-community/x86_64 MySQL Connectors Community 36 mysql-tools-community/x86_64 MySQL Tools Community 47 mysql56-community/x86_64 MySQL 5.6 Community Server 327 或者直接修改 /etc/yum.repos.d/mysql-community.repo 这个文件 # Enable to use MySQL 5.6 [mysql56-community] name=MySQL 5.6 Community Server baseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/7/$basearch/ enabled=1 #表示当前版本是安装 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql [mysql57-community] name=MySQL 5.7 Community Server baseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/ enabled=0 #默认这个是 1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 通过设置 enabled 来决定安装哪个版本。 设置好之后使用 yum 安装即可。 启动 MySQL 服务启动命令很简单 $sudo service mysqld start $sudo systemctl start mysqld #CentOS 7 $sudo systemctl status mysqld ● mysqld.service - MySQL Community Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2017-05-27 12:56:26 CST; 15s ago Process: 2482 ExecStartPost=/usr/bin/mysql-systemd-start post (code=exited, status=0/SUCCESS) Process: 2421 ExecStartPre=/usr/bin/mysql-systemd-start pre (code=exited, status=0/SUCCESS) Main PID: 2481 (mysqld_safe) CGroup: /system.slice/mysqld.service ├─2481 /bin/sh /usr/bin/mysqld_safe --basedir=/usr └─2647 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/... 说明已经正在运行中了。 对于 MySQL 5.7 版本，启动的时候如果数据为空的，则会出现如下提示 The server is initialized. An SSL certificate and key files are generated in the data directory. The validate_password plugin is installed and enabled. A superuser account ‘root’@’localhost’ is created. A password for the superuser is set and stored in the error log file.To reveal it, use the following command: sudo grep &#39;temporary password&#39; /var/log/mysqld.log 简单的说就是服务安装好了，SSL 认证的文件会在 data 目录中生存，密码不要设置的太简单了，初始密码通过下面的命令查看，赶紧去改密码吧。 安装提示，查看密码，登录数据库，然后修改密码： $ mysql -uroot -p #输入查看到的密码 mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!'; MySQL 5.6 的安全设置由于 5.7 版本在安装的时候就设置好了，不需要额外设置，但是 5.6 版本建议从安全角度完善下，运行官方脚本即可 $ mysql_secure_installation 会提示设置5个关键位置 设置 root 密码 禁止 root 账号远程登录 禁止匿名账号（anonymous）登录 删除测试库 是否确认修改 安装第三方组件查看 yum 源中有哪些默认的组件： $ yum --disablerepo=\\* --enablerepo='mysql*-community*' list available 需要安装直接通过 yum 命令安装即可。 修改编码在 /etc/my.cnf 中设置默认的编码 [client] default-character-set = utf8 [mysqld] default-storage-engine = INNODB character-set-server = utf8 collation-server = utf8_general_ci #不区分大小写 collation-server = utf8_bin #区分大小写 collation-server = utf8_unicode_ci #比 utf8_general_ci 更准确 创建数据库和用户创建数据库 CREATE DATABASE &lt;datebasename> CHARACTER SET utf8; CREATE USER 'username'@'host' IDENTIFIED BY 'password'; GRANT privileges ON databasename.tablename TO 'username'@'host'; SHOW GRANTS FOR 'username'@'host'; REVOKE privilege ON databasename.tablename FROM 'username'@'host'; DROP USER 'username'@'host'; 其中 username：你将创建的用户名 host：指定该用户在哪个主机上可以登陆，如果是本地用户可用 localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符 % password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器 privileges：用户的操作权限，如 SELECT，INSERT，UPDATE 等，如果要授予所的权限则使用ALL databasename：数据库名 tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用 * 表示，如 . 参考https://www.jianshu.com/p/7cccdaa2d177","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"}]},{"title":"redux-saga分成多个文件","date":"2019-11-26T07:26:49.000Z","path":"posts/undefined.html","text":"1)&#x2F;&#x2F; single entry point to start all Sagas at once export default function* rootSaga() &#123; yield [ saga1(), saga2(), saga3(), ] &#125; Here the 3 sagas will be run in parallel. The root saga will block until the 3 sagas complete. If one of the 3 fail, the error will be propagated to the root saga which will be killed, which will also kill the other 2 saga 2)export default function* root() &#123; yield [ fork(saga1), fork(saga2), fork(saga3) ] &#125; The only difference I see here is that this time the yield effect will not block because forking is non-blocking, thus the root saga will reach the end but the 3 childs will remain alive. Error behavior is the same as 1) 3)export default function* root() &#123; yield fork(saga1) yield fork(saga2) yield fork(saga3) &#125; I don’t see any difference in behavior from 2) better examplesThe problem with forking is that if any of the root saga fails, then the root saga will be killed, and the other sub sagas will also be killed because their parent got killed. In practice this means that your whole app may become unusable (if it relies heavily on sagas) just because of a minor saga error so it’s not really good. 4)export default function* root() &#123; yield spawn(saga1) yield spawn(saga2) yield spawn(saga3) &#125; This time, if an error occur in saga1, it will not make root, saga2 and saga3 get killed so only a part of your app stops working in case of error. Somehow this can also be very problematic because the saga1 might be killed due to an error like a failing http request that you didn’t catch properly, making the whole feature covered by saga1 unavailable for the app lifetime. 5)@granmoe has suggested the following way to start sagas in: #570 function* rootSaga () &#123; const sagas &#x3D; [ saga1, saga2, saga3, ]; yield sagas.map(saga &#x3D;&gt; spawn(function* () &#123; while (true) &#123; try &#123; yield call(saga) &#125; catch (e) &#123; console.log(e) &#125; &#125; &#125;) ) &#125; This time, if any of the 3 sagas had an error, it would be automatically restarted. This may, or not, be the desired behavior according to your app. 6)Here’s how I handle sagas in my own app: const makeRestartable &#x3D; (saga) &#x3D;&gt; &#123; return function* () &#123; yield spawn(function* () &#123; while (true) &#123; try &#123; yield call(saga); console.error(&quot;unexpected root saga termination. The root sagas are supposed to be sagas that live during the whole app lifetime!&quot;,saga); &#125; catch (e) &#123; console.error(&quot;Saga error, the saga will be restarted&quot;,e); &#125; yield delay(1000); &#x2F;&#x2F; Avoid infinite failures blocking app TODO use backoff retry policy... &#125; &#125;) &#125;; &#125;; const rootSagas &#x3D; [ domain1saga, domain2saga, domain3saga, ].map(makeRestartable); export default function* root() &#123; yield rootSagas.map(saga &#x3D;&gt; call(saga)); &#125; I’m using a saga HOC to add error handling to the root sagas. In my app, all root sagas are never supposed to terminate but should block, and if there are errors they should be automatically restarted. Restarting synchronously can, in my experience, lead to infinite loops (if the saga fails everytime you try to restart it) so I added a hacky delay for now to prevent this issue. You mentionned different domains in your app so this pattern seems appropriate to your usecase where each domain should somehow have its own root saga.","tags":[{"name":"react","slug":"react","permalink":"http://wumuwumu.github.io/tags/react/"}]},{"title":"odoo源码解析4-wsgi_server","date":"2019-11-16T07:35:05.000Z","path":"posts/undefined.html","text":"applicationdef application(environ, start_response): ## 是否启动代理 # FIXME: is checking for the presence of HTTP_X_FORWARDED_HOST really useful? # we're ignoring the user configuration, and that means we won't # support the standardised Forwarded header once werkzeug supports # it if config['proxy_mode'] and 'HTTP_X_FORWARDED_HOST' in environ: return ProxyFix(application_unproxied)(environ, start_response) else: return application_unproxied(environ, start_response) application_unproxied清除数据库和用户的追踪清除动作在application方法的结尾不能完成，因为werkzeu在后面还会生成有关的日志。 def application_unproxied(environ, start_response): \"\"\" WSGI entry point.\"\"\" # cleanup db/uid trackers - they're set at HTTP dispatch in # web.session.OpenERPSession.send() and at RPC dispatch in # odoo.service.web_services.objects_proxy.dispatch(). # /!\\ The cleanup cannot be done at the end of this `application` # method because werkzeug still produces relevant logging afterwards if hasattr(threading.current_thread(), 'uid'): del threading.current_thread().uid if hasattr(threading.current_thread(), 'dbname'): del threading.current_thread().dbname if hasattr(threading.current_thread(), 'url'): del threading.current_thread().url with odoo.api.Environment.manage(): result = odoo.http.root(environ, start_response) if result is not None: return result # We never returned from the loop. return werkzeug.exceptions.NotFound(\"No handler found.\\n\")(environ, start_response) 参考 https://blog.csdn.net/weixin_35737303/article/details/79038982","tags":[{"name":"odoo","slug":"odoo","permalink":"http://wumuwumu.github.io/tags/odoo/"}]},{"title":"odoo源码解析-启动web服务器","date":"2019-11-16T06:41:42.000Z","path":"posts/undefined.html","text":"启动 def start(preload=None, stop=False): \"\"\" Start the odoo http server and cron processor. \"\"\" global server ## 这里加载两个模块web和web_kan，在这里加载模块才能够在用户没有登录的时候才能够访问路由 load_server_wide_modules() odoo.service.wsgi_server._patch_xmlrpc_marshaller() \"\"\" ·GeventServer ·PreforkServer ·ThreadedServer(默认) CommonServer是后面三个类的父类 Odoo服务器通过ThreadedServer.run()运行 \"\"\" if odoo.evented: server = GeventServer(odoo.service.wsgi_server.application) elif config['workers']: if config['test_enable'] or config['test_file']: _logger.warning(\"Unit testing in workers mode could fail; use --workers 0.\") server = PreforkServer(odoo.service.wsgi_server.application) # Workaround for Python issue24291, fixed in 3.6 (see Python issue26721) if sys.version_info[:2] == (3,5): # turn on buffering also for wfile, to avoid partial writes (Default buffer = 8k) werkzeug.serving.WSGIRequestHandler.wbufsize = -1 else: server = ThreadedServer(odoo.service.wsgi_server.application) watcher = None if 'reload' in config['dev_mode'] and not odoo.evented: if inotify: watcher = FSWatcherInotify() watcher.start() elif watchdog: watcher = FSWatcherWatchdog() watcher.start() else: if os.name == 'posix' and platform.system() != 'Darwin': module = 'inotify' else: module = 'watchdog' _logger.warning(\"'%s' module not installed. Code autoreload feature is disabled\", module) if 'werkzeug' in config['dev_mode']: server.app = DebuggedApplication(server.app, evalex=True) ## 启动web服务器 rc = server.run(preload, stop) if watcher: watcher.stop() # like the legend of the phoenix, all ends with beginnings if getattr(odoo, 'phoenix', False): _reexec() return rc if rc else 0 ThreadedServer(CommandServer)Run\"\"\" Start the http server and the cron thread then wait for a signal. The first SIGINT or SIGTERM signal will initiate a graceful shutdown while a second one if any will force an immediate exit. \"\"\" ## 启动一个系统命令监测。。。 self.start(stop=stop) ## 安装、更新、加载模块 rc = preload_registries(preload) if stop: self.stop() return rc ## 加载定时任务 self.cron_spawn() # Wait for a first signal to be handled. (time.sleep will be interrupted # by the signal handler) try: while self.quit_signals_received == 0: self.process_limit() if self.limit_reached_time: has_other_valid_requests = any( not t.daemon and t not in self.limits_reached_threads for t in threading.enumerate() if getattr(t, 'type', None) == 'http') if (not has_other_valid_requests or (time.time() - self.limit_reached_time) > SLEEP_INTERVAL): # We wait there is no processing requests # other than the ones exceeding the limits, up to 1 min, # before asking for a reload. _logger.info('Dumping stacktrace of limit exceeding threads before reloading') dumpstacks(thread_idents=[thread.ident for thread in self.limits_reached_threads]) self.reload() # `reload` increments `self.quit_signals_received` # and the loop will end after this iteration, # therefore leading to the server stop. # `reload` also sets the `phoenix` flag # to tell the server to restart the server after shutting down. else: time.sleep(1) else: time.sleep(SLEEP_INTERVAL) except KeyboardInterrupt: pass self.stop() startdef start(self, stop=False): _logger.debug(\"Setting signal handlers\") set_limit_memory_hard() if os.name == 'posix': signal.signal(signal.SIGINT, self.signal_handler) signal.signal(signal.SIGTERM, self.signal_handler) signal.signal(signal.SIGCHLD, self.signal_handler) signal.signal(signal.SIGHUP, self.signal_handler) signal.signal(signal.SIGXCPU, self.signal_handler) signal.signal(signal.SIGQUIT, dumpstacks) signal.signal(signal.SIGUSR1, log_ormcache_stats) elif os.name == 'nt': import win32api win32api.SetConsoleCtrlHandler(lambda sig: self.signal_handler(sig, None), 1) test_mode = config['test_enable'] or config['test_file'] if test_mode or (config['http_enable'] and not stop): # some tests need the http deamon to be available... self.http_spawn() ThreadedWSGIServerReloadable这个服务可以不启动也能够运行程序。他的作用是debug保持端口是开启的。 Werkzeug是Python的WSGI规范的实现函数库。基于BSD协议。WSGI(Web Server Gateway Interface)WSGI服务允许重用环境提供的监听套接字，它通过自动重加载使用，用于保持当有重加载的时候监听套接字是打开状态 class ThreadedWSGIServerReloadable(LoggingBaseWSGIServerMixIn, werkzeug.serving.ThreadedWSGIServer): \"\"\" werkzeug Threaded WSGI Server patched to allow reusing a listen socket given by the environement, this is used by autoreload to keep the listen socket open when a reload happens. \"\"\" def __init__(self, host, port, app): super(ThreadedWSGIServerReloadable, self).__init__(host, port, app, handler=RequestHandler) # See https://github.com/pallets/werkzeug/pull/770 # This allow the request threads to not be set as daemon # so the server waits for them when shutting down gracefully. self.daemon_threads = False def server_bind(self): SD_LISTEN_FDS_START = 3 if os.environ.get('LISTEN_FDS') == '1' and os.environ.get('LISTEN_PID') == str(os.getpid()): self.reload_socket = True self.socket = socket.fromfd(SD_LISTEN_FDS_START, socket.AF_INET, socket.SOCK_STREAM) _logger.info('HTTP service (werkzeug) running through socket activation') else: self.reload_socket = False super(ThreadedWSGIServerReloadable, self).server_bind() _logger.info('HTTP service (werkzeug) running on %s:%s', self.server_name, self.server_port) def server_activate(self): if not self.reload_socket: super(ThreadedWSGIServerReloadable, self).server_activate() def process_request(self, request, client_address): \"\"\" Start a new thread to process the request. Override the default method of class socketserver.ThreadingMixIn to be able to get the thread object which is instantiated and set its start time as an attribute \"\"\" t = threading.Thread(target = self.process_request_thread, args = (request, client_address)) t.daemon = self.daemon_threads t.type = 'http' t.start_time = time.time() t.start() # TODO: Remove this method as soon as either of the revision # - python/cpython@8b1f52b5a93403acd7d112cd1c1bc716b31a418a for Python 3.6, # - python/cpython@908082451382b8b3ba09ebba638db660edbf5d8e for Python 3.7, # is included in all Python 3 releases installed on all operating systems supported by Odoo. # These revisions are included in Python from releases 3.6.8 and Python 3.7.2 respectively. def _handle_request_noblock(self): \"\"\" In the python module `socketserver` `process_request` loop, the __shutdown_request flag is not checked between select and accept. Thus when we set it to `True` thanks to the call `httpd.shutdown`, a last request is accepted before exiting the loop. We override this function to add an additional check before the accept(). \"\"\" if self._BaseServer__shutdown_request: return super(ThreadedWSGIServerReloadable, self)._handle_request_noblock() 参考 https://blog.csdn.net/weixin_35737303/article/details/79038879","tags":[{"name":"odoo","slug":"odoo","permalink":"http://wumuwumu.github.io/tags/odoo/"}]},{"title":"hibernate使用hbm2ddl.auto=在生产环境更新.md","date":"2019-11-16T06:22:56.000Z","path":"posts/undefined.html","text":"https://www.codenong.com/221379/","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"odoo源码解析2-server命令","date":"2019-11-16T03:40:07.000Z","path":"posts/undefined.html","text":"默认情况下的启动命令的server，这个是将odoo运行起来的命令。核心代码如下 ## 判断是否为root用户，如果为root用户就发送警告 check_root_user() ## 解析命令行参数 odoo.tools.config.parse_config(args) ## 如果为postgres用户就停止运行 check_postgres_user() report_configuration() config = odoo.tools.config # the default limit for CSV fields in the module is 128KiB, which is not # quite sufficient to import images to store in attachment. 500MiB is a # bit overkill, but better safe than sorry I guess csv.field_size_limit(500 * 1024 * 1024) ## 创建加载的数据库 preload = [] if config['db_name']: preload = config['db_name'].split(',') for db_name in preload: try: odoo.service.db._create_empty_database(db_name) config['init']['base'] = True except ProgrammingError as err: if err.pgcode == errorcodes.INSUFFICIENT_PRIVILEGE: # We use an INFO loglevel on purpose in order to avoid # reporting unnecessary warnings on build environment # using restricted database access. _logger.info(\"Could not determine if database %s exists, \" \"skipping auto-creation: %s\", db_name, err) else: raise err except odoo.service.db.DatabaseExists: pass if config[\"translate_out\"]: export_translation() sys.exit(0) if config[\"translate_in\"]: import_translation() sys.exit(0) # This needs to be done now to ensure the use of the multiprocessing # signaling mecanism for registries loaded with -d if config['workers']: odoo.multi_process = True ## 是否在启动服务后停止，用户创建更新数据库 stop = config[\"stop_after_init\"] ## 设置pid文件 setup_pid_file() ## 启动server rc = odoo.service.server.start(preload=preload, stop=stop) sys.exit(rc) 参考 https://blog.csdn.net/weixin_35737303/article/details/79038671","tags":[{"name":"odoo","slug":"odoo","permalink":"http://wumuwumu.github.io/tags/odoo/"}]},{"title":"odoo模块加载机制","date":"2019-11-08T12:36:34.000Z","path":"posts/undefined.html","text":"Odoo的启动通过openerp-server脚本完成，它是系统的入口。 然后加载配置文件openerp-server.conf 或者 openerp_serverrc； openerp-server.conf的主要内容： 这个文件缺省是没有的，Odoo系统会有一个默认值，但是一般情况我们都需配置这个文件。 启动http服务器，监听端口。 模块加载： 模块加载外层就是封装一个Registry(Mapping)对象:实际是一个字典，它包含对应的db，model等映射关系，一个DB对应一个Registry。后续的操作都会围绕这个Registry进行，将相关的数据赋值给相应的属性项。 初始化数据库（初次运行)1)加载base模块下的base.sql文件并执行。此时数据库表为： CREATE TABLE ir_actions ( id serial, primary key(id) ); CREATE TABLE ir_act_window (primary key(id)) INHERITS (ir_actions); CREATE TABLE ir_act_report_xml (primary key(id)) INHERITS (ir_actions); CREATE TABLE ir_act_url (primary key(id)) INHERITS (ir_actions); CREATE TABLE ir_act_server (primary key(id)) INHERITS (ir_actions); CREATE TABLE ir_act_client (primary key(id)) INHERITS (ir_actions); CREATE TABLE ir_model ( id serial, model varchar NOT NULL, name varchar, state varchar, info text, primary key(id) ); CREATE TABLE ir_model_fields ( id serial, model varchar NOT NULL, model_id integer references ir_model on delete cascade, name varchar NOT NULL, relation varchar, select_level varchar, field_description varchar, ttype varchar, state varchar default 'base', relation_field varchar, translate boolean default False, serialization_field_id integer references ir_model_fields on delete cascade, primary key(id) ); CREATE TABLE res_lang ( id serial, name VARCHAR(64) NOT NULL UNIQUE, code VARCHAR(16) NOT NULL UNIQUE, primary key(id) ); CREATE TABLE res_users ( id serial NOT NULL, active boolean default True, login varchar(64) NOT NULL UNIQUE, password varchar(64) default null, -- No FK references below, will be added later by ORM -- (when the destination rows exist) company_id integer, -- references res_company, partner_id integer, -- references res_partner, primary key(id) ); create table wkf ( id serial, name varchar(64), osv varchar(64), on_create bool default false, primary key(id) ); CREATE TABLE ir_module_category ( id serial NOT NULL, create_uid integer, -- references res_users on delete set null, create_date timestamp without time zone, write_date timestamp without time zone, write_uid integer, -- references res_users on delete set null, parent_id integer REFERENCES ir_module_category ON DELETE SET NULL, name character varying(128) NOT NULL, primary key(id) ); CREATE TABLE ir_module_module ( id serial NOT NULL, create_uid integer, -- references res_users on delete set null, create_date timestamp without time zone, write_date timestamp without time zone, write_uid integer, -- references res_users on delete set null, website character varying(256), summary character varying(256), name character varying(128) NOT NULL, author character varying(128), icon varchar, state character varying(16), latest_version character varying(64), shortdesc character varying(256), category_id integer REFERENCES ir_module_category ON DELETE SET NULL, description text, application boolean default False, demo boolean default False, web boolean DEFAULT FALSE, license character varying(32), sequence integer DEFAULT 100, auto_install boolean default False, primary key(id) ); ALTER TABLE ir_module_module add constraint name_uniq unique (name); CREATE TABLE ir_module_module_dependency ( id serial NOT NULL, create_uid integer, -- references res_users on delete set null, create_date timestamp without time zone, write_date timestamp without time zone, write_uid integer, -- references res_users on delete set null, name character varying(128), module_id integer REFERENCES ir_module_module ON DELETE cascade, primary key(id) ); CREATE TABLE ir_model_data ( id serial NOT NULL, create_uid integer, create_date timestamp without time zone, write_date timestamp without time zone, write_uid integer, noupdate boolean, name varchar NOT NULL, date_init timestamp without time zone, date_update timestamp without time zone, module varchar NOT NULL, model varchar NOT NULL, res_id integer, primary key(id) ); -- Records foreign keys and constraints installed by a module (so they can be -- removed when the module is uninstalled): -- - for a foreign key: type is 'f', -- - for a constraint: type is 'u' (this is the convention PostgreSQL uses). CREATE TABLE ir_model_constraint ( id serial NOT NULL, date_init timestamp without time zone, date_update timestamp without time zone, module integer NOT NULL references ir_module_module on delete restrict, model integer NOT NULL references ir_model on delete restrict, type character varying(1) NOT NULL, name varchar NOT NULL, primary key(id) ); -- Records relation tables (i.e. implementing many2many) installed by a module -- (so they can be removed when the module is uninstalled). CREATE TABLE ir_model_relation ( id serial NOT NULL, date_init timestamp without time zone, date_update timestamp without time zone, module integer NOT NULL references ir_module_module on delete restrict, model integer NOT NULL references ir_model on delete restrict, name varchar NOT NULL, primary key(id) ); CREATE TABLE res_currency ( id serial, name varchar NOT NULL, primary key(id) ); CREATE TABLE res_company ( id serial, name varchar NOT NULL, partner_id integer, currency_id integer, primary key(id) ); CREATE TABLE res_partner ( id serial, name varchar, company_id integer, primary key(id) ); 这20张表是odoo系统级的，它是模块加载及系统运行的基础。后续模块生成的表及相关数据都可以在这20张中找到蛛丝马迹。 数据库表初始化后，就可以加载模块数据（addons）到数据库了，这个也是odoo作为平台灵活的原因，所有的数据都在数据库。找到addons-path下所有的模块,然后一个一个的加载到数据库中。Info就是load模块的openerp.py文件，它是一个dict。 根据openerp.py中定义的category创建分类信息：将模块信息写入ir_module_module表：将module信息写入ir_model_data表：一个module要写两次ir_model_data表，写module的dependency表： 根据依赖关系进行判断，递归更新那些需要auto_install的模块状态为“to install”。 到目前为止，模块的加载都是在数据库级别，只是将“模块文件”信息存入数据库表，但是还没有真正加载到程序中。Odoo运行时查找object是通过Registry.get()获取的，而不是通过python自己的机制来找到相应的object，所以odoo在加载模块时会把模块下包含的model全部注册到models.py的module_to_models字典中。 **下面的步骤就是加载模块到内存： 加载base模块创建一个包含model层级的节点图，第二行代码将从数据库更新数据到graph中。然后调用load_module_graph方法加载模块，最终执行加载的方法： 这个方法是odoo加载model的核心，通过 __import__方法加载模块，这个是python的机制，当import到某个继承了BaseModel类的class时，它的实例化将有别于python自身的实例化操作，后者说它根本不会通过python自身的__new__方法创建实例，所有的实例创建都是通过 _build_model 方法及元类创建，并注册到module_to_models中。通过这种方式实例化model就可以解决我们在xml中配置model时指定的继承，字段，约束等各种属性。 标记需要加载或者更新的模块（db）加载被标记的模块（加载过程与加载base模块一致）完成及清理安装清理菜单删除卸载的模块核实model的view运行post-install测试","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"},{"name":"odoo","slug":"odoo","permalink":"http://wumuwumu.github.io/tags/odoo/"}]},{"title":"odoo源码解析1-启动命令","date":"2019-11-06T12:01:48.000Z","path":"posts/undefined.html","text":"启动命令#!/usr/bin/env python3 # set server timezone in UTC before time module imported __import__('os').environ['TZ'] = 'UTC' import odoo if __name__ == \"__main__\": odoo.cli.main() main函数主要是进行一些初始化和启动相关的命令 解析启动命令的参数 def main(): args = sys.argv[1:] # The only shared option is '--addons-path=' needed to discover additional # commands from modules if len(args) > 1 and args[0].startswith('--addons-path=') and not args[1].startswith(\"-\"): # parse only the addons-path, do not setup the logger... odoo.tools.config._parse_config([args[0]]) args = args[1:] # Default legacy command command = \"server\" # TODO: find a way to properly discover addons subcommands without importing the world # Subcommand discovery if len(args) and not args[0].startswith(\"-\"): logging.disable(logging.CRITICAL) for module in get_modules(): if isdir(joinpath(get_module_path(module), 'cli')): __import__('odoo.addons.' + module) logging.disable(logging.NOTSET) command = args[0] args = args[1:] if command in commands: o = commands[command]() o.run(args) else: sys.exit('Unknow command %r' % (command,))","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"},{"name":"odoo","slug":"odoo","permalink":"http://wumuwumu.github.io/tags/odoo/"}]},{"title":"python原类实践","date":"2019-11-03T02:24:27.000Z","path":"posts/undefined.html","text":"使用原来创建ORM的实例我们通过创建一个类似Django中的ORM来熟悉一下元类的使用，通常元类用来创建API是非常好的选择，使用元类的编写很复杂但使用者可以非常简洁的调用API。 #我们想创建一个类似Django的ORM，只要定义字段就可以实现对数据库表和字段的操作。 class User(Model): # 定义类的属性到列的映射： id = IntegerField('id') name = StringField('username') email = StringField('email') password = StringField('password') 例如： # 创建一个实例： u = User(id=12345, name='Michael', email='test@orm.org', password='my-pwd') # 保存到数据库： u.save() 接下来我么来实现这么个功能： #coding:utf-8 #一、首先来定义Field类，它负责保存数据库表的字段名和字段类型： class Field(object): def __init__(self, name, column_type): self.name = name self.column_type = column_type def __str__(self): return '&lt;%s:%s>' % (self.__class__.__name__, self.name) class StringField(Field): def __init__(self, name): super(StringField, self).__init__(name, 'varchar(100)') class IntegerField(Field): def __init__(self, name): super(IntegerField, self).__init__(name, 'bigint') #二、定义元类，控制Model对象的创建 class ModelMetaclass(type): '''定义元类''' def __new__(cls, name, bases, attrs): if name=='Model': return super(ModelMetaclass,cls).__new__(cls, name, bases, attrs) mappings = dict() for k, v in attrs.iteritems(): # 保存类属性和列的映射关系到mappings字典 if isinstance(v, Field): print('Found mapping: %s==>%s' % (k, v)) mappings[k] = v for k in mappings.iterkeys(): #将类属性移除，使定义的类字段不污染User类属性，只在实例中可以访问这些key attrs.pop(k) attrs['__table__'] = name.lower() # 假设表名和为类名的小写,创建类时添加一个__table__类属性 attrs['__mappings__'] = mappings # 保存属性和列的映射关系，创建类时添加一个__mappings__类属性 return super(ModelMetaclass,cls).__new__(cls, name, bases, attrs) #三、编写Model基类 class Model(dict): __metaclass__ = ModelMetaclass def __init__(self, **kw): super(Model, self).__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r\"'Model' object has no attribute '%s'\" % key) def __setattr__(self, key, value): self[key] = value def save(self): fields = [] params = [] args = [] for k, v in self.__mappings__.iteritems(): fields.append(v.name) params.append('?') args.append(getattr(self, k, None)) sql = 'insert into %s (%s) values (%s)' % (self.__table__, ','.join(fields), ','.join(params)) print('SQL: %s' % sql) print('ARGS: %s' % str(args)) #最后，我们使用定义好的ORM接口，使用起来非常的简单。 class User(Model): # 定义类的属性到列的映射： id = IntegerField('id') name = StringField('username') email = StringField('email') password = StringField('password') # 创建一个实例： u = User(id=12345, name='Michael', email='test@orm.org', password='my-pwd') # 保存到数据库： u.save() #输出 # Found mapping: email==>&lt;StringField:email> # Found mapping: password==>&lt;StringField:password> # Found mapping: id==>&lt;IntegerField:id> # Found mapping: name==>&lt;StringField:username> # SQL: insert into User (password,email,username,id) values (?,?,?,?) # ARGS: ['my-pwd', 'test@orm.org', 'Michael', 12345] 使用__new__方法和元类方式分别实现单例模式1、__new__、__init__、__call__的介绍在讲到使用元类创建单例模式之前，比需了解__new__这个内置方法的作用，在上面讲元类的时候我们用到了__new__方法来实现类的创建。然而我在那之前还是对__new__这个方法和__init__方法有一定的疑惑。因此这里花点时间对其概念做一次了解和区分。 __new__方法负责创建一个实例对象，在对象被创建的时候调用该方法它是一个类方法。__new__方法在返回一个实例之后，会自动的调用__init__方法，对实例进行初始化。如果__new__方法不返回值，或者返回的不是实例，那么它就不会自动的去调用__init__方法。 init 方法负责将该实例对象进行初始化，在对象被创建之后调用该方法，在__new__方法创建出一个实例后对实例属性进行初始化。__init__方法可以没有返回值。 __call__方法其实和类的创建过程和实例化没有多大关系了，定义了__call__方法才能被使用函数的方式执行。 例如： class A(object): def __call__(self): print \"__call__ be called\" a = A() a() #输出 #__call__ be called 打个比方帮助理解：如果将创建实例的过程比作建一个房子。 那么class就是一个房屋的设计图，他规定了这个房子有几个房间，每个人房间的大小朝向等。这个设计图就是累的结构 __new__就是一个房屋的框架，每个具体的房屋都需要先搭好框架后才能进行专修，当然现有了房屋设计才能有具体的房屋框架出来。这个就是从类到类实例的创建。 __init__就是装修房子的过程，对房屋的墙面和地板等颜色材质的丰富就是它该做的事情，当然先有具体的房子框架出来才能进行装饰了。这个就是实例属性的初始化，它是在__new__出一个实例后才能初始化。 __call__就是房子的电话，有了固定电话，才能被打电话嘛（就是通过括号的方式像函数一样执行）。 #coding:utf-8 class Foo(object): def __new__(cls, *args, **kwargs): #__new__是一个类方法，在对象创建的时候调用 print \"excute __new__\" return super(Foo,cls).__new__(cls,*args,**kwargs) def __init__(self,value): #__init__是一个实例方法，在对象创建后调用，对实例属性做初始化 print \"excute __init\" self.value = value f1 = Foo(1) print f1.value f2 = Foo(2) print f2.value #输出===： excute __new__ excute __init 1 excute __new__ excute __init 2 #====可以看出new方法在init方法之前执行 子类如果重写__new__方法，一般依然要调用父类的__new__方法。 class Child(Foo): def __new__(cls, *args, **kwargs): return suyper(Child, cls).__new__(cls, *args, **kwargs) 必须注意的是，类的new__方法之后，必须生成本类的实例才能自动调用本类的__init__方法进行初始化，否则不会自动调用__init. class Foo(object): def __init__(self, *args, **kwargs): print \"Foo __init__\" def __new__(cls, *args, **kwargs): return object.__new__(Stranger, *args, **kwargs) class Stranger(object): def __init__(self,name): print \"class Stranger's __init__ be called\" self.name = name foo = Foo(\"test\") print type(foo) #&lt;class '__main__.Stranger'> print foo.name #AttributeError: 'Stranger' object has no attribute 'name' #说明：如果new方法返回的不是本类的实例，那么本类（Foo）的init和生成的类(Stranger)的init都不会被调用 2.实现单例模式依照Python官方文档的说法，__new__方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。接下来我们分别通过这两种方式来实现单例模式。当初在看到cookbook中的元类来实现单例模式的时候对其相当疑惑，因此才有了上面这些对元类的总结。 简单来说，单例模式的原理就是通过在类属性中添加一个单例判定位ins_flag，通过这个flag判断是否已经被实例化过了,如果被实例化过了就返回该实例。 __new__方法实现单例：class Singleton(object): def __new__(cls, *args, **kwargs): if not hasattr(cls,\"_instance\"): cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls._instance s1 = Singleton() s2 = Singleton() print s1 is s2 因为重写__new__方法，所以继承至Singleton的类，在不重写__new__的情况下都将是单例模式。 元类实现单例当初我也很疑惑为什么我们是从写使用元类的__init__方法，而不是使用__new__方法来初为元类增加一个属性。其实我只是上面那一段关于元类中__new__方法迷惑了，它主要用于我们需要对类的结构进行改变的时候我们才要重写这个方法。 class Singleton(type): def __init__(self, *args, **kwargs): print \"__init__\" self.__instance = None super(Singleton,self).__init__(*args, **kwargs) def __call__(self, *args, **kwargs): print \"__call__\" if self.__instance is None: self.__instance = super(Singleton,self).__call__(*args, **kwargs) return self.__instance class Foo(object): __metaclass__ = Singleton #在代码执行到这里的时候，元类中的__new__方法和__init__方法其实已经被执行了，而不是在Foo实例化的时候执行。且仅会执行一次。 foo1 = Foo() foo2 = Foo() print Foo.__dict__ #_Singleton__instance': &lt;__main__.Foo object at 0x100c52f10> 存在一个私有属性来保存属性，而不会污染Foo类（其实还是会污染，只是无法直接通过__instance属性访问） print foo1 is foo2 # True # 输出 # __init__ # __call__ # __call__ # &#123;'__module__': '__main__', '__metaclass__': &lt;class '__main__.Singleton'>, '_Singleton__instance': &lt;__main__.Foo object at 0x100c52f10>, '__dict__': &lt;attribute '__dict__' of 'Foo' objects>, '__weakref__': &lt;attribute '__weakref__' of 'Foo' objects>, '__doc__': None&#125; # True 基于这个例子： 我们知道元类(Singleton)生成的实例是一个类(Foo),而这里我们仅仅需要对这个实例(Foo)增加一个属性(__instance)来判断和保存生成的单例。想想也知道为一个类添加一个属性当然是在__init__中实现了。 关于__call__方法的调用，因为Foo是Singleton的一个实例。所以Foo()这样的方式就调用了Singleton的__call__方法。不明白就回头看看上一节中的__call__方法介绍。 假如我们通过元类的__new__方法来也可以实现，但显然没有通过__init__来实现优雅，因为我们不会为了为实例增加一个属性而重写__new__方法。所以这个形式不推荐。 class Singleton(type): def __new__(cls, name,bases,attrs): print \"__new__\" attrs[\"_instance\"] = None return super(Singleton,cls).__new__(cls,name,bases,attrs) def __call__(self, *args, **kwargs): print \"__call__\" if self._instance is None: self._instance = super(Singleton,self).__call__(*args, **kwargs) return self._instance class Foo(object): __metaclass__ = Singleton foo1 = Foo() foo2 = Foo() print Foo.__dict__ print foo1 is foo2 # True # 输出 # __new__ # __call__ # __call__ # &#123;'__module__': '__main__', '__metaclass__': &lt;class '__main__.Singleton'>, '_instance': &lt;__main__.Foo object at 0x103e07ed0>, '__dict__': &lt;attribute '__dict__' of 'Foo' objects>, '__weakref__': &lt;attribute '__weakref__' of 'Foo' objects>, '__doc__': None&#125; # True","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"}]},{"title":"python原类","date":"2019-11-03T02:05:32.000Z","path":"posts/undefined.html","text":"Python中一切皆对象，类也是对象​ 之前我们说Python中一切都是对象。对象从哪里来，对象是类的实例。如下，使用type()函数查看对象所属的类型。我们可以看到Python中所以实例都是类的对象。那么类呢，既然一切都是对象，那么类也应该是对象。如下代码中发现我们创建的Person类原来也是对象，是type的对象。 a =10; b = 12.12; c=\"hello\" ;d =[1,2,3,\"rr\"];e = &#123;\"aa\":1,\"bb\":\"cc\"&#125; type(a);type(b);type(c);type(d);type(e) &lt;class 'int'> #a = 10;a也是对象，即10是对象，是int类型的对象 &lt;class 'float'> #float也是类，注意python很多类的写法是小写，有的则是大写 &lt;class 'str'> &lt;class 'list'> &lt;class 'dict'>class Person(object): print(\"不调用类，也会执行我\") def __init__(self,name): self.name = name def p(self): print(\"this is a methond\") print(Person) tom = Person(\"tom\") print(\"tom实例的类型是：%s\"%type(tom)) # 实例tom是Person类的对象。 print(\"Peron类的类型：%s\"%type(Person)) #结果看出我们创建的类属于type类,也就是说Person是type类的对象 print(\"type的类型是：%s\"%type(type)) #type是type自己的对象 不调用类，也会执行我 &lt;class '__main__.Person'> tom实例的类型是：&lt;class '__main__.Person'> Peron类的类型：&lt;class 'type'> type的类型是：&lt;class 'type'> 动态创建类通过class动态的构建需要的类因为类也是对象，你可以在运行时动态的创建它们，就像其他任何对象一样。首先，你可以在函数中创建类，使用class关键字即可。 def choose_class(name): if name == 'foo': class Foo(object): pass return Foo # 返回的是类，不是类的实例 else: class Bar(object): pass return Bar MyClass = choose_class('foo') print MyClass # 函数返回的是类，不是类的实例 #输出：&lt;class '__main__.Foo'> print MyClass() # 你可以通过这个类创建类实例，也就是对象 #输出：&lt;__main__.Foo object at 0x1085ed950 通过type函数构造类但这还不够动态，因为你仍然需要自己编写整个类的代码。由于类也是对象，所以它们必须是通过什么东西来生成的才对。当你使用class关键字时，Python解释器自动创建这个对象。但就和Python中的大多数事情一样，Python仍然提供给你手动处理的方法。还记得内建函数type吗？这个古老但强大的函数能够让你知道一个对象的类型是什么，就像这样： print type(1) #输出：&lt;type 'int'> print type(\"1\") #输出：&lt;type 'str'> print type(ObjectCreator) #输出：&lt;type 'type'> print type(ObjectCreator()) #输出：&lt;class '__main__.ObjectCreator'> 这里，type有一种完全不同的能力，它也能动态的创建类。type可以接受一个类的描述作为参数，然后返回一个类。（我知道，根据传入参数的不同，同一个函数拥有两种完全不同的用法是一件很傻的事情，但这在Python中是为了保持向后兼容性） type的语法： type(类名, 父类的元组（针对继承的情况，可以为空），包含属性的字典（名称和值）) 比如下面的代码： class MyShinyClass(object): pass 可以手动通过type创建，其实 MyShinyClass = type('MyShinyClass', (), &#123;&#125;) # 返回一个类对象 print MyShinyClass #输出：&lt;class '__main__.MyShinyClass'> print MyShinyClass() # 创建一个该类的实例 #输出：&lt;__main__.MyShinyClass object at 0x1085cd810> 你会发现我们使用“MyShinyClass”作为类名，并且也可以把它当做一个变量来作为类的引用。 接下来我们通过一个具体的例子看看type是如何创建类的，范例：javascript:void(0);) 1、构建Foo类 #构建目标代码 class Foo(object): bar = True #使用type构建 Foo = type('Foo', (), &#123;'bar':True&#125;) 2.继承Foo类 #构建目标代码： class FooChild(Foo): pass #使用type构建 FooChild = type('FooChild', (Foo,),&#123;&#125;) print FooChild #输出：&lt;class '__main__.FooChild'> print FooChild.bar # bar属性是由Foo继承而来 #输出：True 3.为Foochild类增加方法 def echo_bar(self): print self.bar FooChild = type('FooChild', (Foo,), &#123;'echo_bar': echo_bar&#125;) hasattr(Foo, 'echo_bar') #输出：False hasattr(FooChild, 'echo_bar') #输出：True my_foo = FooChild() my_foo.echo_bar() #输出：True 可以看到，在Python中，类也是对象，你可以动态的创建类。这就是当我们使用关键字class时Python在幕后做的事情，而这就是通过元类来实现的。 type创建类与class的比较使用type创建带属性和方法的类 1.使用type创建带有属性的类,添加的属性是类属性，并不是实例属性 Girl = type(\"Girl\",(),&#123;\"country\":\"china\",\"sex\":\"male\"&#125;) girl = Girl() print(girl.country,girl.sex) #使用type创建的类，调用属性时IDE不会自动提示补全 print(type(girl),type(Girl)) ''' china male &lt;class '__main__.Girl'> &lt;class 'type'> ''' 2.使用type创建带有方法的类 #python中方法有普通方法，类方法，静态方法。 def speak(self): #要带有参数self,因为类中方法默认带self参数。 print(\"这是给类添加的普通方法\") @classmethod def c_run(cls): print(\"这是给类添加的类方法\") @staticmethod def s_eat(): print(\"这是给类添加的静态方法\") #创建类，给类添加静态方法，类方法，普通方法。跟添加类属性差不多. Boy = type(\"Boy\",(),&#123;\"speak\":speak,\"c_run\":c_run,\"s_eat\":s_eat,\"sex\":\"female\"&#125;) boy = Boy() boy.speak() boy.s_eat() #调用类中的静态方法 boy.c_run() #调用类中类方法 print(\"boy.sex:\",boy.sex) print(type(boy),type(Boy)) ''' 这是给类添加的普通方法 这是给类添加的静态方法 这是给类添加的类方法 boy.sex: female &lt;class '__main__.Boy'> &lt;class 'type'> ''' 使用type定义带继承，属性和方法的类class Person(object): def __init__(self,name): self.name = name def p(self): print(\"这是Person的方法\") class Animal(object): def run(self): print(\"animal can run \") #定义一个拥有继承的类，继承的效果和性质和class一样。 Worker = type(\"Worker\",(Person,Animal),&#123;\"job\":\"程序员\"&#125;) w1 = Worker(\"tom\") w1.p() w1.run() print(type(w1),type(Worker)) ''' 这是Person的方法 animal can run &lt;class '__main__.Worker'> &lt;class 'type'> &lt;class '__main__.Person'> ''' 总结： 通过type添加的属性是类属性，并不是实例属性通过type可以给类添加普通方法，静态方法，类方法，效果跟class一样type创建类的效果，包括继承等的使用性质和class创建的类一样。本质class创建类的本质就是用type创建。所以可以说python中所有类都是type创建的。 自定义元类元类的主要目的就是为了当创建类时能够自动地改变类。通常，你会为API做这样的事情，你希望可以创建符合当前上下文的类。假想一个很傻的例子，你决定在你的模块里所有的类的属性都应该是大写形式。有好几种方法可以办到，但其中一种就是通过设定__metaclass__。采用这种方法，这个模块中的所有类都会通过这个元类来创建，我们只需要告诉元类把所有的属性都改成大写形式就万事大吉了。 __metaclass__实际上可以被任意调用，它并不需要是一个正式的类。所以，我们这里就先以一个简单的函数作为例子开始。 1、使用函数当做元类# 元类会自动将你通常传给‘type’的参数作为自己的参数传入 def upper_attr(future_class_name, future_class_parents, future_class_attr): '''返回一个类对象，将属性都转为大写形式''' #选择所有不以'__'开头的属性 attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith('__')) # 将它们转为大写形式 uppercase_attr = dict((name.upper(), value) for name, value in attrs) #通过'type'来做类对象的创建 return type(future_class_name, future_class_parents, uppercase_attr)#返回一个类 class Foo(object): __metaclass__ = upper_attr bar = 'bip' print hasattr(Foo, 'bar') # 输出: False print hasattr(Foo, 'BAR') # 输出:True f = Foo() print f.BAR # 输出:'bip' 2、使用class来当做元类由于__metaclass__必须返回一个类。 # 请记住，'type'实际上是一个类，就像'str'和'int'一样。所以，你可以从type继承 # __new__ 是在__init__之前被调用的特殊方法，__new__是用来创建对象并返回之的方法，__new_()是一个类方法 # 而__init__只是用来将传入的参数初始化给对象，它是在对象创建之后执行的方法。 # 你很少用到__new__，除非你希望能够控制对象的创建。这里，创建的对象是类，我们希望能够自定义它，所以我们这里改写__new__ # 如果你希望的话，你也可以在__init__中做些事情。还有一些高级的用法会涉及到改写__call__特殊方法，但是我们这里不用，下面我们可以单独的讨论这个使用 class UpperAttrMetaClass(type): def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) return type(future_class_name, future_class_parents, uppercase_attr)#返回一个对象，但同时这个对象是一个类 但是，这种方式其实不是OOP。我们直接调用了type，而且我们没有改写父类的__new__方法。现在让我们这样去处理: class UpperAttrMetaclass(type): def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) # 复用type.__new__方法 # 这就是基本的OOP编程，没什么魔法。由于type是元类也就是类，因此它本身也是通过__new__方法生成其实例，只不过这个实例是一个类. return type.__new__(upperattr_metaclass, future_class_name, future_class_parents, uppercase_attr) 你可能已经注意到了有个额外的参数upperattr_metaclass，这并没有什么特别的。类方法的第一个参数总是表示当前的实例，就像在普通的类方法中的self参数一样。当然了，为了清晰起见，这里的名字我起的比较长。但是就像self一样，所有的参数都有它们的传统名称。因此，在真实的产品代码中一个元类应该是像这样的： class UpperAttrMetaclass(type): def __new__(cls, name, bases, dct): attrs = ((name, value) for name, value in dct.items() if not name.startswith('__') uppercase_attr = dict((name.upper(), value) for name, value in attrs) return type.__new__(cls, name, bases, uppercase_attr) 如果使用super方法的话，我们还可以使它变得更清晰一些。 class UpperAttrMetaclass(type): def __new__(cls, name, bases, dct): attrs = ((name, value) for name, value in dct.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) return super(UpperAttrMetaclass, cls).__new__(cls, name, bases, uppercase_attr) 参考https://www.cnblogs.com/tkqasn/p/6524879.html https://blog.csdn.net/qq_26442553/article/details/82459234","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"}]},{"title":"pm2学习","date":"2019-11-02T02:10:05.000Z","path":"posts/undefined.html","text":"pm2基本命令# 启动程序 pm2 start app.js pm2 start npm --name pro -- run dev # 查看程序 pm2 start list pm2 monit pm2 logs # 重启 pm2 restart all pm2 reload all pm2 restartt 0 # 停止 pm2 stop all pm2 stop 0 # 杀死 pm2 delete all pm2 delete 0 # 集群 pm2 start app.js -i max # 根据cpu数目启动线程 pm2 start app.js -i 3 # 启动3个进程 pm2 start app.js -x # 使用fork模式启动 pm2 start app.json 日志问题日志系统对于任意应用而言，通常都是必不可少的一个辅助功能。pm2的相关文件默认存放于$HOME/.pm2/目录下，其日志主要有两类： a. pm2自身的日志，存放于$HOME/.pm2/pm2.log； b. pm2所管理的应用的日志，存放于$HOME/.pm2/logs/目录下，标准谁出日志存放于${APP_NAME}_out.log，标准错误日志存放于${APP_NAME}_error.log； 这里之所以把日志单独说明一下是因为，如果程序开发不严谨，为了调试程序，导致应用产生大量标准输出，使服务器本身记录大量的日志，导致服务磁盘满载问题。一般而言，pm2管理的应用本身都有自己日志系统，所以对于这种不必要的输出内容需禁用日志，重定向到/dev/null。 与crontab比较，也有类似情况，crontab自身日志，与其管理的应用本身的输出。应用脚本输出一定需要重定向到/dev/null，因为该输出内容会以邮件的形式发送给用户，内容存储在邮件文件，会产生意向不到的结果，或会导致脚本压根不被执行； 开机启动pm2 startup systemctl enable pm2-root 参考https://pm2.keymetrics.io/docs/usage/monitoring/","tags":[{"name":"node","slug":"node","permalink":"http://wumuwumu.github.io/tags/node/"}]},{"title":"Dockerfile中的CMD与ENTRYPOINT","date":"2019-10-29T15:49:07.000Z","path":"posts/undefined.html","text":"https://www.cnblogs.com/sparkdev/p/8461576.html","tags":[{"name":"docker","slug":"docker","permalink":"http://wumuwumu.github.io/tags/docker/"}]},{"title":"docker网络模式","date":"2019-10-29T06:26:03.000Z","path":"posts/undefined.html","text":"Docker的网络模式详解1、Docker的四种网络模式 （1）docker四种网络模式如下： Bridge contauner 桥接式网络模式 Host(open) container 开放式网络模式 Container(join) container 联合挂载式网络模式，是host网络模式的延伸 None(Close) container 封闭式网络模式 （2）可以通过docker network命令查看 [root@along ~]# docker network ls NETWORK ID NAME DRIVER SCOPE f23b4899add1 bridge bridge local 65520497f693 host host local a0c5f18e0f04 none null local复制代码 （3）docker run –network 命令可以指定使用网络模式 2、Bridge 网络模式2.1 介绍 当Docker进程启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上，所以有默认地址172.17.0.0/16的地址。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。 从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。在主机上创建一对虚拟网卡veth pair设备，Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0（容器的网卡），另一端放在主机中，以vethxxx这样类似的名字命名，并将这个网络设备加入到docker0网桥中。可以通过brctl show命令查看。 [root@along ~]# brctl show bridge name bridge id STP enabled interfaces docker0 8000.024241c45d6e no复制代码 bridge模式是docker的默认网络模式，不写–net参数，就是bridge模式。使用docker run -p时，docker实际是在iptables做了DNAT规则，实现端口转发功能。可以使用iptables -t nat -vnL查看。 [root@along ~]# iptables -t nat -vnL Chain POSTROUTING (policy ACCEPT 20 packets, 1238 bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0&#x2F;16 0.0.0.0&#x2F;0复制代码 2.2 bridge模式示意图 2.3 演示bridge 网络模式；–network不指定，默认也是bridge模式 [root@along ~]# docker run --name b1 -it --network bridge --rm busybox:latest &#x2F; # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::42:acff:fe11:2&#x2F;64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:12 errors:0 dropped:0 overruns:0 frame:0 TX packets:6 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:1016 (1016.0 B) TX bytes:508 (508.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1&#x2F;128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) &#x2F; # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.17.0.1 0.0.0.0 UG 0 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0 &#x2F; # ping 10.11.55.5 正常访问宿主机 PING 10.11.55.5 (10.11.55.5): 56 data bytes 64 bytes from 10.11.55.5: seq&#x3D;0 ttl&#x3D;64 time&#x3D;0.292 ms &#x2F; # exit复制代码 3、Host 网络模式3.1 介绍 如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。 3.2 Host模式示意图 3.3 演示[root@along ~]# docker run --name b2 -it --network host --rm busybox:latest &#x2F; # ifconfig -a 和宿主机一样 docker0 Link encap:Ethernet HWaddr 02:42:41:C4:5D:6E inet addr:172.17.0.1 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::42:41ff:fec4:5d6e&#x2F;64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:90 errors:0 dropped:0 overruns:0 frame:0 TX packets:26 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:5903 (5.7 KiB) TX bytes:2381 (2.3 KiB) eth0 Link encap:Ethernet HWaddr 00:0C:29:AB:D2:DA inet addr:10.11.55.5 Bcast:10.11.55.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:feab:d2da&#x2F;64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:3913 errors:0 dropped:0 overruns:0 frame:0 TX packets:3327 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:354314 (346.0 KiB) TX bytes:919096 (897.5 KiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1&#x2F;128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)复制代码 4、Container 网络模式4.1 介绍 这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。 4.2 Container模式示意图 4.3 演示（1）在一个终端，使用bridge网络模式启动容器b1 [root@along ~]# docker run --name b1 -it --rm busybox:latest &#x2F; # ifconfig b1的ip为172.17.0.2 eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::42:acff:fe11:2&#x2F;64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:6 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:508 (508.0 B) TX bytes:508 (508.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1&#x2F;128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) &#x2F; # echo &quot;hello world b1&quot; &gt; &#x2F;tmp&#x2F;index.html &#x2F; # httpd -h &#x2F;tmp&#x2F; 在b1上启动httpd服务 &#x2F; # netstat -nutl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 :::80 :::* LISTEN 复制代码 （2）在另一个终端使用Container 网络模式创建容器b2 [root@along ~]# docker run --name b2 -it --network container:b1 --rm busybox:latest &#x2F; # ifconfig -a b2的ip和b1一样 eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::42:acff:fe11:2&#x2F;64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:8 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:648 (648.0 B) TX bytes:648 (648.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1&#x2F;128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) &#x2F; # wget -O - -q 127.0.0.1 b1启动的httpd服务，在b2上直接访问 hello world b1 &#x2F; # ls &#x2F;tmp&#x2F; 但是文件系统并不共享，只共享网络复制代码 5、None 网络模式5.1 介绍 使用none模式，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息，只有lo 网络接口。需要我们自己为Docker容器添加网卡、配置IP等。 不参与网络通信，运行于此类容器中的进程仅能访问本地回环接口；仅适用于进程无须网络通信的场景中，例如：备份、进程诊断及各种离线任务等。 5.2 Node模式示意图5.3 演示[root@along ~]# docker run --name b1 -it --network none --rm busybox:latest &#x2F; # ifconfig lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1&#x2F;128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) &#x2F; # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface","tags":[{"name":"docker","slug":"docker","permalink":"http://wumuwumu.github.io/tags/docker/"}]},{"title":"npm版本管理","date":"2019-10-29T06:08:30.000Z","path":"posts/undefined.html","text":"在打包项目的时候，我们都要更新package.json的版本号，接着给给代码添加tag，最后push代码，这样的流程泰国麻烦有什么方法简化。 1. package.json&#96;中修改递增&#96;version 2. git add -A 3. git commit -m &quot;update version&quot; 4. git push 5. git tag &lt;tag version&gt; 6. git push --tag 7. npm publish 解决方法我们可以使用npm version命令，从文档上我们可以看到其依据semver支持了大部分alias： npm version [&lt;newversion> | major | minor | patch | premajor | preminor | prepatch | prerelease | from-git] 例：初始版本为1.0.0 npm version prepatch //预备补丁版本号 v1.0.1-0 npm version prerelease //预发布版本号 v1.0.1-1 npm version patch //补丁版本号 v1.0.2 npm version preminor //预备次版本号 v1.1.0-0 npm version minor //次版本号 v1.1.0 npm version premajor //预备主版本号 v2.0.0-0 npm version major //主版本号 v2.0.0 当在仓库中执行npm version时，会自动提交git commit并打上git tag。 当使用-m参数时，就可以自定义发布版本的信息，其中%s可以用来代替当前版本号 npm version patch -m &quot;upgrade to %s for reasons&quot; 复制代码 这样以后版本迭代只需要以下步骤 npm version patch | minor | major | ...etc git push git push --tag npm publish npm version会同时创建时 v版本号 形式的tag，将tag push上去就可以自动触发构建了。 也可以简化这步操作，在npm version操作后自动 push 在 package.json中加入下面的代码，即可实现npm version操作后，自动push代码及tag，也就自动触发了 npm 发布操作。 \"scripts\": &#123; \"postversion\": \"git push --follow-tags\" &#125; 衍生问题 如何发布beta，rc，alpha版本呢？如果发布了，应该如何安装？ 解决方案首先我们要理解这些版本的含义 alpha：内部测试版本 beta： 公开测试版本 rc： 候选版本（Release Candidate） 然后将package.json的version改成x.x.x-beta 配合npm publish --tag &lt;tag&gt;，我们可以发布对应的dist-tag 举个例子： 使用npm publish --tag beta发布后，然后就可以使用npm install &lt;pkg&gt;@beta安装对应版本的包。 我们可以通过npm dist-tag ls &lt;pkg&gt;来查看包的dist-tag &#123; latest: 1.0.1, // 这就是npm publish默认发布的tag beta: 1.0.1-beta &#125; 当我们的beta版本稳定后，可以使用npm dist-tag add x.x.x-beta latest设置为稳定版本。 npm version与npm dist-tag关于npm version prerelease的作用我这里不再赘述，你可以查看这个文章。我只是记录一下关于npm version与npm dist-tag的使用： 第一步：发布第一个稳定版本 npm publish&#x2F;&#x2F;1.0.0 第二步：修改文件继续发布第二个版本 git add -A &amp;&amp; git commit -m &quot;c&quot; npm version patch npm publish&#x2F;&#x2F;1.0.1 第三步：继续修改文件发布一个prerelease版本 git add -A &amp;&amp; git commit -m &quot;c&quot; npm version prerelease npm publish --tag -beta&#x2F;&#x2F;版本n-n-n-n@1.0.2-0 第四步：继续修改发布第二个prerelease版本 git add -A &amp;&amp; git commit -m &quot;c&quot; npm version prerelease npm publish --tag -beta&#x2F;&#x2F;版本n-n-n-n@1.0.2-1 第五步：npm info查看我们的版本信息 &#123; name: 'n-n-n-n', 'dist-tags': &#123; latest: '1.0.1', '-beta': '1.0.2-1' &#125;, versions: [ '1.0.0', '1.0.1', '1.0.2-0', '1.0.2-1' ], maintainers: [ 'liangklfang &lt;liangklfang@163.com>' ], time: &#123; modified: '2017-04-01T12:17:56.755Z', created: '2017-04-01T12:15:23.605Z', '1.0.0': '2017-04-01T12:15:23.605Z', '1.0.1': '2017-04-01T12:16:24.916Z', '1.0.2-0': '2017-04-01T12:17:23.354Z', '1.0.2-1': '2017-04-01T12:17:56.755Z' &#125;, homepage: 'https://github.com/liangklfang/n#readme', repository: &#123; type: 'git', url: 'git+https://github.com/liangklfang/n.git' &#125;, bugs: &#123; url: 'https://github.com/liangklfang/n/issues' &#125;, license: 'ISC', readmeFilename: 'README.md', version: '1.0.1', description: '', main: 'index.js', scripts: &#123; test: 'echo \"Error: no test specified\" &amp;&amp; exit 1' &#125;, author: '', gitHead: '8123b8addf6fed83c4c5edead1dc2614241a4479', dist: &#123; shasum: 'a60d8b02222e4cae74e91b69b316a5b173d2ac9d', tarball: 'https://registry.npmjs.org/n-n-n-n/-/n-n-n-n-1.0.1.tgz' &#125;, directories: &#123;&#125; &#125; 我们只要注意下面者两个部分： &#39;dist-tags&#39;: &#123; latest: &#39;1.0.1&#39;, &#39;-beta&#39;: &#39;1.0.2-1&#39; &#125;, versions: [ &#39;1.0.0&#39;, &#39;1.0.1&#39;, &#39;1.0.2-0&#39;, &#39;1.0.2-1&#39; ], 其中最新的稳定版本和最新的beta版本可以在dist-tags中看到，而versions数组中存储的是所有的版本。 第六步：npm dist-tag命令 npm dist-tag ls n-n-n-n 即npm dist-tag获取到所有的最新的版本，包括prerelease与稳定版本，得到下面结果： -beta: 1.0.2-1 latest: 1.0.1 第七步：当我们的prerelease版本已经稳定了，重新设置为稳定版本 npm dist-tag add n-n-n-n@1.0.2-1 latest 此时你通过npm info查看可以知道： &#123; name: 'n-n-n-n', 'dist-tags': &#123; latest: '1.0.2-1', '-beta': '1.0.2-1' &#125;, versions: [ '1.0.0', '1.0.1', '1.0.2-0', '1.0.2-1' ], maintainers: [ 'liangklfang &lt;liangklfang@163.com>' ], time: &#123; modified: '2017-04-01T12:24:55.800Z', created: '2017-04-01T12:15:23.605Z', '1.0.0': '2017-04-01T12:15:23.605Z', '1.0.1': '2017-04-01T12:16:24.916Z', '1.0.2-0': '2017-04-01T12:17:23.354Z', '1.0.2-1': '2017-04-01T12:17:56.755Z' &#125;, homepage: 'https://github.com/liangklfang/n#readme', repository: &#123; type: 'git', url: 'git+https://github.com/liangklfang/n.git' &#125;, bugs: &#123; url: 'https://github.com/liangklfang/n/issues' &#125;, license: 'ISC', readmeFilename: 'README.md', version: '1.0.2-1', description: '', main: 'index.js', scripts: &#123; test: 'echo \"Error: no test specified\" &amp;&amp; exit 1' &#125;, author: '', gitHead: '03189d2cc61604aa05f4b93e429d3caa3b637f8c', dist: &#123; shasum: '41ea170a6b155c8d61658cd4c309f0d5d1b12ced', tarball: 'https://registry.npmjs.org/n-n-n-n/-/n-n-n-n-1.0.2-1.tgz' &#125;, directories: &#123;&#125; &#125; 主要关注如下: &#39;dist-tags&#39;: &#123; latest: &#39;1.0.2-1&#39;, &#39;-beta&#39;: &#39;1.0.2-1&#39; &#125;, versions: [ &#39;1.0.0&#39;, &#39;1.0.1&#39;, &#39;1.0.2-0&#39;, &#39;1.0.2-1&#39; ] 此时latest版本已经是prerelease版本”1.0.2-1”了！此时用户如果直接运行npm install就会安装我们的prerelease版本了，因为版本已经更新了！ 当然，我们的npm publish可以有很多tag的，比如上面是beta，也可以是stable, dev, canary等，比如下面你继续运行： git add -A &amp;&amp; git commit -m &quot;c&quot; npm version prerelease npm publish --tag -dev 此时你运行npm info就会得到下面的信息： &#123; name: &#39;n-n-n-n&#39;, &#39;dist-tags&#39;: &#123; latest: &#39;1.0.2-1&#39;, &#39;-beta&#39;: &#39;1.0.2-1&#39;, &#39;-dev&#39;: &#39;1.0.2-2&#39; &#125;, versions: [ &#39;1.0.0&#39;, &#39;1.0.1&#39;, &#39;1.0.2-0&#39;, &#39;1.0.2-1&#39;, &#39;1.0.2-2&#39; ], maintainers: [ &#39;liangklfang &lt;liangklfang@163.com&gt;&#39; ], time: &#123; modified: &#39;2017-04-01T13:01:17.106Z&#39;, created: &#39;2017-04-01T12:15:23.605Z&#39;, &#39;1.0.0&#39;: &#39;2017-04-01T12:15:23.605Z&#39;, &#39;1.0.1&#39;: &#39;2017-04-01T12:16:24.916Z&#39;, &#39;1.0.2-0&#39;: &#39;2017-04-01T12:17:23.354Z&#39;, &#39;1.0.2-1&#39;: &#39;2017-04-01T12:17:56.755Z&#39;, &#39;1.0.2-2&#39;: &#39;2017-04-01T13:01:17.106Z&#39; &#125;, homepage: &#39;https:&#x2F;&#x2F;github.com&#x2F;liangklfang&#x2F;n#readme&#39;, repository: &#123; type: &#39;git&#39;, url: &#39;git+https:&#x2F;&#x2F;github.com&#x2F;liangklfang&#x2F;n.git&#39; &#125;, bugs: &#123; url: &#39;https:&#x2F;&#x2F;github.com&#x2F;liangklfang&#x2F;n&#x2F;issues&#39; &#125;, license: &#39;ISC&#39;, readmeFilename: &#39;README.md&#39;, version: &#39;1.0.2-1&#39;, description: &#39;&#39;, main: &#39;index.js&#39;, scripts: &#123; test: &#39;echo &quot;Error: no test specified&quot; &amp;&amp; exit 1&#39; &#125;, author: &#39;&#39;, gitHead: &#39;03189d2cc61604aa05f4b93e429d3caa3b637f8c&#39;, dist: &#123; shasum: &#39;41ea170a6b155c8d61658cd4c309f0d5d1b12ced&#39;, tarball: &#39;https:&#x2F;&#x2F;registry.npmjs.org&#x2F;n-n-n-n&#x2F;-&#x2F;n-n-n-n-1.0.2-1.tgz&#39; &#125;, directories: &#123;&#125; &#125; 重点关注如下内容 &#39;dist-tags&#39;: &#123; latest: &#39;1.0.2-1&#39;, &#39;-beta&#39;: &#39;1.0.2-1&#39;, &#39;-dev&#39;: &#39;1.0.2-2&#39; &#125;, versions: [ &#39;1.0.0&#39;, &#39;1.0.1&#39;, &#39;1.0.2-0&#39;, &#39;1.0.2-1&#39;, &#39;1.0.2-2&#39; ], 此时你会看到-beta版本最新是1.0.2-1，而-dev版本最新是1.0.2-2 参考 https://github.com/liangklfangl/npm-dist-tag https://juejin.im/post/5b624d42f265da0fa1223ffa https://docs.npmjs.com/cli/version","tags":[{"name":"node","slug":"node","permalink":"http://wumuwumu.github.io/tags/node/"}]},{"title":"python中and和or用法","date":"2019-10-25T07:41:30.000Z","path":"posts/undefined.html","text":"在Python 中，and 和 or 执行布尔逻辑演算，如你所期待的一样。但是它们并不返回布尔值，而是返回它们实际进行比较的值之一。 （类似C++里面的&amp;&amp;和||的短路求值） （ 在布尔环境中，0、”、[]、()、{}、None为假；其它任何东西都为真。但是可以在类中定义特定的方法使得类实例的演算值为假。） and实例：>>> 'a' and 'b' 'b' >>> '' and 'b' '' >>> 'a' and 'b' and 'c' 'c'12345 从左到右扫描，返回第一个为假的表达式值，无假值则返回最后一个表达式值。 or实例：>>> 'a' or 'b' 'a' >>> '' or 'b' 'b' >>> '' or [] or&#123;&#125; &#123;&#125;12345 从左到右扫描，返回第一个为真的表达式值，无真值则返回最后一个表达式值。 and-or搭配：>>> a = \"betabin\" >>> b = \"python\" >>> 1 and a or b 'betabin' >>> 0 and a or b 'python'12345 看起来类似于于我们Ｃ＋＋中的条件运算符（bool？a：b），是的，当a为true的时候是一样的。但是，当a为false的时候，就明显不同了。 如果坚持要用and-or技巧来实现条件运算符的话，可以用种安全的方法： >>> a = \"\" >>> b = \"betabin\" >>> (1 and [a] or [b])[0] ''123 就是万能的[]，把a为假的可能性给抹杀掉，然后通过[0]再获得（因为要通过[0]获得元素，所以b也得加上[]）。 这个and-or技巧主要在lambda中使用。","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"}]},{"title":"使用jenv对java多版本管理","date":"2019-10-25T02:42:43.000Z","path":"posts/undefined.html","text":"配置JDK环境变量 打开 vim ~/.bash_profile 文件 进行添加 export JAVA_8_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_112.jdk/Contents/Home export JAVA_7_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home # 默认激活 jdk8 export JAVA_HOME=$JAVA_8_HOME 编辑完成，重新加载 .bash_profile $ source ~&#x2F;.bash_profile jEnv安装 安装 $ brew install jenv 配置 安装了zsh，配置如下 $ echo &#39;export PATH&#x3D;&quot;$HOME&#x2F;.jenv&#x2F;bin:$PATH&quot;&#39; &gt;&gt; ~&#x2F;.zshrc $ echo &#39;eval &quot;$(jenv init -)&quot;&#39; &gt;&gt; ~&#x2F;.zshrc 如果是默认的bash $ echo &#39;export PATH&#x3D;&quot;$HOME&#x2F;.jenv&#x2F;bin:$PATH&quot;&#39; &gt;&gt; ~&#x2F;.bash_profile $ echo &#39;eval &quot;$(jenv init -)&quot;&#39; &gt;&gt; ~&#x2F;.bash_profilec jEnv配置JDK查看安装的java版本，如果我们一开始未添加jdk，执行jenv versions 应该是空的，* 号位置表示当前的jdk版本 $ jenv versions system 1.7 * 1.7.0.80 (set by /Users/gulj/.java-version) 1.8 1.8.0.112 oracle64-1.7.0.80 oracle64-1.8.0.112 重启下terminal，为jEnv添加java版本 添加jdk7 $ jenv add &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.7.0_80.jdk&#x2F;Contents&#x2F;Home 添加jdk8 $ jenv add &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_112.jdk&#x2F;Contents&#x2F;Home 添加完jdk7和jdk8之后，再执行 jenv versions 命令就会看到我们添加的jdk jEnv常用命令 移除指定版本jdk $ jenv remove 1.8.0.111 选择一个jdk版本 $ jenv local 1.8.0.111 设置默认的jdk版本 $ jenv global 1.8.0.111 查看当前版本jdk的路径 jenv which java","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"react-tree-walker学习","date":"2019-10-19T09:02:13.000Z","path":"posts/undefined.html","text":"react-tree-walker这个主要用于遍历react的dom树，用于在react服务端渲染数据请求的时候。 import reactTreeWalker from 'react-tree-walker' class DataFetcher extends React.Component &#123; constructor(props) &#123; super(props) this.getData = this.getData.bind(this) &#125; getData() &#123; // Supports promises! You could call an API for example to fetch some // data, or do whatever \"bootstrapping\" you desire. return Promise.resolve(this.props.id) &#125; render() &#123; return &lt;div>&#123;this.props.children&#125;&lt;/div> &#125; &#125; const app = ( &lt;div> &lt;h1>Hello World!&lt;/h1> &lt;DataFetcher id=&#123;1&#125; /> &lt;DataFetcher id=&#123;2&#125;> &lt;DataFetcher id=&#123;3&#125;> &lt;DataFetcher id=&#123;4&#125; /> &lt;/DataFetcher> &lt;/DataFetcher> &lt;DataFetcher id=&#123;5&#125; /> &lt;/div> ) const values = [] // You provide this! See the API docs below for full details. function visitor(element, instance) &#123; if (instance &amp;&amp; typeof instance.getData) &#123; return instance.getData().then(value => &#123; values.push(value) // Return \"false\" to indicate that we do not want to visit \"3\"'s children, // therefore we do not expect \"4\" to make it into our values array. return value !== 3 &#125;) &#125; &#125; reactTreeWalker(app, visitor) .then(() => &#123; console.log(values) // [1, 2, 3, 5]; // Now is a good time to call React's renderToString whilst exposing // whatever values you built up to your app. &#125;) // since v3.0.0 you need to do your own error handling! .catch(err => console.error(err)) react-ssr-prepass这个项目还在维护，是一个不错的选择 安装yarn add react-ssr-prepass # or npm install --save react-ssr-prepass 使用import &#123; createElement &#125; from 'react' import &#123; renderToString &#125; from 'react-dom/server' import ssrPrepass from 'react-ssr-prepass' const renderApp = async App => &#123; const element = createElement(App) await ssrPrepass(element) return renderToString(element) &#125; ssrPrepass(&lt;App />, (element, instance) => &#123; if (element.type === SomeData) &#123; return fetchData() &#125; else if (instance &amp;&amp; instance.fetchData) &#123; return instance.fetchData() &#125; &#125;)","tags":[{"name":"react","slug":"react","permalink":"http://wumuwumu.github.io/tags/react/"}]},{"title":"weboack性能优化笔记","date":"2019-10-18T03:52:51.000Z","path":"posts/undefined.html","text":"https://juejin.im/post/5b652b036fb9a04fa01d616b","tags":[{"name":"js","slug":"js","permalink":"http://wumuwumu.github.io/tags/js/"}]},{"title":"lodash按需加载","date":"2019-10-18T03:48:59.000Z","path":"posts/undefined.html","text":"lodash提供了很多可用的方法供我们使用，绝对是一个很好用且用起来得心应手的工具库。但是同时，lodash的体积也不小，我们项目中使用的大概522K，可能只是使用了几个方法，但是却把整个lodash库引入了。为了吃几条鱼，就承包了整个鱼塘，代价有点大呀！ 对于这个问题，有几种方案可供选择。 一.引入单个函数 lodash整个安装完之后，引用方式： lodash/function 格式，单独引入某个函数，如 let _trim= require(‘lodash/trim’) 或者 import trim from ‘lodash/trim’ 或者 lodash 中的每个函数在 NPM 都有一个单独的发布模块，单独安装并引用部分模块，然后按以下方式引用 let _trim= require(‘lodash.trim’) 或者 import trim from ‘lodash.trim’ trim(‘ 123123 ‘) 二.借助 lodash-webpack-plugin，babel-plugin-lodash插件优化 使用上述两种方式，在使用较多个lodash中方法的情况下，不太美观，且并不方便。那么我们可以借助于lodash-webpack-plugin，去除未引入的模块，需要和babel-plugin-lodash插件配合使用。类似于webpack的tree-shaking。 1）安装插件：npm i -S lodash-webpack-plugin babel-plugin-lodash 2）webpack.conf.js中 var LodashModuleReplacementPlugin = require(‘lodash-webpack-plugin’) plugins: [ new LodashModuleReplacementPlugin()] 3）.babelrc中配置 “plugins”: [“transform-runtime”,”transform-vue-jsx”,”lodash”] 或者在webpack.conf.js的rules配置 &#123; test: &#x2F;\\.(js|jsx)$&#x2F;, loader: &#39;babel-loader&#39;, exclude: &#x2F;node_modules&#x2F;, include: [resolve(&#39;src&#39;), resolve(&#39;test&#39;)] options: &#123;plugins: [&#39;lodash&#39;]&#125; &#125; 三.lodash-es结合tree-shaking lodash-es 是着具备 ES6 模块化的版本，只需要直接引入就可以。 import {isEmpty,forIn, cloneDeep} from ‘lodash-es’ tree-shaking的作用，即移除上下文中未引用的代码（dead code） 只有当函数给定输入后，产生相应的输出，且不修改任何外部的东西，才可以安全做shaking的操作 如何使用tree-shaking？ 1）.确保代码是es6格式,即 export，import 2）.package.json中，设置sideEffects 3）.确保tree-shaking的函数没有副作用 4）.babelrc中设置presets [[“env”, { “modules”: false }]] 禁止转换模块，交由webpack进行模块化处理 5）.结合uglifyjs-webpack-plugin","tags":[{"name":"js","slug":"js","permalink":"http://wumuwumu.github.io/tags/js/"}]},{"title":"babel配置","date":"2019-10-18T03:21:01.000Z","path":"posts/undefined.html","text":"Babel6Babel6 现在使用的越来越少了，但是还是做一个笔记，现在基本都使用babel-preset-env，不需要写babel-preset-esxxxx了，但是babel-preset-stage-x还是要自己去加的。 安装npm install -D babel-cli babel-preset-env 配置文件Babel6的配置文件是.babelrc &#123; //https://juejin.im/post/5a79adeef265da4e93116430 &#125; Babel7Babel7 相对于babel6有很大的变化，相关的模块的名字有很大的变化，官方舍弃了babel-preset-esxxxx和babel-preset-stage-x，后者的原因是提案一直在变化。 安装npm install -D @babel/cli @babel/react @babel/plugin-transform-runtime @babel/env 配置文件Babel7有两种配置文件，一个是.babelrc，是局部的，另外一个是babel.config.js是全局的，具体的可以看下官网。7版本的配置文件解析也变得更加严格。","tags":[{"name":"babel","slug":"babel","permalink":"http://wumuwumu.github.io/tags/babel/"},{"name":"js","slug":"js","permalink":"http://wumuwumu.github.io/tags/js/"}]},{"title":"react的children","date":"2019-10-14T12:44:11.000Z","path":"posts/undefined.html","text":"React的核心为组件。你可以像嵌套HTML标签一样嵌套使用这些组件，这使得编写JSX更加容易因为它类似于标记语言。 当我刚开始学习React时，当时我认为“使用 props.children 就这么回事，我知道它的一切”。我错了。。 因为我们使用的事JavaScript，我们会改变children。我们能够给它们发送特殊的属性，以此来决定它们是否进行渲染。让我们来探究一下React中children的作用。 子组件我们有一个组件 &lt;Grid /&gt; 包含了几个组件 &lt;Row /&gt; 。你可能会这么使用它： &lt;Grid&gt; &lt;Row &#x2F;&gt; &lt;Row &#x2F;&gt; &lt;Row &#x2F;&gt; &lt;&#x2F;Grid&gt; 这三个 Row 组件都成为了 Grid 的 props.children 。使用一个表达式容器，父组件就能够渲染它们的子组件： class Grid extends React.Component &#123; render() &#123; return &lt;div&gt;&#123;this.props.children&#125;&lt;&#x2F;div&gt; &#125; &#125; 父组件也能够决定不渲染任何的子组件或者在渲染之前对它们进行操作。例如，这个 &lt;Fullstop /&gt; 组件就没有渲染它的子组件： class Fullstop extends React.Component &#123; render() &#123; return &lt;h1&gt;Hello world!&lt;&#x2F;h1&gt; &#125; &#125; 不管你将什么子组件传递给这个组件，它都只会显示“Hello world!” 任何东西都能是一个childReact中的Children不一定是组件，它们可以使任何东西。例如，我们能够将上面的文字作为children传递我们的 &lt;Grid /&gt; 组件。 &lt;Grid&gt;Hello world!&lt;&#x2F;Grid&gt; JSX将会自动删除每行开头和结尾的空格，以及空行。它还会把字符串中间的空白行压缩为一个空格。 这意味着以下的这些例子都会渲染出一样的情况： &lt;Grid&gt;Hello world!&lt;&#x2F;Grid&gt; &lt;Grid&gt; Hello world! &lt;&#x2F;Grid&gt; &lt;Grid&gt; Hello world! &lt;&#x2F;Grid&gt; &lt;Grid&gt; Hello world! &lt;&#x2F;Grid&gt; 你也可以将多种类型的children完美的结合在一起： &lt;Grid&gt; Here is a row: &lt;Row &#x2F;&gt; Here is another row: &lt;Row &#x2F;&gt; &lt;&#x2F;Grid&gt; child 的功能我们能够传递任何的JavaScript表达式作为children，包括函数。 为了说明这种情况，以下是一个组件，它将执行一个传递过来的作为child的函数： class Executioner extends React.Component &#123; render() &#123; &#x2F;&#x2F; See how we&#39;re calling the child as a function? &#x2F;&#x2F; ↓ return this.props.children() &#125; &#125; 你会像这样的使用这个组件 &lt;Executioner&gt; &#123;() &#x3D;&gt; &lt;h1&gt;Hello World!&lt;&#x2F;h1&gt;&#125; &lt;&#x2F;Executioner&gt; 当然，这个例子并没什么用，只是展示了这个想法。 假设你想从服务器获取一些数据。你能使用多种方法实现，像这种将函数作为child的方法也是可行的。 &lt;Fetch url&#x3D;&quot;api.myself.com&quot;&gt; &#123;(result) &#x3D;&gt; &lt;p&gt;&#123;result&#125;&lt;&#x2F;p&gt;&#125; &lt;&#x2F;Fetch&gt; 不要担心这些超出了你的脑容量。我想要的是当你以后遇到这种情况时不再惊讶。有了children什么事都会发生。 操作children如果你看过React的文档你就会说“children是一个不透明的数据结构”。从本质上来讲， props.children 可以使任何的类型，比如数组、函数、对象等等。 React提供了一系列的函数助手来使得操作children更加方便。 循环两个最显眼的函数助手就是 React.Children.map 以及 React.Children.forEach 。它们在对应数组的情况下能起作用，除此之外，当函数、对象或者任何东西作为children传递时，它们也会起作用。 class IgnoreFirstChild extends React.Component &#123; render() &#123; const children &#x3D; this.props.children return ( &lt;div&gt; &#123;React.Children.map(children, (child, i) &#x3D;&gt; &#123; &#x2F;&#x2F; Ignore the first child if (i &lt; 1) return return child &#125;)&#125; &lt;&#x2F;div&gt; ) &#125; &#125; &lt;IgnoreFirstChild /&gt; 组件在这里会遍历所有的children，忽略第一个child然后返回其他的。 &lt;IgnoreFirstChild&gt; &lt;h1&gt;First&lt;&#x2F;h1&gt; &lt;h1&gt;Second&lt;&#x2F;h1&gt; &#x2F;&#x2F; &lt;- Only this is rendered &lt;&#x2F;IgnoreFirstChild&gt; 在这种情况下，我们也可以使用 this.props.children.map 的方法。但要是有人讲一个函数作为child传递过来将会发生什么呢？this.props.children 会是一个函数而不是一个数组，接着我们就会产生一个error！ 然而使用 React.Children.map 函数，无论什么都不会报错。 &lt;IgnoreFirstChild&gt; &#123;() &#x3D;&gt; &lt;h1&gt;First&lt;&#x2F;h1&gt;&#125; &#x2F;&#x2F; &lt;- Ignored ? &lt;&#x2F;IgnoreFirstChild&gt; 计数因为this.props.children 可以是任何类型的，检查一个组件有多少个children是非常困难的。天真的使用 this.props.children.length ，当传递了字符串或者函数时程序便会中断。假设我们有个child：&quot;Hello World!&quot; ，但是使用 .length 的方法将会显示为12。 这就是为什么我们有 React.Children.count 方法的原因 class ChildrenCounter extends React.Component &#123; render() &#123; return &lt;p&gt;React.Children.count(this.props.children)&lt;&#x2F;p&gt; &#125; &#125; 无论时什么类型它都会返回children的数量 &#x2F;&#x2F; Renders &quot;1&quot; &lt;ChildrenCounter&gt; Second! &lt;&#x2F;ChildrenCounter&gt; &#x2F;&#x2F; Renders &quot;2&quot; &lt;ChildrenCounter&gt; &lt;p&gt;First&lt;&#x2F;p&gt; &lt;ChildComponent &#x2F;&gt; &lt;&#x2F;ChildrenCounter&gt; &#x2F;&#x2F; Renders &quot;3&quot; &lt;ChildrenCounter&gt; &#123;() &#x3D;&gt; &lt;h1&gt;First!&lt;&#x2F;h1&gt;&#125; Second! &lt;p&gt;Third!&lt;&#x2F;p&gt; &lt;&#x2F;ChildrenCounter&gt; 转换为数组如果以上的方法你都不适合，你能将children转换为数组通过 React.Children.toArray 方法。如果你需要对它们进行排序，这个方法是非常有用的。 class Sort extends React.Component &#123; render() &#123; const children &#x3D; React.Children.toArray(this.props.children) &#x2F;&#x2F; Sort and render the children return &lt;p&gt;&#123;children.sort().join(&#39; &#39;)&#125;&lt;&#x2F;p&gt; &#125; &#125; &lt;Sort&gt; &#x2F;&#x2F; We use expression containers to make sure our strings &#x2F;&#x2F; are passed as three children, not as one string &#123;&#39;bananas&#39;&#125;&#123;&#39;oranges&#39;&#125;&#123;&#39;apples&#39;&#125; &lt;&#x2F;Sort&gt; 上例会渲染为三个排好序的字符串。 执行单一child如果你回过来想刚才的 &lt;Executioner /&gt; 组件，它只能在传递单一child的情况下使用，而且child必须为函数。 class Executioner extends React.Component &#123; render() &#123; return this.props.children() &#125; &#125; 我们可以试着去强制执行 propTypes ，就像下面这样 Executioner.propTypes = &#123; children: React.PropTypes.func.isRequired, &#125; 这会使控制台打印出一条消息，部分的开发者将会把它忽视。相反的，我们可以使用在 render 里面使用 React.Children.only class Executioner extends React.Component &#123; render() &#123; return React.Children.only(this.props.children)() &#125; &#125; 这样只会返回一个child。如果不止一个child，它就会抛出错误，让整个程序陷入中断——完美的避开了试图破坏组件的懒惰的开发者。","tags":[{"name":"react","slug":"react","permalink":"http://wumuwumu.github.io/tags/react/"}]},{"title":"react-cloneElement","date":"2019-10-13T11:40:12.000Z","path":"posts/undefined.html","text":"react提供了一个克隆 API： React.cloneElement( element, [props], [...children] ) 官方定义： Clone and return a new React element using element as the starting point. The resulting element will have the original element&#39;s props with the new props merged in shallowly. New children will replace existing children. key and ref from the original element will be preserved. 下面实现一个demo，通过 React.cloneElement 向子组件传递 state 及 function，代码如下： import React, &#123; Component &#125; from &#39;react&#39;; import ReactDOM from &#39;react-dom&#39;; class MyContainer extends Component &#123; constructor(props) &#123; super(props) this.state &#x3D; &#123; count: 1 &#125; this.handleClick &#x3D; this.handleClick.bind(this); &#125; handleClick() &#123; this.state.count++; this.setState(&#123; count: this.state.count++ &#125;) console.log(this.state) &#125; render() &#123; const childrenWithProps &#x3D; React.Children.map(this.props.children, child &#x3D;&gt; React.cloneElement(child, &#123; parentState: this.state.count, handleClick: this.handleClick &#125; )); return ( &lt;div style&#x3D;&#123;&#123;border:&quot;1px solid blue&quot;&#125;&#125;&gt; &lt;span&gt;父容器:&lt;&#x2F;span&gt; &#123; childrenWithProps &#125; &lt;&#x2F;div&gt; ) &#125; &#125; class MySub extends Component &#123; constructor(props) &#123; super(props) this.state &#x3D; &#123; flag: false &#125; &#125; render() &#123; return ( &lt;div style&#x3D;&#123;&#123;margin: &quot;15px&quot;, border: &quot;1px solid red&quot;&#125;&#125;&gt; 子元素:&#123;this.props.subInfo&#125; &lt;br&#x2F;&gt; 父组件属性count值: &#123; this.props.parentState &#125; &lt;br&#x2F;&gt; &lt;span onClick&#x3D;&#123; () &#x3D;&gt; this.props.handleClick() &#125; style&#x3D;&#123;&#123;display:&quot;inline-block&quot;,padding: &quot;3px 5px&quot;, color:&quot;#ffffff&quot;, background: &quot;green&quot;, borderRadius: &quot;3px&quot;, cursor: &quot;pointer&quot;&#125;&#125; &gt;click me&lt;&#x2F;span&gt; &lt;&#x2F;div&gt; ) &#125; &#125; ReactDOM.render ( ( &lt;MyContainer&gt; &lt;MySub subInfo&#x3D;&#123;&quot;1&quot;&#125;&#x2F;&gt; &lt;MySub subInfo&#x3D;&#123;&quot;2&quot;&#125;&#x2F;&gt; &lt;&#x2F;MyContainer&gt; ) , document.getElementById(&#39;content&#39;)) &lt;!DOCTYPE html> &lt;head> &lt;meta charset=\"UTF-8\"> &lt;title>react drag components example...&lt;/title> &lt;link rel=\"stylesheet\" href=\"/build/main.css\"> &lt;/head> &lt;body> &lt;div id=\"content\">&lt;/div> &lt;script src=\"bundle.js\">&lt;/script> &lt;/body> &lt;/html>","tags":[{"name":"react","slug":"react","permalink":"http://wumuwumu.github.io/tags/react/"}]},{"title":"php5环境搭建","date":"2019-09-02T15:14:11.000Z","path":"posts/undefined.html","text":"安装nginxyum install epel-release yum install nginx 安装phpremi源可以获取更高的版本，php-fpm是要启动的 rpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm yum install --enablerepo=remi --enablerepo=remi-php56 php php-fpm yum install --enablerepo=remi --enablerepo=remi-php56 php-opcache php-mbstring php-mysql* php-gd php-redis php-mcrypt php-xml php-redis nginx配置server &#123; listen 80; server_name www.test.com test.com; root /data/www/Public; index index.php index.html; location / &#123; try_files $uri $uri/ /index.php?$args; &#125; location ~ index.php &#123; fastcgi_connect_timeout 20s; # default of 60s is just too long fastcgi_read_timeout 20s; # default of 60s is just too long include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; # assumes you are running php-fpm locally on port 9000 fastcgi_param PHP_VALUE \"open_basedir=/data/www/:/data/www/Data:/tmp/\"; &#125; &#125; 开启php的日志 修改 php-fpm.conf 文件，添加（或修改）如下配置： [global] error_log = log/error_log [www] catch_workers_output = yes 修改 php.ini 文件，添加（或修改）如下配置： log_errors &#x3D; On error_log &#x3D; &quot;&#x2F;usr&#x2F;local&#x2F;lnmp&#x2F;php&#x2F;var&#x2F;log&#x2F;error_log&quot; error_reporting&#x3D;E_ALL&amp;~E_NOTICE 重启 php-fpm","tags":[]},{"title":"linux压缩","date":"2019-09-02T14:46:45.000Z","path":"posts/undefined.html","text":"tar# 打包 tar -cvf xx.tar dirName # 解包 tar -xvf xx.tar # .gz # 解压 gunzip fileName.gz gzip -d fileName.gz # 压缩 gzip fileName # .tar.gz 和.tgz # 解压 tar zxvf fileName.tar.gz # 压缩 tar zcvf filename.tar.gz dirName # bz2 # 解压 bzip2 -d fileName.bz bunzip2 fileName.bz # .tar.bz # 解压 tar jxvf fileName.tar.bz # 压缩 tar jcvf fileName.tar.bz dirName zip# 安装 yum install zip unzip # 解压 unzip mydata.zip -d mydatabak # 压缩 zip -r abc123.zip abc 123.txt rar# 安装 wget http://www.rarlab.com/rar/rarlinux-x64-5.3.0.tar.gz tar -zxvf rarlinux-x64-5.3.0.tar.gz // 对应64位下载的 cd rar make # 解压 rar x fileName.rar # 压缩 rar fileName.rar dirName 7z# 安装 yum install p7zip p7zip-plugins # 压缩 7za a 压缩包.7z 被压缩文件或目录 # 解压 #将压缩包解压到指定目录，注意：指定目录参数-o后面不要有空格 7za x 压缩包.7z -o解压目录 #将压缩包解压到当前目录 7za x 压缩包.7z","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"nginx伪静态","date":"2019-09-02T14:26:40.000Z","path":"posts/undefined.html","text":"伪静态伪静态是一种可以把文件后缀改成任何可能的一种方法，如果我想把PHP文件伪静态成html文件，这种相当简单的。nginx里使用伪静态是直接在nginx.conf 中写规则的，而apache要开启写模块(mod_rewrite)才能进行伪静态。nginx只需要打开nginx.conf配置文件,然后在里面写需要的规则就可以了。 1、Nginx伪静态案例：（Nginx用伪静态是不需要配置的） 找到nginx.conf配置文件：nginx.conf，然后打开，找到server {} 在里面加上： 下面加的意思是隐藏掉index.php： location / &#123; # 其他的一些规则，自己加 if(!-e $request_filename) &#123; rewrite ^(.*)$ /index.php?s=$1 last; break; &#125; &#125; 2、每个网站独立的配置文件（独立的伪静态规则）： 我们正常的时候每个网站都会有独立的配置文件，直接去改配置文件就好了。然后nginx.conf引入他们所有的配置文件就好了： 如：在nginx.conf配置文件最下面添加以下代码： include vhost/*.conf; 说明：引入nginx.conf配置文件所在目录下vhost目录下的所有以.conf的配置文件！ 以下就是其中一个网站的配置文件内容：规则就是隐藏掉index.php server &#123; listen 80; root /www/web/admin/public; server_name www.admin.com; index index.html index.php index.htm; error_page 400 /errpage/400.html; error_page 403 /errpage/403.html; error_page 404 /errpage/404.html; error_page 503 /errpage/503.html; location ~ \\.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fcgi.conf; &#125; location ~ /\\.ht &#123; deny all; &#125; location / &#123; if (!-e $request_filename) &#123; rewrite ^(.*)$ /index.php?s=$1 last; break; &#125; &#125; &#125; nginx url重写url重写是指通过配置conf文件，以让网站的url中达到某种状态时则定向/跳转到某个规则，比如常见的伪静态、301重定向、浏览器定向等 rewrite语法在配置文件的server块中写，如： server &#123; rewrite 规则 定向路径 重写类型; &#125; 规则：可以是字符串或者正则来表示想匹配的目标url 定向路径：表示匹配到规则后要定向的路径，如果规则里有正则，则可以使用$index来表示正则里的捕获分组 重写类型： last ：相当于Apache里德(L)标记，表示完成rewrite，浏览器地址栏URL地址不变 break；本条规则匹配完成后，终止匹配，不再匹配后面的规则，浏览器地址栏URL地址不变 redirect：返回302临时重定向，浏览器地址会显示跳转后的URL地址 permanent：返回301永久重定向，浏览器地址栏会显示跳转后的URL地址 简单例子server &#123; # 访问 /last.html 的时候，页面内容重写到 /index.html 中 rewrite /last.html /index.html last; # 访问 /break.html 的时候，页面内容重写到 /index.html 中，并停止后续的匹配 rewrite /break.html /index.html break; # 访问 /redirect.html 的时候，页面直接302定向到 /index.html中 rewrite /redirect.html /index.html redirect; # 访问 /permanent.html 的时候，页面直接301定向到 /index.html中 rewrite /permanent.html /index.html permanent; # 把 /html/*.html => /post/*.html ，301定向 rewrite ^/html/(.+?).html$ /post/$1.html permanent; # 把 /search/key => /search.html?keyword=key rewrite ^/search\\/([^\\/]+?)(\\/|$) /search.html?keyword=$1 permanent; &#125; last和break的区别因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解： last一般写在server和if中，而break一般使用在location中 last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配 break和last都能组织继续执行后面的rewrite指令 在location里一旦返回break则直接生效并停止后续的匹配location server &#123; location / &#123; rewrite /last/ /q.html last; rewrite /break/ /q.html break; &#125; location = /q.html &#123; return 400; &#125; &#125; 访问/last/时重写到/q.html，然后使用新的uri再匹配，正好匹配到locatoin = /q.html然后返回了400 访问/break时重写到/q.html，由于返回了break，则直接停止了 if判断只是上面的简单重写很多时候满足不了需求，比如需要判断当文件不存在时、当路径包含xx时等条件，则需要用到if 语法if (表达式) &#123;&#125; 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false 直接比较变量和内容时，使用=或!= 正则表达式匹配，*不区分大小写的匹配，!~区分大小写的不匹配 一些内置的条件判断： -f和!-f用来判断是否存在文件 -d和!-d用来判断是否存在目录 -e和!-e用来判断是否存在文件或目录 -x和!-x用来判断文件是否可执行 内置的全局变量$args ：这个变量等于请求行中的参数，同$query_string $content_length ： 请求头中的Content-length字段。 $content_type ： 请求头中的Content-Type字段。 $document_root ： 当前请求在root指令中指定的值。 $host ： 请求主机头字段，否则为服务器名称。 $http_user_agent ： 客户端agent信息 $http_cookie ： 客户端cookie信息 $limit_rate ： 这个变量可以限制连接速率。 $request_method ： 客户端请求的动作，通常为GET或POST。 $remote_addr ： 客户端的IP地址。 $remote_port ： 客户端的端口。 $remote_user ： 已经经过Auth Basic Module验证的用户名。 $request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。 $scheme ： HTTP方法（如http，https）。 $server_protocol ： 请求使用的协议，通常是HTTP&#x2F;1.0或HTTP&#x2F;1.1。 $server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。 $server_name ： 服务器名称。 $server_port ： 请求到达服务器的端口号。 $request_uri ： 包含请求参数的原始URI，不包含主机名，如：”&#x2F;foo&#x2F;bar.php?arg&#x3D;baz”。 $uri ： 不带请求参数的当前URI，$uri不包含主机名，如”&#x2F;foo&#x2F;bar.html”。 $document_uri ： 与$uri相同。 如： 访问链接是：http://localhost:88/test1/test2/test.php 网站路径是：/var/www/html $host：localhost $server_port：88 $request_uri：http://localhost:88/test1/test2/test.php $document_uri：/test1/test2/test.php $document_root：/var/www/html $request_filename：/var/www/html/test1/test2/test.php 例子# 如果文件不存在则返回400 if (!-f $request_filename) &#123; return 400; &#125; # 如果host不是xuexb.com，则301到xuexb.com中 if ( $host != 'xuexb.com' )&#123; rewrite ^/(.*)$ https://xuexb.com/$1 permanent; &#125; # 如果请求类型不是POST则返回405 if ($request_method = POST) &#123; return 405; &#125; # 如果参数中有 a=1 则301到指定域名 if ($args ~ a=1) &#123; rewrite ^ http://example.com/ permanent; &#125; 在某种场景下可结合location规则来使用，如： # 访问 /test.html 时 location = /test.html &#123; # 默认值为xiaowu set $name xiaowu; # 如果参数中有 name=xx 则使用该值 if ($args ~* name=(\\w+?)(&amp;|$)) &#123; set $name $1; &#125; # 301 rewrite ^ /$name.html permanent; &#125; 上面表示： /test.html =&gt; /xiaowu.html /test.html?name=ok =&gt; /ok.html?name=ok location语法在server块中使用，如： server &#123; location 表达式 &#123; &#125; &#125; location表达式类型 如果直接写一个路径，则匹配该路径下的 ~ 表示执行一个正则匹配，区分大小写 ~* 表示执行一个正则匹配，不区分大小写 ^~ 表示普通字符匹配。使用前缀匹配。如果匹配成功，则不再匹配其他location。 = 进行普通字符精确匹配。也就是完全匹配。 优先级 等号类型（=）的优先级最高。一旦匹配成功，则不再查找其他匹配项。 ^~类型表达式。一旦匹配成功，则不再查找其他匹配项。 正则表达式类型（~ ~*）的优先级次之。如果有多个location的正则能匹配的话，则使用正则表达式最长的那个。 常规字符串匹配类型。按前缀匹配。 例子 - 假地址掩饰真地址server &#123; # 用 xxoo_admin 来掩饰 admin location / &#123; # 使用break拿一旦匹配成功则忽略后续location rewrite /xxoo_admin /admin break; &#125; # 访问真实地址直接报没权限 location /admin &#123; return 403; &#125; &#125; 参考https://www.toolnb.com/tools/rewriteTools.html","tags":[{"name":"nginx","slug":"nginx","permalink":"http://wumuwumu.github.io/tags/nginx/"}]},{"title":"spring数据库事务","date":"2019-09-01T12:22:24.000Z","path":"posts/undefined.html","text":"接口PlatformTransactionManagerPlatformTransactionManager接口中定义了三个方法： Public interface PlatformTransactionManager()...&#123; // Return a currently active transaction or create a new one, according to the specified propagation behavior（根据指定的传播行为，返回当前活动的事务或创建一个新事务。） TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException; // Commit the given transaction, with regard to its status（使用事务目前的状态提交事务） Void commit(TransactionStatus status) throws TransactionException; // Perform a rollback of the given transaction（对执行的事务进行回滚） Void rollback(TransactionStatus status) throws TransactionException; &#125; 复制代码 我们刚刚也说了Spring中PlatformTransactionManager根据不同持久层框架所对应的接口实现类,几个比较常见的如下图所示 比如我们在使用JDBC或者iBatis（就是Mybatis）进行数据持久化操作时,我们的xml配置通常如下： &lt;!-- 事务管理器 --> &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"> &lt;!-- 数据源 --> &lt;property name=\"dataSource\" ref=\"dataSource\" /> &lt;/bean> TransactionDefinition事务管理器接口 PlatformTransactionManager 通过 getTransaction(TransactionDefinition definition) 方法来得到一个事务，这个方法里面的参数是 TransactionDefinition类 ，这个类就定义了一些基本的事务属性。 那么什么是事务属性呢？ 事务属性可以理解成事务的一些基本配置，描述了事务策略如何应用到方法上。事务属性包含了5个方面。 TransactionDefinition接口中的方法如下：TransactionDefinition接口中定义了5个方法以及一些表示事务属性的常量比如隔离级别、传播行为等等的常量。 我下面只是列出了TransactionDefinition接口中的方法而没有给出接口中定义的常量，该接口中的常量信息会在后面依次介绍到。 public interface TransactionDefinition &#123; // 返回事务的传播行为 int getPropagationBehavior(); // 返回事务的隔离级别，事务管理器根据它来控制另外一个事务可以看到本事务内的哪些数据 int getIsolationLevel(); // 返回事务必须在多少秒内完成 //返回事务的名字 String getName()； int getTimeout(); // 返回是否优化为只读事务。 boolean isReadOnly(); &#125; TransactionStatusPlatformTransactionManager.getTransaction(…) 方法返回一个 TransactionStatus 对象。返回的TransactionStatus 对象可能代表一个新的或已经存在的事务（如果在当前调用堆栈有一个符合条件的事务）。TransactionStatus 接口提供了一个简单的控制事务执行和查询事务状态的方法。该接口定义如清单3所示： 清单3. TransactionStatus 接口中定义的主要方法`public interface TransactionStatus&#123;`` ``boolean isNewTransaction();`` ``void setRollbackOnly();`` ``boolean isRollbackOnly();``&#125;` 事务管理API分析事务隔离级别隔离级别是指若干个并发的事务之间的隔离程度。TransactionDefinition 接口中定义了五个表示隔离级别的常量： TransactionDefinition.ISOLATION_DEFAULT：这是默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是TransactionDefinition.ISOLATION_READ_COMMITTED。 TransactionDefinition.ISOLATION_READ_UNCOMMITTED：该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读和不可重复读，因此很少使用该隔离级别。 TransactionDefinition.ISOLATION_READ_COMMITTED：该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。 TransactionDefinition.ISOLATION_REPEATABLE_READ：该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。即使在多次查询之间有新增的数据满足该查询，这些新增的记录也会被忽略。该级别可以防止脏读和不可重复读。 TransactionDefinition.ISOLATION_SERIALIZABLE：所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 事务传播行为所谓事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为。在TransactionDefinition定义中包括了如下几个表示传播行为的常量： TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。 TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。 TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。 TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。 这里需要指出的是，前面的六种事务传播行为是 Spring 从 EJB 中引入的，他们共享相同的概念。而 PROPAGATION_NESTED是 Spring 所特有的。以 PROPAGATION_NESTED 启动的事务内嵌于外部事务中（如果存在外部事务的话），此时，内嵌事务并不是一个独立的事务，它依赖于外部事务的存在，只有通过外部的事务提交，才能引起内部事务的提交，嵌套的子事务不能单独提交。如果熟悉 JDBC 中的保存点（SavePoint）的概念，那嵌套事务就很容易理解了，其实嵌套的子事务就是保存点的一个应用，一个事务中可以包括多个保存点，每一个嵌套子事务。另外，外部事务的回滚也会导致嵌套子事务的回滚。 事务超时所谓事务超时，就是指一个事务所允许执行的最长时间，如果超过该时间限制但事务还没有完成，则自动回滚事务。在 TransactionDefinition 中以 int 的值来表示超时时间，其单位是秒。 事务的只读属性事务的只读属性是指，对事务性资源进行只读操作或者是读写操作。所谓事务性资源就是指那些被事务管理的资源，比如数据源、 JMS 资源，以及自定义的事务性资源等等。如果确定只对事务性资源进行只读操作，那么我们可以将事务标志为只读的，以提高事务处理的性能。在 TransactionDefinition 中以 boolean 类型来表示该事务是否只读。 应用场合： 如果你一次执行单条查询语句，则没有必要启用事务支持，数据库默认支持SQL执行期间的读一致性；如果你一次执行多条查询语句，例如统计查询，报表查询，在这种场景下，多条查询SQL必须保证整体的读一致性，否则，在前条SQL查询之后，后条SQL查询之前，数据被其他用户改变，则该次整体的统计查询将会出现读数据不一致的状态，此时，应该启用事务支持。【注意是一次执行多次查询来统计某些信息，这时为了保证数据整体的一致性，要用只读事务】 怎样设置： 对于只读查询，可以指定事务类型为readonly，即只读事务。由于只读事务不存在数据的修改，因此数据库将会为只读事务提供一些优化手段，例如Oracle对于只读事务，不启动回滚段，不记录回滚log。 （1）在JDBC中，指定只读事务的办法为： connection.setReadOnly(true); （2）在Hibernate中，指定只读事务的办法为： session.setFlushMode(FlushMode.NEVER);此时，Hibernate也会为只读事务提供Session方面的一些优化手段 （3）在Spring的Hibernate封装中，指定只读事务的办法为： bean配置文件中，prop属性增加“readOnly”或者用注解方式@Transactional(readOnly=true)【 if the transaction is marked as read-only, Spring will set the Hibernate Session’s flush mode to FLUSH_NEVER,and will set the JDBC transaction to read-only】也就是说在Spring中设置只读事务是利用上面两种方式 事务的回滚规则通常情况下，如果在事务中抛出了未检查异常（继承自 RuntimeException 的异常），则默认将回滚事务。如果没有抛出任何异常，或者抛出了已检查异常，则仍然提交事务。这通常也是大多数开发者希望的处理方式，也是 EJB 中的默认处理方式。但是，我们可以根据需要人为控制事务在抛出某些未检查异常时任然提交事务，或者在抛出某些已检查异常时回滚事务。","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"},{"name":"spring","slug":"spring","permalink":"http://wumuwumu.github.io/tags/spring/"}]},{"title":"数据库事务","date":"2019-09-01T12:18:43.000Z","path":"posts/undefined.html","text":"本篇讲诉数据库中事务的四大特性（ACID），并且将会详细地说明事务的隔离级别。 如果一个数据库声称支持事务的操作，那么该数据库必须要具备以下四个特性： ⑴ 原子性（Atomicity） 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，这和前面两篇博客介绍事务的功能是一样的概念，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。 ⑵ 一致性（Consistency） 一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 ⑶ 隔离性（Isolation） 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。 关于事务的隔离性数据库提供了多种隔离级别，稍后会介绍到。 ⑷ 持久性（Durability） 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。 以上介绍完事务的四大特性(简称ACID)，现在重点来说明下事务的隔离性，当多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性，在介绍数据库提供的各种隔离级别之前，我们先看看如果不考虑事务的隔离性，会发生的几种问题： 1，脏读 脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。 当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。例如：用户A向用户B转账100元，对应SQL命令如下 update account set money&#x3D;money+100 where name&#x3D;’B’; (此时A通知B) update account set money&#x3D;money - 100 where name&#x3D;’A’; 当只执行第一条SQL时，A通知B查看账户，B发现确实钱已到账（此时即发生了脏读），而之后无论第二条SQL是否执行，只要该事务不提交，则所有操作都将回滚，那么当B以后再次查看账户时就会发现钱其实并没有转。 2，不可重复读 不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。 例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。 在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主。但在另一些情况下就有可能发生问题，例如对于同一个数据A和B依次查询就可能不同，A和B就可能打起来了…… 3，虚读(幻读) 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。 幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。 现在来看看MySQL数据库为我们提供的四种隔离级别： ① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 ② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 ③ Read committed (读已提交)：可避免脏读的发生。 ④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 以上四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，执行效率就越低。像Serializable这样的级别，就是以锁表的方式(类似于Java多线程中的锁)使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。在MySQL数据库中默认的隔离级别为Repeatable read (可重复读)。 在MySQL数据库中，支持上面四种隔离级别，默认的为Repeatable read (可重复读)；而在Oracle数据库中，只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别，其中默认的为Read committed级别。 在MySQL数据库中查看当前事务的隔离级别： select @@tx_isolation; 在MySQL数据库中设置事务的隔离 级别： set [glogal | session] transaction isolation level 隔离级别名称; set tx_isolation&#x3D;’隔离级别名称;’ 后记：隔离级别的设置只对当前链接有效。对于使用MySQL命令窗口而言，一个窗口就相当于一个链接，当前窗口设置的隔离级别只对当前窗口中的事务有效；对于JDBC操作数据库来说，一个Connection对象相当于一个链接，而对于Connection对象设置的隔离级别只对该Connection对象有效，与其他链接Connection对象无关。 参考博客：http://www.zhihu.com/question/23989904http://dev.mysql.com/doc/refman/5.6/en/set-transaction.htmlhttp://www.cnblogs.com/xdp-gacl/p/3984001.htmlhttps://www.cnblogs.com/fjdingsd/p/5273008.html","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"}]},{"title":"mysql性能检测","date":"2019-08-31T15:26:45.000Z","path":"posts/undefined.html","text":"性能检测蝉蛹命令 show status show processlist show variables 瓶颈分析常用命令获取mysql用户下的进程总数ps -ef | awk '&#123;print $1&#125;' | grep \"mysql\" | grep -v \"grep\" | wc -l 主机性能状态uptime CPU使用率top vmstat 磁盘IO量vmstat iostat swap进出量free -m 数据库性能状态QPS方法一 基于 questions 计算qps,基于 com_commit com_rollback 计算tps questions = show global status like 'questions'; uptime = show global status like 'uptime'; qps=questions/uptime com_commit = show global status like 'com_commit'; com_rollback = show global status like 'com_rollback'; uptime = show global status like 'uptime'; tps=(com_commit + com_rollback)/uptime 方法二 基于 com_* 的status 变量计算tps ,qps 使用如下命令： show global status where variable_name in('com_select','com_insert','com_delete','com_update'); 获取间隔1s 的 com_*的值，并作差值运算 del_diff = (int(mystat2['com_delete']) - int(mystat1['com_delete']) ) / diff ins_diff = (int(mystat2['com_insert']) - int(mystat1['com_insert']) ) / diff sel_diff = (int(mystat2['com_select']) - int(mystat1['com_select']) ) / diff upd_diff = (int(mystat2['com_update']) - int(mystat1['com_update']) ) / diff 总结： Questions 是记录了从mysqld启动以来所有的select，dml 次数包括show 命令的查询的次数。这样多少有失准确性，比如很多数据库有监控系统在运行，每5秒对数据库进行一次show 查询来获取当前数据库的状态，而这些查询就被记录到QPS,TPS统计中，造成一定的”数据污染”. 如果数据库中存在比较多的myisam表，则计算还是questions 比较合适。 如果数据库中存在比较多的innodb表，则计算以com_*数据来源比较合适 TPSTPS = (Com_commit + Com_rollback) / seconds show status like 'Com_commit'; show status like 'Com_rollback'; key Buffer 命中率key_buffer_read_hits = (1-key_reads / key_read_requests) * 100%key_buffer_write_hits = (1-key_writes / key_write_requests) * 100% show status like 'Key%'; InnoDB Buffer命中率innodb_buffer_read_hits = (1 - innodb_buffer_pool_reads / innodb_buffer_pool_read_requests) * 100% show status like 'innodb_buffer_pool_read%'; Query Cache命中率Query_cache_hits = (Qcahce_hits / (Qcache_hits + Qcache_inserts )) * 100%; show status like 'Qcache%'; Table Cache状态量show status like 'open%'; Thread Cache 命中率Thread_cache_hits = (1 - Threads_created / connections ) * 100% show status like 'Thread%'; show status like 'Connections'; 锁定状态show status like '%lock%'; 复制延时量show slave status; Tmp Table 状况(临时表状况)show status like 'Create_tmp%'; Binlog Cache 使用状况show status like 'Binlog_cache%'; Innodb_log_waitsshow status like &#39;innodb_log_waits&#39;; 参考https://blog.csdn.net/li_adou/article/details/78791972","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"}]},{"title":"hibernate_Embedded和@Embeddable","date":"2019-08-10T02:57:59.000Z","path":"posts/undefined.html","text":"在使用实体类生成对应的数据库表时，很多的时候都会遇到这种情况：在一个实体类中引用另外的实体类，一般遇上这种情况，我们使用@OneToOne、@OneToMany、@ManyToOne、@ManyToMany这4个注解比较多，但是好奇害死猫，除了这四个有没有别的使用情况，尤其是一个实体类要在多个不同的实体类中进行使用，而本身又不需要独立生成一个数据库表，这就是需要@Embedded、@Embeddable的时候了，下面分成4类来说明在一个实体类中引用另外的实体类的情况，具体的数据库环境是MySQL 5.7。 使用的两个实体类如下： Address类 public class Address implements Serializable&#123; private static final long serialVersionUID = 8849870114128959929L; private String country; private String province; private String city; private String detail; //setter、getter&#125; Person类： @Entity public class Person implements Serializable&#123; private static final long serialVersionUID = 8849870114127659929L; @Id @GeneratedValue private Long id; @Column(nullable = false) private String name; @Column(nullable = false) private Integer age; private Address address; //setter、getter &#125; 两个注解全不使用当这两个注解都不使用时，那么两个实体类和上面的相同，那么生成的表结构如下： Address属性字段会映射成tinyblob类型的字段，这是用来存储不超过255字符的二进制字符串的数据类型，显然我们通常不会这么使用。 只使用@Embeddable我们在Address实体类上加上@Embeddable注解，变成如下类： @Embeddable public class Address implements Serializable&#123; private static final long serialVersionUID = 8849870114128959929L; private String country; private String province; private String city; private String detail; //setter、getter &#125; 而Person实体类不变，生成的数据库表结构如下： 可以看出这次是把Address中的字段映射成数据库列嵌入到Person表中了，而这些字段的类型和长度也使用默认值。如果我们在Address中的字段中设置列的相关属性，则会按照我们设定的值去生成，如下Address类： @Embeddable public class Address implements Serializable&#123; private static final long serialVersionUID = 8849870114128959929L; @Column(nullable = false) private String country; @Column(length = 30) private String province; @Column(unique = true) private String city; @Column(length = 50) private String detail; //setter、getter &#125; 生成的表结构如下： 我们在Address中配置的属性全部成功映射到Person表中。 只使用@Embedded这里我们只在Person中使用@Embedded,如下： @Entity public class Person implements Serializable&#123; private static final long serialVersionUID = 8849870114127659929L; @Id @GeneratedValue private Long id; @Column(nullable = false) private String name; @Column(nullable = false) private Integer age; @Embedded private Address address; //setter、getter &#125; Adddress类和最开始的不同POJO类相同，此时生成的表结构如下： 可以看出这个表结构和在Address中只使用@Embeddable注解时相同，在进入深一步试验，我们在Address中加入列属性，但是不使用@Embeddable注解会发生什么？Address类如下： public class Address implements Serializable&#123; private static final long serialVersionUID = 8849870114128959929L; @Column(nullable = false) private String country; @Column(length = 30) private String province; @Column(unique = true) private String city; @Column(length = 50) private String detail; //setter、getter &#125; 生成数据表结构如下： 所以只使用@Embedded和只使用@Embeddable产生的效果是相同的。 两个注解全使用既然单独使用@Embedded或者只使用@Embeddable都会产生作用，那么这两个都使用效果也一定是一样的，我们平时也是这么用的。所以在这部分我们就不演示和上面相同的效果了，而是说两个深入的话题。 覆盖@Embeddable类中字段的列属性这里就要使用另外的两个注解@AttributeOverrides和@AttributeOverride，这两个注解是用来覆盖@Embeddable类中字段的属性的。 @AttributeOverrides：里面只包含了@AttributeOverride类型数组；@AttributeOverride：包含要覆盖的@Embeddable类中字段名name和新增的@Column字段的属性；使用如下：Person类如下： @Entity public class Person implements Serializable&#123; private static final long serialVersionUID = 8849870114127659929L; @Id @GeneratedValue private Long id; @Column(nullable = false) private String name; @Column(nullable = false) private Integer age; @Embedded @AttributeOverrides(&#123;@AttributeOverride(name=\"country\", column=@Column(name = \"person_country\", length = 25, nullable = false)), @AttributeOverride(name=\"city\", column = @Column(name = \"person_city\", length = 15))&#125;) private Address address; //setter、getter &#125; Address类如下： @Embeddable public class Address implements Serializable&#123; private static final long serialVersionUID = 8849870114128959929L; @Column(nullable = false) private String country; @Column(length = 30) private String province; @Column(unique = true) private String city; @Column(length = 50) private String detail; //setter、getter &#125; 生成的数据表如下： 可以看出我们的@AttributeOverrides和@AttributeOverride两个注解起作用了。 多层嵌入实体类属性上面所有的例子都是使用两层实体类嵌入，其实这种实体类的嵌入映射是可以使用多层的，具体的例子如下。我们新建立一个类Direction表示方位如下： @Embeddable public class Direction implements Serializable&#123; @Column(nullable = false) private Integer longitude; private Integer latitude; &#125; Address如下： @Embeddable public class Address implements Serializable&#123; private static final long serialVersionUID &#x3D; 8849870114128959929L; @Column(nullable &#x3D; false) private String country; @Column(length &#x3D; 30) private String province; @Column(unique &#x3D; true) private String city; @Column(length &#x3D; 50) private String detail; @Embedded private Direction direction; &#125; Person类如下： @Entity public class Person implements Serializable&#123; private static final long serialVersionUID = 8849870114127659929L; @Id @GeneratedValue private Long id; @Column(nullable = false) private String name; @Column(nullable = false) private Integer age; @Embedded @AttributeOverrides(&#123;@AttributeOverride(name=\"direction.latitude\", column=@Column(name = \"person_latitude\")), @AttributeOverride(name=\"direction.longitude\", column = @Column(name = \"person_longitude\"))&#125;) private Address address; &#125; 生成的数据表如下： 在上面需要注意如下几点：在Person中定义Direction中的属性时，需要用”.”将所有相关的属性连接起来；在Direction中longitude属性定义为not null，但是由于使用了@AttributeOverride注解，其中虽然没有定义null属性，但是这时使用的是默认的nullable属性，默认为true; 参考 https://blog.csdn.net/lmy86263/article/details/52108130","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"create-react-app脚手架","date":"2019-08-07T01:38:30.000Z","path":"posts/undefined.html","text":"安装npm install -g create-react-app # 切记项目名称不能大写 create-react-app firstapp cd firstapp npm run start eject这是一次性的操作 npm run eject 启动less或者sasssasscreate-react-app默认有sass的配置，只需要安装依赖就行 npm install node-sass --save less默认没有less的配置，需要自己在webpack中配置 安装依赖 npm install less less-loader --save 运行完成之后，打开 config 目录下的 webpack.config.js 文件，找到 // style files regexes 注释位置，仿照其解析 sass 的规则，在下面添加两行代码 // 添加 less 解析规则 const lessRegex = /\\.less$/; const lessModuleRegex = /\\.module\\.less$/; 复制代码 找到 rules 属性配置，在其中添加 less 解析配置 !!!注意： 这里有一个需要注意的地方，下面的这些 less 配置规则放在 sass 的解析规则下面即可，如果放在了 file-loader 的解析规则下面，less 文件解析不会生效。 // Less 解析配置 &#123; test: lessRegex, exclude: lessModuleRegex, use: getStyleLoaders( &#123; importLoaders: 2, sourceMap: isEnvProduction &amp;&amp; shouldUseSourceMap, &#125;, 'less-loader' ), sideEffects: true, &#125;, &#123; test: lessModuleRegex, use: getStyleLoaders( &#123; importLoaders: 2, sourceMap: isEnvProduction &amp;&amp; shouldUseSourceMap, modules: true, getLocalIdent: getCSSModuleLocalIdent, &#125;, 'less-loader' ) &#125;, css module在css的命名中使用*.module.css就可以使用css module，也可以自己修改webpack的文件。 参考 https://www.jianshu.com/p/1f054623ecac","tags":[{"name":"react","slug":"react","permalink":"http://wumuwumu.github.io/tags/react/"}]},{"title":"python-类","date":"2019-08-04T10:12:22.000Z","path":"posts/undefined.html","text":"类中默认函数____new____和____init____区别new:创建对象时调用，会返回当前对象的一个实例 init:创建完对象后调用，对当前对象的一些实例初始化，无返回值 1、在类中，如果new__和__init__同时存在，会优先调用__new class Data(object): def __new__(self): print \"new\" def __init__(self): print \"init\" data = Data() # new 2、__new__方法会返回所构造的对象，__init__则不会。__init__无返回值。 class Data(object): def __init__(cls): cls.x = 2 print \"init\" return cls data = Data() ''' init Traceback (most recent call last): File \"&lt;stdin>\", line 1, in &lt;module> TypeError: __init__() should return None, not 'Data' ''' class Data(object): def __new__(cls): print(\"new\") cls.x = 1 return cls def __init__(self): print(\"init\") data = Data() print(data.x) # new # 1 data.x =2 print(data.x) # 2 If new() returns an instance of cls, then the new instance’s init() method will be invoked like init(self[, …]), where self is the new instance and the remaining arguments are the same as were passed to new(). 如果new__返回一个对象的实例，会隐式调用__init If new() does not return an instance of cls, then the new instance’s init() method will not be invoked. 如果__new__不返回一个对象的实例，__init__不会被调用 class A(object): def __new__(Class): object = super(A,Class).__new__(Class) print \"in New\" return object def __init__(self): print \"in init\" A() # in New # in init class A(object): def __new__(cls): print \"in New\" return cls def __init__(self): print \"in init\" a = A() # in New object.init(self[, …])Called when the instance is created. The arguments are those passed to the class constructor expression. If a base class has an init() method, the derived class’s init() method, if any, must explicitly call it to ensure proper initialization of the base class part of the instance; for example: BaseClass.init(self, [args…]). As a special constraint on constructors, no value may be returned; doing so will cause a TypeError to be raised at runtime. 在对象的实例创建完成后调用。参数被传给类的构造函数。如果基类有__init__方法，子类必须显示调用基类的__init__。 没有返回值，否则会再引发TypeError错误。","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"}]},{"title":"spring的jms事务","date":"2019-08-03T07:05:17.000Z","path":"posts/undefined.html","text":"","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://wumuwumu.github.io/tags/spring/"}]},{"title":"spring事务实现","date":"2019-08-03T06:40:33.000Z","path":"posts/undefined.html","text":"事务概念回顾 什么是事务？ 事务是逻辑上的一组操作，要么都执行，要么都不执行. 事物的特性（ACID）： 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性： 执行事务前后，数据保持一致； 隔离性： 并发访问数据库时，一个用户的事物不被其他事物所干扰，各并发事务之间数据库是独立的； 持久性: 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 Spring事务管理接口介绍 Spring事务管理接口： PlatformTransactionManager： （平台）事务管理器 TransactionDefinition： 事务定义信息(事务隔离级别、传播行为、超时、只读、回滚规则) TransactionStatus： 事务运行状态 所谓事务管理，其实就是“按照给定的事务规则来执行提交或者回滚操作”。 PlatformTransactionManager接口介绍 Spring并不直接管理事务，而是提供了多种事务管理器 ，他们将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现。 Spring事务管理器的接口是： org.springframework.transaction.PlatformTransactionManager ，通过这个接口，Spring为各个平台如JDBC、Hibernate等都提供了对应的事务管理器，但是具体的实现就是各个平台自己的事情了。 PlatformTransactionManager接口代码如下：PlatformTransactionManager接口中定义了三个方法： Public interface PlatformTransactionManager()...&#123; &#x2F;&#x2F; Return a currently active transaction or create a new one, according to the specified propagation behavior（根据指定的传播行为，返回当前活动的事务或创建一个新事务。） TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException; &#x2F;&#x2F; Commit the given transaction, with regard to its status（使用事务目前的状态提交事务） Void commit(TransactionStatus status) throws TransactionException; &#x2F;&#x2F; Perform a rollback of the given transaction（对执行的事务进行回滚） Void rollback(TransactionStatus status) throws TransactionException; &#125; 复制代码 我们刚刚也说了Spring中PlatformTransactionManager根据不同持久层框架所对应的接口实现类,几个比较常见的如下图所示 比如我们在使用JDBC或者iBatis（就是Mybatis）进行数据持久化操作时,我们的xml配置通常如下： &lt;!-- 事务管理器 --&gt; &lt;bean id&#x3D;&quot;transactionManager&quot; class&#x3D;&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;!-- 数据源 --&gt; &lt;property name&#x3D;&quot;dataSource&quot; ref&#x3D;&quot;dataSource&quot; &#x2F;&gt; &lt;&#x2F;bean&gt; 复制代码 TransactionDefinition接口介绍 事务管理器接口 PlatformTransactionManager 通过 getTransaction(TransactionDefinition definition) 方法来得到一个事务，这个方法里面的参数是 TransactionDefinition类 ，这个类就定义了一些基本的事务属性。 那么什么是事务属性呢？ 事务属性可以理解成事务的一些基本配置，描述了事务策略如何应用到方法上。事务属性包含了5个方面。 TransactionDefinition接口中的方法如下：TransactionDefinition接口中定义了5个方法以及一些表示事务属性的常量比如隔离级别、传播行为等等的常量。 我下面只是列出了TransactionDefinition接口中的方法而没有给出接口中定义的常量，该接口中的常量信息会在后面依次介绍到。 public interface TransactionDefinition &#123; &#x2F;&#x2F; 返回事务的传播行为 int getPropagationBehavior(); &#x2F;&#x2F; 返回事务的隔离级别，事务管理器根据它来控制另外一个事务可以看到本事务内的哪些数据 int getIsolationLevel(); &#x2F;&#x2F; 返回事务必须在多少秒内完成 &#x2F;&#x2F;返回事务的名字 String getName()； int getTimeout(); &#x2F;&#x2F; 返回是否优化为只读事务。 boolean isReadOnly(); &#125; 复制代码 （1）事务隔离级别（定义了一个事务可能受其他并发事务影响的程度）：我们先来看一下 并发事务带来的问题 ，然后再来介绍一下 TransactionDefinition 接口 中定义了五个表示隔离级别的常量。 并发事务带来的问题 在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对统一数据进行操作）。并发虽然是必须的，但可能会导致一下的问题。 脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。 不可重复读（Unrepeatableread）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 不可重复度和幻读区别： 不可重复读的重点是修改，幻读的重点在于新增或者删除。 例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导 致A再读自己的工资时工资变为 2000；这就是不可重复读。 例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。 隔离级别 TransactionDefinition 接口中定义了五个表示隔离级别的常量： TransactionDefinition.ISOLATION_DEFAULT: 使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别. TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读 TransactionDefinition.ISOLATION_READ_COMMITTED: 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生 TransactionDefinition.ISOLATION_REPEATABLE_READ: 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 TransactionDefinition.ISOLATION_SERIALIZABLE: 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 （2）事务传播行为（为了解决业务层方法之间互相调用的事务问题）：当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。在TransactionDefinition定义中包括了如下几个表示传播行为的常量： 支持当前事务的情况： TransactionDefinition.PROPAGATION_REQUIRED： 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。 TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_MANDATORY： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性） 不支持当前事务的情况： TransactionDefinition.PROPAGATION_REQUIRES_NEW： 创建一个新的事务，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常。 其他情况： TransactionDefinition.PROPAGATION_NESTED： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。 这里需要指出的是，前面的六种事务传播行为是 Spring 从 EJB 中引入的，他们共享相同的概念。而 PROPAGATION_NESTED 是 Spring 所特有的。以 PROPAGATION_NESTED 启动的事务内嵌于外部事务中（如果存在外部事务的话），此时，内嵌事务并不是一个独立的事务，它依赖于外部事务的存在，只有通过外部的事务提交，才能引起内部事务的提交，嵌套的子事务不能单独提交。如果熟悉 JDBC 中的保存点（SavePoint）的概念，那嵌套事务就很容易理解了，其实嵌套的子事务就是保存点的一个应用，一个事务中可以包括多个保存点，每一个嵌套子事务。另外，外部事务的回滚也会导致嵌套子事务的回滚。 (3) 事务超时属性(一个事务允许执行的最长时间)所谓事务超时，就是指一个事务所允许执行的最长时间，如果超过该时间限制但事务还没有完成，则自动回滚事务。在 TransactionDefinition 中以 int 的值来表示超时时间，其单位是秒。 (4) 事务只读属性（对事物资源是否执行只读操作）事务的只读属性是指，对事务性资源进行只读操作或者是读写操作。所谓事务性资源就是指那些被事务管理的资源，比如数据源、 JMS 资源，以及自定义的事务性资源等等。如果确定只对事务性资源进行只读操作，那么我们可以将事务标志为只读的，以提高事务处理的性能。在 TransactionDefinition 中以 boolean 类型来表示该事务是否只读。 (5) 回滚规则（定义事务回滚规则）例子使用API下面给出一个基于底层 API 的编程式事务管理的示例，基于PlatformTransactionManager、TransactionDefinition 和 TransactionStatus 三个核心接口，我们完全可以通过编程的方式来进行事务管理。 public class BankServiceImpl implements BankService &#123; private BankDao bankDao; private TransactionDefinition txDefinition; private PlatformTransactionManager txManager; public boolean transfer(Long fromId， Long toId， double amount) &#123; // 获取一个事务 TransactionStatus txStatus = txManager.getTransaction(txDefinition); boolean result = false; try &#123; result = bankDao.transfer(fromId， toId， amount); txManager.commit(txStatus); // 事务提交 &#125; catch (Exception e) &#123; result = false; txManager.rollback(txStatus); // 事务回滚 System.out.println(\"Transfer Error!\"); &#125; return result; &#125; 相应的配置文件如下所示： &lt;bean id=\"bankService\" class=\"footmark.spring.core.tx.programmatic.origin.BankServiceImpl\"> &lt;property name=\"bankDao\" ref=\"bankDao\"/> &lt;property name=\"txManager\" ref=\"transactionManager\"/> &lt;property name=\"txDefinition\"> &lt;bean class=\"org.springframework.transaction.support.DefaultTransactionDefinition\"> &lt;property name=\"propagationBehaviorName\" value=\"PROPAGATION_REQUIRED\"/> &lt;/bean> &lt;/property> &lt;/bean>如上所示，我们在BankServiceImpl类中增加了两个属性：一个是 TransactionDefinition 类型的属性，它用于定义事务的规则；另一个是 PlatformTransactionManager 类型的属性，用于执行事务管理操作。如果一个业务方法需要添加事务，我们首先需要在方法开始执行前调用PlatformTransactionManager.getTransaction(…) 方法启动一个事务；创建并启动了事务之后，便可以开始编写业务逻辑代码，然后在适当的地方执行事务的提交或者回滚。 基于 TransactionTemplate 的编程式事务管理 当然，除了可以使用基于底层 API 的编程式事务外，还可以使用基于 TransactionTemplate 的编程式事务管理。通过上面的示例可以发现，上述事务管理的代码散落在业务逻辑代码中，破坏了原有代码的条理性，并且每一个业务方法都包含了类似的启动事务、提交/回滚事务的样板代码。Spring 也意识到了这些，并提供了简化的方法，这就是 Spring 在数据访问层非常常见的 模板回调模式。 public class BankServiceImpl implements BankService &#123; private BankDao bankDao; private TransactionTemplate transactionTemplate; ...... public boolean transfer(final Long fromId， final Long toId， final double amount) &#123; return (Boolean) transactionTemplate.execute(new TransactionCallback()&#123; public Object doInTransaction(TransactionStatus status) &#123; Object result; try &#123; result = bankDao.transfer(fromId， toId， amount); &#125; catch (Exception e) &#123; status.setRollbackOnly(); result = false; System.out.println(\"Transfer Error!\"); &#125; return result; &#125; &#125;); &#125; &#125; 相应的配置文件如下所示： &lt;bean id=\"bankService\" class=\"footmark.spring.core.tx.programmatic.template.BankServiceImpl\"> &lt;property name=\"bankDao\" ref=\"bankDao\"/> &lt;property name=\"transactionTemplate\" ref=\"transactionTemplate\"/> &lt;/bean> TransactionTemplate 的 execute() 方法有一个 TransactionCallback 类型的参数，该接口中定义了一个 doInTransaction() 方法，通常我们以匿名内部类的方式实现 TransactionCallback 接口，并在其 doInTransaction() 方法中书写业务逻辑代码。这里可以使用默认的事务提交和回滚规则，这样在业务代码中就不需要显式调用任何事务管理的 API。doInTransaction() 方法有一个TransactionStatus 类型的参数，我们可以在方法的任何位置调用该参数的 setRollbackOnly() 方法将事务标识为回滚的，以执行事务回滚。 ​ 此外，TransactionCallback 接口有一个子接口 TransactionCallbackWithoutResult，该接口中定义了一个 doInTransactionWithoutResult() 方法，TransactionCallbackWithoutResult 接口主要用于事务过程中不需要返回值的情况。当然，对于不需要返回值的情况，我们仍然可以使用 TransactionCallback 接口，并在方法中返回任意值即可。 基于底层 API 的编程式事务管理 下面给出一个基于底层 API 的编程式事务管理的示例，基于PlatformTransactionManager、TransactionDefinition 和 TransactionStatus 三个核心接口，我们完全可以通过编程的方式来进行事务管理。 public class BankServiceImpl implements BankService &#123; private BankDao bankDao; private TransactionDefinition txDefinition; private PlatformTransactionManager txManager; public boolean transfer(Long fromId， Long toId， double amount) &#123; // 获取一个事务 TransactionStatus txStatus = txManager.getTransaction(txDefinition); boolean result = false; try &#123; result = bankDao.transfer(fromId， toId， amount); txManager.commit(txStatus); // 事务提交 &#125; catch (Exception e) &#123; result = false; txManager.rollback(txStatus); // 事务回滚 System.out.println(\"Transfer Error!\"); &#125; return result; &#125; 相应的配置文件如下所示： &lt;bean id=\"bankService\" class=\"footmark.spring.core.tx.programmatic.origin.BankServiceImpl\"> &lt;property name=\"bankDao\" ref=\"bankDao\"/> &lt;property name=\"txManager\" ref=\"transactionManager\"/> &lt;property name=\"txDefinition\"> &lt;bean class=\"org.springframework.transaction.support.DefaultTransactionDefinition\"> &lt;property name=\"propagationBehaviorName\" value=\"PROPAGATION_REQUIRED\"/> &lt;/bean> &lt;/property> &lt;/bean> 如上所示，我们在BankServiceImpl类中增加了两个属性：一个是 TransactionDefinition 类型的属性，它用于定义事务的规则；另一个是 PlatformTransactionManager 类型的属性，用于执行事务管理操作。如果一个业务方法需要添加事务，我们首先需要在方法开始执行前调用PlatformTransactionManager.getTransaction(…) 方法启动一个事务；创建并启动了事务之后，便可以开始编写业务逻辑代码，然后在适当的地方执行事务的提交或者回滚。 基于 TransactionTemplate 的编程式事务管理 当然，除了可以使用基于底层 API 的编程式事务外，还可以使用基于 TransactionTemplate 的编程式事务管理。通过上面的示例可以发现，上述事务管理的代码散落在业务逻辑代码中，破坏了原有代码的条理性，并且每一个业务方法都包含了类似的启动事务、提交/回滚事务的样板代码。Spring 也意识到了这些，并提供了简化的方法，这就是 Spring 在数据访问层非常常见的 模板回调模式。 public class BankServiceImpl implements BankService &#123; private BankDao bankDao; private TransactionTemplate transactionTemplate; ...... public boolean transfer(final Long fromId， final Long toId， final double amount) &#123; return (Boolean) transactionTemplate.execute(new TransactionCallback()&#123; public Object doInTransaction(TransactionStatus status) &#123; Object result; try &#123; result = bankDao.transfer(fromId， toId， amount); &#125; catch (Exception e) &#123; status.setRollbackOnly(); result = false; System.out.println(\"Transfer Error!\"); &#125; return result; &#125; &#125;); &#125; &#125; 相应的配置文件如下所示： &lt;bean id=\"bankService\" class=\"footmark.spring.core.tx.programmatic.template.BankServiceImpl\"> &lt;property name=\"bankDao\" ref=\"bankDao\"/> &lt;property name=\"transactionTemplate\" ref=\"transactionTemplate\"/> &lt;/bean> TransactionTemplate 的 execute() 方法有一个 TransactionCallback 类型的参数，该接口中定义了一个 doInTransaction() 方法，通常我们以匿名内部类的方式实现 TransactionCallback 接口，并在其 doInTransaction() 方法中书写业务逻辑代码。这里可以使用默认的事务提交和回滚规则，这样在业务代码中就不需要显式调用任何事务管理的 API。doInTransaction() 方法有一个TransactionStatus 类型的参数，我们可以在方法的任何位置调用该参数的 setRollbackOnly() 方法将事务标识为回滚的，以执行事务回滚。 此外，TransactionCallback 接口有一个子接口 TransactionCallbackWithoutResult，该接口中定义了一个 doInTransactionWithoutResult() 方法，TransactionCallbackWithoutResult 接口主要用于事务过程中不需要返回值的情况。当然，对于不需要返回值的情况，我们仍然可以使用 TransactionCallback 接口，并在方法中返回任意值即可。 Spring 声明式事务管理 Spring 的声明式事务管理是建立在 Spring AOP 机制之上的，其本质是对目标方法前后进行拦截，并在目标方法开始之前创建或者加入一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务。 声明式事务最大的优点就是不需要通过编程的方式管理事务，这样就不需要在业务逻辑代码中掺杂事务管理的代码，只需在配置文件中作相关的事务规则声明（或通过等价的基于标注的方式），便可以将事务规则应用到业务逻辑中。总的来说，声明式事务得益于 Spring IoC容器 和 Spring AOP 机制的支持：IoC容器为声明式事务管理提供了基础设施，使得 Bean 对于 Spring 框架而言是可管理的；而由于事务管理本身就是一个典型的横切逻辑（正是 AOP 的用武之地），因此 Spring AOP 机制是声明式事务管理的直接实现者。 显然，声明式事务管理要优于编程式事务管理，这正是spring倡导的非侵入式的开发方式。声明式事务管理使业务代码不受污染，一个普通的POJO对象，只要在XML文件中配置或者添加注解就可以获得完全的事务支持。因此，通常情况下，笔者强烈建议在开发中使用声明式事务，不仅因为其简单，更主要是因为这样使得纯业务代码不被污染，极大方便后期的代码维护。 基于 命名空间的声明式事务管理 Spring 2.x 引入了 命名空间，结合使用 命名空间，带给开发人员配置声明式事务的全新体验，配置变得更加简单和灵活。总的来说，开发者只需基于和命名空间在XML中进行简答配置便可实现声明式事务管理。下面基于使用Hibernate事务管理的配置文件： &lt;!-- 配置 DataSourece --> &lt;bean id=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\" destroy-method=\"close\"> &lt;!-- results in a setDriverClassName(String) call --> &lt;property name=\"driverClassName\"> &lt;value>com.mysql.jdbc.Driver&lt;/value> &lt;/property> &lt;property name=\"url\"> &lt;value>jdbc:mysql://localhost:3306/ssh&lt;/value> &lt;/property> &lt;property name=\"username\"> &lt;value>root&lt;/value> &lt;/property> &lt;property name=\"password\"> &lt;value>root&lt;/value> &lt;/property> &lt;/bean> &lt;!-- 配置 sessionFactory --> &lt;bean id=\"sessionFactory\" class=\"org.springframework.orm.hibernate3.annotation.AnnotationSessionFactoryBean\"> &lt;!-- 数据源的设置 --> &lt;property name=\"dataSource\" ref=\"dataSource\" /> &lt;!-- 用于持久化的实体类类列表 --> &lt;property name=\"annotatedClasses\"> &lt;list> &lt;value>cn.edu.tju.rico.model.entity.User&lt;/value> &lt;value>cn.edu.tju.rico.model.entity.Log&lt;/value> &lt;/list> &lt;/property> &lt;!-- Hibernate 的配置 --> &lt;property name=\"hibernateProperties\"> &lt;props> &lt;!-- 方言设置 --> &lt;prop key=\"hibernate.dialect\">org.hibernate.dialect.MySQLDialect&lt;/prop> &lt;!-- 显示sql --> &lt;prop key=\"hibernate.show_sql\">true&lt;/prop> &lt;!-- 格式化sql --> &lt;prop key=\"hibernate.format_sql\">true&lt;/prop> &lt;!-- 自动创建/更新数据表 --> &lt;prop key=\"hibernate.hbm2ddl.auto\">update&lt;/prop> &lt;/props> &lt;/property> &lt;/bean> &lt;!-- 配置 TransactionManager --> &lt;bean id=\"txManager\" class=\"org.springframework.orm.hibernate3.HibernateTransactionManager\"> &lt;property name=\"sessionFactory\" ref=\"sessionFactory\" /> &lt;/bean> &lt;!-- 配置事务增强处理的切入点，以保证其被恰当的织入 --> &lt;aop:config> &lt;!-- 切点 --> &lt;aop:pointcut expression=\"execution(* cn.edu.tju.rico.service.impl.*.*(..))\" id=\"bussinessService\" /> &lt;!-- 声明式事务的切入 --> &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"bussinessService\" /> &lt;/aop:config> &lt;!-- 由txAdvice切面定义事务增强处理 --> &lt;tx:advice id=\"txAdvice\" transaction-manager=\"txManager\"> &lt;tx:attributes> &lt;!-- get打头的方法为只读方法,因此将read-only设为 true --> &lt;tx:method name=\"get*\" read-only=\"true\" /> &lt;!-- 其他方法为读写方法,因此将read-only设为 false --> &lt;tx:method name=\"*\" read-only=\"false\" propagation=\"REQUIRED\" isolation=\"DEFAULT\" /> &lt;/tx:attributes> &lt;/tx:advice> 事实上，Spring配置文件中关于事务的配置总是由三个部分组成，即：DataSource、TransactionManager和代理机制三部分，无论哪种配置方式，一般变化的只是代理机制这部分。其中，DataSource、TransactionManager这两部分只是会根据数据访问方式有所变化，比如使用hibernate进行数据访问时，DataSource实际为SessionFactory，TransactionManager的实现为 HibernateTransactionManager。如下图所示： 基于 @Transactional 的声明式事务管理 除了基于命名空间的事务配置方式，Spring 还引入了基于 Annotation 的方式，具体主要涉及@Transactional 标注。@Transactional 可以作用于接口、接口方法、类以及类方法上：当作用于类上时，该类的所有 public 方法将都具有该类型的事务属性；当作用于方法上时，该标注来覆盖类级别的定义。如下所示： @Transactional(propagation = Propagation.REQUIRED) public boolean transfer(Long fromId， Long toId， double amount) &#123; return bankDao.transfer(fromId， toId， amount); &#125; Spring 使用 BeanPostProcessor 来处理 Bean 中的标注，因此我们需要在配置文件中作如下声明来激活该后处理 Bean，如下所示： &lt;tx:annotation-driven transaction-manager=\"transactionManager”/> 1 与前面相似，transaction-manager、datasource 和 sessionFactory的配置不变，只需将基于和命名空间的配置更换为上述配置即可。 Spring 声明式事务的本质 就Spring 声明式事务而言，无论其基于 命名空间的实现还是基于 @Transactional 的实现，其本质都是 Spring AOP 机制的应用：即通过以@Transactional的方式或者XML配置文件的方式向业务组件中的目标业务方法插入事务增强处理并生成相应的代理对象供应用程序(客户端)使用从而达到无污染地添加事务的目的。如下图所示： 参考https://juejin.im/post/5b00c52ef265da0b95276091 https://blog.csdn.net/justloveyou_/article/details/73733278","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://wumuwumu.github.io/tags/spring/"}]},{"title":"docker教程","date":"2019-08-03T03:04:39.000Z","path":"posts/undefined.html","text":"docker基本命令镜像相关# 1. 查找镜像 docker search mysql docker search -s 100 mysql # 搜索100star以上的mysql镜像 # 2. 获取镜像 docker pull centos7 # 3. 查找镜像 docker image ls # 4. 删除镜像 docker rmi od16d0a97dd1 # 5. 创建镜像 docker build -t nginx:1.14.0 . 容器相关# 1. 启动容器 docker run -it --rm php:7 bash # 启动一个容器，并分配一个为终端，退出容器就会被删除 docker run -d -p 9000:9000 php:7 # 运行我们常用的容器 # 2. 查看容器的信息 docker inspect a47342323232 # image id # 3. 进入容器 docker exec -it es2dffg2f2gh bash #image id ,bash根据系统会有不同 # 4. 停止容器 docker stop 34fvd234234f # 5. 启动容器 docker start 3fg23fsfsfs # 6. 查看容器 docker ps # 查看启动的容器 docker ps -a # 查看全部容器 # 7. 删除容器 docker rm d989ds82kjk volume创建# 使用匿名volume docker run -v 容器路径 ... docker run -v host路径:容器路径 ... # 使用volumes-from 1. 创建一个容器 2. Docker run —volumes-from data-container ubuntu ,可以共享文件 删除这个功能可能会更加重要，如果你已经使用 docker rm 来删除你的容器，那可能有很多的孤立的Volume仍在占用着空间。 Volume只有在下列情况下才能被删除： 该容器是用docker rm －v命令来删除的（-v是必不可少的）。 docker run中使用了--rm参数 即使用以上两种命令，也只能删除没有容器连接的Volume。连接到用户指定主机目录的Volume永远不会被docker删除。 除非你已经很小心的，总是像这样来运行容器，否则你将会在 &#x2F;var&#x2F;lib&#x2F;docker&#x2F;vfs&#x2F;dir 目录下得到一些僵尸文件和目录，并且还不容易说出它们到底代表什么。 dockerfile参考FROM debian:wheezy MAINTAINER Steeve Morin &quot;steeve.morin@gmail.com&quot; RUN apt-get update &amp;&amp; apt-get -y install unzip \\ xz-utils \\ curl \\ bc \\ git \\ build-essential \\ cpio \\ gcc-multilib libc6-i386 libc6-dev-i386 \\ kmod \\ squashfs-tools \\ genisoimage \\ xorriso \\ syslinux \\ automake \\ pkg-config ENV KERNEL_VERSION 3.16.1 ENV AUFS_BRANCH aufs3.16 # Fetch the kernel sources RUN curl --retry 10 https:&#x2F;&#x2F;www.kernel.org&#x2F;pub&#x2F;linux&#x2F;kernel&#x2F;v3.x&#x2F;linux-$KERNEL_VERSION.tar.xz | tar -C &#x2F; -xJ &amp;&amp; \\ mv &#x2F;linux-$KERNEL_VERSION &#x2F;linux-kernel # Download AUFS and apply patches and files, then remove it RUN git clone -b $AUFS_BRANCH --depth 1 git:&#x2F;&#x2F;git.code.sf.net&#x2F;p&#x2F;aufs&#x2F;aufs3-standalone &amp;&amp; \\ cd aufs3-standalone &amp;&amp; \\ cd &#x2F;linux-kernel &amp;&amp; \\ cp -r &#x2F;aufs3-standalone&#x2F;Documentation &#x2F;linux-kernel &amp;&amp; \\ cp -r &#x2F;aufs3-standalone&#x2F;fs &#x2F;linux-kernel &amp;&amp; \\ cp -r &#x2F;aufs3-standalone&#x2F;include&#x2F;uapi&#x2F;linux&#x2F;aufs_type.h &#x2F;linux-kernel&#x2F;include&#x2F;uapi&#x2F;linux&#x2F; &amp;&amp;\\ for patch in aufs3-kbuild aufs3-base aufs3-mmap aufs3-standalone aufs3-loopback; do \\ patch -p1 &lt; &#x2F;aufs3-standalone&#x2F;$patch.patch; \\ done COPY kernel_config &#x2F;linux-kernel&#x2F;.config RUN jobs&#x3D;$(nproc); \\ cd &#x2F;linux-kernel &amp;&amp; \\ make -j $&#123;jobs&#125; oldconfig &amp;&amp; \\ make -j $&#123;jobs&#125; bzImage &amp;&amp; \\ make -j $&#123;jobs&#125; modules # The post kernel build process ENV ROOTFS &#x2F;rootfs ENV TCL_REPO_BASE http:&#x2F;&#x2F;tinycorelinux.net&#x2F;5.x&#x2F;x86 ENV TCZ_DEPS iptables \\ iproute2 \\ openssh openssl-1.0.0 \\ tar \\ gcc_libs \\ acpid \\ xz liblzma \\ git expat2 libiconv libidn libgpg-error libgcrypt libssh2 \\ nfs-utils tcp_wrappers portmap rpcbind libtirpc \\ curl ntpclient # Make the ROOTFS RUN mkdir -p $ROOTFS # Install the kernel modules in $ROOTFS RUN cd &#x2F;linux-kernel &amp;&amp; \\ make INSTALL_MOD_PATH&#x3D;$ROOTFS modules_install firmware_install # Remove useless kernel modules, based on unclejack&#x2F;debian2docker RUN cd $ROOTFS&#x2F;lib&#x2F;modules &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;sound&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;drivers&#x2F;gpu&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;drivers&#x2F;infiniband&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;drivers&#x2F;isdn&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;drivers&#x2F;media&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;drivers&#x2F;staging&#x2F;lustre&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;drivers&#x2F;staging&#x2F;comedi&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;fs&#x2F;ocfs2&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;net&#x2F;bluetooth&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;net&#x2F;mac80211&#x2F;* &amp;&amp; \\ rm -rf .&#x2F;*&#x2F;kernel&#x2F;net&#x2F;wireless&#x2F;* # Install libcap RUN curl -L ftp:&#x2F;&#x2F;ftp.de.debian.org&#x2F;debian&#x2F;pool&#x2F;main&#x2F;libc&#x2F;libcap2&#x2F;libcap2_2.22.orig.tar.gz | tar -C &#x2F; -xz &amp;&amp; \\ cd &#x2F;libcap-2.22 &amp;&amp; \\ sed -i &#39;s&#x2F;LIBATTR :&#x3D; yes&#x2F;LIBATTR :&#x3D; no&#x2F;&#39; Make.Rules &amp;&amp; \\ sed -i &#39;s&#x2F;\\(^CFLAGS :&#x3D; .*\\)&#x2F;\\1 -m32&#x2F;&#39; Make.Rules &amp;&amp; \\ make &amp;&amp; \\ mkdir -p output &amp;&amp; \\ make prefix&#x3D;&#96;pwd&#96;&#x2F;output install &amp;&amp; \\ mkdir -p $ROOTFS&#x2F;usr&#x2F;local&#x2F;lib &amp;&amp; \\ cp -av &#96;pwd&#96;&#x2F;output&#x2F;lib64&#x2F;* $ROOTFS&#x2F;usr&#x2F;local&#x2F;lib # Make sure the kernel headers are installed for aufs-util, and then build it RUN cd &#x2F;linux-kernel &amp;&amp; \\ make INSTALL_HDR_PATH&#x3D;&#x2F;tmp&#x2F;kheaders headers_install &amp;&amp; \\ cd &#x2F; &amp;&amp; \\ git clone git:&#x2F;&#x2F;git.code.sf.net&#x2F;p&#x2F;aufs&#x2F;aufs-util &amp;&amp; \\ cd &#x2F;aufs-util &amp;&amp; \\ git checkout aufs3.9 &amp;&amp; \\ CPPFLAGS&#x3D;&quot;-m32 -I&#x2F;tmp&#x2F;kheaders&#x2F;include&quot; CLFAGS&#x3D;$CPPFLAGS LDFLAGS&#x3D;$CPPFLAGS make &amp;&amp; \\ DESTDIR&#x3D;$ROOTFS make install &amp;&amp; \\ rm -rf &#x2F;tmp&#x2F;kheaders # Download the rootfs, don&#39;t unpack it though: RUN curl -L -o &#x2F;tcl_rootfs.gz $TCL_REPO_BASE&#x2F;release&#x2F;distribution_files&#x2F;rootfs.gz # Install the TCZ dependencies RUN for dep in $TCZ_DEPS; do \\ echo &quot;Download $TCL_REPO_BASE&#x2F;tcz&#x2F;$dep.tcz&quot; &amp;&amp;\\ curl -L -o &#x2F;tmp&#x2F;$dep.tcz $TCL_REPO_BASE&#x2F;tcz&#x2F;$dep.tcz &amp;&amp; \\ unsquashfs -f -d $ROOTFS &#x2F;tmp&#x2F;$dep.tcz &amp;&amp; \\ rm -f &#x2F;tmp&#x2F;$dep.tcz ;\\ done COPY VERSION $ROOTFS&#x2F;etc&#x2F;version # Get the Docker version that matches our boot2docker version # Note: &#96;docker version&#96; returns non-true when there is no server to ask RUN curl -L -o $ROOTFS&#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker https:&#x2F;&#x2F;get.docker.io&#x2F;builds&#x2F;Linux&#x2F;x86_64&#x2F;docker-$(cat $ROOTFS&#x2F;etc&#x2F;version) &amp;&amp; \\ chmod +x $ROOTFS&#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker &amp;&amp; \\ &#123; $ROOTFS&#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker version || true; &#125; # get generate_cert RUN curl -L -o $ROOTFS&#x2F;usr&#x2F;local&#x2F;bin&#x2F;generate_cert https:&#x2F;&#x2F;github.com&#x2F;SvenDowideit&#x2F;generate_cert&#x2F;releases&#x2F;download&#x2F;0.1&#x2F;generate_cert-0.1-linux-386&#x2F; &amp;&amp; \\ chmod +x $ROOTFS&#x2F;usr&#x2F;local&#x2F;bin&#x2F;generate_cert # Get the git versioning info COPY .git &#x2F;git&#x2F;.git RUN cd &#x2F;git &amp;&amp; \\ GIT_BRANCH&#x3D;$(git rev-parse --abbrev-ref HEAD) &amp;&amp; \\ GITSHA1&#x3D;$(git rev-parse --short HEAD) &amp;&amp; \\ DATE&#x3D;$(date) &amp;&amp; \\ echo &quot;$&#123;GIT_BRANCH&#125; : $&#123;GITSHA1&#125; - $&#123;DATE&#125;&quot; &gt; $ROOTFS&#x2F;etc&#x2F;boot2docker COPY rootfs&#x2F;isolinux &#x2F;isolinux # Copy our custom rootfs COPY rootfs&#x2F;rootfs $ROOTFS # These steps can only be run once, so can&#39;t be in make_iso.sh (which can be run in chained Dockerfiles) # see https:&#x2F;&#x2F;github.com&#x2F;boot2docker&#x2F;boot2docker&#x2F;blob&#x2F;master&#x2F;doc&#x2F;BUILD.md RUN \\ # Make sure init scripts are executable &amp;&amp; \\ find $ROOTFS&#x2F;etc&#x2F;rc.d&#x2F; $ROOTFS&#x2F;usr&#x2F;local&#x2F;etc&#x2F;init.d&#x2F; -exec chmod +x &#39;&#123;&#125;&#39; &#39;;&#39; &amp;&amp; \\ # Download Tiny Core Linux rootfs &amp;&amp; \\ ( cd $ROOTFS &amp;&amp; zcat &#x2F;tcl_rootfs.gz | cpio -f -i -H newc -d --no-absolute-filenames ) &amp;&amp; \\ # Change MOTD &amp;&amp; \\ mv $ROOTFS&#x2F;usr&#x2F;local&#x2F;etc&#x2F;motd $ROOTFS&#x2F;etc&#x2F;motd &amp;&amp; \\ # Make sure we have the correct bootsync &amp;&amp; \\ mv $ROOTFS&#x2F;boot*.sh $ROOTFS&#x2F;opt&#x2F; &amp;&amp; \\ chmod +x $ROOTFS&#x2F;opt&#x2F;*.sh &amp;&amp; \\ # Make sure we have the correct shutdown &amp;&amp; \\ mv $ROOTFS&#x2F;shutdown.sh $ROOTFS&#x2F;opt&#x2F;shutdown.sh &amp;&amp; \\ chmod +x $ROOTFS&#x2F;opt&#x2F;shutdown.sh &amp;&amp; \\ # Add serial console &amp;&amp; \\ echo &quot;#!&#x2F;bin&#x2F;sh&quot; &gt; $ROOTFS&#x2F;usr&#x2F;local&#x2F;bin&#x2F;autologin &amp;&amp; \\ echo &quot;&#x2F;bin&#x2F;login -f docker&quot; &gt;&gt; $ROOTFS&#x2F;usr&#x2F;local&#x2F;bin&#x2F;autologin &amp;&amp; \\ chmod 755 $ROOTFS&#x2F;usr&#x2F;local&#x2F;bin&#x2F;autologin &amp;&amp; \\ echo &#39;ttyS0:2345:respawn:&#x2F;sbin&#x2F;getty -l &#x2F;usr&#x2F;local&#x2F;bin&#x2F;autologin 9600 ttyS0 vt100&#39; &gt;&gt; $ROOTFS&#x2F;etc&#x2F;inittab &amp;&amp; \\ # fix su - &amp;&amp; \\ echo root &gt; $ROOTFS&#x2F;etc&#x2F;sysconfig&#x2F;superuser COPY rootfs&#x2F;make_iso.sh &#x2F; RUN &#x2F;make_iso.sh CMD [&quot;cat&quot;, &quot;boot2docker.iso&quot;] FROM指令和MAINTAINER指令 脚本的第1行是FROM指令。通过FROM指令，docker编译程序能够知道在哪个基础镜像执行来进行编译。所有的Dockerfile都必须以FROM指令开始。第二条指令MAINTAINER，用来标明这个镜像的维护者信息。 RUN指令 接下来是RUN指令。这条指令用来在docker的编译环境中运行指定命令。上面这条指令会在编译环境运行/bin/sh -c &quot;apt-get update &amp;&amp; apt-get -y install ...&quot;。RUN指令还有另外一种格式： RUN [&quot;程序名&quot;, &quot;参数1&quot;, &quot;参数2&quot;] 这种格式运行程序，可以免除运行/bin/sh的消耗。这种格式使用Json格式将程序名与所需参数组成一个字符串数组，所以如果参数中有引号等特殊字符，需要进行转义。 ENV指令 ENV指令用来指定在执行docker run命令运行镜像时，自动设置的环境变量。这些环境变量可以通过docker run命令的--evn参数来进行修改。 COPY指令和ADD指令 COPY指令用来将本地（Dockerfile所在位置）的文件或文件夹复制到编译环境的指定路径下。上面的例子里，boot2docker的Dockerfile希望将与Dockerfile同一目录下的kernel_config文件复制到编译环境的/linux-kernal/.config。Dockerfile还提供了另外一个类似的指令：ADD。在复制文件方面ADD指令和COPY指令的格式和效果是完全一样的。这两个指令的区别主要由两点： ADD指令可以从一个URL地址下载内容复制到容器的文件系统中; ADD指令会将压缩打包格式的文件解开后复制到指定位置，而COPY指令只做复制操作。 CMD指令 这是整个Dockerfile脚本的最后一条指令。当Dockerfile已经完成了所有环境的安装与配置，通过CMD指令来指示docker run命令运行镜像时要执行的命令。上面的例子里，在完成所有工作后，boot2docker的编译脚本将编译结果输出到本地环境下。 其他指令 上面我们通过boot2docker的Dockerfile脚本学习了几个最常用的指令。接下来我们再学习剩下的几个指令。 EXPOSE指令EXPOSE &lt;端口&gt; [&lt;端口&gt;...]指令用于标明，这个镜像中的应用将会侦听某个端口，并且希望能将这个端口映射到主机的网络界面上。但是，为了安全，docker run命令如果没有带上响应的端口映射参数，docker并不会将端口映射出了。 ENTRYPOINT指令ENTRYPOINT指令和前面介绍过的CMD一样，用于标明一个镜像作为容器运行时，最后要执行的程序或命令。这两个指令有相同之处，也有区别。通过两个指令的配合使用可以配置出不同的效果。 ENTRYPOINT指令有两种格式，CMD指令有三种格式： ENTRYPOINT [&quot;程序名&quot;, &quot;参数1&quot;, &quot;参数2&quot;] ENTRYPOINT 命令 参数1 参数2 CMD [&quot;程序名&quot;, &quot;参数1&quot;, &quot;参数2&quot;] CMD 命令 参数1 参数2 CMD 参数1 参数2 ENTRYPOINT是容器运行程序的入口。也就是说，在docker run命令中指定的命令都将作为参数提供给ENTRYPOINT指定的程序。同样，上面列举的CMD指令格式的后面两种格式也将作为参数提供给ENTRYPOINT指定的程序。 默认的ENTRYPOINT是/bin/sh -c。你可以根据实际需要任意设置。但是如果在一个Dockerfile中出现了多个ENTRYPOINT指令，那么，只有最后一个ENTRYPOINT指令是起效的。 一种常用的设置是将命令与必要参数设置到ENTRYPOINT中，而运行时只提供其他选项。例如：你有一个MySQL的客户端程序运行在容器中，而客户端所需要的主机地址、用户名和密码你不希望每次都输入，你就可以将ENTRYPOINT设置成：ENTRYPOINT mysql -u &lt;用户名&gt; -p &lt;密码&gt; -h &lt;主机名&gt;。而你运行时，只需要指定数据库名。 VOLUME指令VOLUME [&quot;路径&quot;] VOLUME指令用于在容器内创建一个或多个卷。而更多的时候，是在执行docker run时指定要创建的卷以及本地路径来进行映射。关于这个用法将在后面的章节学习到。 USER指令USER 用户名或用户ID USER指令用于容器内运行RUN指令或CMD指令的用户。例如，在构建一个nginx镜像时，你希望最后运行nginx的用户为nginx，就可以在CMD [&quot;nginx&quot;]之前将用户设置为nginx。 如果在运行docker run命令时设置了-u 用户名参数，那么将覆盖USER指令设置的用户。 WORKDIR指令WORKDIR 路径 WORKDIR指令用于设置执行RUN指令、CMD指令和ENTRYPOINT指令执行时的工作目录。在Dockerfile中可以多次设置WORKDIR，在每次设置之后的命令将使用新的路径。 ONBUILD指令ONBUILD 指令 ONBUILD指令用于设置一些指令，当本镜像作为基础镜像被其他Dockerfile用FROM指令引用时，在所有其他指令执行之前先执行这些指令。 Compose基本命令# 批量启动 docker-compose up -d # 改名了实现了构建镜像、(重新)创建服务、启动服务，并关联服务相关的容器操作 # 启动 docker-compose start # -f指定配置文件 # 停止 docker-compose stop docker-compose.yaml参考version: '2' services: web: image: dockercloud/hello-world ports: - 8080 networks: - front-tier - back-tier redis: image: redis links: - web networks: - back-tier lb: image: dockercloud/haproxy ports: - 80:80 links: - web networks: - front-tier - back-tier volumes: - /var/run/docker.sock:/var/run/docker.sock networks: front-tier: driver: bridge back-tier: driver: bridge versionversion是compose的版本，下表是compose版本与docker版本对照表： servicesservices是用来配置定义每个容器启动参数，每个service就是一个容器，services下一级配置即是服务名称，例如上面示例中的redis, db等。 imageimage是指定服务的镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 build服务除了可以基于指定的镜像，还可以基于一份 Dockerfile，在使用 up 启动之时执行构建任务，这个构建标签就是 build，它可以指定 Dockerfile 所在文件夹的路径。Compose 将会利用它自动构建这个镜像，然后使用这个镜像启动服务容器。 build: &#x2F;path&#x2F;to&#x2F;build&#x2F;dir 也可以是相对路径，只要上下文确定就可以读取到 Dockerfile。 build: .&#x2F;dir 设定上下文根目录，然后以该目录为准指定 Dockerfile。 build: context: ..&#x2F; dockerfile: path&#x2F;of&#x2F;Dockerfile 注意 build 都是一个目录，如果你要指定 Dockerfile 文件需要在 build 标签的子级标签中使用 dockerfile 标签指定，如上面的例子。 如果你同时指定了 image 和 build 两个标签，那么 Compose 会构建镜像并且把镜像命名为 image 后面的那个名字。 既然可以在 docker-compose.yml 中定义构建任务，那么一定少不了 arg 这个标签，就像 Dockerfile 中的 ARG 指令，它可以在构建过程中指定环境变量，但是在构建成功后取消，在 docker-compose.yml 文件中也支持这样的写法： build: context: . args: buildno: 1 password: secret 下面这种写法也是支持的，一般来说下面的写法更适合阅读。 build: context: . args: - buildno&#x3D;1 - password&#x3D;secret 与 ENV 不同的是，ARG 是允许空值的。例如： args: - buildno - password 这样构建过程可以向它们赋值。 注意：YAML 的布尔值（true, false, yes, no, on, off）必须要使用引号引起来（单引号、双引号均可），否则会当成字符串解析。 command使用 command 可以覆盖容器启动后默认执行的命令。 command: bundle exec thin -p 3000 也可以写成类似 Dockerfile 中的格式： command: [bundle, exec, thin, -p, 3000] container_nameCompose 的容器名称格式是：&lt;项目名称&gt;&lt;服务名称&gt;&lt;序号&gt;虽然可以自定义项目名称、服务名称，但是如果你想完全控制容器的命名，可以使用这个标签指定： container_name: app 这样容器的名字就指定为 app 了。 depends_on在使用 Compose 时，最大的好处就是少打启动命令，但是一般项目容器启动的顺序是有要求的，如果直接从上到下启动容器，必然会因为容器依赖问题而启动失败。 例如在没启动数据库容器的时候启动了应用容器，这时候应用容器会因为找不到数据库而退出，为了避免这种情况我们需要加入一个标签，就是 depends_on，这个标签解决了容器的依赖、启动先后的问题。 例如下面容器会先启动 redis 和 db 两个服务，最后才启动 web 服务： version: &#39;2&#39; services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意的是，默认情况下使用 docker-compose up web 这样的方式启动 web 服务时，也会启动 redis 和 db 两个服务，因为在配置文件中定义了依赖关系。 dns和 –dns 参数一样用途，格式如下： dns: 8.8.8.8 也可以是一个列表： dns: - 8.8.8.8 - 9.9.9.9 此外 dns_search 的配置也类似： dns_search: example.com dns_search: - dc1.example.com - dc2.example.com environment和 arg 有几分类似，这个标签的作用是设置镜像变量，它可以保存变量到镜像里面，也就是说启动的容器也会包含这些变量设置，这是与 arg 最大的不同。 一般 arg 标签的变量仅用在构建过程中。而 environment 和 Dockerfile 中的 ENV 指令一样会把变量一直保存在镜像、容器中，类似 docker run -e 的效果。 environment: RACK_ENV: development SHOW: &#39;true&#39; SESSION_SECRET: environment: - RACK_ENV&#x3D;development - SHOW&#x3D;true - SESSION_SECRET extra_hosts添加主机名的标签，就是往/etc/hosts文件中添加一些记录，与Docker client的–add-host类似： extra_hosts: - &quot;somehost:162.242.195.82&quot; - &quot;otherhost:50.31.209.229&quot; 启动之后查看容器内部hosts： 162.242.195.82 somehost 50.31.209.229 otherhost labels向容器添加元数据，和Dockerfile的LABEL指令一个意思，格式如下： labels: com.example.description: &quot;Accounting webapp&quot; com.example.department: &quot;Finance&quot; com.example.label-with-empty-value: &quot;&quot; labels: - &quot;com.example.description&#x3D;Accounting webapp&quot; - &quot;com.example.department&#x3D;Finance&quot; - &quot;com.example.label-with-empty-value&quot; 映射端口的标签。 使用HOST:CONTAINER格式或者只是指定容器的端口，宿主机会随机映射端口。 ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; 注意：当使用HOST:CONTAINER格式来映射端口时，如果你使用的容器端口小于60你可能会得到错误得结果，因为YAML将会解析xx:yy这种数字格式为60进制。所以建议采用字符串格式。 volumes挂载一个目录或者一个已存在的数据卷容器，可以直接使用 [HOST:CONTAINER] 这样的格式，或者使用 [HOST:CONTAINER:ro] 这样的格式，后者对于容器来说，数据卷是只读的，这样可以有效保护宿主机的文件系统。 Compose的数据卷指定路径可以是相对路径，使用 . 或者 .. 来指定相对目录。 数据卷的格式可以是下面多种形式： volumes: &#x2F;&#x2F; 只是指定一个路径，Docker 会自动在创建一个数据卷（这个路径是容器内部的）。 - &#x2F;var&#x2F;lib&#x2F;mysql &#x2F;&#x2F; 使用绝对路径挂载数据卷 - &#x2F;opt&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql &#x2F;&#x2F; 以 Compose 配置文件为中心的相对路径作为数据卷挂载到容器。 - .&#x2F;cache:&#x2F;tmp&#x2F;cache &#x2F;&#x2F; 使用用户的相对路径（~&#x2F; 表示的目录是 &#x2F;home&#x2F;&lt;用户目录&gt;&#x2F; 或者 &#x2F;root&#x2F;）。 - ~&#x2F;configs:&#x2F;etc&#x2F;configs&#x2F;:ro &#x2F;&#x2F; 已经存在的命名的数据卷。 - datavolume:&#x2F;var&#x2F;lib&#x2F;mysql 如果你不使用宿主机的路径，你可以指定一个volume_driver。 volume_driver: mydriver networks加入指定网络，格式如下： services: some-service: networks: - some-network - other-network 关于这个标签还有一个特别的子标签aliases，这是一个用来设置服务别名的标签，例如： services: some-service: networks: some-network: aliases: - alias1 - alias3 other-network: aliases: - alias2 相同的服务可以在不同的网络有不同的别名。 network_mode网络模式，与Docker client的–net参数类似，只是相对多了一个service:[service name] 的格式。 例如： network_mode: &quot;bridge&quot; network_mode: &quot;host&quot; network_mode: &quot;none&quot; network_mode: &quot;service:[service name]&quot; network_mode: &quot;container:[container name&#x2F;id]&quot; 参考https://juejin.im/post/5b319c3cf265da597d0aa79d https://github.com/zhangpeihao/LearningDocker/blob/master/manuscript/04-WriteDockerfile.md https://www.jianshu.com/p/4f14637f4b35 http://dockone.io/article/128","tags":[{"name":"docker","slug":"docker","permalink":"http://wumuwumu.github.io/tags/docker/"}]},{"title":"python-装饰器","date":"2019-07-31T11:44:57.000Z","path":"posts/undefined.html","text":"简单的装饰器import logging def use_logging(func): def wrapper(): logging.warning(\"%s is running\" % func.__name__) return func() # 把 foo 当做参数传递进来时，执行func()就相当于执行foo() return wrapper def foo(): print('i am foo') foo = use_logging(foo) # 因为装饰器 use_logging(foo) 返回的时函数对象 wrapper，这条语句相当于 foo = wrapper foo() # 执行foo()就相当于执行 wrapper() ''' WARNING:root:foo is running i am foo ''' @ 语法糖def use_logging(func): def wrapper(): logging.warn(\"%s is running\" % func.__name__) return func() return wrapper @use_logging def foo(): print(\"i am foo\") foo() *args、**kwargs可能有人问，如果我的业务逻辑函数 foo 需要参数怎么办？比如： def foo(name): print(&quot;i am %s&quot; % name) 我们可以在定义 wrapper 函数的时候指定参数： def wrapper(name): logging.warn(\"%s is running\" % func.__name__) return func(name) return wrapper 这样 foo 函数定义的参数就可以定义在 wrapper 函数中。这时，又有人要问了，如果 foo 函数接收两个参数呢？三个参数呢？更有甚者，我可能传很多个。当装饰器不知道 foo 到底有多少个参数时，我们可以用 *args 来代替： def wrapper(*args): logging.warn(\"%s is running\" % func.__name__) return func(*args) return wrapper 如此一来，甭管 foo 定义了多少个参数，我都可以完整地传递到 func 中去。这样就不影响 foo 的业务逻辑了。这时还有读者会问，如果 foo 函数还定义了一些关键字参数呢？比如： def foo(name, age=None, height=None): print(\"I am %s, age %s, height %s\" % (name, age, height)) 这时，你就可以把 wrapper 函数指定关键字函数： def wrapper(*args, **kwargs): # args是一个数组，kwargs一个字典 logging.warn(\"%s is running\" % func.__name__) return func(*args, **kwargs) return wrapper 带参数的装饰器装饰器还有更大的灵活性，例如带参数的装饰器，在上面的装饰器调用中，该装饰器接收唯一的参数就是执行业务的函数 foo 。装饰器的语法允许我们在调用时，提供其它参数，比如@decorator(a)。这样，就为装饰器的编写和使用提供了更大的灵活性。比如，我们可以在装饰器中指定日志的等级，因为不同业务函数可能需要的日志级别是不一样的。 def use_logging(level): def decorator(func): def wrapper(*args, **kwargs): if level == \"warn\": logging.warn(\"%s is running\" % func.__name__) elif level == \"info\": logging.info(\"%s is running\" % func.__name__) return func(*args) return wrapper return decorator @use_logging(level=\"warn\") def foo(name='foo'): print(\"i am %s\" % name) foo() 上面的 use_logging 是允许带参数的装饰器。它实际上是对原有装饰器的一个函数封装，并返回一个装饰器。我们可以将它理解为一个含有参数的闭包。当我 们使用@use_logging(level=&quot;warn&quot;)调用的时候，Python 能够发现这一层的封装，并把参数传递到装饰器的环境中。 @use_logging(level=\"warn\")`等价于`@decorator 类装饰器没错，装饰器不仅可以是函数，还可以是类，相比函数装饰器，类装饰器具有灵活度大、高内聚、封装性等优点。使用类装饰器主要依靠类的__call__方法，当使用 @ 形式将装饰器附加到函数上时，就会调用此方法。 class Foo(object): def __init__(self, func): self._func = func def __call__(self): print ('class decorator runing') self._func() print ('class decorator ending') @Foo def bar(): print ('bar') bar() functools.wraps使用装饰器极大地复用了代码，但是他有一个缺点就是原函数的元信息不见了，比如函数的docstring、__name__、参数列表，先看例子： # 装饰器 def logged(func): def with_logging(*args, **kwargs): print func.__name__ # 输出 'with_logging' print func.__doc__ # 输出 None return func(*args, **kwargs) return with_logging # 函数 @logged def f(x): \"\"\"does some math\"\"\" return x + x * x logged(f) 不难发现，函数 f 被with_logging取代了，当然它的docstring，__name__就是变成了with_logging函数的信息了。好在我们有functools.wraps，wraps本身也是一个装饰器，它能把原函数的元信息拷贝到装饰器里面的 func 函数中，这使得装饰器里面的 func 函数也有和原函数 foo 一样的元信息了。 from functools import wraps def logged(func): @wraps(func) def with_logging(*args, **kwargs): print func.__name__ # 输出 'f' print func.__doc__ # 输出 'does some math' return func(*args, **kwargs) return with_logging @logged def f(x): \"\"\"does some math\"\"\" return x + x * x 装饰器顺序一个函数还可以同时定义多个装饰器，比如： @a @b @c def f (): pass 它的执行顺序是从里到外，最先调用最里层的装饰器，最后调用最外层的装饰器，它等效于 f = a(b(c(f))) 补充*与**区别在Python的函数定义中使用args和**kwargs可传递可变参数。args用作传递非命名键值可变长参数列表（位置参数），**kwargs用作传递键值可变长参数列表。在函数调用的时候也有解构的使用 def test_var_args(farg, *args): print \"formal arg:\", farg for arg in args: print \"another arg:\", arg test_var_args(1, \"two\", 3) ''' formal arg: 1 another arg: two another arg: 3 ''' def test_var_kwargs(farg, **kwargs): print \"formal arg:\", farg for key in kwargs: print \"another keyword arg: %s: %s\" % (key, kwargs[key]) test_var_kwargs(farg=1, myarg2=\"two\", myarg3=3) ''' Required argument: 1 Optional argument (*args): 2 Optional argument (*args): 3 Optional argument (*args): 4 Optional argument k2 (*kwargs): 6 Optional argument k1 (*kwargs): 5 ''' def test_var_args_call(arg1, arg2, arg3): print \"arg1:\", arg1 print \"arg2:\", arg2 print \"arg3:\", arg3 args = (\"two\", 3) test_var_args_call(1, *args) def test_var_args_call(arg1, arg2, arg3): print \"arg1:\", arg1 print \"arg2:\", arg2 print \"arg3:\", arg3 kwargs = &#123;\"arg3\": 3, \"arg2\": \"two\"&#125; test_var_args_call(1, **kwargs) 参考 https://foofish.net/python-decorator.html https://www.biaodianfu.com/python-args-kwargs.html https://my.oschina.net/leejun2005/blog/477614 例子介绍的很详细","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"}]},{"title":"python-字符串格式","date":"2019-07-31T02:59:16.000Z","path":"posts/undefined.html","text":"格式化操作符（%）“%”是Python风格的字符串格式化操作符，非常类似C语言里的printf()函数的字符串格式化（C语言中也是使用%）。 下面整理了一下Python中字符串格式化符合： 格式化符号 说明 %c 转换成字符（ASCII 码值，或者长度为一的字符串） %r 优先用repr()函数进行字符串转换 %s 优先用str()函数进行字符串转换 %d / %i 转成有符号十进制数 %u 转成无符号十进制数 %o 转成无符号八进制数 %x / %X 转成无符号十六进制数（x / X 代表转换后的十六进制字符的大小写） %e / %E 转成科学计数法（e / E控制输出e / E） %f / %F 转成浮点数（小数部分自然截断） %g / %G %e和%f / %E和%F 的简写 %% 输出% （格式化字符串里面包括百分号，那么必须使用%%） 这里列出的格式化符合都比较简单，唯一想要强调一下的就是”%s”和”%r”的差别。 看个简单的代码： string = \"Hello\\tWill\\n\" print(\"%s\" %string) print(\"%r\" %string) ''' Hello Will 'Hello\\tWill\\n' ''' 补充： Python打印值的时候会保持该值在Python代码中的状态，不是用户所希望看到的状态。而使用print打印值则不一样，print打印出来的值是用户所希望看到的状态。 str和repr的区别： str 把值转换为合理形式的字符串，给用户看的。str实际上类似于int，long，是一种类型。 print str(\"Hello, world!\") # Hello, world! print str(1000L) # 1000 str(\"Hello, world!\") # 'Hello, world!' # 字符串转换之后仍然是字符串 str(1000L) # '1000' repr() 创建一个字符串，以合法python表达式的形式来表示值。repr()是一个函数。 print repr(\"Hello, world!\") # 'Hello, world!' print repr(1000L) # 1000L repr(\"Hello, world!\") # \"'Hello, world!'\" repr(1000L) # '1000L' 格式化操作辅助符通过”%”可以进行字符串格式化，但是”%”经常会结合下面的辅助符一起使用。 辅助符号 说明 ***** 定义宽度或者小数点精度 - 用做左对齐 + 在正数前面显示加号(+) # 在八进制数前面显示零(0)，在十六进制前面显示”0x”或者”0X”（取决于用的是”x”还是”X”） 0 显示的数字前面填充”0”而不是默认的空格 (var) 映射变量（通常用来处理字段类型的参数） m.n m 是显示的最小总宽度，n 是小数点后的位数（如果可用的话） num = 100 print(\"%d to hex is %x\" %(num, num)) print(\"%d to hex is %X\" %(num, num)) print(\"%d to hex is %#x\" %(num, num)) print(\"%d to hex is %#X\" %(num, num)) # 浮点数 f = 3.1415926 print(\"value of f is: %.4f\" %f) # 指定宽度和对齐 students = [&#123;\"name\":\"Wilber\", \"age\":27&#125;, &#123;\"name\":\"Will\", \"age\":28&#125;, &#123;\"name\":\"June\", \"age\":27&#125;] print(\"name: %10s, age: %10d\" %(students[0][\"name\"], students[0][\"age\"])) print(\"name: %-10s, age: %-10d\" %(students[1][\"name\"], students[1][\"age\"])) print(\"name: %*s, age: %0*d\" %(10, students[2][\"name\"], 10, students[2][\"age\"])) # dict参数 for student in students: print(\"%(name)s is %(age)d years old\" %student) ''' 100 to hex is 64 100 to hex is 64 100 to hex is 0x64 100 to hex is 0X64 value of f is: 3.1416 name: Wilber, age: 27 name: Will , age: 28 name: June, age: 0000000027 Wilber is 27 years old Will is 28 years old June is 27 years old ''' 字符串模板其实，在Python中进行字符串的格式化，除了格式化操作符，还可以使用string模块中的字符串模板（Template）对象。下面就主要看看Template对象的substitute()方法： from string import Template sTemp = Template('Hi ,$name,$$ ') print(sTemp.substitute(name='wumu')) ''' Hi ,wumu,$ ''' format# 位置参数 print(\"&#123;&#125; is &#123;&#125; years old\".format(\"Wilber\", 28)) print(\"Hi, &#123;0&#125;! &#123;0&#125; is &#123;1&#125; years old\".format(\"Wilber\", 28)) # 关键字参数 print(\"&#123;name&#125; is &#123;age&#125; years old\".format(name = \"Wilber\", age = 28)) # 下标参数 li = [\"Wilber\", 28] print(\"&#123;0[0]&#125; is &#123;0[1]&#125; years old\".format(li)) # 填充与对齐 # ^、&lt;、>分别是居中、左对齐、右对齐，后面带宽度 # :号后面带填充的字符，只能是一个字符，不指定的话默认是用空格填充 print('&#123;:>8&#125;'.format('3.14')) print('&#123;:&lt;8&#125;'.format('3.14')) print('&#123;:^8&#125;'.format('3.14')) print('&#123;:0>8&#125;'.format('3.14')) print('&#123;:a>8&#125;'.format('3.14')) # 浮点数精度 print('&#123;:.4f&#125;'.format(3.1415926)) print('&#123;:0>10.4f&#125;'.format(3.1415926)) # 进制 # b、d、o、x分别是二进制、十进制、八进制、十六进制 print('&#123;:b&#125;'.format(11)) print('&#123;:d&#125;'.format(11)) print('&#123;:o&#125;'.format(11)) print('&#123;:x&#125;'.format(11)) print('&#123;:#x&#125;'.format(11)) print('&#123;:#X&#125;'.format(11)) # 千位分隔符 print('&#123;:,&#125;'.format(15700000000)) ''' Wilber is 28 years old Hi, Wilber! Wilber is 28 years old Wilber is 28 years old Wilber is 28 years old 3.14 3.14 3.14 00003.14 aaaa3.14 3.1416 00003.1416 1011 11 13 b 0xb 0XB 15,700,000,000 ''' 参考 https://www.cnblogs.com/wilber2013/p/4641616.html","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"}]},{"title":"mysql自带的数据库","date":"2019-07-27T10:06:05.000Z","path":"posts/undefined.html","text":"information_schema SCHEMATA表：提供了当前mysql实例中所有数据库的信息。是show databases的结果取之此表。 TABLES表：提供了关于数据库中的表的信息（包括视图）。详细表述了某个表属于哪个schema，表类型，表引擎，创建时间等信息。是show tables from schemaname的 结果取之此表。 COLUMNS表：提供了表中的列信息。详细表述了某张表的所有列以及每个列的信息。是show columns from schemaname.tablename的结果取之此表。 STATISTICS表：提供了关于表索引的信息。是show index from schemaname.tablename的结果取之此表。 USER_PRIVILEGES（用户权限）表：给出了关于全程权限的信息。该信息源自mysql.user授权表。是非标准表。 SCHEMA_PRIVILEGES（方案权限）表：给出了关于方案（数据库）权限的信息。该信息来自mysql.db授权表。是非标准表。 TABLE_PRIVILEGES（表权限）表：给出了关于表权限的信息。该信息源自mysql.tables_priv授权表。是非标准表。 COLUMN_PRIVILEGES（列权限）表：给出了关于列权限的信息。该信息源自mysql.columns_priv授权表。是非标准表。 CHARACTER_SETS（字符集）表：提供了mysql实例可用字符集的信息。是SHOW CHARACTER SET结果集取之此表。 COLLATIONS表：提供了关于各字符集的对照信息。 COLLATION_CHARACTER_SET_APPLICABILITY表：指明了可用于校对的字符集。这些列等效于SHOW COLLATION的前两个显示字段。 TABLE_CONSTRAINTS表：描述了存在约束的表。以及表的约束类型。 KEY_COLUMN_USAGE表：描述了具有约束的键列。 ROUTINES表：提供了关于存储子程序（存储程序和函数）的信息。此时，ROUTINES表不包含自定义函数（UDF）。名为“mysql.proc name”的列指明了对应于 INFORMATION_SCHEMA.ROUTINES表的mysql.proc表列。 VIEWS表：给出了关于数据库中的视图的信息。需要有show views权限，否则无法查看视图信息。 TRIGGERS表：提供了关于触发程序的信息。必须有super权限才能查看该表。 mysqlperformance_schema 需要设置参数： performance_schema 才可以启动该功能 按照相关的标准对进行的事件统计表, 表也是只读的，只能turcate events_waits_summary_by_instance events_waits_summary_by_thread_by_event_name events_waits_summary_global_by_event_name file_summary_by_event_name file_summary_by_instance setup_consumers 描述各种事件 setup_instruments 描述这个数据库下的表名以及是否开启监控。 setup_timers 描述 监控选项已经采样频率的时间间隔 events_waits_current 记录当前正在发生的等待事件，这个表是只读的表，不能update ，delete ，但是可以truncate 性能历史表 ：events_waits_history 只保留每个线程（thread） 的最近的10个事件 性能历史表 ：events_waits_history_long 记录最近的10000个事件 标准的先进先出（FIFO) 这俩表也是只读表，只能truncate sakila 这是一个MySQL的一个样本数据库，里边都是一些例子表。","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"}]},{"title":"mysql修改字符集","date":"2019-07-27T08:55:17.000Z","path":"posts/undefined.html","text":"概念 字符集（character set）：定义了字符以及字符的编码。 字符序（collation）：定义了字符的比较规则。 Mysql字符集 一个字符集对应至少一种字符序（一般是1对多）。 两个不同的字符集不能有相同的字符序。 每个字符集都有默认的字符序。 -- 第一种方式 SHOW CHARACTER SET; -- 第二种方式 use information_schema; select * from CHARACTER_SETS; -- 例子 SHOW CHARACTER SET WHERE Charset&#x3D;&quot;utf8&quot;; SHOW CHARACTER SET LIKE &quot;utf8%&quot;; Mysql字符序-- 第一种方式 SHOW COLLATION WHERE Charset &#x3D; &#39;utf8&#39;; -- 第二种方式 USE information_schema; SELECT * FROM COLLATIONS WHERE CHARACTER_SET_NAME&#x3D;&quot;utf8&quot;; 命名规范字符序的命名，以其对应的字符集作为前缀，如下所示。比如字符序utf8_general_ci，标明它是字符集utf8的字符序。 更多规则可以参考 官方文档。 [information_schema]&gt; SELECT CHARACTER_SET_NAME, COLLATION_NAME FROM COLLATIONS WHERE CHARACTER_SET_NAME&#x3D;&quot;utf8&quot; limit 2; 设置修改 修改数据库字符集 ALTER DATABASE db_name DEFAULT CHARACTER SET character_name [COLLATE ...]; 把表默认的字符集和所有字符列（CHAR,VARCHAR,TEXT）改为新的字符集： ALTER TABLE tbl_name CONVERT TO CHARACTER SET character_name [COLLATE ...] 如：ALTER TABLE logtest CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci; 修改表的默认字符集 ALTER TABLE tbl_name DEFAULT CHARACTER SET character_name [COLLATE...]; 如：ALTER TABLE logtest DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 修改字段的字符集 ALTER TABLE tbl_name CHANGE c_name c_name CHARACTER SET character_name [COLLATE ...]; 如：ALTER TABLE logtest CHANGE title title VARCHAR(100) CHARACTER SET utf8 COLLATE utf8_general_ci; 查看数据库编码 SHOW CREATE DATABASE db_name; 查看表编码 SHOW CREATE TABLE tbl_name; 查看字段编码 SHOW FULL COLUMNS FROM tbl_name; 查看系统的编码字符 SHOW VARIABLES WHERE Variable_name LIKE &#39;character\\_set\\_%&#39; OR Variable_name LIKE &#39;collation%&#39;; MySQL字符集设置 系统变量： – character_set_server：默认的内部操作字符集 – character_set_client：客户端来源数据使用的字符集 – character_set_connection：连接层字符集 – character_set_results：查询结果字符集 – character_set_database：当前选中数据库的默认字符集 – character_set_system：系统元数据(字段名等)字符集 – 还有以collation_开头的同上面对应的变量，用来描述字符序。 用introducer指定文本字符串的字符集： – 格式为：[_charset] ‘string’ [COLLATE collation] – 例如： • SELECT _latin1 ‘string’; • SELECT _utf8 ‘你好’ COLLATE utf8_general_ci; –- 由introducer修饰的文本字符串在请求过程中不经过多余的转码，直接转换为内部字符集处理。 MySQL中的字符集转换过程 MySQL Server收到请求时将请求数据从character_set_client转换为character_set_connection； 进行内部操作前将请求数据从character_set_connection转换为内部操作字符集，其确定方法如下： • 使用每个数据字段的CHARACTER SET设定值； • 若上述值不存在，则使用对应数据表的DEFAULT CHARACTER SET设定值(MySQL扩展，非SQL标准)； • 若上述值不存在，则使用对应数据库的DEFAULT CHARACTER SET设定值； • 若上述值不存在，则使用character_set_server设定值。 参考 https://www.cnblogs.com/chyingp/p/mysql-character-set-collation.html https://www.cnblogs.com/qiumingcheng/p/10336170.html","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"}]},{"title":"管理Odoo服务器实例","date":"2019-06-18T06:02:38.000Z","path":"posts/undefined.html","text":"全书完整目录请见：Odoo 12开发者指南（Cookbook）第三版 本章中，我们将讲解如下内容： 配置插件路径 更新插件模块列表 标准化你的实例目录布局 安装并升级本地插件模块 对插件应用修改 应用及尝试建议的拉取请求 引言在第一章 安装Odoo开发环境中，我们看了如何使用与编辑器一同发布的标准核心插件来设置 Odoo 实例。本章集中讲解为 Odoo 实例添加非核心插件。Odoo中，你可以从多个目录中加载插件。此外，推荐你将第三方插件（如OCA模块）或你自定义的插件放在一个单独的文件夹中，这样可以避免与 Odoo 核心模块产生冲突。甚至Odoo 企业版也是一种类型的插件目录，你需要像普通插件目录一样加载它。 ℹ️有关用词 – 插件(add-on) vs. 模块(module) 本书中，我们使用插件或插件模块来指代 Odoo 所预期安装的 Python 包。用户界面常使用应用（app）或模块的表达 ，但我们更愿意保留模块一词来表示Python模块或包，它们不一定是 Odoo 插件，而应用（app）来表示适当定义为应用的插件模块，表示它不是Odoo主菜单中的入口。 配置插件路径通过addons_path参数的配置，你可以在 Odoo 中加载自己的插件模块。在Odoo初始化一个新数据库时，它会搜索在addons_path配置参数中给定的这些目录。addons_path会在这些目录中搜索潜在的插件模块。addons_path中所列出的目录预期应包含子目录，每个子目录是一个插件模块。在数据库初始化完成后，你将能够安装这些目录中所给出的模块。 准备工作这一部分假定你已经准备好了实例并生成了配置文件，如在第一章 安装Odoo开发环境中在一个文件中存储实例配置一节所描述。Odoo的源码存放在/odoo-dev/odoo中，而配置文件存放在/odoo-dev/myinstance.cfg中。 如何配置…按如下步骤在实例的addons_path中添加~/odoo-dev/local-addons目录： 编辑你的实例的配置文件，即 ~/odoo-dev/my-instance.cfg。 定位到以addons_path =开头一行，默认，你会看到如下内容： addons_path &#x3D; ~&#x2F;odoo-dev&#x2F;odoo&#x2F;odoo&#x2F;addons,~&#x2F;odoo-dev&#x2F;odoo&#x2F;add-ons 译者注： 当前默认生成的配置文件中为绝对路径，且仅包含xxx/odoo/addons 修改该行，添加一个逗号（英文半角），并接你想想要添加为addons_的目录名称，如以下代码所示： addons_path &#x3D; ~&#x2F;odoo-dev&#x2F;odoo&#x2F;odoo&#x2F;addons,~&#x2F;odoo-dev&#x2F;odoo&#x2F;addons,~&#x2F;odoo-dev&#x2F;local-addons 重启你的实例 $ ~&#x2F;odoo-dev&#x2F;odoo&#x2F;odoo-bin -c my-instance.cfg 运行原理…在重启 Odoo 时，会读取配置文件。addons_path变量的值应为一个逗号分隔的目录列表。可接受相对路径，但它们是相对于当前工作目录的，因此应在配置文件中尽量避免。 至此，~/odoo-dev/local-addons中包含的新插件尚不在该实例的可用模块列表中。为此，你需要执行一个额外的操作，在下一部分更新插件模块列表中会进行讲解。 扩展知识…在第一次调用 odoo-bin脚本来初始化新数据库时，你可以传递一个带逗号分隔目录列表的–addons-path命令行参数。这会以所提供插件路径中所找到的所有插件来初始化可用插件模块列表。这么做时，你要显式地包含基础插件目录（odoo/odoo/addons）以及核心插件目录（odoo/addons）。 与前面稍有不同的是本地插件目录不能为空（译者注：请先阅读下面的小贴士），它必须要至少包含一个子目录，并包含插件模块的最小化结构。在第四章 创建Odoo插件模块中，我们会来看如何编写你自己的模块。同时，这里有一个生成内容来满足Odoo要求的快捷版黑科技： $ mkdir -p ~&#x2F;odoo-dev&#x2F;local-addons&#x2F;dummy$ touch ~&#x2F;odoo-dev&#x2F;local-addons&#x2F;dummy&#x2F;__init__.py$ echo &#39;&#123;&quot;name&quot;: &quot;dummy&quot;, &quot;installable&quot;: False&#125;&#39; &gt; \\~&#x2F;odoo-dev&#x2F;local-addons&#x2F;dummy&#x2F;__manifest__.py 你可以使用–save选项来保存配置文件的路径： $ odoo&#x2F;odoo-bin -d mydatabase \\--add-ons-path&#x3D;&quot;odoo&#x2F;odoo&#x2F;addons,odoo&#x2F;addons,~&#x2F;odoo-dev&#x2F;local-addons&quot; \\--save -c ~&#x2F;odoo-dev&#x2F;my-instance.cfg --stop-after-init 本例中，使用相对路径不会有问题，因为它们会在配置文件中转化为绝对路径。 小贴士：因为Odoo仅当从命令行中设置路径时在插件路径的目录中查看插件，而不是在从配置文件中加载路径的时候，dummy已不再必要。因此，你可以删除它（或保留到你确定不需要新建一个配置文件时）。 更新插件模块列表我们在前面的部分已经说到，在向插件路径添加目录时，仅仅重启Odoo服务是不足以安装其中一个新插件模块的。Odoo还需要有一个指定动作来扫描路径并更新可用插件模块的列表。 准备工作启动你的实例并使用管理员账号连接它。然后，激活开发者模式（如果你不知道如何激活开发者模式，请参见第一章 安装Odoo开发环境）。 如何更新…要更新你实例中的可用插件模块列表，你需要执行如下步骤： 打开Apps菜单 点击Update Apps List： 在弹出对话框中，点击Update按钮： 在更新的最后，你可以点击Apps入口来查看已更新的可用插件模块列表。你将需要删除Apps搜索框中的默认过滤器来查看所有模块。 运行原理…在点击了Update按钮之后，Odoo会读取插件路径配置变量。对于列表中的每一个目录，它会查看包含保存在插件模块目录中名为manifest.py的插件声明文件的直接子目录。Odoo读取声明内容，并预期查找其中的Python字典。除非声明内容中包含一个键installable的值为False，插件模块的元数据就会存储在数据库中。如果模块已存在，则更新相关信息。否则，会创建一条新记录。如果此前可用的插件模块未找到，则从列表中删除该记录。 ℹ️仅在初始化数据库后添加了新的插件路径时才需要更新应用列表。如果你在初始化数据库之前在配置文件中添加了新插件路径，那么就无需手动更新模块列表。 标准化你的实例目录布局我们推荐你在开发和生产环境都使用相似的目录布局。这一标准化会在你要执行运维时体现出用处，它也会缓解你日常工作的压力。 这一部分创建将相似生命周期或相似用途的文件分组放在标准化子目录中的目录结构。请自由按照自己的需求来调整这一结构，但请确保你将这一结构在某处进行记录存档。 如何标准化…创建所推荐实例布局，你需要执行如下步骤： 译者注：读者也可直接使用 Alan 在 GitHub 上准备的安装脚本进行操作 为实例创建一个目录： $ mkdir ~&#x2F;odoo-dev&#x2F;projectname$ cd ~&#x2F;odoo-dev&#x2F;projectname 在名为env/的子目录中创建一个Python虚拟环境： $ virtualenv -p python3 env 创建一些子目录，如下： $ mkdir src local bin filestore logs 这些子目录的功能如下： src/：这包含Odoo本身的一个拷贝，以及一些第三方插件项目（我们在下一步中添加了Odoo源码） local/：这用于保存你针对具体实例的插件 bin/：这包含各类帮助可执行shell脚本 filestore/：这用于文件存储 logs/（可选）：这用于存储服务日志文件 克隆Odoo并安装所需依赖包（参见 第一章 安装Odoo开发环境 获取更多内容）： $ git clone https://github.com/odoo/odoo.git src/odoo $ env/bin/pip3 install -r src/odoo/requirements.txt 以bin/odoo保存如下shell脚本： ROOT=$(dirname $0)/.. PYTHON=$ROOT/env/bin/python3 ODOO=$ROOT/src/odoo/odoo-bin $PYTHON $ODOO -c $ROOT/projectname.cfg \"$@\" exit $? 让该脚本可执行： $ chmod +x bin&#x2F;odoo 创建一个空的本地模块dummy： $ mkdir -p local&#x2F;dummy $ touch local&#x2F;dummy&#x2F;__init__.py $ echo &#39;&#123;&quot;name&quot;: &quot;dummy&quot;, &quot;installable&quot;: False&#125;&#39; &gt;\\local&#x2F;dummy&#x2F;__manifest__.py 为你的实例生成配置文件： $ bin&#x2F;odoo --stop-after-init --save \\ --addons-path src&#x2F;odoo&#x2F;odoo&#x2F;addons,src&#x2F;odoo&#x2F;addons,local \\ --data-dir filestore 添加一个.gitignore文件，用于告诉GitHub排除这些给定目录，这样Git在提交代码时就会忽略掉这些目录，例如 filestore/, env/, logs/和src/： # dotfiles, with exceptions: .* !.gitignore # python compiled files *.py[co] # emacs backup files *~ # not tracked subdirectories /env/ /src/ /filestore/ /logs/ 为这个实例创建一个Git仓库并将已添加的文件添加到Git中： $ git init $ git add . $ git commit -m \"initial version of projectname\" 运行原理…我们生成了一个有明确标签目录和独立角色的干净的目录结构。我使用了不同的目录来存储如下内容： 由其它人所维护的代码（src/中） 本地相关的具体代码 实例的文件存储 通过为每个项目建一个virtualenv环境，我们可以确保该项目的依赖文件不会与其它项目的依赖产生冲突，这些项目你可能运行着不同的Odoo版本或使用了不同的第三方插件模块，这将需要不同版本的Python依赖。这当然也会带来一部分磁盘空间的开销。 以类似的方式，通过为我们不同的项目使用不同的Odoo拷贝以及第三方插件模块，我们可以让每个项目单独的进行推进并仅在需要时在这些实例上安装更新，因此也减少了引入回退的风险。 bin/odoo允许我们不用记住各个路径或激活虚拟环境就可以运行服务。这还为我们设置了配置文件。你可以在其中添加其它脚本来协助你的日常工作。例如，你可以添加一个脚本来检查运行实例所需的第三方项目。 有关配置文件，我们仅展示了这里需要设置的最小化选项，但很明显你可以设置更多，例如数据库名、数据库过滤器或项目所监听的端口。有关这一话题的更多信息，请参见第一章 安装Odoo开发环境。 最后，通过在Git仓库中管理所有这些，在不同的电脑上复制这一设置及在团队中分享开发内容变得相当容易。 小贴士：加速贴士 要加速项目的创建，你可以创建一个包含空结构的模板仓库，并为每个项目复制（fork）该仓库。这会省却你重新输入bin/odoo脚本、.gitignore及其它所需模板文件（持续集成配置、README.md、ChangeLog等等）所花费的时间。 参见内容如果你喜欢这种方法，我们建议你尝试第三章 服务器部署中的使用 Docker 运行 Odoo 一部分的内容。 扩展知识…复杂模块的开发要求有各类配置选项，在想要尝试任何配置选项时都会要更新配置文件。更新配置常常是一件头痛的事，避免它的一种方式是通过命令行传递所有配置选项，如下： 手动激活虚拟环境： $ source env/bin/activate 进行Odoo源代码目录： $ cd src/odoo 运行服务： ./odoo-bin --addons-path=addons,../../local -d test-12 -i account,sale,purchase --log-level=debug 第三步中，我们直接通过命令行传递了一些参数。第一个是–addons-path，它加载Odoo的核心插件目录addons，以及你自己的插件目录local，在其中你可以放自己的插件模块。选项-d会使用test-12数据库或者在该数据库不存在时新建一个数据库。选项-i 会安装会计、销售和采购模块。接着，我们传递了log-level选项来将日志级别提升为debug，这样日志中会显示更多的信息。 ℹ️通过使用命令行，你可以快速地修改配置选项。你也可以在Terminal中查看实时日志。所有可用选项可参见第一章 安装Odoo开发环境，或使用-help命令来查看所有的选项列表及各个选项的描述。 安装并升级本地插件模块Odoo 功能的核心来自于它的插件模块。Odoo自带的插件是你所拥有的财富，同时你也可以在应用商店下载一些插件模块或者自己写。 这一部分中，我们将展示如何通过网页界面及命令行来安装并升级插件模块。 对这些操作使用命令行的主要好处包含可以同时作用于一个以上的插件以及在安装或升级的过程中可以清晰地浏览到服务端日志，对于开发模式或编写脚本安装实例时都非常有用。 准备工作确保你有一个运行中的 Odoo 实例，且数据库已初始化、插件路径已进行恰当地设置。在这一部分中，我们将安装/升级一些插件模块。 如何安装升级…安装或升级插件有两种方法-可以使用网页界面或命令行。 通过网页界面可按照如下步骤来使用网页界面安装新的插件模块到数据库中： 使用管理员账户连接实例并打开Apps菜单 使用搜索框来定位你想要安装的插件。这里有一些帮助你完成该任务的操作指南： 激活Not Installed过滤器 如果你要查找一个具体的功能插件而不是广泛的功能插件，删除Apps过滤器 在搜索框中输入模块名的一部分并使用它来作为模块过滤器 你会发现使用列表视图可以阅读到更多的信息 点击卡片中模块名下的Install按钮。 注意有些Odoo插件模块需要有外部Python依赖，如果你的系统中未安装该Python依赖，那么 Odoo 会中止安装并显示如下的对话框： 译者注：按正常安装不会出现一错误，需通过 pip uninstall pyldap 才能复现这一错误 修复这一问题，仅需在你的系统中安装相关的Python依赖即可。 要升级已安装到数据库的模块，使用如下步骤： 使用管理员账户连接到实例 打开Apps菜单 点击Apps: 使用搜索框来定位你所安装的插件。有如下的小贴士： 激活Installed过滤器 如果你要查找一个具体的功能插件而不是广泛的功能插件，删除Apps过滤器 在搜索框中输入部分插件模块的名称并按下 Enter 来使用它作为模块过滤器。例如，输入CRM并按下 Enter 来搜索CRM应用 你会发现使用列表视图可以阅读到更多的信息 点击卡片右上角的的三个点，然后点击Upgrade选项： 激活开发者模式来查看模块的技术名称。如果你不知道如何激活开发者模式，请参见第一章 安装Odoo开发环境： 在激活开发者模式之后，它会以红色显示模块的技术名称。如果你使用的是Odoo社区版，会看到一些带有Upgrade的附加应用。这些是Odoo企业版的应用，要想安装/使用它们，需要购买一个证书。 通过命令行要在你的数据库中安装新插件，可按照如下步骤： 查找插件的名称。这是包含manifest.py文件的目录名，不带前面的路径。 停止实例。如果你在操作生产数据库，请进行备份。 运行如下命令： odoo/odoo-bin -c instance.cfg -d dbname -i addon1,addon2 --stop-after-init 译者注： 请将addon1,addon2替换为你所要安装的插件名 小贴士：你可以省略掉-d dbname，因为这在配置文件中进行了设置。 重新启动实例 运行原理…插件模块的安装和升级是两个紧密关联的操作，但有一些重要的区别，在下面两部分中进行了强调： 插件安装在你安装插件时，Odoo以提供的名称检查它的可用插件列表中未安装插件。它还会检查该插件的依赖，并且如果有依赖的话，它会在安装插件前递归安装这些依赖。 单个模块的安装包含如下步骤： 如果存在，运行插件preinit钩子 从Python源代码中加载模型定义并在必要时更新数据库结构（参见第五章 应用模型了解更多信息） 加载插件的数据文件并在必要时更新数据库内容（参见第七章 模块数据了解更多信息） 如果实例中启用了演示数据则安装插件演示数据 如果存在，运行插件postinit钩子 运行对插件视图定义的验证 如果启用了演示数据并启用了测试，运行该插件的测试（参见第十八章 自动化测试用例了解更多信息） 在数据库中更新模块状态 从插件的翻译文件中更新数据库中的翻译（参见第十二章 国际化了解更多信息） ℹ️preinit和postinit钩子分别使用pre_init_hook和post_init_hook键名在manifest.py文件中定义。这些钩子用于在插件模块的安装之前及之后触发Python函数。参见第四章 创建Odoo插件模块了解更多有关 init 钩子的知识。 插件升级升级插件时，Odoo以给定的名称在可用的插件模块列表中检查已安装插件。它还会检查该插件的反向依赖（即依赖于所升级插件的那些插件）。如果存在，则也会对它们进行递归升级。 单个插件模块的升级过程包含如下步骤： 如果有的话，先运行插件模块的预迁移步骤（参见第七章 模块数据了解更多信息） 从Python源码中加载模型定义并在必要时更新数据库结构（参见第五章 应用模型了解更多信息） 加载插件的数据文件并在必要时更新数据库内容（参见第七章 模块数据了解更多信息） 如果实例中启用了演示数据更新插件演示数据 如果模块有任何迁移方法的话，先运行插件模块的后置迁移步骤（参见第七章 模块数据了解更多信息） 运行对插件视图定义的验证 如果启用了演示数据并启用了测试，运行该插件的测试（参见第十八章 自动化测试用例了解更多信息） 在数据库中更新模块状态 从插件的翻译文件中更新数据库中的翻译（参见第十二章 国际化了解更多信息） ℹ️注意更新未安装的插件模块什么也不会做。但是安装已安装的插件模块会重新安装该插件，这会通过一些包含数据的数据文件产生一些预期外的问题，这些文件可能应由用户进行更新而非在常规的模块升级处理时进行更新（参见第七章 模块数据中使用noupdate和forcecreate标记部分的内容）。通过用户界面不存在错误的风险，但通过命令行时则有可能发生。 扩展知识…要当心依赖的处理。假定有一个实例你想要安装sale、sale_stock和sale_specific插件，sale_specific依赖于sale_stock，而sale_stock依赖于sale。要安装这三者，你只需要安装sale_specific，因为它会递归安装sale_stock和sale这两个依赖。要升级这两者，你需要升级sale，因为这样会递归升级其反向依赖，sale_stock和sale_specific。 管理依赖另一个比较搞的地方是在你向已经有一个版本安装了的插件添加依赖的时候。我们继续通过前例来理解这一问题。想像一下你在sale_specific中添加了一个对stock_dropshipping的依赖。更新sale_specific插件不会自动安装新的依赖，也会要求安装sale_specific。在这种情况下，你会收到非常糟糕的错误消息，因为插件的Python代码没有成功的加载，而插件的数据和模型表则存在于数据库中。要解决这一问题，你需要停止该实例并手动安装新的依赖。 从GitHub安装插件模块GitHub是第三方插件的一个很好的来源。很多Odoo合作伙伴使用GitHub来分享他们内部维护的插件，而Odoo社区联盟（OCA）在GitHub上共同维护着几百个插件。在你开始编写自己的插件之前，确保查看是否已有可用的插件或者作为初始以继续扩展插件。 这一部分向你展示如何从GitHub上克隆OCA的partner-contact项目并让其中所包含的插件模块在我们实例中可用。 准备工作假设你想要改变你的实例中地址的处理方式，你的客户需要在Odoo两个字段（街道和街道2）之外的第三个字段来存储地址。你肯定是可以编写自己的插件来为res.partne添加一个字段的，但如果想要让地址在发票上以合适的格式显示，问题就要比看上去麻烦一些了。所幸，你邮件列表上的某个人告诉了你partner_address_street3插件，由OCA作为partner-contact项目的一部分进行维护。 本部分中所使用的路径反映了我们在标准化你的实例目录布局一节中所推荐的布局。 如何安装…按照如下步骤来安装partner_address_street3： 进入你的项目目录： $ cd ~/odoo-dev/my-odoo/src 在src/目录中克隆partner-contact项目的12.0分支： $ git clone --branch 12.0 \\https://github.com/OCA/partner-contact.git src/partner-contact 修改插件路径来包含该目录并更新你的实例中的插件列表（参见本章中的配置插件路径和更新插件模块列表一节）。instance.cfg中的addons_path一行应该是这样的： addons_path &#x3D; ~&#x2F;odoo-dev&#x2F;my-odoo&#x2F;src&#x2F;odoo&#x2F;odoo&#x2F;addons, \\~&#x2F;odoo-dev&#x2F;my-odoo&#x2F;src&#x2F;odoo&#x2F;addons, \\~&#x2F;odoo-dev&#x2F;my-odoo&#x2F;src&#x2F;, \\~&#x2F;odoo-dev&#x2F;local-addons 安装partner_address_street3插件（如果你不知道如何安装该模块，参见前面一节，安装并升级本地插件模块） 运行原理…所有 Odoo社区联盟的代码仓库都将他们自己的插件放在单独的目录中，这与Odoo对插件路径中目录的预期是相一致的。因此，只需复制某处的仓库并将其添加到插件路径中就够了。 扩展知识…有些维护者遵循不同的方法，每个插件模块一个仓库，放在仓库的根目录下。这种情况下，你需要创建一个新的目录，在这个目录中添加插件路径并克隆你所需的维护者的插件到该目录中。记住在每次添加一个新仓库拷贝时要更新插件模块列表。 对插件应用修改GitHub上可用的大部分插件需要进行修改并且不遵循Odoo对其稳定发行版所强制的规则。它们可能收到漏洞修复或改善，包含你提交的问题或功能请求，这些修改可能会引入数据库模式的修改或数据文件和视图中的更新。这一部分讲解如何安装升级后的版本。 准备工作假定你对partner_address_street3报告了一个问题并收到通知说该问题已在partner-contact项目12.0分支的最近一次修订中得以解决。这种情况下，你可以使用最新版本来更新你的实例。 如何修改…要对GitHub的插件进行源的变更，需执行如下步骤： 停止使用该插件的实例。 如果是生产实例请做一个备份（参见第一章 安装Odoo开发环境中管理Odoo服务端数据库一节）。 进入克隆了partner-contact的目录： $ cd ~/odoo-dev/my-odoo/src/partner-contact 为该项目创建一个本地标签，这样万一出现了崩溃你可以进行回退： $ git checkout 12.0$ git tag 12.0-before-update-$(date --iso) 获取源码的最新版本： $ git pull --ff-only 在你的数据库中更新partner_address_street3插件（参见安装并升级本地插件模块一节） 重启实例 运行原理…通常，插件模块的开发者有时会发布插件的最新版本。这一更新一般包含漏洞修复及新功能。这里，我们将获取一个插件的新版本并在我们的实例中更新它。 如果git pull –ff-only失败的话，你可以使用如下命令回退到前一个版本： $ git reset --hard 12.0-before-update-$(date --iso) 然后，你可以尝试git pull（不添加–ff-only），它会产生一个合并，但这表示你对插件做了本地修改。 扩展知识…如果更新这一步崩溃了，参见第一章 安装Odoo开发环境从源码更新Odoo一节获取恢复的操作指南。记住要总是在一个生产数据库的拷贝上先进行测试。 应用及尝试建议的拉取请求在GitHub的世界中，拉取请求（PR）是由开发者所提交的请求，这样项目维护人员可以添加一些新的开发。比如一个 PR 可能包含漏洞修复或新功能。这里请求在拉取到主分支之前会进行审核和测试。 这一部分讲解如何对你的 Odoo 项目应用一个PR来测试漏洞修复的改进。 准备工作在前一节中，假定你对partner_address_street3 报告了一个问题并收到一条通知在拉取请求中问题已修复，尚未合并到项目的12.0分支中。开发人员要求你验证PR #123中的修复状况。你需要使用这一分支更新一个测试实例。 你不应在生产数据库直接使用该分支，因此先创建一个带有生产数据库拷贝的测试环境（参见第一章 安装Odoo开发环境和第三章 服务器部署）。 如何操作…应用并测试一个插件的GitHub拉取请求，你需要执行如下步骤： 停止实例 进入partner-contact所被克隆的目录： $ cd ~/odoo-dev/my-odoo/src/partner-contact 为该项目创建一个本地标签，这样万一出现崩溃时你可以回退： $ git checkout 12.0$ git tag 12.0-before-update-$(date --iso 拉取pull请求的分支。这么做最容易的方式是使用PR编号，在开发者与你沟通时你应该可以看到。在本例中，这个拉取请求编号是123： $ git pull origin pull/123/head 在你的数据库中更新partner_address_street3插件模块并重启该实例（如果你不知道如何更新该模块的话请参见安装并升级本地插件模块一节） 测试该更新 – 尝试重现问题，或测试你想要的功能。 如果这不能运行，在GitHub的PR页面进行评论，说明你做了什么以及什么不能运行，这样开发者可以更新这个拉取请求。 如果它没有问题，也在PR页面说下；这是PR验证流程中非常重要的一部分；这会加速主分支中的合并。 运行原理…我们在使用一个GitHub功能，使用pull/nnnn/head分支名称来通过编号进行拉取请求的拉取，其中nnnn是PR的编号。Git pull命令合并远程分支到我们的分支，在我们基础代码中应用修改。在这之后，我们更新插件模块、对其测试并向作者报回修改是成功或是失败。 扩展知识…如果你想要同步测试它们，你可以针对相同仓库的不同拉取请求重复本节中的第4步。如果你对结果很满意，你可以创建一个分支来保留对应用了改变的结果的引用： $ git checkout -b 12.0-custom 使用一个不同的分支会帮助你记住你没有从GitHub使用该版本，而是一个自定义的版本。 ℹ️git branch命令可用于列出你仓库中的所有本地分支。 从这开始，如果你需要应用来自GitHub中12.0分支的最近一个审核版本，你需要不使用–ff-only来拉取它： $ git pull origin 12.0","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"},{"name":"odoo","slug":"odoo","permalink":"http://wumuwumu.github.io/tags/odoo/"}]},{"title":"__import__在python中的区别","date":"2019-06-01T07:49:16.000Z","path":"posts/undefined.html","text":"import作用：导入/引入一个python标准模块，其中包括.py文件、带有init.py文件的目录(自定义模块)。 import module_name[,module1,…] from module import *|child[,child1,…] 注意：多次重复使用import语句时，不会重新加载被指定的模块，只是把对该模块的内存地址给引用到本地变量环境。 实例： pythontab.py `#!/usr/bin/env python ``#encoding: utf-8 ``import` `os ``print` `'in pythontab'``,``id``(os)` test.py &#96;#!&#x2F;usr&#x2F;bin&#x2F;env python &#96;&#96;#encoding: utf-8 &#96;&#96;import&#96; &#96;pythontab &#96;&#96;#第一次会打印pythontab里面的语句 &#96;&#96;import&#96; &#96;os &#96;&#96;#再次导入os后，其内存地址和pythontab里面的是一样的，因此这里只是对os的本地引用 &#96;&#96;print&#96; &#96;&#39;in c&#39;&#96;&#96;,&#96;&#96;id&#96;&#96;(os) &#96;&#96;import&#96; &#96;pythontab &#96;&#96;#第二次不会打印pythontab里面的语句，因为没有重新加载&#96; reload作用：对已经加载的模块进行重新加载，一般用于原模块有变化等特殊情况，reload前该模块必须已经import过。 import os reload(os) 说明： reload会重新加载已加载的模块，但原来已经使用的实例还是会使用旧的模块，而新生产的实例会使用新的模块；reload后还是用原来的内存地址；不能支持from。。import。。格式的模块进行重新加载。 实例： pythontab.py `#!/usr/bin/env python ``#encoding: utf-8 ``import` `os ``print` `'in pythontab'``,``id``(os)` test.py `#!/usr/bin/env python ``#encoding: utf-8 ``import` `pythontab ``#第一次import会打印pythontab里面的语句 ``print` `id``(pythontab) ``#原来pythontab的内存地址 ``reload``(pythontab) ``#第二次reload还会打印pythontab里面的语句，因为有重新加载 ``print` `id``(pythontab) ``#reload后pythontab的内存地址，和原来一样` 扩展： 上面说了，在特殊情况的下才会使用reload函数；除了原来模块文件有修改外，还有哪些情况需要使用reload函数呢，这里举个例子。 `#!/usr/bin/env python ``#encoding: utf-8 ``import` `sys ``#引用sys模块进来，并不是进行sys的第一次加载 ``reload``(sys) ``#重新加载sys ``sys.setdefaultencoding(``'utf8'``) ``##调用setdefaultencoding函数` 上面的代码是正确的，再测试下面的代码 `#!/usr/bin/env python ``#encoding: utf-8 ``import` `sys ``sys.setdefaultencoding(``'utf8'``)` 上面的测试会失败，那么为什么要在调用setdefaultencoding时必须要先reload一次sys模块呢？因为这里的import语句其实并不是sys的第一次导入语句，也就是说这里其实可能是第二、三次进行sys模块的import，这里只是一个对sys的引用，只能reload才能进行重新加载；那么为什么要重新加载，而直接引用过来则不能调用该函数呢？因为setdefaultencoding函数在被系统调用后被删除了，所以通过import引用进来时其实已经没有了，所以必须reload一次sys模块，这样setdefaultencoding才会为可用，才能在代码里修改解释器当前的字符编码。试试下面的代码，同样会报错： `#!/usr/bin/env python ``#encoding: utf-8 ``import` `sys ``reload``(sys) ``sys.setdefaultencoding(``'utf8'``) ``del` `sys.setdefaultencoding ``##删除原来的setdefaultencoding函数 ``sys.setdefaultencoding(``'gb2312'``)` 那么到底是谁在之前就导入sys并且调用了setdefaultencoding函数呢？答案就在python安装目录的Lib文件夹下，有一个叫site.py的文件【python2.6】，在里面可以找到main() –&gt; setencoding()–&gt;sys.setdefaultencoding(encoding),因为这个site.py每次启动python解释器时会自动加载，所以main函数每次都会被执行，setdefaultencoding函数一出来就已经被删除了。 import作用： 同import语句同样的功能，但import__是一个函数，并且只接收字符串作为参数，所以它的作用就可想而知了。其实import语句就是调用这个函数进行导入工作的，import sys &lt;==&gt;sys = __import(‘sys’) 使用： import(module_name[, globals[, locals[, fromlist]]]) #可选参数默认为globals(),locals(),[] import(‘os’) import(‘os’,globals(),locals(),[‘path’,’pip’]) #等价于from os import path, pip 说明： 通常在动态加载时可以使用到这个函数，比如你希望加载某个文件夹下的所用模块，但是其下的模块名称又会经常变化时，就可以使用这个函数动态加载所有模块了，最常见的场景就是插件功能的支持。 扩展： 既然可以通过字符串来动态导入模块，那么是否可以通过字符串动态重新加载模块吗？试试reload(‘os’)直接报错，是不是没有其他方式呢?虽然不能直接reload但是可以先unimport一个模块，然后再__import__来重新加载模块。现在看看unimport操作如何实现，在Python解释里可以通过globals(),locals(),vars(),dir()等函数查看到当前环境下加载的模块及其位置，但是这些都只能看不能删除，所以无法unimport；不过除此之外还有一个地方是专门存放模块的，这就是sys.modules，通过sys.modules可以查看所有的已加载并且成功的模块，而且比globals要多，说明默认会加载一些额外的模块，接下来就是unimport了。 `#!/usr/bin/env python ``#encoding: utf-8 ``import` `sys ``__import__``(``'a'``) ``#第一次导入会打印消息 ``del` `sys.modules[``'a'``] ``#unimport ``__import__``(``'a'``) ``#再次导入还是会打印消息，因为已经unimport一次了 ``__import__``(``'a'``) ``#这次就不会打印消息了`","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"}]},{"title":"redis分布式锁","date":"2019-04-11T09:55:56.000Z","path":"posts/undefined.html","text":"单机Redis实现分布式锁获取锁获取锁的过程很简单，客户端向Redis发送命令： SET resource_name my_random_value NX PX 30000 复制代码 my_random_value是由客户端生成的一个随机字符串，它要保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的。 NX表示只有当resource_name对应的key值不存在的时候才能SET成功。这保证了只有第一个请求的客户端才能获得锁，而其它客户端在锁被释放之前都无法获得锁。 PX 30000表示这个锁有一个30秒的自动过期时间。 释放锁if redis.call(&quot;get&quot;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then return redis.call(&quot;del&quot;,KEYS[1]) else return 0 end 复制代码 之前获取锁的时候生成的my_random_value 作为参数传到Lua脚本里面，作为：ARGV[1],而 resource_name作为KEYS[1]。Lua脚本可以保证操作的原子性。 关于单点Redis实现分布式锁的讨论网络上有文章说用如下命令获取锁: SETNX resource_name my_random_value EXPIRE resource_name 30 复制代码 由于这两个命令不是原子的。如果客户端在执行完SETNX后crash了，那么就没有机会执行EXPIRE了，导致它一直持有这个锁，其他的客户端就永远获取不到这个锁了。 为什么my_random_value 要设置成随机值? 保证了一个客户端释放的锁是自己持有的那个锁。如若不然，可能出现锁不安全的情况。 客户端1获取锁成功。 客户端1在某个操作上阻塞了很长时间。 过期时间到了，锁自动释放了。 客户端2获取到了对应同一个资源的锁。 客户端1从阻塞中恢复过来，释放掉了客户端2持有的锁。 复制代码 用 SETNX获取锁 网上大量文章说用如下命令获取锁： SETNX lock.foo &lt;current Unix time + lock timeout + 1&gt; 复制代码 原文在Redis对SETNX的官网说明，Redis官网文档建议用Set命令来代替，主要原因是SETNX不支持超时时间的设置。 redis.io/commands/se… Redis集群实现分布式锁上面的讨论中我们有一个非常重要的假设：Redis是单点的。如果Redis是集群模式，我们考虑如下场景: 客户端1从Master获取了锁。 Master宕机了，存储锁的key还没有来得及同步到Slave上。 Slave升级为Master。 客户端2从新的Master获取到了对应同一个资源的锁。 客户端1和客户端2同时持有了同一个资源的锁，锁不再具有安全性。 复制代码 就此问题，Redis作者antirez写了RedLock算法来解决这种问题。 RedLock获取锁 获取当前时间。 按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。 计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（&gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。 如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。 如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的单机Redis Lua脚本释放锁的方法）。 RedLock释放锁客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁的时候成功与否。 关于RedLock的问题讨论 如果有节点发生崩溃重启 假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列： 客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）。 节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。 节点C重启后，客户端2锁住了C, D, E，获取锁成功。 客户端1和客户端2同时获得了锁。 复制代码 为了应对这一问题，antirez又提出了延迟重启(delayed restarts)的概念。也就是说，一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间(lock validity time)。这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。 如果客户端长期阻塞导致锁过期 解释一下这个时序图，客户端1在获得锁之后发生了很长时间的GC pause，在此期间，它获得的锁过期了，而客户端2获得了锁。当客户端1从GC pause中恢复过来的时候，它不知道自己持有的锁已经过期了，它依然向共享资源（上图中是一个存储服务）发起了写数据请求，而这时锁实际上被客户端2持有，因此两个客户端的写请求就有可能冲突（锁的互斥作用失效了）。 如何解决这个问题呢?引入了fencing token的概念： 客户端1先获取到的锁，因此有一个较小的fencing token，等于33，而客户端2后获取到的锁，有一个较大的fencing token，等于34。客户端1从GC pause中恢复过来之后，依然是向存储服务发送访问请求，但是带了fencing token = 33。存储服务发现它之前已经处理过34的请求，所以会拒绝掉这次33的请求。这样就避免了冲突。 但是其实这已经超出了Redis实现分布式锁的范围，单纯用Redis没有命令来实现生成Token。 时钟跳跃问题 假设有5个Redis节点A, B, C, D, E。 客户端1从Redis节点A, B, C成功获取了锁（多数节点）。由于网络问题，与D和E通信失败。 节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。 客户端2从Redis节点C, D, E成功获取了同一个资源的锁（多数节点）。 客户端1和客户端2现在都认为自己持有了锁。 这个问题用Redis实现分布式锁暂时无解。而生产环境这种情况是存在的。 复制代码 结论 Redis并不能实现严格意义上的分布式锁。但是这并不意味着上面讨论的方案一无是处。如果你的应用场景为了效率(efficiency)，协调各个客户端避免做重复的工作，即使锁失效了，只是可能把某些操作多做一遍而已，不会产生其它的不良后果。但是如果你的应用场景是为了正确性(correctness)，那么用Redis实现分布式锁并不合适，会存在各种各样的问题，且解决起来就很复杂，为了正确性，需要使用zab、raft共识算法，或者使用带有事务的数据库来实现严格意义上的分布式锁。 参考资料 Distributed locks with Redis 基于Redis的分布式锁到底安全吗（上）？ - 铁蕾的个人博客 martin.kleppmann.com/2016/02/08/…","tags":[{"name":"redis","slug":"redis","permalink":"http://wumuwumu.github.io/tags/redis/"}]},{"title":"protobuf使用","date":"2019-04-10T02:31:04.000Z","path":"posts/undefined.html","text":"安装wget https:&#x2F;&#x2F;github.com&#x2F;protocolbuffers&#x2F;protobuf&#x2F;releases&#x2F;download&#x2F;v3.6.1&#x2F;protobuf-all-3.6.1.zip unzop protobuf-all-3.6.1.zip cd protobuf-all-3.6.1 .&#x2F;configure &amp;&amp; make &amp;&amp; make install 语法规则&#x2F;&#x2F; 声明版本，默认是proto2 syntax &#x3D; &quot;proto3&quot;; &#x2F;&#x2F; 声明包名 package tutorial option java_package &#x3D; &quot;com.example.tutorial&quot;; &#x2F;&#x2F; java类名 option java_outer_classname &#x3D; &quot;AddressBookProtos&quot;; message Person &#123; required string name &#x3D;1; required int32 id &#x3D; 2; optional string email &#x3D; 3; enum PhoneType &#123; MOBILE &#x3D; 0; HOME &#x3D; 1; WORK &#x3D; 2; &#125; message PhoneNumber &#123; required string number &#x3D; 1; optional PhoneType type &#x3D; 2[default &#x3D; HOME]; &#125; repeated PhoneNumber phones &#x3D; 4; &#125; message AddressBook &#123; repreated Person people &#x3D; 1; &#125; &#x2F;&#x2F; 保留字段，编程过程中某些功能没有想好，可以先把该tag 进行保留，以备以后使用。 message Foo &#123; reserved 2, 15, 9 to 11; reserved &quot;foo&quot;, &quot;bar&quot;; &#125; 编码 https://blog.csdn.net/zxhoo/article/details/53228303 方法 Standard Message Methods isInitialized(): checks if all the required fields have been set. toString(): returns a human-readable representation of the message, particularly useful for debugging. mergeFrom(Message other): (builder only) merges the contents of other into this message, overwriting singular scalar fields, merging composite fields, and concatenating repeated fields. clear(): (builder only) clears all the fields back to the empty state. Parsing and Serialization byte[] toByteArray();: serializes the message and returns a byte array containing its raw bytes. static Person parseFrom(byte[] data);: parses a message from the given byte array. void writeTo(OutputStream output);: serializes the message and writes it to an OutputStream. static Person parseFrom(InputStream input);: reads and parses a message from an InputStream. 编译注意 升级协议 you must not change the tag numbers of any existing fields. you must not add or delete any required fields. you may delete optional or repeated fields. you may add new optional or repeated fields but you must use fresh tag numbers (i.e. tag numbers that were never used in this protocol buffer, not even by deleted fields). protobuf对repeated压缩不够好，所以尽量在后面加上[packed = true]。 不要让protobuf对象成为全局变量或者类成员，因为其clear方法只会把占用的内存空间清零，而不会释放，使得进程空间越来越大，可参考《Protobuf使用不当导致的程序内存上涨问题》。 https://www.jianshu.com/p/27fdf44dd63b","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"go基本语法","date":"2019-04-10T02:29:55.000Z","path":"posts/undefined.html","text":"接口 duck typing了解 在程序设计中，鸭子类型（英语：duck typing）是动态类型的一种风格。在这种风格中，一个对象有效的语义，不是由继承自特定的类或实现特定的接口，而是由“当前方法和属性的集合”决定。 flagSync1. WaitGroupAdd() Done() Wait() 2. Context Regexp https://www.cnblogs.com/golove/p/3269099.html &#x2F;&#x2F; MatchString matched, err :&#x3D; regexp.MatchString(&quot;foo.*&quot;, &quot;seafood&quot;) fmt.Println(matched, err) matched, err &#x3D; regexp.MatchString(&quot;bar.*&quot;, &quot;seafood&quot;) fmt.Println(matched, err) &#x2F;&#x2F; false error parsing regexp: missing closing ): &#96;a(b&#96; matched, err &#x3D; regexp.MatchString(&quot;a(b&quot;, &quot;seafood&quot;) fmt.Println(matched, err) &#x2F;&#x2F; true &lt;nil&gt; matched, err &#x3D; regexp.MatchString(&#96;a\\(b&#96;, &quot;a(b&quot;) fmt.Println(matched, err) &#x2F;&#x2F; false error parsing regexp: missing closing ): &#96;a(b&#96; matched, err &#x3D; regexp.MatchString(&#96;a(b&#96;, &quot;a(b&quot;) fmt.Println(matched, err) &#x2F;&#x2F; true &lt;nil&gt; matched, err &#x3D; regexp.MatchString(&quot;a\\\\(b&quot;, &quot;a(b&quot;) fmt.Println(matched, err) &#x2F;&#x2F; 将所有特殊字符进行转义 fmt.Println(regexp.QuoteMeta(&quot;Escaping symbols like: .+*?()|[]&#123;&#125;^$&quot;)) &#x2F;&#x2F; ExpandString content :&#x3D; &#96; # comment line option1: value1 option2: value2 # another comment line option3: value3 &#96; &#x2F;&#x2F; Regex pattern captures &quot;key: value&quot; pair from the content. pattern :&#x3D; regexp.MustCompile(&#96;(?m)(?P&lt;key&gt;\\w+):\\s+(?P&lt;value&gt;\\w+)$&#96;) &#x2F;&#x2F; Template to convert &quot;key: value&quot; to &quot;key&#x3D;value&quot; by &#x2F;&#x2F; referencing the values captured by the regex pattern. template :&#x3D; &quot;$key&#x3D;$value\\n&quot; result :&#x3D; []byte&#123;&#125; &#x2F;&#x2F; For each match of the regex in the content. for _, submatches :&#x3D; range pattern.FindAllStringSubmatchIndex(content, -1) &#123; &#x2F;&#x2F; Apply the captured submatches to the template and append the output &#x2F;&#x2F; to the result. result &#x3D; pattern.ExpandString(result, template, content, submatches) &#125; fmt.Println(string(result)) &#x2F;&#x2F; findAllString re :&#x3D; regexp.MustCompile(&quot;a.&quot;) fmt.Println(re.FindAllString(&quot;paranormal&quot;, -1)) fmt.Println(re.FindAllString(&quot;paranormal&quot;, 2)) fmt.Println(re.FindAllString(&quot;graal&quot;, -1)) fmt.Println(re.FindAllString(&quot;none&quot;, -1)) &#x2F;&#x2F; FindAllStringSubmatch re :&#x3D; regexp.MustCompile(&quot;a(x*)b&quot;) fmt.Printf(&quot;%q\\n&quot;, re.FindAllStringSubmatch(&quot;-ab-&quot;, -1)) fmt.Printf(&quot;%q\\n&quot;, re.FindAllStringSubmatch(&quot;-axxb-&quot;, -1)) fmt.Printf(&quot;%q\\n&quot;, re.FindAllStringSubmatch(&quot;-ab-axb-&quot;, -1)) fmt.Printf(&quot;%q\\n&quot;, re.FindAllStringSubmatch(&quot;-axxb-ab-&quot;, -1)) &#x2F;&#x2F; findStringSubmatch，只查找第一个 re :&#x3D; regexp.MustCompile(&quot;a(x*)b(y|z)c&quot;) fmt.Printf(&quot;%q\\n&quot;, re.FindStringSubmatch(&quot;-axxxbyc-&quot;)) fmt.Printf(&quot;%q\\n&quot;, re.FindStringSubmatch(&quot;-abzc-&quot;))","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"makefile编写","date":"2019-04-10T02:27:53.000Z","path":"posts/undefined.html","text":"例子.PHONY: build clean test package package-deb ui api statics requirements ui-requirements serve update-vendor internal&#x2F;statics internal&#x2F;migrations static&#x2F;swagger&#x2F;api.swagger.json PKGS :&#x3D; $(shell go list .&#x2F;... | grep -v &#x2F;vendor |grep -v lora-app-server&#x2F;api | grep -v &#x2F;migrations | grep -v &#x2F;static | grep -v &#x2F;ui) VERSION :&#x3D; $(shell git describe --always |sed -e &quot;s&#x2F;^v&#x2F;&#x2F;&quot;) build: ui&#x2F;build internal&#x2F;statics internal&#x2F;migrations mkdir -p build go build $(GO_EXTRA_BUILD_ARGS) -ldflags &quot;-s -w -X main.version&#x3D;$(VERSION)&quot; -o build&#x2F;lora-app-server cmd&#x2F;lora-app-server&#x2F;main.go clean: @echo &quot;Cleaning up workspace&quot; @rm -rf build dist internal&#x2F;migrations internal&#x2F;static ui&#x2F;build static&#x2F;static @rm -f static&#x2F;index.html static&#x2F;icon.png static&#x2F;manifest.json static&#x2F;asset-manifest.json static&#x2F;service-worker.js @rm -rf static&#x2F;logo @rm -rf docs&#x2F;public @rm -rf dist test: internal&#x2F;statics internal&#x2F;migrations @echo &quot;Running tests&quot; @for pkg in $(PKGS) ; do \\ golint $$pkg ; \\ done @go vet $(PKGS) @go test -p 1 -v $(PKGS) documentation: @echo &quot;Building documentation&quot; @mkdir -p dist&#x2F;docs @cd docs &amp;&amp; hugo @cd docs&#x2F;public&#x2F; &amp;&amp; tar -pczf ..&#x2F;..&#x2F;dist&#x2F;lora-app-server-documentation.tar.gz . dist: ui&#x2F;build internal&#x2F;statics internal&#x2F;migrations @goreleaser build-snapshot: ui&#x2F;build internal&#x2F;statics internal&#x2F;migrations @goreleaser --snapshot package-deb: package @echo &quot;Building deb package&quot; @cd packaging &amp;&amp; TARGET&#x3D;deb .&#x2F;package.sh ui&#x2F;build: @echo &quot;Building ui&quot; @cd ui &amp;&amp; npm run build @mv ui&#x2F;build&#x2F;* static api: @echo &quot;Generating API code from .proto files&quot; @go generate api&#x2F;api.go internal&#x2F;statics internal&#x2F;migrations: static&#x2F;swagger&#x2F;api.swagger.json @echo &quot;Generating static files&quot; @go generate cmd&#x2F;lora-app-server&#x2F;main.go static&#x2F;swagger&#x2F;api.swagger.json: @echo &quot;Generating combined Swagger JSON&quot; @GOOS&#x3D;&quot;&quot; GOARCH&#x3D;&quot;&quot; go run api&#x2F;swagger&#x2F;main.go api&#x2F;swagger &gt; static&#x2F;swagger&#x2F;api.swagger.json @cp api&#x2F;swagger&#x2F;*.json static&#x2F;swagger # shortcuts for development requirements: echo &quot;Installing development tools&quot; go get -u github.com&#x2F;golang&#x2F;lint&#x2F;golint go get -u github.com&#x2F;grpc-ecosystem&#x2F;grpc-gateway&#x2F;protoc-gen-grpc-gateway go get -u github.com&#x2F;grpc-ecosystem&#x2F;grpc-gateway&#x2F;protoc-gen-swagger go get -u github.com&#x2F;golang&#x2F;protobuf&#x2F;protoc-gen-go go get -u github.com&#x2F;elazarl&#x2F;go-bindata-assetfs&#x2F;... go get -u github.com&#x2F;jteeuwen&#x2F;go-bindata&#x2F;... go get -u github.com&#x2F;kisielk&#x2F;errcheck go get -u github.com&#x2F;smartystreets&#x2F;goconvey go get -u golang.org&#x2F;x&#x2F;tools&#x2F;cmd&#x2F;stringer go get -u github.com&#x2F;golang&#x2F;dep&#x2F;cmd&#x2F;dep go get -u github.com&#x2F;goreleaser&#x2F;goreleaser dep ensure -v ui-requirements: @echo &quot;Installing UI requirements&quot; @cd ui &amp;&amp; npm install serve: build @echo &quot;Starting Lora App Server&quot; .&#x2F;build&#x2F;lora-app-server update-vendor: @echo &quot;Updating vendored packages&quot; @govendor update +external run-compose-test: docker-compose run --rm appserver make test 文件格式&lt;target&gt; : &lt;prerequisites&gt; [tab] &lt;commands&gt; target：执行的命令或者文件名。如果只是执行的命令这是伪指令，在大部分时候使用.PHONY声明伪指令，这样不仅仅提供效率，同时也避免和文件名冲突。 prerequisites：前置条件。 commands：需要执行的命令， 前面需要添加[tab]，如果想要换成其他的，使用.RECIPEPREFIX = ？换成你喜欢的。 执行命令的时候会打印出相关的命令内容，这个叫做回显，如果不想显示出来可以在命令前面添加@。 命令执行的时候，每行命令在不同一个shell中执行，如果想在同一个shell中执行，有下面几个办法。 将命令写在同一行 在命令后面添加\\，实现命令多行 使用.ONESHELL: 内置变量makefile可以通过=、:=、?=、+=给变量赋值，同时Make命令提供一系列内置变量，比如，((CC)指向当前使用的编译器，)(MAKE) 指向当前使用的Make工具。这主要是为了跨平台的兼容性，详细的内置变量清单见手册。 参考https://blog.csdn.net/u010230971/article/details/80335613 https://www.cnblogs.com/wang_yb/p/3990952.html http://www.ruanyifeng.com/blog/2015/02/make.html","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"mybatis-sessions","date":"2019-04-10T02:25:51.000Z","path":"posts/undefined.html","text":"SqlSessionFactorysqlSessionFactory是工厂类的接口，默认实现是DefaultSqlSessionFactory，通过sqlSessionFactoryBuilder创建，我们不具体讨论配置文件的具体解析，主要分析mybatis的运行流程。 SqlSessionFactory主要是用来创建SqlSession，SqlSession是线程不安全的，因此每次操作都要重新创建。 // 通过数据源创建SqlSession，是我们比较常用的一种方式 private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); //通过事务工厂来产生一个事务 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); //生成一个执行器(事务包含在执行器里) final Executor executor = configuration.newExecutor(tx, execType); //然后产生一个DefaultSqlSession return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; //如果打开事务出错，则关闭它 closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); &#125; finally &#123; //最后清空错误上下文 ErrorContext.instance().reset(); &#125; &#125; SqlSession SqlSession有两方式调用方法，第一种方式是通过命名空间调用，第二种方式是JavaBean调用，也就是通过我们常用的Mapper接口进行调用。现在Myabtis3我们基本使用第二种方式。 通过Mapper接口进行调用，核心是 获取Mapper接口，并通过动态代理，进行方法拦截。 SqlSession通过getMapper获取相应的Mapper接口。SqlSession的的数据库操作是调用Executor的相关方法。 在getMapper调用的时候，有几个核心的类 MapperProxyFactory:用于创建MapperProxyd的工厂方法 MapperProxy:动态代理的InvocationHandler的实现，实际中就是执行sql语句 MapperRegistry MapperMethood:调用SqlSession的方法","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"http://wumuwumu.github.io/tags/mybatis/"}]},{"title":"git基本操作","date":"2019-04-09T05:59:25.000Z","path":"posts/undefined.html","text":"简介在实际开发中，会使用git作为版本控制工具来完成团队协作。因此，对基本的git操作指令进行总结是十分有必要的，本文对一些术语或者理论基础，不重新码字，可以参考廖雪峰老师的博文，本文只对命令做归纳总结。 git的通用操作流程如下图（来源于网络） 主要涉及到四个关键点： 工作区：本地电脑存放项目文件的地方，比如learnGitProject文件夹； 暂存区（Index/Stage）：在使用git管理项目文件的时候，其本地的项目文件会多出一个.git的文件夹，将这个.git文件夹称之为版本库。其中.git文件夹中包含了两个部分，一个是暂存区（Index或者Stage）,顾名思义就是暂时存放文件的地方，通常使用add命令将工作区的文件添加到暂存区里； 本地仓库：.git文件夹里还包括git自动创建的master分支，并且将HEAD指针指向master分支。使用commit命令可以将暂存区中的文件添加到本地仓库中； 远程仓库：不是在本地仓库中，项目代码在远程git服务器上，比如项目放在github上，就是一个远程仓库，通常使用clone命令将远程仓库拷贝到本地仓库中，开发后推送到远程仓库中即可； 更细节的来看： 日常开发时代码实际上放置在工作区中，也就是本地的XXX.java这些文件，通过add等这些命令将代码文教提交给暂存区（Index/Stage），也就意味着代码全权交给了git进行管理，之后通过commit等命令将暂存区提交给master分支上，也就是意味打了一个版本，也可以说代码提交到了本地仓库中。另外，团队协作过程中自然而然还涉及到与远程仓库的交互。 因此，经过这样的分析，git命令可以分为这样的逻辑进行理解和记忆： git管理配置的命令； 几个核心存储区的交互命令： 工作区与暂存区的交互； 暂存区与本地仓库（分支）上的交互； 本地仓库与远程仓库的交互。 安装git安装 https://git-scm.com/ 配置$ git config --global user.name \"Your Name\" $ git config --global user.email \"email@example.com\" $ git config --global core.editor emacs $ git config --list $ git config user.name 快速开始$ git init # 初始化工程 $ git add * # 将文件添加到暂存区 $ git commit -m # 提交 $ git clone https://github.com/libgit2/libgit2 常用命令add git add -A 保存所有的修改 git add . 保存新的添加和修改，但是不包括删除 git add -u 保存修改和删除，但是不包括新建文件。 commit git commit -m git commit -ma // -a是添加全部修改 git commit –amend checkout git checkout — //使用暂缓区替换工作区 git checkout 切换分支 git checkout head — //直接使用本地参考的文件覆盖工作区文件 rm git rm // 删除工作区，并且提交 git rm —cached // 只删除暂存区 git rm -f // 暂存区和工作区都删除 reset谨慎使用！！！！！ –soft – 缓存区和工作目录都不会被改变 –mixed – 默认选项。缓存区和你指定的提交同步，但工作目录不受影响 –hard – 缓存区和工作目录都同步到你指定的提交 revert前提是已经提交，缺点：一次回滚过个记录会出现冲突。","tags":[{"name":"git","slug":"git","permalink":"http://wumuwumu.github.io/tags/git/"}]},{"title":"go工程搭建","date":"2019-04-09T01:26:21.000Z","path":"posts/undefined.html","text":"工程基本结构","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"mysql权限管理","date":"2019-03-29T08:55:22.000Z","path":"posts/undefined.html","text":"用户管理基本操作create user zhangsan identified by 'zhangsan'; SELECT current_user(); ← 查看当前用户 SELECT user,host FROM mysql.user; ← 查看用户信息 SHOW GRANTS; ← 当前用户权限，会生成SQL语句 CREATE USER 'user'@'host' IDENTIFIED BY 'password'; ← 创建用户 DROP USER 'user'@'host'; ← 删除用户 RENAME USER 'user'@'host' TO 'fool'@'host'; 修改密码mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'new-password'; ← 修改密码(recommand) mysql> SET PASSWORD FOR 'root'@'localhost'=PASSWORD('new-password'); ← 修改密码 mysql> UPDATE mysql.user SET password=PASSWORD('new-password') WHERE USER='root' AND Host='127.0.0.1'; mysql> UPDATE mysql.user SET password='' WHERE user='root'; ← 清除密码 mysql> FLUSH PRIVILEGES; $ mysqladmin -uROOT -pOLD_PASSWD password NEW_PASSWD ← 通过mysqladmin修改 $ mysqladmin -uROOT -p flush-privileges 权限管理mysql> GRANT ALL ON *.* TO 'user'@'%' [IDENTIFIED BY 'password']; mysql> GRANT ALL ON [TABLE | DATABASE] student,course TO user1,user2; mysql> GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, CREATE TEMPORARY, ALTER, DROP, REFERENCES, INDEX, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EXECUTE ON db.tbl TO 'user'@'host' [IDENTIFIED BY 'password']; mysql> GRANT ALL ON sampdb.* TO PUBLIC WITH GRANT OPTION; ← 所有人，可以授权给其他人 mysql> GRANT UPDATE(col),SELECT ON TABLE tbl TO user; ← 针对列赋值 mysql> SHOW GRANTS [FOR 'user'@'host']; ← 查看权限信息 mysql> REVOKE ALL ON *.* FROM 'user'@'host'; ← 撤销权限 mysql> REVOKE SELECT(user, host), UPDATE(host) ON db.tbl FROM 'user'@'%'; 权限adminmysql&gt; CREATE USER &#39;admin&#39;@&#39;IP&#39; IDENTIFIED BY &#39;password&#39;; mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;admin&#39;@&#39;IP&#39;; mysql&gt; REVOKE ALL PRIVILEGES ON *.* FROM &#39;admin&#39;@&#39;IP&#39;; mysql&gt; DROP USER &#39;admin&#39;@&#39;IP&#39;; rootmysql> GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION; 其他重置root密码----- 1. 停止mysql服务器 # systemctl stop mysqld # /opt/mysql-5.7/bin/mysqladmin -uroot -p'init-password' shutdown Shutting down MySQL.. done ----- 2. 获取跳过认证的启动参数 # mysqld --help --verbose | grep 'skip-grant-tables' -A1 --skip-grant-tables Start without grant tables. This gives all users FULL ACCESS to all tables. ----- 3. 启动服务器，跳过认证 # mysqld --skip-grant-tables --user=mysql &amp; [1] 10209 ----- 4. 取消密码 mysql> UPDATE mysql.user SET password='' WHERE user='root'; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 密码策略参数解释validate_password_dictionary_file插件用于验证密码强度的字典文件路径。 validate_password_length密码最小长度，参数默认为8，它有最小值的限制，最小值为：validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count) validate_password_mixed_case_count密码至少要包含的小写字母个数和大写字母个数。 validate_password_number_count密码至少要包含的数字个数。 validate_password_policy密码强度检查等级，0/LOW、1/MEDIUM、2/STRONG。有以下取值：Policy Tests Performed0 or LOW Length1 or MEDIUM Length; numeric, lowercase/uppercase, and special characters2 or STRONG Length; numeric, lowercase/uppercase, and special characters; dictionary file默认是1，即MEDIUM，所以刚开始设置的密码必须符合长度，且必须含有数字，小写或大写字母，特殊字符。 validate_password_special_char_count密码至少要包含的特殊字符数。 修改mysql参数配置mysql&gt; set global validate_password_policy&#x3D;0; Query OK, 0 rows affected (0.05 sec) mysql&gt; set global validate_password_mixed_case_count&#x3D;0; Query OK, 0 rows affected (0.00 sec) mysql&gt; set global validate_password_number_count&#x3D;3; Query OK, 0 rows affected (0.00 sec) mysql&gt; set global validate_password_special_char_count&#x3D;0; Query OK, 0 rows affected (0.00 sec) mysql&gt; set global validate_password_length&#x3D;3; Query OK, 0 rows affected (0.00 sec) mysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;; +--------------------------------------+-------+ | Variable_name | Value | +--------------------------------------+-------+ | validate_password_dictionary_file | | | validate_password_length | 3 | | validate_password_mixed_case_count | 0 | | validate_password_number_count | 3 | | validate_password_policy | LOW | | validate_password_special_char_count | 0 | +--------------------------------------+-------+ 6 rows in set (0.00 sec) MySQL 中 localhost 127.0.0.1 区别% 是一个通配符，用以匹配所有的 IP 地址，但是不能匹配到 locahost 这个特殊的域名。 也就是说，如果要允许本地登录，单纯只配置一个 % 是不够的 (应该是说对这种方式是不够的)，需要同时配置一个 locahost 的账号。 mysql> GRANT ALL ON *.* TO 'foobar'@'%' IDENTIFIED BY '123456'; Query OK, 0 rows affected (0.01 sec) mysql> SELECT user, host, password FROM mysql.user WHERE user like 'foobar%'; +--------+------+-------------------------------------------+ | user | host | password | +--------+------+-------------------------------------------+ | foobar | % | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 | +--------+------+-------------------------------------------+ 1 row in set (0.00 sec) $ mysql -ufoobar -h127.0.0.1 -P3307 -p'123456' ERROR 1045 (28000): Access denied for user 'foobar'@'localhost' (using password: YES) https://jin-yang.github.io/post/mysql-localhost-vs-127.0.0.1-introduce.html 参考https://jin-yang.github.io/post/mysql-users.html https://www.cnblogs.com/Richardzhu/p/3318595.html","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos安装mysql","date":"2019-03-29T07:45:32.000Z","path":"posts/undefined.html","text":"添加 MySQL YUM 源$wget 'https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm' $sudo rpm -Uvh mysql57-community-release-el7-11.noarch.rpm $yum repolist all | grep mysql mysql-connectors-community/x86_64 MySQL Connectors Community 36 mysql-tools-community/x86_64 MySQL Tools Community 47 mysql57-community/x86_64 MySQL 5.7 Community Server 187 安装MySQL## 安装最新版 $sudo yum install mysql-community-server $ sudo yum install mysql ## 安装客户端 ## 安装老版本 ## 1. yum-config-manager $ sudo dnf config-manager --disable mysql57-community $ sudo dnf config-manager --enable mysql56-community $ yum repolist | grep mysql mysql-connectors-community&#x2F;x86_64 MySQL Connectors Community 36 mysql-tools-community&#x2F;x86_64 MySQL Tools Community 47 mysql56-community&#x2F;x86_64 MySQL 5.6 Community Server 327 ## 2. 直接修改 &#x2F;etc&#x2F;yum.repos.d&#x2F;mysql-community.repo # Enable to use MySQL 5.6 [mysql56-community] name&#x3D;MySQL 5.6 Community Server baseurl&#x3D;http:&#x2F;&#x2F;repo.mysql.com&#x2F;yum&#x2F;mysql-5.6-community&#x2F;el&#x2F;7&#x2F;$basearch&#x2F; enabled&#x3D;1 #表示当前版本是安装 gpgcheck&#x3D;1 gpgkey&#x3D;file:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-mysql [mysql57-community] name&#x3D;MySQL 5.7 Community Server baseurl&#x3D;http:&#x2F;&#x2F;repo.mysql.com&#x2F;yum&#x2F;mysql-5.7-community&#x2F;el&#x2F;7&#x2F;$basearch&#x2F; enabled&#x3D;0 #默认这个是 1 gpgcheck&#x3D;1 gpgkey&#x3D;file:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-mysql 启动Mysql$sudo service mysqld start $sudo systemctl start mysqld #CentOS 7 $sudo systemctl status mysqld ● mysqld.service - MySQL Community Server Loaded: loaded (&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2017-05-27 12:56:26 CST; 15s ago Process: 2482 ExecStartPost&#x3D;&#x2F;usr&#x2F;bin&#x2F;mysql-systemd-start post (code&#x3D;exited, status&#x3D;0&#x2F;SUCCESS) Process: 2421 ExecStartPre&#x3D;&#x2F;usr&#x2F;bin&#x2F;mysql-systemd-start pre (code&#x3D;exited, status&#x3D;0&#x2F;SUCCESS) Main PID: 2481 (mysqld_safe) CGroup: &#x2F;system.slice&#x2F;mysqld.service ├─2481 &#x2F;bin&#x2F;sh &#x2F;usr&#x2F;bin&#x2F;mysqld_safe --basedir&#x3D;&#x2F;usr └─2647 &#x2F;usr&#x2F;sbin&#x2F;mysqld --basedir&#x3D;&#x2F;usr --datadir&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql --plugin-dir&#x3D;&#x2F;usr&#x2F;... 修改密码## 获取临时密码 sudo grep &#39;temporary password&#39; &#x2F;var&#x2F;log&#x2F;mysqld.log $ mysql -uroot -p #输入查看到的密码 mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;MyNewPass4!&#39;; mysql的密码存在安全等级 shell&gt; mysql_secure_installation mysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;; validate_password_number_count参数是密码中至少含有的数字个数，当密码策略是MEDIUM或以上时生效。 validate_password_special_char_count参数是密码中非英文数字等特殊字符的个数，当密码策略是MEDIUM或以上时生效。 validate_password_mixed_case_count参数是密码中英文字符大小写的个数，当密码策略是MEDIUM或以上时生效。 validate_password_length参数是密码的长度，这个参数由下面的公式生成 validate_password_number_count+ validate_password_special_char_count+ (2 * validate_password_mixed_case_count) validate_password_dictionary_file参数是指定密码验证的字典文件路径。 validate_password_policy这个参数可以设为0、1、2，分别代表从低到高的密码强度，此参数的默认值为1，如果想将密码强度改弱，则更改此参数为0。 修改密码策略更改密码策略为LOW mysql&gt; set global validate_password_policy&#x3D;0; 更改密码长度 mysql&gt; set global validate_password_length&#x3D;0; 安全设置## 会提示设置5个关键位置 ## 设置 root 密码 ## 禁止 root 账号远程登录 ## 禁止匿名账号（anonymous）登录 ## 删除测试库 ## 是否确认修改 $ mysql_secure_installation 安装三方插件yum --disablerepo&#x3D;\\* --enablerepo&#x3D;&#39;mysql*-community*&#39; list available 修改编码## &#x2F;etc&#x2F;my.cnf [client] default-character-set &#x3D; utf8 [mysqld] default-storage-engine &#x3D; INNODB character-set-server &#x3D; utf8 collation-server &#x3D; utf8_general_ci #不区分大小写 collation-server &#x3D; utf8_bin #区分大小写 collation-server &#x3D; utf8_unicode_ci #比 utf8_general_ci 更准确 修改服务器时间## mysql 中默认的时间戳是 UTC 时间，需要改为服务器时间的话官网提供了 3 种方式 $ mysql_tzinfo_to_sql tz_dir $ mysql_tzinfo_to_sql tz_file tz_name $ mysql_tzinfo_to_sql --leap tz_file ## tz_dir 代表服务器时间数据库，CentOS 7 中默认的目录为 &#x2F;usr&#x2F;share&#x2F;zoneinfo ，tz_name 为具体的时区。如果设置的时区需要闰秒，则使用 --leap，具体的用法如下： $ mysql_tzinfo_to_sql &#x2F;usr&#x2F;share&#x2F;zoneinfo | mysql -u root -p mysql $ mysql_tzinfo_to_sql tz_file tz_name | mysql -u root mysql $ mysql_tzinfo_to_sql --leap tz_file | mysql -u root mysql &gt; set global time_zone &#x3D; &#39;+8:00&#39;; ##修改mysql全局时区为北京时间，即我们所在的东8区 &gt; set time_zone &#x3D; &#39;+8:00&#39;; ##修改当前会话时区 &gt; flush privileges; #立即生效 ## 通过修改my.cnf配置文件来修改时区 # vim &#x2F;etc&#x2F;my.cnf ##在[mysqld]区域中加上 default-time_zone &#x3D; &#39;+8:00&#39; # &#x2F;etc&#x2F;init.d&#x2F;mysqld restart ##重启mysql使新时区生效","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"ngrok环境搭建","date":"2019-03-29T01:28:43.000Z","path":"posts/undefined.html","text":"下载安装 配置golang环境 安装go yum install golang 配置GOPATH 安装git2 sudo yum remove git sudo yum install epel-release sudo yum install https:&#x2F;&#x2F;centos7.iuscommunity.org&#x2F;ius-release.rpm sudo yum install git2u 下载ngrok go get github.com/inconshreveable/ngrok 生成证书 使用let’s encrypt证书 申请证书（具体看申请证书，主要通配符证书和三级域名） 修改证书 客户端证书 cd ngrok cp /etc/letsencrypt/live/xncoding.com/chain.pem assets/client/tls/ngrokroot.crt 服务端证书 cp /etc/letsencrypt/live/xncoding.com/cert.pem assets/server/tls/snakeoil.crt cp /etc/letsencrypt/live/xncoding.com/privkey.pem assets/server/tls/snakeoil.key 编译 编译服务端 make release-server 编译客户端 不同平台的客户端需要分开编译。不同平台使用不同的 GOOS 和 GOARCH，GOOS为go编译出来的操作系统 (windows,linux,darwin)，GOARCH, 对应的构架 (386,amd64,arm) GOOS=linux GOARCH=amd64 make release-client GOOS=windows GOARCH=amd64 make release-client GOOS=linux GOARCH=arm make release-client 启动服务器在开启之前，请主要端口是否开放 ./ngrokd -domain=ngrok.sciento.top -httpAddr=:9580 -httpsAddr=:9443 -tunnelAddr=\":9444\" 启动客户端 配置文件,具体看官方文档 server_addr: &quot;ngrok.sciento.top:9444&quot; trust_host_root_certs: false tunnels: http: subdomain: &quot;demo&quot; proto: http: &quot;9000&quot; https: subdomain: &quot;demo&quot; proto: https: &quot;9000&quot; 启动 ./ngrok -config=ngrok.cfg start http https nginx配置 安装nginx 配置 server &#123; listen 80; server_name demo.ngrok.xncoding.com; return 301 https://demo.ngrok.xncoding.com$request_uri; &#125; server &#123; listen 443 ssl http2; server_name demo.ngrok.xncoding.com; charset utf-8; ssl_certificate /etc/letsencrypt/live/demo.ngrok.xncoding.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/demo.ngrok.xncoding.com/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/demo.ngrok.xncoding.com/chain.pem; access_log /var/log/nginx/ngrok.log main; error_log /var/log/nginx/ngrok_error.log error; location / &#123; proxy_pass http://127.0.0.1:5442; proxy_redirect off; proxy_set_header Host $http_host:5442; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; 参考https://www.xncoding.com/2017/12/29/web/ngrok.html https://www.coldawn.com/how-to-issue-acmev2-wildcard-certificates-with-certbot-on-centos-7/ https://www.jianshu.com/p/c5c9d071e395 http://ngrok.cn/docs.html#tcp","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"Druid初始化","date":"2019-03-25T10:17:33.000Z","path":"posts/undefined.html","text":"public void init() throws SQLException &#123; if (inited) &#123; return; &#125; // bug fixed for dead lock, for issue #2980 DruidDriver.getInstance(); final ReentrantLock lock = this.lock; try &#123; lock.lockInterruptibly(); &#125; catch (InterruptedException e) &#123; throw new SQLException(\"interrupt\", e); &#125; boolean init = false; try &#123; //双重检查 if (inited) &#123; return; &#125; initStackTrace = Utils.toString(Thread.currentThread().getStackTrace()); this.id = DruidDriver.createDataSourceId(); if (this.id > 1) &#123; long delta = (this.id - 1) * 100000; this.connectionIdSeedUpdater.addAndGet(this, delta); this.statementIdSeedUpdater.addAndGet(this, delta); this.resultSetIdSeedUpdater.addAndGet(this, delta); this.transactionIdSeedUpdater.addAndGet(this, delta); &#125; if (this.jdbcUrl != null) &#123; this.jdbcUrl = this.jdbcUrl.trim(); initFromWrapDriverUrl(); &#125; for (Filter filter : filters) &#123; filter.init(this); &#125; if (this.dbType == null || this.dbType.length() == 0) &#123; this.dbType = JdbcUtils.getDbType(jdbcUrl, null); &#125; if (JdbcConstants.MYSQL.equals(this.dbType) || JdbcConstants.MARIADB.equals(this.dbType) || JdbcConstants.ALIYUN_ADS.equals(this.dbType)) &#123; boolean cacheServerConfigurationSet = false; if (this.connectProperties.containsKey(\"cacheServerConfiguration\")) &#123; cacheServerConfigurationSet = true; &#125; else if (this.jdbcUrl.indexOf(\"cacheServerConfiguration\") != -1) &#123; cacheServerConfigurationSet = true; &#125; if (cacheServerConfigurationSet) &#123; this.connectProperties.put(\"cacheServerConfiguration\", \"true\"); &#125; &#125; if (maxActive &lt;= 0) &#123; throw new IllegalArgumentException(\"illegal maxActive \" + maxActive); &#125; if (maxActive &lt; minIdle) &#123; throw new IllegalArgumentException(\"illegal maxActive \" + maxActive); &#125; if (getInitialSize() > maxActive) &#123; throw new IllegalArgumentException(\"illegal initialSize \" + this.initialSize + \", maxActive \" + maxActive); &#125; if (timeBetweenLogStatsMillis > 0 &amp;&amp; useGlobalDataSourceStat) &#123; throw new IllegalArgumentException(\"timeBetweenLogStatsMillis not support useGlobalDataSourceStat=true\"); &#125; if (maxEvictableIdleTimeMillis &lt; minEvictableIdleTimeMillis) &#123; throw new SQLException(\"maxEvictableIdleTimeMillis must be grater than minEvictableIdleTimeMillis\"); &#125; if (this.driverClass != null) &#123; this.driverClass = driverClass.trim(); &#125; initFromSPIServiceLoader(); // 处理驱动 if (this.driver == null) &#123; if (this.driverClass == null || this.driverClass.isEmpty()) &#123; this.driverClass = JdbcUtils.getDriverClassName(this.jdbcUrl); &#125; if (MockDriver.class.getName().equals(driverClass)) &#123; driver = MockDriver.instance; &#125; else &#123; if (jdbcUrl == null &amp;&amp; (driverClass == null || driverClass.length() == 0)) &#123; throw new SQLException(\"url not set\"); &#125; driver = JdbcUtils.createDriver(driverClassLoader, driverClass); &#125; &#125; else &#123; if (this.driverClass == null) &#123; this.driverClass = driver.getClass().getName(); &#125; &#125; // 进行参数的核对，没有什么逻辑 initCheck(); // 为不同的数据库处理异常，这个可以借鉴 initExceptionSorter(); initValidConnectionChecker(); // 做了一些检查，不知道 validationQueryCheck(); // 创建数据统计对象 if (isUseGlobalDataSourceStat()) &#123; dataSourceStat = JdbcDataSourceStat.getGlobal(); if (dataSourceStat == null) &#123; dataSourceStat = new JdbcDataSourceStat(\"Global\", \"Global\", this.dbType); JdbcDataSourceStat.setGlobal(dataSourceStat); &#125; if (dataSourceStat.getDbType() == null) &#123; dataSourceStat.setDbType(this.dbType); &#125; &#125; else &#123; dataSourceStat = new JdbcDataSourceStat(this.name, this.jdbcUrl, this.dbType, this.connectProperties); &#125; dataSourceStat.setResetStatEnable(this.resetStatEnable); // 创建连接池 connections = new DruidConnectionHolder[maxActive]; evictConnections = new DruidConnectionHolder[maxActive]; keepAliveConnections = new DruidConnectionHolder[maxActive]; SQLException connectError = null; // 同步或者异步创建线程池 if (createScheduler != null &amp;&amp; asyncInit) &#123; for (int i = 0; i &lt; initialSize; ++i) &#123; createTaskCount++; CreateConnectionTask task = new CreateConnectionTask(true); this.createSchedulerFuture = createScheduler.submit(task); &#125; &#125; else if (!asyncInit) &#123; // init connections while (poolingCount &lt; initialSize) &#123; try &#123; PhysicalConnectionInfo pyConnectInfo = createPhysicalConnection(); DruidConnectionHolder holder = new DruidConnectionHolder(this, pyConnectInfo); connections[poolingCount++] = holder; &#125; catch (SQLException ex) &#123; LOG.error(\"init datasource error, url: \" + this.getUrl(), ex); if (initExceptionThrow) &#123; connectError = ex; break; &#125; else &#123; Thread.sleep(3000); &#125; &#125; &#125; if (poolingCount > 0) &#123; poolingPeak = poolingCount; poolingPeakTime = System.currentTimeMillis(); &#125; &#125; // 用来打印线程池 createAndLogThread(); createAndStartCreatorThread(); // 停止 createAndStartDestroyThread(); // 等待线程创建完成 initedLatch.await(); init = true; initedTime = new Date(); // 注册mbean registerMbean(); if (connectError != null &amp;&amp; poolingCount == 0) &#123; throw connectError; &#125; // 检查连接池，防止连接池超出最大连接池 if (keepAlive) &#123; // async fill to minIdle if (createScheduler != null) &#123; for (int i = 0; i &lt; minIdle; ++i) &#123; createTaskCount++; CreateConnectionTask task = new CreateConnectionTask(true); this.createSchedulerFuture = createScheduler.submit(task); &#125; &#125; else &#123; this.emptySignal(); &#125; &#125; &#125; catch (SQLException e) &#123; LOG.error(\"&#123;dataSource-\" + this.getID() + \"&#125; init error\", e); throw e; &#125; catch (InterruptedException e) &#123; throw new SQLException(e.getMessage(), e); &#125; catch (RuntimeException e)&#123; LOG.error(\"&#123;dataSource-\" + this.getID() + \"&#125; init error\", e); throw e; &#125; catch (Error e)&#123; LOG.error(\"&#123;dataSource-\" + this.getID() + \"&#125; init error\", e); throw e; &#125; finally &#123; // 初始化成功 inited = true; // 解锁 lock.unlock(); if (init &amp;&amp; LOG.isInfoEnabled()) &#123; String msg = \"&#123;dataSource-\" + this.getID(); if (this.name != null &amp;&amp; !this.name.isEmpty()) &#123; msg += \",\"; msg += this.name; &#125; msg += \"&#125; inited\"; LOG.info(msg); &#125; &#125; &#125;","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"java多线程","date":"2019-02-15T08:37:30.000Z","path":"posts/undefined.html","text":"相关的类 Runnable Thread Callable:比Runnable有个返回值 Future FutureTask","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"sqlx基本使用","date":"2019-02-13T08:15:58.000Z","path":"posts/undefined.html","text":"安装go get github.com/jmoiron/sqlx 连接数据库var db *sqlx.DB // exactly the same as the built-in db = sqlx.Open(\"sqlite3\", \":memory:\") // from a pre-existing sql.DB; note the required driverName db = sqlx.NewDb(sql.Open(\"sqlite3\", \":memory:\"), \"sqlite3\") // force a connection and test that it worked err = db.Ping() 查询Exec直接执行，适合add,update,delete schema := `CREATE TABLE place ( country text, city text NULL, telcode integer);` // execute a query on the server result, err := db.Exec(schema) // or, you can use MustExec, which panics on error cityState := `INSERT INTO place (country, telcode) VALUES (?, ?)` countryCity := `INSERT INTO place (country, city, telcode) VALUES (?, ?, ?)` db.MustExec(cityState, \"Hong Kong\", 852) db.MustExec(cityState, \"Singapore\", 65) db.MustExec(countryCity, \"South Africa\", \"Johannesburg\", 27) Query查询数据库，适合select // fetch all places from the db rows, err := db.Query(\"SELECT country, city, telcode FROM place\") // iterate over each row for rows.Next() &#123; var country string // note that city can be NULL, so we use the NullString type var city sql.NullString var telcode int err = rows.Scan(&amp;country, &amp;city, &amp;telcode) &#125; // queryx 可以对结果转换成结构体 var person2 User rowxs,err :=db.Queryx(\"SELECT * FROM sys_user LIMIT 1\") if err != nil&#123; panic(err) &#125; for rowxs.Next()&#123; rowxs.StructScan(&amp;person2) fmt.Println(person2) &#125; Selectp := Place&#123;&#125; pp := []Place&#123;&#125; // this will pull the first place directly into p err = db.Get(&amp;p, \"SELECT * FROM place LIMIT 1\") // this will pull places with telcode > 50 into the slice pp err = db.Select(&amp;pp, \"SELECT * FROM place WHERE telcode > ?\", 50) // they work with regular types as well var id int err = db.Get(&amp;id, \"SELECT count(*) FROM place\") // fetch at most 10 place names var names []string err = db.Select(&amp;names, \"SELECT name FROM place LIMIT 10\") 事务// this will not work if connection pool > 1 db.MustExec(\"BEGIN;\") db.MustExec(...) db.MustExec(\"COMMIT;\") 预编译stmt, err := db.Prepare(`SELECT * FROM place WHERE telcode=?`) row = stmt.QueryRow(65) tx, err := db.Begin() txStmt, err := tx.Prepare(`SELECT * FROM place WHERE telcode=?`) row = txStmt.QueryRow(852) Named Queries// named query with a struct p := Place&#123;Country: \"South Africa\"&#125; rows, err := db.NamedQuery(`SELECT * FROM place WHERE country=:country`, p) // named query with a map m := map[string]interface&#123;&#125;&#123;\"city\": \"Johannesburg\"&#125; result, err := db.NamedExec(`SELECT * FROM place WHERE city=:city`, m) p := Place&#123;TelephoneCode: 50&#125; pp := []Place&#123;&#125; // select all telcodes > 50 nstmt, err := db.PrepareNamed(`SELECT * FROM place WHERE telcode > :telcode`) err = nstmt.Select(&amp;pp, p) arg := map[string]interface&#123;&#125;&#123; \"published\": true, \"authors\": []&#123;8, 19, 32, 44&#125;, &#125; query, args, err := sqlx.Named(\"SELECT * FROM articles WHERE published=:published AND author_id IN (:authors)\", arg) query, args, err := sqlx.In(query, args...) query = db.Rebind(query) db.Query(query, args...) 参考 http://jmoiron.github.io/sqlx/","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"jquery基本操作","date":"2019-01-12T08:20:45.000Z","path":"posts/undefined.html","text":"选择器// 基本选择器 $('#id') $('.class') $('element') $('*') $('select1 ,select2')//可以使用css选择器 // 层次选择器 $('ancestor descendant') $('parent >child') $('prev+next') $('prev~siblings')//获取所有同辈元素 DOM操作基本操作// attr $('div').attr(\"background\")//获取属性 $('div').attr(\"background\",\"white\") $('div').attr(&#123;\"background\":\"white\",\"height\":\"200px\"&#125;) // css $(\"div\").css('background') $('div').css(\"background\",\"white\") $('div').css(&#123;'background':'blue',\"height\":'200px'&#125;) // width height width() height() // addClass $('div').addClass('className'); // removeAttr $('div').removeAttr('background') // removeClass 没参数删除所有 // hasClass // 创建节点 var p $('&lt;p>hello&lt;/p>') // append() 添加内容 // appendTo() // prepend() 向元素内部前面添加内容 // prependTo() ​``` html &lt;p>hello&lt;/p> ​``` $('&lt;i>hi!&lt;/i>').prependTo(\"p\") ​``` html &lt;p>&lt;i>hi!&lt;/i>hello&lt;/p> ​``` // 在相应位置添加元素，是在元素的外面 // after // insertAfter // before //insertBefore // remove() // detach()：和remove()几乎一样，不同的是detach方法不会删除节点所绑定的事件和附加的数据 // empty() 清空内容 // clone()复制节点，可以有参数true，当有true参数时，将同时复制节点所绑定的事件 // replaceWith 将匹配的节点替换成指定的节点 // replaceAll() 只是用一个 // wrap 包裹节点 // wrapAll // wrapInner 将匹配的节点内部的节点或者文本内容用指定的节点包裹起来 ​``` &lt;p>我是内容&lt;/p> ​``` $(\"p\").wrapInner(\"&lt;span>&lt;/span>\"); ​``` &lt;p>&lt;span>我是内容&lt;/span>&lt;/p> ​``` // html() // text() // val() // children() // next() // prev() // siblings() // closest() 获取最近的符合匹配的一个父元素 ​``` &lt;div> &lt;div class=\"div2\"> &lt;p>我是内容&lt;/p> &lt;/div> &lt;/div> ​``` var $div=$(\"p\").closest();//返回class为div2的div元素 // parent() // parents() // offset() // position() // scrollTop() // scrollLeft() 事件与动画$().ready() $('').bind(type,func) $('').click() $('').mouseover // 合成事件 hover(enter,leave) toggle(fn1,fn2) // 阻止事件 event.stopPropagation(); event.preventDefault(); // unbind 移除事件 // trigger 触发事件 // 动画 hide(); show(time); fadeLn(); fadeOut(); slideUp(); slideDown(); slideToggle(); fadeTo(); fadeToggle(); animate(); delay(); 参考 jQuery简明参考手册——30分钟快速入门jQuery","tags":[{"name":"js","slug":"js","permalink":"http://wumuwumu.github.io/tags/js/"},{"name":"jquery","slug":"jquery","permalink":"http://wumuwumu.github.io/tags/jquery/"}]},{"title":"springcloud-eureka","date":"2019-01-06T10:27:25.000Z","path":"posts/undefined.html","text":"建立工程 添加依赖 &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-server&lt;/artifactId> &lt;version>$&#123;spring-cloud.version&#125;&lt;/version> &lt;/dependency> 添加Application @SpringBootApplication @EnableEurekaServer public class EurekaApplication &#123; public static void main(String[] arg)&#123; SpringApplication.run(EurekaApplication.class,arg); &#125; &#125; 添加配置文件 server: port: 8761 eureka: instance: hostname: localhost client: registerWithEureka: false ## 是否注册到eureka server fetchRegistry: false ## 是否获取Eureka server 注册信息，单机可以设置为false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ ## 默认http://localhost:8761/eureka spring: application: name: eurka-server 运行工程，访问127.0.0.1:9761可以看到web界面。 安全 添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; 添加配置 老版本 security: basic: true user: name: wumu password: wumu 新版本 security: user: name: wumu password: wumu 问题 在依赖包中同时添加的spring-cloud-starter-netflix-eureka-server与springb-boot-starter-web两个依赖会导致tomcat的依赖问题，应用不能启动。","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://wumuwumu.github.io/tags/spring-cloud/"}]},{"title":"Tiemline设计方案","date":"2019-01-04T12:33:08.000Z","path":"posts/undefined.html","text":"参考 朋友圈式的TIMELINE设计方案 朋友圈的设计及实现 几个大型网站的Feeds(Timeline)设计简单对比","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"查找附近的人","date":"2019-01-04T11:46:12.000Z","path":"posts/undefined.html","text":"GeoHash比较原始的方法，简单方便 Mysql计算公式 C &#x3D; sin(MLatA)*sin(MLatB)*cos(MLonA-MLonB) + cos(MLatA)*cos(MLatB) Distance &#x3D; R*Arccos(C)*Pi&#x2F;180 在经纬度小节中我们了解了两个公式用来计算两个位置之间的距离, 该小节我们以测试数据说明如何实现.测试需要的表结构和数据: 表结构: CREATE TABLE &#96;geotest&#96; ( &#96;userid&#96; int(10) NOT NULL, &#96;longitude&#96; decimal(9,6) NOT NULL, &#96;latitude&#96; decimal(9,6) NOT NULL, &#96;create_time&#96; datetime DEFAULT NULL, UNIQUE KEY &#96;unq_uid&#96; (&#96;userid&#96;), KEY &#96;idx_lat_lng&#96; (&#96;longitude&#96;,&#96;latitude&#96;) ) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 测试数据: insert geotest values(10000, 116.417480, 40.003033, now()); insert geotest values(10001, 116.437480, 40.004033, now()); insert geotest values(10002, 116.457480, 40.005033, now()); insert geotest values(10003, 116.477480, 40.006033, now()); ...... ...... 第一种公式中, google 为我们介绍了如何使用 sql 来获取附近的点, 如下所示, 我们选用 6371km 作为地球的半径,根据上述小节的计算公式推断: C &#x3D; sin(MLatA)*sin(MLatB)*cos(MLonA-MLonB) + cos(MLatA)*cos(MLatB) Distance &#x3D; R*Arccos(C)*Pi&#x2F;180 google 地图的计算公式可以参考 geo_search 两个位置之间的距离则可以换算成以下公式: R*arccos( cos( radians(latA)*cos( radians(latB) ) * cos( radians(lonA - lonB) )) + sin( radians(latA)*cos(latB) )) radians 函数计算出相应的弧度信息, 得到下面的 sql: SELECT user_id, ( 6371 * acos ( cos ( radians(40.003033) ) * cos( radians( latitude ) ) * cos( radians( longitude ) - radians(116.417481) ) + sin ( radians(40.003033) ) * sin( radians( latitude ) ) ) ) AS distance FROM geotest HAVING distance &lt; 1 ORDER BY distance LIMIT 0 , 20; 上面的 sql 从 geotest 中从 geotest 表中获取到经度(116.417481) 和纬度(40.003033) 位置附近 1km 所有的user_id 信息.观察这个 sql, 可以预见到在表数据较大的时候仅建立复合索引 idx_lat_lng 肯定会遇到性能瓶颈, 因为每行记录都需要做相关的运算, 才能跑出最后的结果. 所以要提高该 sql 的性能就需要尽量过滤不需要的 longitude 和 latitude 两列的值. 参考 geo_search 和 fastest-way-to-find-distance, 在近距离的情况下我们可以认为当前区域内的所有位置都在一个平面内, 虽然有点误差, 但是比起地球这么大的椭球, 我们完全可以忽略其中的误差. 以经纬度来讲, 1 纬度约等于 69 英里, 大约 111044.736 米, 其中的换算公式为: 1°latitude ~&#x3D; 69 miles 1°longitude ~&#x3D; cos(latitude)*69 miles 所以对于位置信息(lng, lat), 我们可以计算出以其为中心周边指定距离的四个点, 如下图所示: +-------------+ | | | | | + | | | | | +-------------+ 计算公式如下: lng1 &#x3D; lon - dist&#x2F;abs(cos(radians(lat))*69) lng2 &#x3D; lon + dist&#x2F;abs(cos(radians(lat))*69) lat1 &#x3D; lat - (dist&#x2F;69); lat2 &#x3D; lat + (dist&#x2F;69); 四个点的坐标就分别为 (lng1, lat1), (lng1, lat2), (lng2, lat1), (lng2, lat2), 所以存在于该四个点组成的平面之间的点即可以被认为在(lng, lat) 的 dist 距离内. 基于上述的规则, 修改 sql 为以下: SELECT user_id, ( 6371 * acos ( cos ( radians(40.003033) ) * cos( radians( latitude ) ) * cos( radians( longitude ) - radians(116.417481) ) + sin ( radians(40.003033) ) * sin( radians( latitude ) ) ) ) AS distance FROM geotest WHERE longitude BETWEEN lng1 AND lng2 AND latitude BETWEEN lat1 AND lat2 HAVING distance &lt; 1 ORDER BY distance LIMIT 0 , 20; 这样就能很好的使用索引, 如果还想增加超时设置, 可以在 sql 里加上 create_time 条件进行过滤, 比如只查找最近一天的附近的用户. 另外开发者也可以结合使用 sphinx 或 elasticsearch 得到更好的性能. 下面为根据上面介绍的规则整理成存储过程, 方便开发者调用访问. 这里我们将地球半径的公里数转换为米即为 6371392.89m, 69英里则转为 111044.736m, 如下存储过程返回 user_id 和 距离(米): DELIMITER $$ drop procedure if exists geo_dist$$ create procedure geo_dist(IN lng decimal(9, 6), IN lat decimal(9, 6), IN dist int) begin declare lng1 decimal(9, 6); declare lng2 decimal(16, 13); declare lat1 decimal(9, 6); declare lat1 decimal(16, 13); -- calculate lng and lat for the rectangle, in meters unit set lng1 &#x3D; lng - dist&#x2F;abs(cos(radians(lat))*111044.736); set lng2 &#x3D; lng + dist&#x2F;abs(cos(radians(lat))*111044.736); set lat1 &#x3D; lat - (dist&#x2F;111044.736); set lat2 &#x3D; lat + (dist&#x2F;111044.736); -- run the query select user_id, round(( 6371392.89 * acos ( cos ( radians(lat) ) * cos( radians( latitude ) ) * cos( radians( longitude ) - radians(lng) ) + sin ( radians(lat) ) * sin( radians( latitude ) ) ) ), 0) AS distance from user_position where lng between lng1 and lng2 and lat between lat1 and lat2 having distance &lt; dist ORDER BY distance LIMIT 0 , 20; END$$ DELIMITER ; 运行存储过程, 取出该经纬度下附近 5km 的用户和距离(m): mysql &gt; call geo_dist(116.4174800000000, 40.0030330000000, 5000); +---------+----------+ | user_id | distance | +---------+----------+ | 10000 | 0 | | 10001 | 1707 | | 10002 | 3414 | +---------+----------+ 3 rows in set (0.00 sec) Query OK, 0 rows affected (0.01 sec) 10001 用户和指定的经纬度距离为1707米, 我们在 redis 3.2 版本中进行简单测试, 可以看到结果都很相近: 127.0.0.1:6380&gt; geoadd tttt 116.417480 40.003033 t1 (integer) 0 127.0.0.1:6380&gt; geoadd tttt 116.437481 40.004034 t2 (integer) 0 127.0.0.1:6380&gt; GEODIST tttt t1 t2 &quot;1707.5093&quot; mongodb创建位置索引 参考 使用 MySQL 实现搜索附近的人 GeoHash算法学习讲解、解析及原理分析","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"},{"name":"mongodb","slug":"mongodb","permalink":"http://wumuwumu.github.io/tags/mongodb/"},{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"}]},{"title":"springboot-mongodb使用","date":"2019-01-04T01:43:06.000Z","path":"posts/undefined.html","text":"基本注解 @id @Document @DBRef $Indexed @CompoundIndex @GenSpatialIndexed @Transient @PersistenceConstructor","tags":[{"name":"springboot","slug":"springboot","permalink":"http://wumuwumu.github.io/tags/springboot/"},{"name":"mongodb","slug":"mongodb","permalink":"http://wumuwumu.github.io/tags/mongodb/"}]},{"title":"cordova打包vue","date":"2019-01-02T09:12:09.000Z","path":"posts/undefined.html","text":"https://segmentfault.com/a/1190000013159076","tags":[{"name":"vue","slug":"vue","permalink":"http://wumuwumu.github.io/tags/vue/"}]},{"title":"Oracle表管理","date":"2018-12-29T13:45:47.000Z","path":"posts/undefined.html","text":"数据类型## 字符型 char 定长，后面空格补全 varchar2() 变长 clob 字符型大对象 ## 数字类型 number number(5，2) 标识5位有效数，2位小数-999.99-999.99 number(5) 5位整数 ## 日期类型 date timestramp ## 图片 blob 二进制4g,为了安全可以放入数据库 表操作create table table_name( ) drop table table_name; rename table_name to other_table_name; alter table table_name add ...; alter table table_name modify ...; alter table table_name drop column ...;","tags":[{"name":"oracle","slug":"oracle","permalink":"http://wumuwumu.github.io/tags/oracle/"}]},{"title":"Oracle基本管理","date":"2018-12-29T12:37:37.000Z","path":"posts/undefined.html","text":"用户管理## 创建用户 create user test identified by test; show user; ## 删除用户 delete test (cascade); ## 修改用户 alter user test identified by wumu; alter user test expire; ## 用户口令 ## 密码输错三次就密码锁定2天 create profile lock_account limit failed_login_attempts 3 password_lock_time 2; alter user tea profile lock_account; ## 解锁 alter user tea account unlock; ## 每10天需要修改密码，宽限期为两天 create profile myprofile limit password_life_time 10 password_grace_time 2; alter user tea profile myprofile; ## 口令10天后可以重用 create profile password_history limit password_lift_time 10 password_grace_time 2 password_reuse_time 10 ## 撤销profile drop profile my_profile CASCADE； 权限管理## 授权 grant system_privilege|all privileges to &#123;user identified by password |role|&#125; [with admin option] grant object_privileage | All on schema.object to user | role [with admin option] [with the grant any object] grant select on test to wumu with grant option; grant connect tp wumu with admin option; ## create session 用于登录 ## dba 管路员 ## resource 可以建表 ## desc table_name ## 撤销权限 ## 如果授权者的权限被撤回，那么它的被授予者也会失去相关的权限 invoke system_privilege from user|role invoke object_privilege|All on scheme.object from user|role [cascade contraints] ## 查询权限 ## 系统权限放在DBA_SYS_PRIVS ## 对象权限放在数据字典DBA_TAB_PRIVS","tags":[{"name":"oracle","slug":"oracle","permalink":"http://wumuwumu.github.io/tags/oracle/"}]},{"title":"Vue插件开发","date":"2018-12-17T12:52:34.000Z","path":"posts/undefined.html","text":"基本结构插件的功能包括全局方法和属性、指令、mixin、实例方法。插件都有一个install方法，第一个参数是Vue，第二个参数是options。 MyPlugin.install = function (Vue, options) &#123; Vue.myGlobalMethod = function () &#123; // 1. 添加全局方法或属性，如: vue-custom-element // 逻辑... &#125; Vue.directive('my-directive', &#123; // 2. 添加全局资源：指令/过滤器/过渡等，如 vue-touch bind (el, binding, vnode, oldVnode) &#123; // 逻辑... &#125; ... &#125;) Vue.mixin(&#123; created: function () &#123; // 3. 通过全局 mixin方法添加一些组件选项，如: vuex // 逻辑... &#125; ... &#125;) Vue.prototype.$myMethod = function (options) &#123; // 4. 添加实例方法，通过把它们添加到 Vue.prototype 上实现 // 逻辑... &#125; &#125; vue-toast","tags":[{"name":"js","slug":"js","permalink":"http://wumuwumu.github.io/tags/js/"},{"name":"vue","slug":"vue","permalink":"http://wumuwumu.github.io/tags/vue/"}]},{"title":"JSqlParser教程","date":"2018-12-05T13:58:31.000Z","path":"posts/undefined.html","text":"解析获取表名//获取所有使用过的表 Statement statement = CCJSqlParserUtil.parse(\"SELECT * FROM MY_TABLE1\"); Select selectStatement = (Select) statement; TablesNamesFinder tablesNamesFinder = new TablesNamesFinder(); List&lt;String> tableList = tablesNamesFinder.getTableList(selectStatement); 应用别名// SELECT a AS A1, b AS A2, c AS A3 FROM test Select select = (Select) CCJSqlParserUtil.parse(\"select a,b,c from test\"); final AddAliasesVisitor instance = new AddAliasesVisitor(); select.getSelectBody().accept(instance); 添加一列或者表达式// SELECT a, b FROM mytable Select select = (Select) CCJSqlParserUtil.parse(\"select a from mytable\"); SelectUtils.addExpression(select, new Column(\"b\")); 添加where语句新建whereSelect select = (Select) CCJSqlParserUtil.parse(\"select name from user\"); PlainSelect plainSelect = (PlainSelect) select.getSelectBody(); if (plainSelect.getWhere() == null) &#123; EqualsTo equalsTo = new EqualsTo(); equalsTo.setLeftExpression(new Column(\"id\")); equalsTo.setRightExpression(new LongValue(1000L)); plainSelect.setWhere(equalsTo); &#125; 添加whereSelect select = (Select) CCJSqlParserUtil.parse(\"select name from user where id = 1000\"); PlainSelect plainSelect = (PlainSelect) select.getSelectBody(); // 原where表达式 Expression where = plainSelect.getWhere(); // 新增的查询条件表达式 EqualsTo equalsTo = new EqualsTo(); equalsTo.setLeftExpression(new Column(\"name\")); equalsTo.setRightExpression(new StringValue(\"'张三'\")); // 用and链接条件 AndExpression and = new AndExpression(where, equalsTo); // 设置新的where条件 plainSelect.setWhere(and); 添加nullSelect select = (Select) CCJSqlParserUtil.parse(\"select name from user where id = 1000\"); PlainSelect plainSelect = (PlainSelect) select.getSelectBody(); // 原where表达式 Expression where = plainSelect.getWhere(); // 新增的null判断条件 IsNullExpression isNullExpression = new IsNullExpression(); isNullExpression.setLeftExpression(new Column(\"name\")); isNullExpression.setNot(true); // 用and链接条件 AndExpression and = new AndExpression(where, isNullExpression); // 设置新的where条件 plainSelect.setWhere(and); 生成扩展插入// INSERT INTO mytable (col1) VALUES (1) // INSERT INTO mytable (col1, col2) VALUES (1, 5) // INSERT INTO mytable (col1, col2, col3) VALUES (1, 5, 10) Insert insert = (Insert) CCJSqlParserUtil.parse(\"insert into mytable (col1) values (1)\"); System.out.println(insert.toString()); insert.getColumns().add(new Column(\"col2\")); insert.getItemsList().accept(new ItemsListVisitor() &#123; public void visit(SubSelect subSelect) &#123; throw new UnsupportedOperationException(\"Not supported yet.\"); &#125; public void visit(ExpressionList expressionList) &#123; expressionList.getExpressions().add(new LongValue(5)); &#125; public void visit(MultiExpressionList multiExprList) &#123; throw new UnsupportedOperationException(\"Not supported yet.\"); &#125; &#125;); System.out.println(insert.toString()); insert.getColumns().add(new Column(\"col3\")); ((ExpressionList) insert.getItemsList()).getExpressions().add(new LongValue(10)); 建立selectSelect select = SelectUtils.buildSelectFromTable(new Table(\"mytable\")); Select select = SelectUtils.buildSelectFromTableAndExpressions(new Table(\"mytable\"), new Column(\"a\"), new Column(\"b\")); Select select = SelectUtils.buildSelectFromTableAndExpressions(new Table(\"mytable\"), \"a+b\", \"test\"); 代替字符串的值String sql =\"SELECT NAME, ADDRESS, COL1 FROM USER WHERE SSN IN ('11111111111111', '22222222222222');\"; Select select = (Select) CCJSqlParserUtil.parse(sql); //Start of value modification StringBuilder buffer = new StringBuilder(); ExpressionDeParser expressionDeParser = new ExpressionDeParser() &#123; @Override public void visit(StringValue stringValue) &#123; this.getBuffer().append(\"XXXX\"); &#125; &#125;; SelectDeParser deparser = new SelectDeParser(expressionDeParser,buffer ); expressionDeParser.setSelectVisitor(deparser); expressionDeParser.setBuffer(buffer); select.getSelectBody().accept(deparser); //End of value modification System.out.println(buffer.toString()); //Result is: SELECT NAME, ADDRESS, COL1 FROM USER WHERE SSN IN (XXXX, XXXX) import net.sf.jsqlparser.JSQLParserException; import net.sf.jsqlparser.expression.LongValue; import net.sf.jsqlparser.expression.StringValue; import net.sf.jsqlparser.parser.CCJSqlParserUtil; import net.sf.jsqlparser.statement.Statement; import net.sf.jsqlparser.util.deparser.ExpressionDeParser; import net.sf.jsqlparser.util.deparser.SelectDeParser; import net.sf.jsqlparser.util.deparser.StatementDeParser; public class ReplaceColumnValues &#123; static class ReplaceColumnAndLongValues extends ExpressionDeParser &#123; @Override public void visit(StringValue stringValue) &#123; this.getBuffer().append(\"?\"); &#125; @Override public void visit(LongValue longValue) &#123; this.getBuffer().append(\"?\"); &#125; &#125; public static String cleanStatement(String sql) throws JSQLParserException &#123; StringBuilder buffer = new StringBuilder(); ExpressionDeParser expr = new ReplaceColumnAndLongValues(); SelectDeParser selectDeparser = new SelectDeParser(expr, buffer); expr.setSelectVisitor(selectDeparser); expr.setBuffer(buffer); StatementDeParser stmtDeparser = new StatementDeParser(expr, selectDeparser, buffer); Statement stmt = CCJSqlParserUtil.parse(sql); stmt.accept(stmtDeparser); return stmtDeparser.getBuffer().toString(); &#125; public static void main(String[] args) throws JSQLParserException &#123; System.out.println(cleanStatement(\"SELECT 'abc', 5 FROM mytable WHERE col='test'\")); System.out.println(cleanStatement(\"UPDATE table1 A SET A.columna = 'XXX' WHERE A.cod_table = 'YYY'\")); System.out.println(cleanStatement(\"INSERT INTO example (num, name, address, tel) VALUES (1, 'name', 'test ', '1234-1234')\")); System.out.println(cleanStatement(\"DELETE FROM table1 where col=5 and col2=4\")); &#125; &#125; /* SELECT ?, ? FROM mytable WHERE col = ? UPDATE table1 A SET A.columna = ? WHERE A.cod_table = ? INSERT INTO example (num, name, address, tel) VALUES (?, ?, ?, ?) DELETE FROM table1 WHERE col = ? AND col2 = ? */ 参考 https://github.com/JSQLParser/JSqlParser/wiki","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"react入门教程","date":"2018-12-05T13:56:22.000Z","path":"posts/undefined.html","text":"webpack4初始化cnpm i -D webpack cnpm i -D webpack-cli &#x2F;&#x2F;相关的命令 相应包的安装 react 专门用于创建组件和虚拟DOM，同事组件的生命周期在这个包中。 react-dom 专门进行dom操作的，最主要的应用场景，就是ReactDom.render() babel babel-node 一个命令行工具 babel-register 可以实现动态转换 babel-core 核心包 babel-preset-env 一个套餐 jsx使用安装babel插件cnpm i babel-core babel-loader babel-plugin-transform-runtime -D cnpm i babel-preset-env babel-preset-stage-0 -D cnpm i babel-preset-react -D 添加.babelrc配置文件&#123; &quot;presets&quot;:[&quot;env&quot;,&quot;stage-0&quot;,&quot;react&quot;], &quot;plugins&quot;:[&quot;transform-runtime&quot;] &#125; ##添加babel-loader配置项 module：&#123; rules:[ &#123;test:&#x2F;\\.js|jsx&#x2F;,use:&#39;babel-loader&#39;,exclude:&#x2F;node_modules&#x2F;&#125; ] &#125;","tags":[{"name":"react","slug":"react","permalink":"http://wumuwumu.github.io/tags/react/"}]},{"title":"nginx配置","date":"2018-12-05T13:47:32.000Z","path":"posts/undefined.html","text":"配置web服务器server &#123; listen 80; server_name api.lufficc.com *.lufficc.com; location &#x2F;images&#x2F; &#123; root &#x2F;data; &#125; location &#x2F; &#123; proxy_pass https:&#x2F;&#x2F;lufficc.com; &#125; &#125; 反向代理server&#123; listen 80; server_name search.lufficc.com; location &#x2F; &#123; proxy_pass https:&#x2F;&#x2F;www.baidu.com; &#125; &#125; 参考 https://lufficc.com/blog/configure-nginx-as-a-web-server https://blog.csdn.net/hj7jay/article/details/53905943 http://www.nginx.cn/76.html","tags":[{"name":"web","slug":"web","permalink":"http://wumuwumu.github.io/tags/web/"},{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos7修改网卡","date":"2018-12-05T13:40:23.000Z","path":"posts/undefined.html","text":"修改mac使用virtualbox导入一个虚拟机时mac地址是一样的，此时需要修改。 修改mac地址直接在virtualBox的setting&gt;network配置中进行修改。 修改网卡名称修改网卡的配置文件vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eno16777736 &#x2F;&#x2F;修改NAME，DEVICE 成希望的（不要加ifcfg） mv ifcfg-eno16777736 ifcfg-eth0 &#x2F;&#x2F;修改配置文件的名字 禁用可预测命名规则vim &#x2F;etc&#x2F;default&#x2F;grub 添加内核参数： net.ifnames=0 biosdevname=0 [root@ansheng network-scripts]# vi &#x2F;etc&#x2F;default&#x2F;grub GRUB_TIMEOUT&#x3D;5 GRUB_DISTRIBUTOR&#x3D;&quot;$(sed &#39;s, release .*$,,g&#39; &#x2F;etc&#x2F;system-release)&quot; GRUB_DEFAULT&#x3D;saved GRUB_DISABLE_SUBMENU&#x3D;true GRUB_TERMINAL_OUTPUT&#x3D;&quot;console&quot; GRUB_CMDLINE_LINUX&#x3D;&quot;rd.lvm.lv&#x3D;centos&#x2F;root rd.lvm.lv&#x3D;centos&#x2F;swap rhgb quiet net.ifnames&#x3D;0 biosdevname&#x3D;0&quot; GRUB_DISABLE_RECOVERY&#x3D;&quot;true&quot; 用 grub2-mkconfig 命令重新生成GRUB配置并更新内核[root@ansheng network-scripts]# grub2-mkconfig -o &#x2F;boot&#x2F;grub2&#x2F;grub.cfg Generating grub configuration file ... Found linux image: &#x2F;boot&#x2F;vmlinuz-3.10.0-327.el7.x86_64 Found initrd image: &#x2F;boot&#x2F;initramfs-3.10.0-327.el7.x86_64.img Found linux image: &#x2F;boot&#x2F;vmlinuz-0-rescue-4dd6b54f74c94bff9e92c61d669fc195 Found initrd image: &#x2F;boot&#x2F;initramfs-0-rescue-4dd6b54f74c94bff9e92c61d669fc195.img done 重启系统","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"nvc-server安装","date":"2018-12-05T13:39:00.000Z","path":"posts/undefined.html","text":"centos 安装 vnc serverVNC需要系统安装的有桌面，如果是生产环境服务器，安装时使用的最小化安装，那么进行下面操作按章GNOME 桌面。 # 列出的组列表里有GNOME Desktop。 yum grouplist #安装之 yum groupinstall -y \"GNOME Desktop\" # 安装完成后，修改默认启动方式为图形化界面 systemctl set-default graphical.target //设置成图形模式 # 如果要换回来 systemctl set-default multi-user.target //设置成命令模式 #然后重启系统即可 第一步：安装VNC服务软件，使用root用户执行以下命令（以下操作没有特别说明均在root用户）： yum install tigervnc-server -y 安装后可以使用如下命令来验证是否安装成功： rpm -qa|grep tigervnc-server 第二步：复制vnc的启动操作脚本, vncserver@:1.service中的：1表示”桌面号”，启动的端口号就是5900+桌面号，即是5901，如果再有一个就是2啦，端口号加1就是5902，以此类推： cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service 第三步：编辑 /etc/systemd/system/vncserver@:1.service vim /etc/systemd/system/vncserver@\\:1.service vnc配置文件修改前 找到其中的 ，修改成自己的用户名，如果是root用户登录桌面就使用root用户，如果使用普通用户登录桌面使用普通用户，这里笔者使用用户名：cy vnc配置文件修改后 修改完毕后保存退出vim。 第四步：设置vnc密码，执行su cy，切换到刚配置文件设置的cy用户，执行（这一步是在cy用户下操作），输入两次密码，输入完成后会提示是否设置view-only password（“View-only password”密码，只允许查看,无控制权限。）这个可设可不设： vncpasswd 第五步：启动服务： systemctl start vncserver@\\:1.service 第一次输入启动服务命令可能会要求输入（从新加载配置文件，新增和配置文件发生变化时都需要执行 daemon-reload 子命令）： systemctl daemon-reload 执行完毕之后在执行启动命令就可以了： 可以加入开机启动，下次开机就会自动启动啦： systemctl enable vncserver@\\:1.service 第六步：查看端口是否监听： netstat -lnpt|grep Xvnc 这里我们可以看到5901端口已经被监听 第七步：开放防火墙的5901端口： firewall-cmd --zone=public --add-port=5901/tcp --permanent 如果防火墙没有启动需要先启动防火墙。 当然也可以狠一点，直接停止防火墙： systemctl stop firewalld.service 停止之后该需要禁止开机启动： systemctl disable firewalld.service 第八步：关闭SELinux，编辑/etc/selinux/config 文件： vim /etc/selinux/config 将selinux设置为disabled 到这里vnc服务已经安装完毕，下面就可使用vnc客户端来连接。 第九步：在vnc客户端（vnc viewer）输入服务器IP:桌面号（如192.168.31.100:1），输入后回车： 第十步：输入IP后会弹出确认，点击contiue即可： 第十一步：输入vnc密码： 第十二步：登录成功，输入远程机器密码（登录成功后需要输入远程机器的用户的密码，如果没有密码就可以直接进入系统）： 第十三步：成功进入远程桌面： 至此整个CentOS7.x 的VNC服务安装完毕^_^。 小贴士：vnc服务只能在局域网使用，如果在外网，则需要有公网IP地址，VNC不仅具备内网穿透功能。 ubuntu 安装 vnc viewervnc view的网站https://www.realvnc.com/en/connect/download/viewer/ sudo dpkg -i VNC-Viewer-6.17.1113-Linux-x64.deb 参考 https://my.oschina.net/huhaoren/blog/497394","tags":[{"name":"web","slug":"web","permalink":"http://wumuwumu.github.io/tags/web/"}]},{"title":"VirtualBox磁盘扩容","date":"2018-12-05T13:36:46.000Z","path":"posts/undefined.html","text":"扩展磁盘文件VDIVBoxManage modifyhd centos.vdi --resize 16000 # 单位M VMDKVBoxManage clonehd &quot;centos.vmdk&quot; &quot;centos.vdi&quot; --format vdi # vmdk是转换前的文件，vdi是转换之后的文件 VBoxManage modifyhd &quot;centos.vdi&quot; --resize 16000 # 这里的单位是M VBoxManage clonehd &quot;centos.vdi&quot; &quot;resized.vmdk&quot; --format vmdk #可以再转回来 使用克隆本人在使用的时候，前面两种方式不能实现，采用第三种方式 VBoxManage createhd -filename centos7-main-64g -size 65536 -format VDI -variant Standard # 创建一个新的磁盘，磁盘大小为想要的大小 VBoxManage clonemedium ..&#x2F;centos7-main\\ Clone&#x2F;centos7-main\\ Clone.vdi centos7-main-64g.vdi --existing # 将原有的磁盘复制到新磁盘上 磁盘扩容这里可以使用gparted进行磁盘的扩容 下载gparted-live镜像 设置iso镜像开机启动 进行分区的修改 LVM扩容如果你没有使用逻辑卷就可以跳过这节。如果使用逻辑卷也可以通过添加新磁盘的形式对文件系统进行扩容，这种方式更加简单方便。 创建PE、VG扩展LVsudo vgextend VolGroup &#x2F;dev&#x2F;sda4 # 通过新卷的方式扩展到卷组 lvresize -l +122 &#x2F;dev&#x2F;centos&#x2F;root # 直接扩容 刷新逻辑分区容量xfs_growfs &#x2F;devices&#x2F;centos&#x2F;root # resize2fs是不能成功的","tags":[{"name":"web","slug":"web","permalink":"http://wumuwumu.github.io/tags/web/"}]},{"title":"lorawan协议（中文版）","date":"2018-12-05T13:34:09.000Z","path":"posts/undefined.html","text":"介绍网关和服务器之间的协议是有目的的非常基本的，仅用于演示目的，或用于私有和可靠的网络。 这里没有网关或服务器的认证，并且确认仅用于网络质量评估，而不是 纠正UDP数据报丢失（无重试）。 系统原理和相关定义 ((( Y ))) | | + - -|- - - - - - - - - - - - - + xxxxxxxxxxxx +--------+ | +--+-----------+ +------+ | xx x x xxx | | | | | | | | xx Internet xx | | | | Concentrator |&lt;---&gt;| Host |&lt;-------xx or xx--------&gt;| | | | | SPI | | | xx Intranet xx | Server | | +--------------+ +------+ | xxxx x xxxx | | | ^ ^ | xxxxxxxx | | | | PPS +-------+ NMEA | | | | | +-----| GPS |-------+ | +--------+ | | (opt) | | | +-------+ | | | | Gateway | +- - - - - - - - - - - - - - - -+ 网关：无线电RX / TX板，基于Semtech多通道调制解调器（SX130x），收发器（SX135x）和/或低功耗独立调制解调器（SX127x）。 主机：运行包转发器的嵌入式计算机。通过SPI链路驱动集中器。 GPS：具有“每秒1脉冲”的GNSS（GPS，伽利略，GLONASS等）接收器 输出和到主机的串行链接，以发送包含时间和地理坐标数据的NMEA帧。可选的。 网关：由至少一个无线电集中器，主机，一些组成的设备网络连接到互联网或专用网络（以太网，3G，Wifi，微波链路），以及可选的GPS接收器进行同步。 服务器：一种抽象计算机，它将处理由网关接收和转发的RF数据包，并发出RF数据包以响应网关必须发出的数据包。 假设网关可以在NAT后面或防火墙停止任何传入连接。 假设服务器具有静态IP地址（或通过DNS服务可解决的地址），并且能够接收特定端口上的传入连接。 上行协议3.1 时序图 +---------+ +---------+ | Gateway | | Server | +---------+ +---------+ | -----------------------------------\\ | |-| When 1-N RF packets are received | | | ------------------------------------ | | | | PUSH_DATA (token X, GW MAC, JSON payload) | |-------------------------------------------------------------&gt;| | | | PUSH_ACK (token X) | |&lt;-------------------------------------------------------------| | ------------------------------\\ | | | process packets *after* ack |-| | ------------------------------- | | | PUSH_DATA 包网关使用该数据包类型主要是将所接收的RF分组和相关联的元数据转发到服务器。 字节 功能 0 协议版本2 1-2 随机凭证 3 PUSH_DATA标识0x00 4-11 网关唯一标识（MAC地址） 12-结束 JSON对象，看第4章 PUSH_ACK包服务器使用该数据包类型立即确认收到的所有PUSH_DATA数据包。 字节 功能 0 协议版本2 1-2 与PUSH_DATA包中相同的凭证，用于确认 3 PUSH_ACK标识0x01 上行JSON数据结构根对象包含名为&quot;rxpk&quot;的数组： &#123; &quot;rxpk&quot;:[ &#123;...&#125;, ...] &#125; 该数组包含至少一个JSON对象，每个对象包含一个RF数据包以及包含以下字段的关联元数据： 名称 类别 功能 time string UTC time of pkt RX, us precision, ISO 8601 ‘compact’ format tmst number Internal timestamp of “RX finished” event (32b unsigned) freq number RX central frequency in MHz (unsigned float, Hz precision) chan number Concentrator “IF” channel used for RX (unsigned integer) rfch number Concentrator “RF chain” used for RX (unsigned integer) stat number CRC status: 1 = OK, -1 = fail, 0 = no CRC modu string Modulation identifier “LORA” or “FSK” datr string LoRa datarate identifier (eg. SF12BW500) datr number FSK datarate (unsigned, in bits per second) codr string LoRa ECC coding rate identifier rssi number RSSI in dBm (signed integer, 1 dB precision) lsnr number Lora SNR ratio in dB (signed float, 0.1 dB precision) size number RF packet payload size in bytes (unsigned integer) data string Base64 encoded RF packet payload, padded 示例（为了便于阅读而添加了空格，缩进和换行符）： &#123;&quot;rxpk&quot;:[ &#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.528002Z&quot;, &quot;tmst&quot;:3512348611, &quot;chan&quot;:2, &quot;rfch&quot;:0, &quot;freq&quot;:866.349812, &quot;stat&quot;:1, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF7BW125&quot;, &quot;codr&quot;:&quot;4&#x2F;6&quot;, &quot;rssi&quot;:-35, &quot;lsnr&quot;:5.1, &quot;size&quot;:32, &quot;data&quot;:&quot;-DS4CGaDCdG+48eJNM3Vai-zDpsR71Pn9CPA9uCON84&quot; &#125;,&#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.530974Z&quot;, &quot;tmst&quot;:3512348514, &quot;chan&quot;:9, &quot;rfch&quot;:1, &quot;freq&quot;:869.1, &quot;stat&quot;:1, &quot;modu&quot;:&quot;FSK&quot;, &quot;datr&quot;:50000, &quot;rssi&quot;:-75, &quot;size&quot;:16, &quot;data&quot;:&quot;VEVTVF9QQUNLRVRfMTIzNA&#x3D;&#x3D;&quot; &#125;,&#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.532038Z&quot;, &quot;tmst&quot;:3316387610, &quot;chan&quot;:0, &quot;rfch&quot;:0, &quot;freq&quot;:863.00981, &quot;stat&quot;:1, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF10BW125&quot;, &quot;codr&quot;:&quot;4&#x2F;7&quot;, &quot;rssi&quot;:-38, &quot;lsnr&quot;:5.5, &quot;size&quot;:32, &quot;data&quot;:&quot;ysgRl452xNLep9S1NTIg2lomKDxUgn3DJ7DE+b00Ass&quot; &#125; ]&#125; 根对象还可以包含名为&quot;stat&quot;的对象： &#123; &quot;rxpk&quot;:[ &#123;...&#125;, ...], &quot;stat&quot;:&#123;...&#125; &#125; 数据包可能不包含&quot;rxpk&quot;数组而是“stat”对象。 &#123; &quot;stat&quot;:&#123;...&#125; &#125; 该对象包含网关的状态，包含以下字段： 名称 类型 功能 time string UTC ‘system’ time of the gateway, ISO 8601 ‘expanded’ format lati number GPS latitude of the gateway in degree (float, N is +) long number GPS latitude of the gateway in degree (float, E is +) alti number GPS altitude of the gateway in meter RX (integer) rxnb number Number of radio packets received (unsigned integer) rxok number Number of radio packets received with a valid PHY CRC rxfw number Number of radio packets forwarded (unsigned integer) ackr number Percentage of upstream datagrams that were acknowledged dwnb number Number of downlink datagrams received (unsigned integer) txnb number Number of packets emitted (unsigned integer) 示例（为了便于阅读而添加了空格，缩进和换行符）： &#123;&quot;stat&quot;:&#123; &quot;time&quot;:&quot;2014-01-12 08:59:28 GMT&quot;, &quot;lati&quot;:46.24000, &quot;long&quot;:3.25230, &quot;alti&quot;:145, &quot;rxnb&quot;:2, &quot;rxok&quot;:2, &quot;rxfw&quot;:2, &quot;ackr&quot;:100.0, &quot;dwnb&quot;:2, &quot;txnb&quot;:2 &#125;&#125; 下行协议时序图+---------+ +---------+ | Gateway | | Server | +---------+ +---------+ | -----------------------------------\\ | |-| Every N seconds (keepalive time) | | | ------------------------------------ | | | | PULL_DATA (token Y, MAC@) | |-------------------------------------------------------------&gt;| | | | PULL_ACK (token Y) | |&lt;-------------------------------------------------------------| | | +---------+ +---------+ | Gateway | | Server | +---------+ +---------+ | ------------------------------------------------------\\ | | | Anytime after first PULL_DATA for each packet to TX |-| | ------------------------------------------------------- | | | | PULL_RESP (token Z, JSON payload) | |&lt;-------------------------------------------------------------| | | | TX_ACK (token Z, JSON payload) | |-------------------------------------------------------------&gt;| PULL_DATA包网关使用该数据包类型来轮询来自服务器的数据。 此数据交换由网关初始化，因为如果网关位于NAT后面，服务器可能无法将数据包发送到网关。 当网关初始化交换机时，将打开通向服务器的网络路由，并允许数据包在两个方向上流动。 网关必须定期发送PULL_DATA数据包，以确保网络路由保持打开状态，以便服务器随时使用。 Bytes Function 0 protocol version = 2 1-2 random token 3 PULL_DATA identifier 0x02 4-11 Gateway unique identifier (MAC address) PULL_ACK 包服务器使用该数据包类型来确认网络路由是否已打开，以及服务器是否可以随时发送PULL_RESP数据包。 Bytes Function 0 protocol version = 2 1-2 same token as the PULL_DATA packet to acknowledge 3 PULL_ACK identifier 0x04 PULL_RESP 包服务器使用该数据包类型来发送必须由网关发出的RF数据包和相关元数据。 Bytes Function 0 protocol version = 2 1-2 random token 3 PULL_RESP identifier 0x03 4-end JSON object, starting with {, ending with }, see section 6 TX_ACK 包网关使用该分组类型向服务器发送反馈，以通知网关是否已接受或拒绝下行链路请求。 数据报可以选项包含一个JSON字符串，以提供有关acknoledge的更多详细信息。 如果没有JSON（空字符串），这意味着没有发生错误。 Bytes Function 0 protocol version = 2 1-2 same token as the PULL_RESP packet to acknowledge 3 TX_ACK identifier 0x05 4-11 Gateway unique identifier (MAC address) 12-end [optional] JSON object, starting with {, ending with }, see section 6 下行JSON数据结构 PULL_RESP数据包的根对象必须包含名为“txpk”的对象： &#123; &quot;txpk&quot;: &#123;...&#125; &#125; 该对象包含要发出的RF数据包以及与以下字段相关联的元数据： Name Type Function imme bool Send packet immediately (will ignore tmst &amp; time) tmst number Send packet on a certain timestamp value (will ignore time) time string Send packet at a certain time (GPS synchronization required) freq number TX central frequency in MHz (unsigned float, Hz precision) rfch number Concentrator “RF chain” used for TX (unsigned integer) powe number TX output power in dBm (unsigned integer, dBm precision) modu string Modulation identifier “LORA” or “FSK” datr string LoRa datarate identifier (eg. SF12BW500) datr number FSK datarate (unsigned, in bits per second) codr string LoRa ECC coding rate identifier fdev number FSK frequency deviation (unsigned integer, in Hz) ipol bool Lora modulation polarization inversion prea number RF preamble size (unsigned integer) size number RF packet payload size in bytes (unsigned integer) data string Base64 encoded RF packet payload, padding optional ncrc bool If true, disable the CRC of the physical layer (optional) 大多数字段都是可选的。如果省略字段，将使用默认参数。 示例（为便于阅读而添加了空格，缩进和换行符）： &#123;&quot;txpk&quot;:&#123; &quot;imme&quot;:true, &quot;freq&quot;:864.123456, &quot;rfch&quot;:0, &quot;powe&quot;:14, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF11BW125&quot;, &quot;codr&quot;:&quot;4&#x2F;6&quot;, &quot;ipol&quot;:false, &quot;size&quot;:32, &quot;data&quot;:&quot;H3P3N2i9qc4yt7rK7ldqoeCVJGBybzPY5h1Dd7P7p8v&quot; &#125;&#125; &#123;&quot;txpk&quot;:&#123; &quot;imme&quot;:true, &quot;freq&quot;:861.3, &quot;rfch&quot;:0, &quot;powe&quot;:12, &quot;modu&quot;:&quot;FSK&quot;, &quot;datr&quot;:50000, &quot;fdev&quot;:3000, &quot;size&quot;:32, &quot;data&quot;:&quot;H3P3N2i9qc4yt7rK7ldqoeCVJGBybzPY5h1Dd7P7p8v&quot; &#125;&#125; TX_ACK数据包的根对象必须包含名为“txpk_ack”的对象： &#123; &quot;txpk_ack&quot;: &#123;...&#125; &#125; 该对象包含有关相关PULL_RESP数据包的状态信息。 Name Type Function error string Indication about success or type of failure that occured for downlink request. 可能的错误有： Value Definition NONE Packet has been programmed for downlink TOO_LATE Rejected because it was already too late to program this packet for downlink TOO_EARLY Rejected because downlink packet timestamp is too much in advance COLLISION_PACKET Rejected because there was already a packet programmed in requested timeframe COLLISION_BEACON Rejected because there was already a beacon planned in requested timeframe TX_FREQ Rejected because requested frequency is not supported by TX RF chain TX_POWER Rejected because requested power is not supported by gateway GPS_UNLOCKED Rejected because GPS is unlocked, so GPS timestamp cannot be used 示例（为便于阅读而添加了空格，缩进和换行符）： &#123;&quot;txpk_ack&quot;:&#123; &quot;error&quot;:&quot;COLLISION_PACKET&quot; &#125;&#125;","tags":[{"name":"lorawan","slug":"lorawan","permalink":"http://wumuwumu.github.io/tags/lorawan/"}]},{"title":"lorawan协议","date":"2018-12-05T13:32:24.000Z","path":"posts/undefined.html","text":"Introduction The protocol between the gateway and the server is purposefully very basic and for demonstration purpose only, or for use on private and reliable networks. There is no authentication of the gateway or the server, and the acknowledges are only used for network quality assessment, not to correct UDP datagrams losses (no retries). System schematic and definitions ((( Y ))) | | + - -|- - - - - - - - - - - - - + xxxxxxxxxxxx +--------+ | +--+-----------+ +------+ | xx x x xxx | | | | | | | | xx Internet xx | | | | Concentrator |&lt;---&gt;| Host |&lt;-------xx or xx--------&gt;| | | | | SPI | | | xx Intranet xx | Server | | +--------------+ +------+ | xxxx x xxxx | | | ^ ^ | xxxxxxxx | | | | PPS +-------+ NMEA | | | | | +-----| GPS |-------+ | +--------+ | | (opt) | | | +-------+ | | | | Gateway | +- - - - - - - - - - - - - - - -+ Concentrator: radio RX/TX board, based on Semtech multichannel modems (SX130x), transceivers (SX135x) and/or low-power stand-alone modems (SX127x). Host: embedded computer on which the packet forwarder is run. Drives the concentrator through a SPI link. GPS: GNSS (GPS, Galileo, GLONASS, etc) receiver with a “1 Pulse Per Second” output and a serial link to the host to send NMEA frames containing time and geographical coordinates data. Optional. Gateway: a device composed of at least one radio concentrator, a host, some network connection to the internet or a private network (Ethernet, 3G, Wifi, microwave link), and optionally a GPS receiver for synchronization. Server: an abstract computer that will process the RF packets received and forwarded by the gateway, and issue RF packets in response that the gateway will have to emit. It is assumed that the gateway can be behind a NAT or a firewall stopping any incoming connection. It is assumed that the server has an static IP address (or an address solvable through a DNS service) and is able to receive incoming connections on a specific port. Upstream protocol Sequence diagram+---------+ +---------+ | Gateway | | Server | +---------+ +---------+ | -----------------------------------\\ | |-| When 1-N RF packets are received | | | ------------------------------------ | | | | PUSH_DATA (token X, GW MAC, JSON payload) | |-------------------------------------------------------------&gt;| | | | PUSH_ACK (token X) | |&lt;-------------------------------------------------------------| | ------------------------------\\ | | | process packets *after* ack |-| | ------------------------------- | | | PUSH_DATA packetThat packet type is used by the gateway mainly to forward the RF packets received, and associated metadata, to the server. Bytes Function 0 protocol version = 2 1-2 random token 3 PUSH_DATA identifier 0x00 4-11 Gateway unique identifier (MAC address) 12-end JSON object, starting with {, ending with }, see section 4 PUSH_ACK packetThat packet type is used by the server to acknowledge immediately all the PUSH_DATA packets received. Bytes Function 0 protocol version = 2 1-2 same token as the PUSH_DATA packet to acknowledge 3 PUSH_ACK identifier 0x01 Upstream JSON data structure The root object can contain an array named “rxpk”: &#123; &quot;rxpk&quot;:[ &#123;...&#125;, ...] &#125; That array contains at least one JSON object, each object contain a RF packet and associated metadata with the following fields: Name Type Function time string UTC time of pkt RX, us precision, ISO 8601 ‘compact’ format tmst number Internal timestamp of “RX finished” event (32b unsigned) freq number RX central frequency in MHz (unsigned float, Hz precision) chan number Concentrator “IF” channel used for RX (unsigned integer) rfch number Concentrator “RF chain” used for RX (unsigned integer) stat number CRC status: 1 = OK, -1 = fail, 0 = no CRC modu string Modulation identifier “LORA” or “FSK” datr string LoRa datarate identifier (eg. SF12BW500) datr number FSK datarate (unsigned, in bits per second) codr string LoRa ECC coding rate identifier rssi number RSSI in dBm (signed integer, 1 dB precision) lsnr number Lora SNR ratio in dB (signed float, 0.1 dB precision) size number RF packet payload size in bytes (unsigned integer) data string Base64 encoded RF packet payload, padded Example (white-spaces, indentation and newlines added for readability): &#123;&quot;rxpk&quot;:[ &#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.528002Z&quot;, &quot;tmst&quot;:3512348611, &quot;chan&quot;:2, &quot;rfch&quot;:0, &quot;freq&quot;:866.349812, &quot;stat&quot;:1, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF7BW125&quot;, &quot;codr&quot;:&quot;4&#x2F;6&quot;, &quot;rssi&quot;:-35, &quot;lsnr&quot;:5.1, &quot;size&quot;:32, &quot;data&quot;:&quot;-DS4CGaDCdG+48eJNM3Vai-zDpsR71Pn9CPA9uCON84&quot; &#125;,&#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.530974Z&quot;, &quot;tmst&quot;:3512348514, &quot;chan&quot;:9, &quot;rfch&quot;:1, &quot;freq&quot;:869.1, &quot;stat&quot;:1, &quot;modu&quot;:&quot;FSK&quot;, &quot;datr&quot;:50000, &quot;rssi&quot;:-75, &quot;size&quot;:16, &quot;data&quot;:&quot;VEVTVF9QQUNLRVRfMTIzNA&#x3D;&#x3D;&quot; &#125;,&#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.532038Z&quot;, &quot;tmst&quot;:3316387610, &quot;chan&quot;:0, &quot;rfch&quot;:0, &quot;freq&quot;:863.00981, &quot;stat&quot;:1, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF10BW125&quot;, &quot;codr&quot;:&quot;4&#x2F;7&quot;, &quot;rssi&quot;:-38, &quot;lsnr&quot;:5.5, &quot;size&quot;:32, &quot;data&quot;:&quot;ysgRl452xNLep9S1NTIg2lomKDxUgn3DJ7DE+b00Ass&quot; &#125; ]&#125; The root object can also contain an object named “stat” : &#123; &quot;rxpk&quot;:[ &#123;...&#125;, ...], &quot;stat&quot;:&#123;...&#125; &#125; It is possible for a packet to contain no “rxpk” array but a “stat” object. &#123; &quot;stat&quot;:&#123;...&#125; &#125; That object contains the status of the gateway, with the following fields: Name Type Function time string UTC ‘system’ time of the gateway, ISO 8601 ‘expanded’ format lati number GPS latitude of the gateway in degree (float, N is +) long number GPS latitude of the gateway in degree (float, E is +) alti number GPS altitude of the gateway in meter RX (integer) rxnb number Number of radio packets received (unsigned integer) rxok number Number of radio packets received with a valid PHY CRC rxfw number Number of radio packets forwarded (unsigned integer) ackr number Percentage of upstream datagrams that were acknowledged dwnb number Number of downlink datagrams received (unsigned integer) txnb number Number of packets emitted (unsigned integer) Example (white-spaces, indentation and newlines added for readability): &#123;&quot;stat&quot;:&#123; &quot;time&quot;:&quot;2014-01-12 08:59:28 GMT&quot;, &quot;lati&quot;:46.24000, &quot;long&quot;:3.25230, &quot;alti&quot;:145, &quot;rxnb&quot;:2, &quot;rxok&quot;:2, &quot;rxfw&quot;:2, &quot;ackr&quot;:100.0, &quot;dwnb&quot;:2, &quot;txnb&quot;:2 &#125;&#125; Downstream protocol Sequence diagram+---------+ +---------+ | Gateway | | Server | +---------+ +---------+ | -----------------------------------\\ | |-| Every N seconds (keepalive time) | | | ------------------------------------ | | | | PULL_DATA (token Y, MAC@) | |-------------------------------------------------------------&gt;| | | | PULL_ACK (token Y) | |&lt;-------------------------------------------------------------| | | +---------+ +---------+ | Gateway | | Server | +---------+ +---------+ | ------------------------------------------------------\\ | | | Anytime after first PULL_DATA for each packet to TX |-| | ------------------------------------------------------- | | | | PULL_RESP (token Z, JSON payload) | |&lt;-------------------------------------------------------------| | | | TX_ACK (token Z, JSON payload) | |-------------------------------------------------------------&gt;| PULL_DATA packetThat packet type is used by the gateway to poll data from the server. This data exchange is initialized by the gateway because it might be impossible for the server to send packets to the gateway if the gateway is behind a NAT. When the gateway initialize the exchange, the network route towards the server will open and will allow for packets to flow both directions. The gateway must periodically send PULL_DATA packets to be sure the network route stays open for the server to be used at any time. Bytes Function 0 protocol version = 2 1-2 random token 3 PULL_DATA identifier 0x02 4-11 Gateway unique identifier (MAC address) PULL_ACK packetThat packet type is used by the server to confirm that the network route is open and that the server can send PULL_RESP packets at any time. Bytes Function 0 protocol version = 2 1-2 same token as the PULL_DATA packet to acknowledge 3 PULL_ACK identifier 0x04 PULL_RESP packetThat packet type is used by the server to send RF packets and associated metadata that will have to be emitted by the gateway. Bytes Function 0 protocol version = 2 1-2 random token 3 PULL_RESP identifier 0x03 4-end JSON object, starting with {, ending with }, see section 6 TX_ACK packetThat packet type is used by the gateway to send a feedback to the server to inform if a downlink request has been accepted or rejected by the gateway. The datagram may optionnaly contain a JSON string to give more details on acknoledge. If no JSON is present (empty string), this means than no error occured. Bytes Function 0 protocol version = 2 1-2 same token as the PULL_RESP packet to acknowledge 3 TX_ACK identifier 0x05 4-11 Gateway unique identifier (MAC address) 12-end [optional] JSON object, starting with {, ending with }, see section 6 Downstream JSON data structure The root object of PULL_RESP packet must contain an object named “txpk”: &#123; &quot;txpk&quot;: &#123;...&#125; &#125; That object contain a RF packet to be emitted and associated metadata with the following fields: Name Type Function imme bool Send packet immediately (will ignore tmst &amp; time) tmst number Send packet on a certain timestamp value (will ignore time) time string Send packet at a certain time (GPS synchronization required) freq number TX central frequency in MHz (unsigned float, Hz precision) rfch number Concentrator “RF chain” used for TX (unsigned integer) powe number TX output power in dBm (unsigned integer, dBm precision) modu string Modulation identifier “LORA” or “FSK” datr string LoRa datarate identifier (eg. SF12BW500) datr number FSK datarate (unsigned, in bits per second) codr string LoRa ECC coding rate identifier fdev number FSK frequency deviation (unsigned integer, in Hz) ipol bool Lora modulation polarization inversion prea number RF preamble size (unsigned integer) size number RF packet payload size in bytes (unsigned integer) data string Base64 encoded RF packet payload, padding optional ncrc bool If true, disable the CRC of the physical layer (optional) Most fields are optional. If a field is omitted, default parameters will be used. Examples (white-spaces, indentation and newlines added for readability): &#123;&quot;txpk&quot;:&#123; &quot;imme&quot;:true, &quot;freq&quot;:864.123456, &quot;rfch&quot;:0, &quot;powe&quot;:14, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF11BW125&quot;, &quot;codr&quot;:&quot;4&#x2F;6&quot;, &quot;ipol&quot;:false, &quot;size&quot;:32, &quot;data&quot;:&quot;H3P3N2i9qc4yt7rK7ldqoeCVJGBybzPY5h1Dd7P7p8v&quot; &#125;&#125; &#123;&quot;txpk&quot;:&#123; &quot;imme&quot;:true, &quot;freq&quot;:861.3, &quot;rfch&quot;:0, &quot;powe&quot;:12, &quot;modu&quot;:&quot;FSK&quot;, &quot;datr&quot;:50000, &quot;fdev&quot;:3000, &quot;size&quot;:32, &quot;data&quot;:&quot;H3P3N2i9qc4yt7rK7ldqoeCVJGBybzPY5h1Dd7P7p8v&quot; &#125;&#125; The root object of TX_ACK packet must contain an object named “txpk_ack”: &#123; &quot;txpk_ack&quot;: &#123;...&#125; &#125; That object contain status information concerning the associated PULL_RESP packet. Name Type Function error string Indication about success or type of failure that occured for downlink request. The possible values of “error” field are: Value Definition NONE Packet has been programmed for downlink TOO_LATE Rejected because it was already too late to program this packet for downlink TOO_EARLY Rejected because downlink packet timestamp is too much in advance COLLISION_PACKET Rejected because there was already a packet programmed in requested timeframe COLLISION_BEACON Rejected because there was already a beacon planned in requested timeframe TX_FREQ Rejected because requested frequency is not supported by TX RF chain TX_POWER Rejected because requested power is not supported by gateway GPS_UNLOCKED Rejected because GPS is unlocked, so GPS timestamp cannot be used Examples (white-spaces, indentation and newlines added for readability): &#123;&quot;txpk_ack&quot;:&#123; &quot;error&quot;:&quot;COLLISION_PACKET&quot; &#125;&#125; Revisions v1.3 Added downlink feedback from gateway to server (PULL_RESP -&gt; TX_ACK) v1.2 Added value of FSK bitrate for upstream. Added parameters for FSK bitrate and frequency deviation for downstream. v1.1 Added syntax for status report JSON object on upstream. v1.0 Initial version.","tags":[{"name":"lorawan","slug":"lorawan","permalink":"http://wumuwumu.github.io/tags/lorawan/"}]},{"title":"let-us-encrypt证书","date":"2018-12-05T12:59:59.000Z","path":"posts/undefined.html","text":"基本知识为了实现通配符证书，Let’s Encrypt 对 ACME 协议的实现进行了升级，只有 v2 协议才能支持通配符证书。 客户在申请 Let’s Encrypt 证书的时候，需要校验域名的所有权，证明操作者有权利为该域名申请证书，目前支持三种验证方式： dns-01：给域名添加一个 DNS TXT 记录。 http-01：在域名对应的 Web 服务器下放置一个 HTTP well-known URL 资源文件。 tls-sni-01：在域名对应的 Web 服务器下放置一个 HTTPS well-known URL 资源文件。 而申请通配符证书，只能使用 dns-01 的方式 ACME v2 和 v1 协议是互相不兼容的，为了使用 v2 版本，客户端需要创建另外一个账户（代表客户端操作者），以 Certbot 客户端为例，大家可以查看： Enumerable Orders 和限制 安装wget https://dl.eff.org/certbot-auto chmod a+x ./certbot-auto 申请./certbot-auto certonly -d *.newyingyong.cn --manual --preferred-challenges dns --server https://acme-v02.api.letsencrypt.org/directory certonly，表示安装模式，Certbot 有安装模式和验证模式两种类型的插件。 –manual 表示手动安装插件，Certbot 有很多插件，不同的插件都可以申请证书，用户可以根据需要自行选择 -d 为那些主机申请证书，如果是通配符，输入 *.newyingyong.cn（可以替换为你自己的域名） -preferred-challenges dns，使用 DNS 方式校验域名所有权 –server，Let’s Encrypt ACME v2 版本使用的服务器不同于 v1 版本，需要显示指定。 添加记录根据命令行提示，填写相关的内容，注意在添加记录的时候，要等到记录生效才确定。 ------------------------------------------------------------------------------- Please deploy a DNS TXT record under the name _acme-challenge.newyingyong.cn with the following value: 2_8KBE_jXH8nYZ2unEViIbW52LhIqxkg6i9mcwsRvhQ Before continuing, verify the record is deployed. ------------------------------------------------------------------------------- Press Enter to Continue Waiting for verification... Cleaning up challenges ## 检测记录生效 $ dig -t txt _acme-challenge.newyingyong.cn @8.8.8.8 更新查看当前服务器所配置的证书 certbot-auto certificates 使用申请的普通证书，使用certbot-auto renew 使用通配符证书。 添加DNS记录 git clone https://github.com/ywdblog/certbot-letencrypt-wildcardcertificates-alydns-au.git ./certbot-auto renew --cert-name simplehttps.com --manual-auth-hook /脚本目录/au.sh 自动更新 1 1 *&#x2F;1 * * root certbot-auto renew --manual --preferred-challenges dns --manual-auth-hook &#x2F;脚本目录&#x2F;sslupdate.sh 参考 https://www.jianshu.com/p/c5c9d071e395 https://www.jianshu.com/p/074e147b68b0 certbot工具https://segmentfault.com/a/1190000015354547","tags":[{"name":"web","slug":"web","permalink":"http://wumuwumu.github.io/tags/web/"}]},{"title":"css动画","date":"2018-12-04T13:36:49.000Z","path":"posts/undefined.html","text":"transition transition-duration transition-property transition-delay transition-timing-function animation @keyframes animation animation-name animation-duration animation-timing-function animation-delay animation-iteration-count animation-fill-mode animation-direction animation-play-state(这个要写在最下面，不然不会生效) transform none translate(x,y)/translate3d(x,y,z) translateX(x)/translateY(y)/translateZ(z) materix/materix3d scale/scale3d scaleX/scaleY/scaleZ rotate/rotate3d rotateX/rotateY/rotateZ skew/skewX/skewY perspective","tags":[{"name":"css","slug":"css","permalink":"http://wumuwumu.github.io/tags/css/"}]},{"title":"清除inline-block之间的间隙","date":"2018-12-03T11:54:08.000Z","path":"posts/undefined.html","text":"原因两个inline-block之间存在间隙，这是因为html元素换行导致的（换行和元素之间的空格、tabs、多个空格，结果一样，最后都是一个空格） 移除空格如果我们使用html minimize工具，会清除html之间的空格。如果没有使用就需要我们手动去除。该方法简单但是不推荐使用，阅读不方便。 &lt;!-- 方法一 --> &lt;div> one&lt;/div>&lt;div> two&lt;/div>&lt;div> three&lt;/div> &lt;!-- 方法二 --> &lt;div>one&lt;/div >&lt;div>two&lt;/div >&lt;div>three&lt;/div> &lt;!-- 方法三 --> &lt;div>one&lt;/div>&lt;!-- -->&lt;div>two&lt;/div>&lt;!-- -->&lt;div>three&lt;/div> 负值margin不推荐使用，每个浏览器之间的间隙不同。 nav a &#123; display: inline-block; margin-right: -4px; &#125; 父元素font-size设置为0.space &#123; font-size: 0; &#125; .space a &#123; font-size: 12px; &#125; 这种方法是推荐使用的，但是在ie和Chrome浏览器(新的浏览器没有问题)上可能出现问题，因为在chrome上有最小字体限制。改进方法如下。 .space &#123; font-size: 0; -webkit-text-size-adjust:none; &#125; 使用letter-spacingletter-spacing用于修改字符间的间隙。 .space &#123; letter-spacing: -3px; &#125; .space a &#123; letter-spacing: 0; &#125; 使用word-spacingword-spacing修改单词之间的间隙 .space &#123; word-spacing: -6px; &#125; .space a &#123; word-spacing: 0; &#125; 使用浮动a&#123; float:left; &#125; 参考 https://www.zhangxinxu.com/wordpress/2012/04/inline-block-space-remove-%E5%8E%BB%E9%99%A4%E9%97%B4%E8%B7%9D/ 代码 https://codepen.io/wumuwumu/pen/WYmKYX","tags":[{"name":"js","slug":"js","permalink":"http://wumuwumu.github.io/tags/js/"}]}]